{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "vkZxat4Y-IsQ",
    "outputId": "da86392c-66e8-4b60-b471-086e745cdcbc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from torch import nn, optim\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O0TfzOhU-QlG"
   },
   "outputs": [],
   "source": [
    "class Argments():\n",
    "  def __init__(self):\n",
    "    self.batch_size = 40\n",
    "    self.test_batch = 1000\n",
    "    self.global_epochs = 200\n",
    "    self.local_epochs = 2\n",
    "    self.lr = None\n",
    "    self.momentum = 0.9\n",
    "    self.weight_decay = 10**-4.0\n",
    "    self.clip = 20.0\n",
    "    self.partience = 10\n",
    "    self.worker_num = 20\n",
    "    self.sample_num = 20\n",
    "    self.unlabeleddata_size = 1000\n",
    "    self.device = torch.device('cuda:0'if torch.cuda.is_available() else'cpu')\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    self.alpha_label = 0.5\n",
    "    self.alpha_size = 10\n",
    "\n",
    "args = Argments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned value\n",
    "lr = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(10**-3.0)\n",
    "lr_list.append(10**-2.5)\n",
    "lr_list.append(10**-2.0)\n",
    "lr_list.append(10**-1.5)\n",
    "lr_list.append(10**-1.0)\n",
    "lr_list.append(10**-0.5)\n",
    "lr_list.append(10**0.0)\n",
    "lr_list.append(10**0.5)\n",
    "\n",
    "args.lr = lr_list[lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r5PuCcqmJNUQ"
   },
   "outputs": [],
   "source": [
    "class LocalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.label = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_data = self.data[idx]\n",
    "        out_label = self.label[idx]\n",
    "        if self.transform:\n",
    "            out_data = self.transform(out_data)\n",
    "        return out_data, out_label\n",
    "    \n",
    "class DatasetFromSubset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.subset[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "    \n",
    "class GlobalDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,federated_dataset,transform=None):\n",
    "    self.transform = transform\n",
    "    self.data = []\n",
    "    self.label = []\n",
    "    for dataset in federated_dataset:\n",
    "      for (data,label) in dataset:\n",
    "        self.data.append(data)\n",
    "        self.label.append(label)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    out_data = self.data[idx]\n",
    "    out_label = self.label[idx]\n",
    "    if self.transform:\n",
    "        out_data = self.transform(out_data)\n",
    "    return out_data, out_label\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "class UnlabeledDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,transform=None):\n",
    "    self.transform = transform\n",
    "    self.data = []\n",
    "    self.target = None\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    out_data = self.data[idx]\n",
    "    out_label = 'unlabeled'\n",
    "    if self.transform:\n",
    "        out_data = self.transform(out_data)\n",
    "    return out_data, out_label\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(Centralized=False,unlabeled_data=False):\n",
    "    \n",
    "    transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomCrop(32, padding=2),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.491372549, 0.482352941, 0.446666667), (0.247058824, 0.243529412, 0.261568627))])\n",
    "    transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.491372549, 0.482352941, 0.446666667), (0.247058824, 0.243529412, 0.261568627))])\n",
    "\n",
    "    # download train data\n",
    "    all_trainset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True)\n",
    "    #trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "    # download test data\n",
    "    all_testset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True)\n",
    "    #testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "    \n",
    "    ## get unlabeled dataset\n",
    "    if unlabeled_data:\n",
    "        unlabeled_dataset = UnlabeledDataset(transform_test)\n",
    "        idx = sorted(random.sample(range(len(all_trainset)),args.unlabeleddata_size))\n",
    "        unlabeled_dataset.data = np.array([all_trainset.data[i]  for i in idx])\n",
    "        all_trainset.data = np.delete(all_trainset.data,idx,0)\n",
    "        all_trainset.targets = np.delete(all_trainset.targets,idx,0)\n",
    "    all_train_data = np.array(all_trainset.data)\n",
    "    all_train_label = np.array(all_trainset.targets)\n",
    "    all_test_data = np.array(all_testset.data)\n",
    "    all_test_label = np.array(all_testset.targets)\n",
    "    print('Train:{} Test:{}'.format(len(all_train_data),len(all_test_data)))\n",
    "\n",
    "\n",
    "    ## Data size heterogeneity\n",
    "    data_proportions = np.random.dirichlet(np.repeat(args.alpha_size, args.worker_num))\n",
    "    train_data_proportions = np.array([0 for _ in range(args.worker_num)])\n",
    "    test_data_proportions = np.array([0 for _ in range(args.worker_num)])\n",
    "    for i in range(len(data_proportions)):\n",
    "        if i==(len(data_proportions)-1):\n",
    "            train_data_proportions = train_data_proportions.astype('int64')\n",
    "            test_data_proportions = test_data_proportions.astype('int64')\n",
    "            train_data_proportions[-1] = len(all_train_data) - np.sum(train_data_proportions[:-1])\n",
    "            test_data_proportions[-1] = len(all_test_data) - np.sum(test_data_proportions[:-1])\n",
    "        else:\n",
    "            train_data_proportions[i] = (data_proportions[i] * len(all_train_data))\n",
    "            test_data_proportions[i] = (data_proportions[i] * len(all_test_data))\n",
    "    min_size = 0\n",
    "    K = 10\n",
    "\n",
    "    '''\n",
    "    label_list = np.arange(10)\n",
    "    np.random.shuffle(label_list)\n",
    "    '''\n",
    "    label_list = list(range(K))\n",
    "\n",
    "\n",
    "    ## Data distribution heterogeneity\n",
    "    while min_size<10:\n",
    "        idx_train_batch = [[] for _ in range(args.worker_num)]\n",
    "        idx_test_batch = [[] for _ in range(args.worker_num)]\n",
    "        for k in label_list:\n",
    "            proportions_train = np.random.dirichlet(np.repeat(args.alpha_label, args.worker_num))\n",
    "            proportions_test = copy.deepcopy(proportions_train)\n",
    "            idx_k_train = np.where(all_train_label == k)[0]\n",
    "            idx_k_test = np.where(all_test_label == k)[0]\n",
    "            np.random.shuffle(idx_k_train)\n",
    "            np.random.shuffle(idx_k_test)\n",
    "            ## Balance (train)\n",
    "            proportions_train = np.array([p*(len(idx_j)<train_data_proportions[i]) for i,(p,idx_j) in enumerate(zip(proportions_train,idx_train_batch))])\n",
    "            proportions_train = proportions_train/proportions_train.sum()\n",
    "            proportions_train = (np.cumsum(proportions_train)*len(idx_k_train)).astype(int)[:-1]\n",
    "            idx_train_batch = [idx_j + idx.tolist() for idx_j,idx in zip(idx_train_batch,np.split(idx_k_train,proportions_train))]\n",
    "\n",
    "            ## Balance (test)\n",
    "            proportions_test = np.array([p*(len(idx_j)<test_data_proportions[i]) for i,(p,idx_j) in enumerate(zip(proportions_test,idx_test_batch))])\n",
    "            proportions_test = proportions_test/proportions_test.sum()\n",
    "            proportions_test = (np.cumsum(proportions_test)*len(idx_k_test)).astype(int)[:-1]\n",
    "            idx_test_batch = [idx_j + idx.tolist() for idx_j,idx in zip(idx_test_batch,np.split(idx_k_test,proportions_test))]\n",
    "\n",
    "            min_size = min([len(idx_j) for idx_j in idx_train_batch])\n",
    "\n",
    "    federated_trainset = []\n",
    "    federated_testset = []\n",
    "    for i in range(args.worker_num):\n",
    "        ## create trainset\n",
    "        data = [all_train_data[idx] for idx in idx_train_batch[i]]\n",
    "        label = [all_train_label[idx] for idx in idx_train_batch[i]]\n",
    "        federated_trainset.append(LocalDataset())\n",
    "        federated_trainset[-1].data = data\n",
    "        federated_trainset[-1].label = label\n",
    "\n",
    "        ## create testset\n",
    "        data = [all_test_data[idx] for idx in idx_test_batch[i]]\n",
    "        label = [all_test_label[idx] for idx in idx_test_batch[i]]\n",
    "        federated_testset.append(LocalDataset())\n",
    "        federated_testset[-1].data = data\n",
    "        federated_testset[-1].label = label\n",
    "\n",
    "        \n",
    "    ## split trainset\n",
    "    federated_valset = [None]*args.worker_num\n",
    "    for i in range(args.worker_num):\n",
    "        n_samples = len(federated_trainset[i])\n",
    "        if n_samples==1:\n",
    "            train_subset = federated_trainset[i]\n",
    "            val_subset = copy.deepcopy(federated_trainset[i])\n",
    "        else:\n",
    "            train_size = int(len(federated_trainset[i]) * 0.8) \n",
    "            val_size = n_samples - train_size \n",
    "            train_subset,val_subset = torch.utils.data.random_split(federated_trainset[i], [train_size, val_size])\n",
    "\n",
    "        federated_trainset[i] = DatasetFromSubset(train_subset)\n",
    "        federated_valset[i] = DatasetFromSubset(val_subset)\n",
    "\n",
    "    ## show data distribution\n",
    "    H = 4\n",
    "    W = 5\n",
    "    fig, axs = plt.subplots(H, W, figsize=(20, 5))\n",
    "    x = np.arange(1,11)\n",
    "    for i, (trainset,valset,testset) in enumerate(zip(federated_trainset,federated_valset,federated_testset)):\n",
    "        bottom = [0]*10\n",
    "        count = [0]*10\n",
    "        for _,label in trainset:\n",
    "            count[label] += 1\n",
    "        axs[int(i/W), i%W].bar(x, count,bottom=bottom)\n",
    "        for j in range(len(count)):\n",
    "            bottom[j]+=count[j]\n",
    "        count = [0]*10\n",
    "        for _,label in valset:\n",
    "            count[label] += 1\n",
    "        axs[int(i/W), i%W].bar(x, count,bottom=bottom)\n",
    "        for j in range(len(count)):\n",
    "            bottom[j]+=count[j]\n",
    "        count = [0]*10\n",
    "        for _,label in testset:\n",
    "            count[label] += 1\n",
    "        axs[int(i/W), i%W].bar(x, count,bottom=bottom)\n",
    "        #axs[int(i/W), i%W].title(\"worker{}\".format(i+1), fontsize=12, color = \"green\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    ## get global dataset\n",
    "    if Centralized:\n",
    "        global_trainset = GlobalDataset(federated_trainset)\n",
    "        global_valset = GlobalDataset(federated_valset)\n",
    "        global_testset =  GlobalDataset(federated_testset)\n",
    "        \n",
    "        #show_cifer(global_trainset.data,global_testset.label, cifar10_labels)\n",
    "\n",
    "        global_trainset.transform = transform_train\n",
    "        global_valset.transform = transform_test\n",
    "        global_testset.transform = transform_test\n",
    "\n",
    "        global_trainloader = torch.utils.data.DataLoader(global_trainset,batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "        global_valloader = torch.utils.data.DataLoader(global_valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "        global_testloader = torch.utils.data.DataLoader(global_testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "\n",
    "    ## set transform\n",
    "    for i in range(args.worker_num):\n",
    "        federated_trainset[i].transform = transform_train\n",
    "        federated_valset[i].transform = transform_test\n",
    "        federated_testset[i].transform = transform_test\n",
    "    \n",
    "    if Centralized and unlabeled_data:\n",
    "        return federated_trainset,federated_valset,federated_testset,global_trainloader,global_valloader,global_testloader,unlabeled_dataset\n",
    "    if Centralized:\n",
    "        return federated_trainset,federated_valset,federated_testset,global_trainloader,global_valloader,global_testloader\n",
    "    elif unlabeled_data:\n",
    "        return federated_trainset,federated_valset,federated_testset,unlabeled_dataset\n",
    "    else:\n",
    "        return federated_trainset,federated_valset,federated_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train:49000 Test:10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "federated_trainset,federated_valset,federated_testset,global_trainloader,global_valloader,global_testloader,unlabeled_dataset = get_dataset(Centralized=True,unlabeled_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#federated_trainset,federated_valset,federated_testset,unlabeled_dataset = get_dataset(unlabeled_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39191, 9809, 10000]\n"
     ]
    }
   ],
   "source": [
    "total = [0,0,0]\n",
    "for i in range(args.worker_num):\n",
    "    total[0]+=len(federated_trainset[i])\n",
    "    total[1]+=len(federated_valset[i])\n",
    "    total[2]+=len(federated_testset[i])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZU3vAAb9-6SD"
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    '''\n",
    "    VGG model \n",
    "    '''\n",
    "    def __init__(self, features, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "         # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            #print(\"in_channels: {}, v: {}\".format(in_channels, v))\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', \n",
    "          512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGGConvBlocks(nn.Module):\n",
    "    '''\n",
    "    VGG containers that only contains the conv layers \n",
    "    '''\n",
    "    def __init__(self, features, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "         # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "class VGGContainer(nn.Module):\n",
    "    '''\n",
    "    VGG model \n",
    "    '''\n",
    "    def __init__(self, features, input_dim, hidden_dims, num_classes=10):\n",
    "        super(VGGContainer, self).__init__()\n",
    "        self.features = features\n",
    "        # note: we hard coded here a bit by assuming we only have two hidden layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(input_dim, hidden_dims[0]),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden_dims[0], hidden_dims[1]),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(hidden_dims[1], num_classes),\n",
    "        )\n",
    "         # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def matched_vgg11(matched_shapes):\n",
    "    # [(67, 27), (67,), (132, 603), (132,), (260, 1188), (260,), (261, 2340), (261,), (516, 2349), (516,), (517, 4644), (517,), \n",
    "    # (516, 4653), (516,), (516, 4644), (516,), (516, 515), (515,), (515, 515), (515,), (515, 10), (10,)]\n",
    "    processed_matched_shape = [matched_shapes[0][0], \n",
    "                                'M', \n",
    "                                matched_shapes[2][0], \n",
    "                                'M', \n",
    "                                matched_shapes[4][0], \n",
    "                                matched_shapes[6][0], \n",
    "                                'M', \n",
    "                                matched_shapes[8][0], \n",
    "                                matched_shapes[10][0], \n",
    "                                'M', \n",
    "                                matched_shapes[12][0], \n",
    "                                matched_shapes[14][0], \n",
    "                                'M']\n",
    "    return VGGContainer(make_layers(processed_matched_shape), input_dim=matched_shapes[16][0], \n",
    "            hidden_dims=[matched_shapes[16][1], matched_shapes[18][1]], num_classes=10)\n",
    "\n",
    "\n",
    "def vgg11():\n",
    "    \"\"\"VGG 11-layer model (configuration \"A\")\"\"\"\n",
    "    return VGG(make_layers(cfg['A']))\n",
    "\n",
    "\n",
    "def vgg11_bn(num_classes=10):\n",
    "    \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\"\"\"\n",
    "    return VGG(make_layers(cfg['A'], batch_norm=True), num_classes=num_classes)\n",
    "\n",
    "\n",
    "def vgg13():\n",
    "    \"\"\"VGG 13-layer model (configuration \"B\")\"\"\"\n",
    "    return VGG(make_layers(cfg['B']))\n",
    "\n",
    "\n",
    "def vgg13_bn():\n",
    "    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n",
    "    return VGG(make_layers(cfg['B'], batch_norm=True))\n",
    "\n",
    "\n",
    "def vgg16():\n",
    "    \"\"\"VGG 16-layer model (configuration \"D\")\"\"\"\n",
    "    return VGG(make_layers(cfg['D']))\n",
    "\n",
    "\n",
    "def vgg16_bn():\n",
    "    \"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\"\"\"\n",
    "    return VGG(make_layers(cfg['D'], batch_norm=True))\n",
    "\n",
    "\n",
    "def vgg19():\n",
    "    \"\"\"VGG 19-layer model (configuration \"E\")\"\"\"\n",
    "    return VGG(make_layers(cfg['E']))\n",
    "\n",
    "\n",
    "def vgg19_bn():\n",
    "    \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\"\"\"\n",
    "    return VGG(make_layers(cfg['E'], batch_norm=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Yu90X1TWJVKJ"
   },
   "outputs": [],
   "source": [
    "class Server():\n",
    "  def __init__(self):\n",
    "    self.model = vgg13()\n",
    "\n",
    "  def create_worker(self,federated_trainset,federated_valset,federated_testset):\n",
    "    workers = []\n",
    "    for i in range(args.worker_num):\n",
    "      workers.append(Worker(federated_trainset[i],federated_valset[i],federated_testset[i]))\n",
    "    return workers\n",
    "\n",
    "  def sample_worker(self,workers):\n",
    "    sample_worker = []\n",
    "    sample_worker_num = random.sample(range(args.worker_num),args.sample_num)\n",
    "    for i in sample_worker_num:\n",
    "      sample_worker.append(workers[i])\n",
    "    return sample_worker\n",
    "\n",
    "\n",
    "  def send_model(self,workers):\n",
    "    nums = 0\n",
    "    for worker in workers:\n",
    "      nums += worker.train_data_num\n",
    "\n",
    "    for worker in workers:\n",
    "      worker.aggregation_weight = 1.0*worker.train_data_num/nums\n",
    "      worker.model = copy.deepcopy(self.model)\n",
    "      worker.model = worker.model.to(args.device)\n",
    "\n",
    "  def aggregate_model(self,workers):   \n",
    "    new_params = OrderedDict()\n",
    "    for i,worker in enumerate(workers):\n",
    "      worker_state = worker.model.state_dict()\n",
    "      for key in worker_state.keys():\n",
    "        if i==0:\n",
    "          new_params[key] = worker_state[key]*worker.aggregation_weight\n",
    "        else:\n",
    "          new_params[key] += worker_state[key]*worker.aggregation_weight\n",
    "      worker.model = worker.model.to('cpu')\n",
    "      del worker.model\n",
    "    self.model.load_state_dict(new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LDWEBjgfJYFc"
   },
   "outputs": [],
   "source": [
    "class Worker():\n",
    "  def __init__(self,trainset,valset,testset):\n",
    "    self.trainloader = torch.utils.data.DataLoader(trainset,batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.valloader = torch.utils.data.DataLoader(valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.testloader = torch.utils.data.DataLoader(testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.model = None\n",
    "    self.train_data_num = len(trainset)\n",
    "    self.test_data_num = len(testset)\n",
    "    self.aggregation_weight = None\n",
    "\n",
    "  def local_train(self):\n",
    "    acc_train,loss_train = local_train(self.model,args.criterion,self.trainloader,args.local_epochs)\n",
    "    acc_valid,loss_valid = test(self.model,args.criterion,self.valloader)\n",
    "    return acc_train,loss_train,acc_valid,loss_valid\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7-GY66gROuEU"
   },
   "outputs": [],
   "source": [
    "def local_train(model,criterion,trainloader,epochs):\n",
    "  optimizer = optim.SGD(model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "  model.train()\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for (data,labels) in trainloader:\n",
    "      data,labels = Variable(data),Variable(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      count += len(labels)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "      optimizer.step()\n",
    "\n",
    "  return 100.0*correct/count,running_loss/len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_train(model,criterion,trainloader,valloader,epochs,partience=0,early_stop=False):\n",
    "  if early_stop:\n",
    "    early_stopping = Early_Stopping(partience)\n",
    "\n",
    "  acc_train = []\n",
    "  loss_train = []\n",
    "  acc_valid = []\n",
    "  loss_valid = []\n",
    "  optimizer = optim.SGD(model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    model.train()\n",
    "    for (data,labels) in trainloader:\n",
    "      count += len(labels)\n",
    "      data,labels = Variable(data),Variable(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "      optimizer.step()\n",
    "    acc_train.append(100.0*correct/count)\n",
    "    loss_train.append(running_loss/len(trainloader))\n",
    "        \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    for (data,labels) in valloader:\n",
    "      count += len(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      \n",
    "    print('Epoch:{}  accuracy:{}  loss:{}'.format(epoch+1,100.0*correct/count,running_loss/len(valloader)))\n",
    "    acc_valid.append(100.0*correct/count)\n",
    "    loss_valid.append(running_loss/len(valloader))\n",
    "    if early_stop:\n",
    "      if early_stopping.validate(running_loss):\n",
    "        print('Early Stop')\n",
    "        return acc_train,loss_train,acc_valid,loss_valid\n",
    "\n",
    "  return acc_train,loss_train,acc_valid,loss_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oA4URv9mQ3xV"
   },
   "outputs": [],
   "source": [
    "def test(model,criterion,testloader):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  count = 0\n",
    "  for (data,labels) in testloader:\n",
    "    data,labels = data.to(args.device),labels.to(args.device)\n",
    "    outputs = model(data)\n",
    "    running_loss += criterion(outputs,labels).item()\n",
    "    predicted = torch.argmax(outputs,dim=1)\n",
    "    correct += (predicted==labels).sum().item()\n",
    "    count += len(labels)\n",
    "\n",
    "  accuracy = 100.0*correct/count\n",
    "  loss = running_loss/len(testloader)\n",
    "\n",
    "\n",
    "  return accuracy,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WMO7_WSLHeGl"
   },
   "outputs": [],
   "source": [
    "class Early_Stopping():\n",
    "  def __init__(self,partience):\n",
    "    self.step = 0\n",
    "    self.loss = float('inf')\n",
    "    self.partience = partience\n",
    "\n",
    "  def validate(self,loss):\n",
    "    if self.loss<loss:\n",
    "      self.step += 1\n",
    "      if self.step>self.partience:\n",
    "        return True\n",
    "    else:\n",
    "      self.step = 0\n",
    "      self.loss = loss\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1  accuracy:15.608114996431848  loss:2.274055314064026\n",
      "Epoch:2  accuracy:29.850137628708328  loss:1.8576419234275818\n",
      "Epoch:3  accuracy:37.11897237231114  loss:1.6468947887420655\n",
      "Epoch:4  accuracy:42.481394637577736  loss:1.5116349816322328\n",
      "Epoch:5  accuracy:46.997655214598836  loss:1.405281376838684\n",
      "Epoch:6  accuracy:51.45274747680701  loss:1.2923513531684876\n",
      "Epoch:7  accuracy:56.01998164950555  loss:1.1835212409496307\n",
      "Epoch:8  accuracy:59.190539300642264  loss:1.1064811766147613\n",
      "Epoch:9  accuracy:63.411153022734226  loss:1.0085255205631256\n",
      "Epoch:10  accuracy:67.06086247323886  loss:0.9164419949054718\n",
      "Epoch:11  accuracy:65.82730145784484  loss:0.9208846271038056\n",
      "Epoch:12  accuracy:69.52798450402692  loss:0.8655185699462891\n",
      "Epoch:13  accuracy:70.86349271077582  loss:0.8304315328598022\n",
      "Epoch:14  accuracy:70.10908349474973  loss:0.8496272742748261\n",
      "Epoch:15  accuracy:74.0544398001835  loss:0.745823347568512\n",
      "Epoch:16  accuracy:73.0553573249057  loss:0.7718769162893295\n",
      "Epoch:17  accuracy:76.26669385258437  loss:0.6868653297424316\n",
      "Epoch:18  accuracy:77.3983076766235  loss:0.6626950085163117\n",
      "Epoch:19  accuracy:78.21388520746254  loss:0.6285104334354401\n",
      "Epoch:20  accuracy:78.96829442348863  loss:0.6138680130243301\n",
      "Epoch:21  accuracy:79.51880925680497  loss:0.6118635386228561\n",
      "Epoch:22  accuracy:79.06004689570803  loss:0.6329573154449463\n",
      "Epoch:23  accuracy:80.63003364257315  loss:0.5731392949819565\n",
      "Epoch:24  accuracy:80.63003364257315  loss:0.5727120012044906\n",
      "Epoch:25  accuracy:80.60964420430217  loss:0.5706567734479904\n",
      "Epoch:26  accuracy:80.85431746355388  loss:0.575087770819664\n",
      "Epoch:27  accuracy:81.25191150983791  loss:0.583167240023613\n",
      "Epoch:28  accuracy:81.95534713018657  loss:0.5629091024398803\n",
      "Epoch:29  accuracy:81.96554184932205  loss:0.5446987539529801\n",
      "Epoch:30  accuracy:82.80150881843205  loss:0.5407833456993103\n",
      "Epoch:31  accuracy:82.52625140177388  loss:0.5532728046178818\n",
      "Epoch:32  accuracy:81.99612600672852  loss:0.5660830020904541\n",
      "Epoch:33  accuracy:82.25099398511571  loss:0.5808465331792831\n",
      "Epoch:34  accuracy:82.70975634621266  loss:0.5529506981372834\n",
      "Epoch:35  accuracy:83.16851870730962  loss:0.552898445725441\n",
      "Epoch:36  accuracy:83.81078601284534  loss:0.5165961295366287\n",
      "Epoch:37  accuracy:82.55683555918034  loss:0.5698286116123199\n",
      "Epoch:38  accuracy:81.04801712712815  loss:0.6343785226345062\n",
      "Epoch:39  accuracy:83.3520236517484  loss:0.5476143926382064\n",
      "Epoch:40  accuracy:83.8413701702518  loss:0.5559881240129471\n",
      "Epoch:41  accuracy:83.86175960852279  loss:0.5555105209350586\n",
      "Epoch:42  accuracy:83.08696095422572  loss:0.6079698711633682\n",
      "Epoch:43  accuracy:83.10735039249668  loss:0.6095915853977203\n",
      "Epoch:44  accuracy:83.8413701702518  loss:0.5424103111028671\n",
      "Epoch:45  accuracy:83.60689163013559  loss:0.6006064504384995\n",
      "Epoch:46  accuracy:84.33071668875523  loss:0.553544357419014\n",
      "Epoch:47  accuracy:84.49383219492303  loss:0.596351221203804\n",
      "Early Stop\n"
     ]
    }
   ],
   "source": [
    "model = vgg13()\n",
    "model = model.to(args.device)\n",
    "\n",
    "start = time.time()\n",
    "acc_train,loss_train,acc_valid,loss_valid = global_train(model,args.criterion,global_trainloader,global_valloader,args.global_epochs,partience=args.partience,early_stop=True)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = Server()\n",
    "workers = server.create_worker(federated_trainset,federated_valset,federated_testset)\n",
    "server.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "mi_uceyoptLP",
    "outputId": "bc067e09-01bc-4e65-daf9-ac2f42373cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:76.95852534562212  loss:0.8892805576324463\n",
      "Worker2 accuracy:84.42622950819673  loss:0.6386640071868896\n",
      "Worker3 accuracy:85.33333333333333  loss:0.6122786402702332\n",
      "Worker4 accuracy:87.5  loss:0.4714757204055786\n",
      "Worker5 accuracy:85.65853658536585  loss:0.5955828726291656\n",
      "Worker6 accuracy:78.83008356545962  loss:0.9106189608573914\n",
      "Worker7 accuracy:78.10526315789474  loss:0.804499089717865\n",
      "Worker8 accuracy:89.03775883069427  loss:0.4709402918815613\n",
      "Worker9 accuracy:87.64331210191082  loss:0.5057756900787354\n",
      "Worker10 accuracy:80.55555555555556  loss:0.7536396384239197\n",
      "Worker11 accuracy:89.2063492063492  loss:0.5061701536178589\n",
      "Worker12 accuracy:84.89208633093526  loss:0.5809253454208374\n",
      "Worker13 accuracy:92.65306122448979  loss:0.2531377971172333\n",
      "Worker14 accuracy:81.37931034482759  loss:0.732693612575531\n",
      "Worker15 accuracy:82.57080610021787  loss:0.6368874907493591\n",
      "Worker16 accuracy:83.84279475982532  loss:0.6855120658874512\n",
      "Worker17 accuracy:87.26415094339623  loss:0.6219316124916077\n",
      "Worker18 accuracy:85.19195612431444  loss:0.5865132212638855\n",
      "Worker19 accuracy:83.52059925093633  loss:0.640822172164917\n",
      "Worker20 accuracy:84.71177944862156  loss:0.588525652885437\n",
      "Test  loss:0.6242937296628952  accuracy:84.46407458589735\n"
     ]
    }
   ],
   "source": [
    "acc_test = []\n",
    "loss_test = []\n",
    "\n",
    "server.model.to(args.device)\n",
    "\n",
    "nums = 0\n",
    "for worker in workers:\n",
    "  nums += worker.test_data_num\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "  worker.aggregation_weight = 1.0*worker.test_data_num/nums\n",
    "  acc_tmp,loss_tmp = test(server.model,args.criterion,worker.testloader)\n",
    "  acc_test.append(acc_tmp)\n",
    "  loss_test.append(loss_tmp)\n",
    "  print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "acc_test_avg = sum(acc_test)/len(acc_test)\n",
    "loss_test_avg = sum(loss_test)/len(loss_test)\n",
    "print('Test  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 Valid accuracy:87.83151326053041  loss:0.5195301175117493\n",
      "Worker1 Test accuracy:84.94623655913979  loss:0.5430549383163452\n",
      "Worker2 Valid accuracy:92.32365145228216  loss:0.3624081611633301\n",
      "Worker2 Test accuracy:90.77868852459017  loss:0.41827142238616943\n",
      "Worker3 Valid accuracy:85.9375  loss:0.5839946269989014\n",
      "Worker3 Test accuracy:87.23809523809524  loss:0.519051194190979\n",
      "Worker4 Valid accuracy:89.4949494949495  loss:0.4020896852016449\n",
      "Worker4 Test accuracy:89.48412698412699  loss:0.36940497159957886\n",
      "Worker5 Valid accuracy:86.35458167330677  loss:0.7159607410430908\n",
      "Worker5 Test accuracy:89.17073170731707  loss:0.2540260162204504\n",
      "Worker6 Valid accuracy:86.93181818181819  loss:0.5281125903129578\n",
      "Worker6 Test accuracy:85.51532033426184  loss:0.6875086426734924\n",
      "Worker7 Valid accuracy:90.36402569593147  loss:0.30584174394607544\n",
      "Worker7 Test accuracy:88.21052631578948  loss:0.43742257356643677\n",
      "Worker8 Valid accuracy:93.54838709677419  loss:0.21323427557945251\n",
      "Worker8 Test accuracy:92.08282582216809  loss:0.32170233130455017\n",
      "Worker9 Valid accuracy:92.59740259740259  loss:0.32895106077194214\n",
      "Worker9 Test accuracy:92.35668789808918  loss:0.29266852140426636\n",
      "Worker10 Valid accuracy:94.73684210526316  loss:0.199106827378273\n",
      "Worker10 Test accuracy:91.26984126984127  loss:0.29298830032348633\n",
      "Worker11 Valid accuracy:91.58576051779936  loss:0.31177210807800293\n",
      "Worker11 Test accuracy:89.2063492063492  loss:0.3579518496990204\n",
      "Worker12 Valid accuracy:86.9309838472834  loss:0.44482237100601196\n",
      "Worker12 Test accuracy:89.35251798561151  loss:0.4750633239746094\n",
      "Worker13 Valid accuracy:94.824016563147  loss:0.18864570558071136\n",
      "Worker13 Test accuracy:96.73469387755102  loss:0.13194973766803741\n",
      "Worker14 Valid accuracy:88.65248226950355  loss:0.3470786213874817\n",
      "Worker14 Test accuracy:87.24137931034483  loss:0.46083909273147583\n",
      "Worker15 Valid accuracy:86.25277161862527  loss:0.4040335714817047\n",
      "Worker15 Test accuracy:88.45315904139433  loss:0.4166982173919678\n",
      "Worker16 Valid accuracy:89.42731277533039  loss:0.453696608543396\n",
      "Worker16 Test accuracy:86.02620087336244  loss:0.6518204808235168\n",
      "Worker17 Valid accuracy:88.40579710144928  loss:0.5168153643608093\n",
      "Worker17 Test accuracy:88.91509433962264  loss:0.5539221167564392\n",
      "Worker18 Valid accuracy:83.27137546468401  loss:0.6050468683242798\n",
      "Worker18 Test accuracy:86.83729433272394  loss:0.5544726252555847\n",
      "Worker19 Valid accuracy:87.73946360153256  loss:0.4860435426235199\n",
      "Worker19 Test accuracy:85.3932584269663  loss:0.5628982186317444\n",
      "Worker20 Valid accuracy:91.21447028423772  loss:0.37942537665367126\n",
      "Worker20 Test accuracy:88.7218045112782  loss:0.49129587411880493\n",
      "Validation(tune)  loss:0.4148304983973503  accuracy:89.42125528009254\n",
      "Test(tune)  loss:0.43965052245184777  accuracy:88.89674162793118\n"
     ]
    }
   ],
   "source": [
    "acc_tune_test = []\n",
    "loss_tune_test = []\n",
    "acc_tune_valid = []\n",
    "loss_tune_valid = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "    worker.model = copy.deepcopy(server.model)\n",
    "    worker.model = worker.model.to(args.device)\n",
    "    _,_,acc_tmp,loss_tmp = worker.local_train()\n",
    "    acc_tune_valid.append(acc_tmp)\n",
    "    loss_tune_valid.append(loss_tmp)\n",
    "    print('Worker{} Valid accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    \n",
    "    acc_tmp,loss_tmp = test(worker.model,args.criterion,worker.testloader)\n",
    "    acc_tune_test.append(acc_tmp)\n",
    "    loss_tune_test.append(loss_tmp)\n",
    "    print('Worker{} Test accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    worker.model = worker.model.to('cpu')\n",
    "    del worker.model\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "acc_valid_avg = sum(acc_tune_valid)/len(acc_tune_valid)\n",
    "loss_valid_avg = sum(loss_tune_valid)/len(loss_tune_valid)\n",
    "print('Validation(tune)  loss:{}  accuracy:{}'.format(loss_valid_avg,acc_valid_avg))\n",
    "acc_test_avg = sum(acc_tune_test)/len(acc_tune_test)\n",
    "loss_test_avg = sum(loss_tune_test)/len(loss_tune_test)\n",
    "print('Test(tune)  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FedAvg_femnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
