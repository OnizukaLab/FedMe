{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "vkZxat4Y-IsQ",
    "outputId": "da86392c-66e8-4b60-b471-086e745cdcbc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from torch import nn, optim\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O0TfzOhU-QlG"
   },
   "outputs": [],
   "source": [
    "class Argments():\n",
    "  def __init__(self):\n",
    "    self.batch_size = 40\n",
    "    self.test_batch = 1000\n",
    "    #self.global_epochs = 500\n",
    "    self.local_epochs = 200\n",
    "    self.lr = None\n",
    "    self.momentum = 0.9\n",
    "    self.weight_decay = 10**-4.0\n",
    "    self.clip = 20.0\n",
    "    self.partience = 10\n",
    "    self.worker_num = 20\n",
    "    #self.sample_num = 20\n",
    "    self.unlabeleddata_size = 1000\n",
    "    self.device = torch.device('cuda:0'if torch.cuda.is_available() else'cpu')\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    self.alpha_label = 0.5\n",
    "    self.alpha_size = 10\n",
    "\n",
    "args = Argments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned value\n",
    "lr = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(10**-3.0)\n",
    "lr_list.append(10**-2.5)\n",
    "lr_list.append(10**-2.0)\n",
    "lr_list.append(10**-1.5)\n",
    "lr_list.append(10**-1.0)\n",
    "lr_list.append(10**-0.5)\n",
    "lr_list.append(10**0.0)\n",
    "lr_list.append(10**0.5)\n",
    "\n",
    "args.lr = lr_list[lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.label = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_data = self.data[idx]\n",
    "        out_label = self.label[idx]\n",
    "        if self.transform:\n",
    "            out_data = self.transform(out_data)\n",
    "        return out_data, out_label\n",
    "    \n",
    "class DatasetFromSubset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.subset[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "    \n",
    "class GlobalDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,federated_dataset,transform=None):\n",
    "    self.transform = transform\n",
    "    self.data = []\n",
    "    self.label = []\n",
    "    for dataset in federated_dataset:\n",
    "      for (data,label) in dataset:\n",
    "        self.data.append(data)\n",
    "        self.label.append(label)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    out_data = self.data[idx]\n",
    "    out_label = self.label[idx]\n",
    "    if self.transform:\n",
    "        out_data = self.transform(out_data)\n",
    "    return out_data, out_label\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "class UnlabeledDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,transform=None):\n",
    "    self.transform = transform\n",
    "    self.data = []\n",
    "    self.target = None\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    out_data = self.data[idx]\n",
    "    out_label = 'unlabeled'\n",
    "    if self.transform:\n",
    "        out_data = self.transform(out_data)\n",
    "    return out_data, out_label\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(Centralized=False,unlabeled_data=False):\n",
    "    \n",
    "    transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomCrop(32, padding=2),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.491372549, 0.482352941, 0.446666667), (0.247058824, 0.243529412, 0.261568627))])\n",
    "    transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.491372549, 0.482352941, 0.446666667), (0.247058824, 0.243529412, 0.261568627))])\n",
    "\n",
    "    # download train data\n",
    "    all_trainset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True)\n",
    "    #trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "    # download test data\n",
    "    all_testset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True)\n",
    "    #testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "    \n",
    "    ## get unlabeled dataset\n",
    "    if unlabeled_data:\n",
    "        unlabeled_dataset = UnlabeledDataset(transform_test)\n",
    "        idx = sorted(random.sample(range(len(all_trainset)),args.unlabeleddata_size))\n",
    "        unlabeled_dataset.data = np.array([all_trainset.data[i]  for i in idx])\n",
    "        all_trainset.data = np.delete(all_trainset.data,idx,0)\n",
    "        all_trainset.targets = np.delete(all_trainset.targets,idx,0)\n",
    "    all_train_data = np.array(all_trainset.data)\n",
    "    all_train_label = np.array(all_trainset.targets)\n",
    "    all_test_data = np.array(all_testset.data)\n",
    "    all_test_label = np.array(all_testset.targets)\n",
    "    print('Train:{} Test:{}'.format(len(all_train_data),len(all_test_data)))\n",
    "\n",
    "\n",
    "    ## Data size heterogeneity\n",
    "    data_proportions = np.random.dirichlet(np.repeat(args.alpha_size, args.worker_num))\n",
    "    train_data_proportions = np.array([0 for _ in range(args.worker_num)])\n",
    "    test_data_proportions = np.array([0 for _ in range(args.worker_num)])\n",
    "    for i in range(len(data_proportions)):\n",
    "        if i==(len(data_proportions)-1):\n",
    "            train_data_proportions = train_data_proportions.astype('int64')\n",
    "            test_data_proportions = test_data_proportions.astype('int64')\n",
    "            train_data_proportions[-1] = len(all_train_data) - np.sum(train_data_proportions[:-1])\n",
    "            test_data_proportions[-1] = len(all_test_data) - np.sum(test_data_proportions[:-1])\n",
    "        else:\n",
    "            train_data_proportions[i] = (data_proportions[i] * len(all_train_data))\n",
    "            test_data_proportions[i] = (data_proportions[i] * len(all_test_data))\n",
    "    min_size = 0\n",
    "    K = 10\n",
    "\n",
    "    '''\n",
    "    label_list = np.arange(10)\n",
    "    np.random.shuffle(label_list)\n",
    "    '''\n",
    "    label_list = list(range(K))\n",
    "\n",
    "\n",
    "    ## Data distribution heterogeneity\n",
    "    while min_size<10:\n",
    "        idx_train_batch = [[] for _ in range(args.worker_num)]\n",
    "        idx_test_batch = [[] for _ in range(args.worker_num)]\n",
    "        for k in label_list:\n",
    "            proportions_train = np.random.dirichlet(np.repeat(args.alpha_label, args.worker_num))\n",
    "            proportions_test = copy.deepcopy(proportions_train)\n",
    "            idx_k_train = np.where(all_train_label == k)[0]\n",
    "            idx_k_test = np.where(all_test_label == k)[0]\n",
    "            np.random.shuffle(idx_k_train)\n",
    "            np.random.shuffle(idx_k_test)\n",
    "            ## Balance (train)\n",
    "            proportions_train = np.array([p*(len(idx_j)<train_data_proportions[i]) for i,(p,idx_j) in enumerate(zip(proportions_train,idx_train_batch))])\n",
    "            proportions_train = proportions_train/proportions_train.sum()\n",
    "            proportions_train = (np.cumsum(proportions_train)*len(idx_k_train)).astype(int)[:-1]\n",
    "            idx_train_batch = [idx_j + idx.tolist() for idx_j,idx in zip(idx_train_batch,np.split(idx_k_train,proportions_train))]\n",
    "\n",
    "            ## Balance (test)\n",
    "            proportions_test = np.array([p*(len(idx_j)<test_data_proportions[i]) for i,(p,idx_j) in enumerate(zip(proportions_test,idx_test_batch))])\n",
    "            proportions_test = proportions_test/proportions_test.sum()\n",
    "            proportions_test = (np.cumsum(proportions_test)*len(idx_k_test)).astype(int)[:-1]\n",
    "            idx_test_batch = [idx_j + idx.tolist() for idx_j,idx in zip(idx_test_batch,np.split(idx_k_test,proportions_test))]\n",
    "\n",
    "            min_size = min([len(idx_j) for idx_j in idx_train_batch])\n",
    "\n",
    "    federated_trainset = []\n",
    "    federated_testset = []\n",
    "    for i in range(args.worker_num):\n",
    "        ## create trainset\n",
    "        data = [all_train_data[idx] for idx in idx_train_batch[i]]\n",
    "        label = [all_train_label[idx] for idx in idx_train_batch[i]]\n",
    "        federated_trainset.append(LocalDataset())\n",
    "        federated_trainset[-1].data = data\n",
    "        federated_trainset[-1].label = label\n",
    "\n",
    "        ## create testset\n",
    "        data = [all_test_data[idx] for idx in idx_test_batch[i]]\n",
    "        label = [all_test_label[idx] for idx in idx_test_batch[i]]\n",
    "        federated_testset.append(LocalDataset())\n",
    "        federated_testset[-1].data = data\n",
    "        federated_testset[-1].label = label\n",
    "\n",
    "        \n",
    "    ## split trainset\n",
    "    federated_valset = [None]*args.worker_num\n",
    "    for i in range(args.worker_num):\n",
    "        n_samples = len(federated_trainset[i])\n",
    "        if n_samples==1:\n",
    "            train_subset = federated_trainset[i]\n",
    "            val_subset = copy.deepcopy(federated_trainset[i])\n",
    "        else:\n",
    "            train_size = int(len(federated_trainset[i]) * 0.8) \n",
    "            val_size = n_samples - train_size \n",
    "            train_subset,val_subset = torch.utils.data.random_split(federated_trainset[i], [train_size, val_size])\n",
    "\n",
    "        federated_trainset[i] = DatasetFromSubset(train_subset)\n",
    "        federated_valset[i] = DatasetFromSubset(val_subset)\n",
    "\n",
    "    ## show data distribution\n",
    "    H = 4\n",
    "    W = 5\n",
    "    fig, axs = plt.subplots(H, W, figsize=(20, 5))\n",
    "    x = np.arange(1,11)\n",
    "    for i, (trainset,valset,testset) in enumerate(zip(federated_trainset,federated_valset,federated_testset)):\n",
    "        bottom = [0]*10\n",
    "        count = [0]*10\n",
    "        for _,label in trainset:\n",
    "            count[label] += 1\n",
    "        axs[int(i/W), i%W].bar(x, count,bottom=bottom)\n",
    "        for j in range(len(count)):\n",
    "            bottom[j]+=count[j]\n",
    "        count = [0]*10\n",
    "        for _,label in valset:\n",
    "            count[label] += 1\n",
    "        axs[int(i/W), i%W].bar(x, count,bottom=bottom)\n",
    "        for j in range(len(count)):\n",
    "            bottom[j]+=count[j]\n",
    "        count = [0]*10\n",
    "        for _,label in testset:\n",
    "            count[label] += 1\n",
    "        axs[int(i/W), i%W].bar(x, count,bottom=bottom)\n",
    "        #axs[int(i/W), i%W].title(\"worker{}\".format(i+1), fontsize=12, color = \"green\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    ## get global dataset\n",
    "    if Centralized:\n",
    "        global_trainset = GlobalDataset(federated_trainset)\n",
    "        global_valset = GlobalDataset(federated_valset)\n",
    "        global_testset =  GlobalDataset(federated_testset)\n",
    "        \n",
    "        #show_cifer(global_trainset.data,global_testset.label, cifar10_labels)\n",
    "\n",
    "        global_trainset.transform = transform_train\n",
    "        global_valset.transform = transform_test\n",
    "        global_testset.transform = transform_test\n",
    "\n",
    "        global_trainloader = torch.utils.data.DataLoader(global_trainset,batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "        global_valloader = torch.utils.data.DataLoader(global_valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "        global_testloader = torch.utils.data.DataLoader(global_testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "\n",
    "    ## set transform\n",
    "    for i in range(args.worker_num):\n",
    "        federated_trainset[i].transform = transform_train\n",
    "        federated_valset[i].transform = transform_test\n",
    "        federated_testset[i].transform = transform_test\n",
    "    \n",
    "    if Centralized and unlabeled_data:\n",
    "        return federated_trainset,federated_valset,federated_testset,global_trainloader,global_valloader,global_testloader,unlabeled_dataset\n",
    "    if Centralized:\n",
    "        return federated_trainset,federated_valset,federated_testset,global_trainloader,global_valloader,global_testloader\n",
    "    elif unlabeled_data:\n",
    "        return federated_trainset,federated_valset,federated_testset,unlabeled_dataset\n",
    "    else:\n",
    "        return federated_trainset,federated_valset,federated_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train:49000 Test:10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "federated_trainset,federated_valset,federated_testset,unlabeled_dataset = get_dataset(unlabeled_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39191, 9809, 10000]\n"
     ]
    }
   ],
   "source": [
    "total = [0,0,0]\n",
    "for i in range(args.worker_num):\n",
    "    total[0]+=len(federated_trainset[i])\n",
    "    total[1]+=len(federated_valset[i])\n",
    "    total[2]+=len(federated_testset[i])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZU3vAAb9-6SD"
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    '''\n",
    "    VGG model \n",
    "    '''\n",
    "    def __init__(self, features, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "         # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            #print(\"in_channels: {}, v: {}\".format(in_channels, v))\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', \n",
    "          512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGGConvBlocks(nn.Module):\n",
    "    '''\n",
    "    VGG containers that only contains the conv layers \n",
    "    '''\n",
    "    def __init__(self, features, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "         # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "class VGGContainer(nn.Module):\n",
    "    '''\n",
    "    VGG model \n",
    "    '''\n",
    "    def __init__(self, features, input_dim, hidden_dims, num_classes=10):\n",
    "        super(VGGContainer, self).__init__()\n",
    "        self.features = features\n",
    "        # note: we hard coded here a bit by assuming we only have two hidden layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(input_dim, hidden_dims[0]),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden_dims[0], hidden_dims[1]),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(hidden_dims[1], num_classes),\n",
    "        )\n",
    "         # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def matched_vgg11(matched_shapes):\n",
    "    # [(67, 27), (67,), (132, 603), (132,), (260, 1188), (260,), (261, 2340), (261,), (516, 2349), (516,), (517, 4644), (517,), \n",
    "    # (516, 4653), (516,), (516, 4644), (516,), (516, 515), (515,), (515, 515), (515,), (515, 10), (10,)]\n",
    "    processed_matched_shape = [matched_shapes[0][0], \n",
    "                                'M', \n",
    "                                matched_shapes[2][0], \n",
    "                                'M', \n",
    "                                matched_shapes[4][0], \n",
    "                                matched_shapes[6][0], \n",
    "                                'M', \n",
    "                                matched_shapes[8][0], \n",
    "                                matched_shapes[10][0], \n",
    "                                'M', \n",
    "                                matched_shapes[12][0], \n",
    "                                matched_shapes[14][0], \n",
    "                                'M']\n",
    "    return VGGContainer(make_layers(processed_matched_shape), input_dim=matched_shapes[16][0], \n",
    "            hidden_dims=[matched_shapes[16][1], matched_shapes[18][1]], num_classes=10)\n",
    "\n",
    "\n",
    "def vgg11():\n",
    "    \"\"\"VGG 11-layer model (configuration \"A\")\"\"\"\n",
    "    return VGG(make_layers(cfg['A']))\n",
    "\n",
    "\n",
    "def vgg11_bn(num_classes=10):\n",
    "    \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\"\"\"\n",
    "    return VGG(make_layers(cfg['A'], batch_norm=True), num_classes=num_classes)\n",
    "\n",
    "\n",
    "def vgg13():\n",
    "    \"\"\"VGG 13-layer model (configuration \"B\")\"\"\"\n",
    "    return VGG(make_layers(cfg['B']))\n",
    "\n",
    "\n",
    "def vgg13_bn():\n",
    "    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n",
    "    return VGG(make_layers(cfg['B'], batch_norm=True))\n",
    "\n",
    "\n",
    "def vgg16():\n",
    "    \"\"\"VGG 16-layer model (configuration \"D\")\"\"\"\n",
    "    return VGG(make_layers(cfg['D']))\n",
    "\n",
    "\n",
    "def vgg16_bn():\n",
    "    \"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\"\"\"\n",
    "    return VGG(make_layers(cfg['D'], batch_norm=True))\n",
    "\n",
    "\n",
    "def vgg19():\n",
    "    \"\"\"VGG 19-layer model (configuration \"E\")\"\"\"\n",
    "    return VGG(make_layers(cfg['E']))\n",
    "\n",
    "\n",
    "def vgg19_bn():\n",
    "    \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\"\"\"\n",
    "    return VGG(make_layers(cfg['E'], batch_norm=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Yu90X1TWJVKJ"
   },
   "outputs": [],
   "source": [
    "class Server():\n",
    "  def __init__(self):\n",
    "    self.model = vgg13()\n",
    "\n",
    "  def create_worker(self,federated_trainset,federated_valset,federated_testset):\n",
    "    workers = []\n",
    "    for i in range(args.worker_num):\n",
    "      workers.append(Worker(federated_trainset[i],federated_valset[i],federated_testset[i]))\n",
    "    return workers\n",
    "\n",
    "  def sample_worker(self,workers):\n",
    "    sample_worker = []\n",
    "    sample_worker_num = random.sample(range(args.worker_num),args.sample_num)\n",
    "    for i in sample_worker_num:\n",
    "      sample_worker.append(workers[i])\n",
    "    return sample_worker\n",
    "\n",
    "\n",
    "  def send_model(self,workers):\n",
    "    nums = 0\n",
    "    for worker in workers:\n",
    "      nums += worker.train_data_num\n",
    "\n",
    "    for worker in workers:\n",
    "      worker.aggregation_weight = 1.0*worker.train_data_num/nums\n",
    "      worker.model = copy.deepcopy(self.model)\n",
    "      worker.model = worker.model.to(args.device)\n",
    "\n",
    "  def aggregate_model(self,workers):   \n",
    "    new_params = OrderedDict()\n",
    "    for i,worker in enumerate(workers):\n",
    "      worker_state = worker.model.state_dict()\n",
    "      for key in worker_state.keys():\n",
    "        if i==0:\n",
    "          new_params[key] = worker_state[key]*worker.aggregation_weight\n",
    "        else:\n",
    "          new_params[key] += worker_state[key]*worker.aggregation_weight\n",
    "      worker.model = worker.model.to('cpu')\n",
    "      del worker.model\n",
    "    self.model.load_state_dict(new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LDWEBjgfJYFc"
   },
   "outputs": [],
   "source": [
    "class Worker():\n",
    "  def __init__(self,trainset,valset,testset):\n",
    "    self.trainloader = torch.utils.data.DataLoader(trainset,batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.valloader = torch.utils.data.DataLoader(valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.testloader = torch.utils.data.DataLoader(testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.model = None\n",
    "    self.train_data_num = len(trainset)\n",
    "    self.test_data_num = len(testset)\n",
    "    self.aggregation_weight = None\n",
    "\n",
    "  def local_train(self):\n",
    "    acc_valid,loss_valid = train(self.model,args.criterion,self.trainloader,self.valloader,args.local_epochs,partience=args.partience,early_stop=True)\n",
    "    return acc_valid[-1],loss_valid[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7-GY66gROuEU"
   },
   "outputs": [],
   "source": [
    "def train(model,criterion,trainloader,valloader,epochs,partience=0,early_stop=False):\n",
    "  if early_stop:\n",
    "    early_stopping = Early_Stopping(partience)\n",
    "\n",
    "  acc_valid = []\n",
    "  loss_valid = []\n",
    "  optimizer = optim.SGD(model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    model.train()\n",
    "    for (data,labels) in trainloader:\n",
    "      data,labels = Variable(data),Variable(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "      optimizer.step()\n",
    "      \n",
    "    model.eval()\n",
    "    for (data,labels) in valloader:\n",
    "      count += len(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      \n",
    "    print('Epoch:{}  accuracy:{}  loss:{}'.format(epoch+1,100.0*correct/count,running_loss/len(valloader)))\n",
    "    acc_valid.append(100.0*correct/count)\n",
    "    loss_valid.append(running_loss/len(valloader))\n",
    "    if early_stop:\n",
    "      if early_stopping.validate(running_loss):\n",
    "        print('Early Stop')\n",
    "        return acc_valid,loss_valid\n",
    "\n",
    "  return acc_valid,loss_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "oA4URv9mQ3xV"
   },
   "outputs": [],
   "source": [
    "def test(model,criterion,testloader):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  count = 0\n",
    "  for (data,labels) in testloader:\n",
    "    data,labels = data.to(args.device),labels.to(args.device)\n",
    "    outputs = model(data)\n",
    "    running_loss += criterion(outputs,labels).item()\n",
    "    predicted = torch.argmax(outputs,dim=1)\n",
    "    correct += (predicted==labels).sum().item()\n",
    "    count += len(labels)\n",
    "\n",
    "  accuracy = 100.0*correct/count\n",
    "  loss = running_loss/len(testloader)\n",
    "\n",
    "\n",
    "  return accuracy,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WMO7_WSLHeGl"
   },
   "outputs": [],
   "source": [
    "class Early_Stopping():\n",
    "  def __init__(self,partience):\n",
    "    self.step = 0\n",
    "    self.loss = float('inf')\n",
    "    self.partience = partience\n",
    "\n",
    "  def validate(self,loss):\n",
    "    if self.loss<loss:\n",
    "      self.step += 1\n",
    "      if self.step>self.partience:\n",
    "        return True\n",
    "    else:\n",
    "      self.step = 0\n",
    "      self.loss = loss\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "-noG_98IR-nZ",
    "outputId": "78a6ebe2-854a-4f83-dc45-5c4ac35b69e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 start\n",
      "Epoch:1  accuracy:33.541341653666144  loss:2.099371910095215\n",
      "Epoch:2  accuracy:33.541341653666144  loss:1.8135875463485718\n",
      "Epoch:3  accuracy:33.541341653666144  loss:1.81685209274292\n",
      "Epoch:4  accuracy:33.541341653666144  loss:1.8065166473388672\n",
      "Epoch:5  accuracy:33.541341653666144  loss:1.8002419471740723\n",
      "Epoch:6  accuracy:33.541341653666144  loss:1.7978066205978394\n",
      "Epoch:7  accuracy:33.541341653666144  loss:1.788761854171753\n",
      "Epoch:8  accuracy:33.697347893915754  loss:1.7752641439437866\n",
      "Epoch:9  accuracy:40.5616224648986  loss:1.7485074996948242\n",
      "Epoch:10  accuracy:44.14976599063962  loss:1.684731364250183\n",
      "Epoch:11  accuracy:43.8377535101404  loss:1.6683796644210815\n",
      "Epoch:12  accuracy:42.90171606864275  loss:1.6776244640350342\n",
      "Epoch:13  accuracy:46.02184087363494  loss:1.6339290142059326\n",
      "Epoch:14  accuracy:46.48985959438377  loss:1.6231786012649536\n",
      "Epoch:15  accuracy:46.64586583463338  loss:1.6162793636322021\n",
      "Epoch:16  accuracy:47.113884555382214  loss:1.5939615964889526\n",
      "Epoch:17  accuracy:44.77379095163806  loss:1.628602147102356\n",
      "Epoch:18  accuracy:48.673946957878314  loss:1.555905818939209\n",
      "Epoch:19  accuracy:48.517940717628704  loss:1.5290007591247559\n",
      "Epoch:20  accuracy:49.141965678627145  loss:1.5096811056137085\n",
      "Epoch:21  accuracy:48.049921996879874  loss:1.5167142152786255\n",
      "Epoch:22  accuracy:50.702028081123245  loss:1.491943359375\n",
      "Epoch:23  accuracy:51.014040561622465  loss:1.4934563636779785\n",
      "Epoch:24  accuracy:51.794071762870516  loss:1.4413599967956543\n",
      "Epoch:25  accuracy:51.482059282371296  loss:1.436050534248352\n",
      "Epoch:26  accuracy:50.234009360374415  loss:1.4522366523742676\n",
      "Epoch:27  accuracy:52.574102964118566  loss:1.3969477415084839\n",
      "Epoch:28  accuracy:49.297971918876755  loss:1.4420140981674194\n",
      "Epoch:29  accuracy:50.858034321372855  loss:1.4152734279632568\n",
      "Epoch:30  accuracy:51.794071762870516  loss:1.3923096656799316\n",
      "Epoch:31  accuracy:52.418096723868956  loss:1.3761259317398071\n",
      "Epoch:32  accuracy:50.858034321372855  loss:1.5007189512252808\n",
      "Epoch:33  accuracy:53.042121684867396  loss:1.370064377784729\n",
      "Epoch:34  accuracy:53.35413416536662  loss:1.3545596599578857\n",
      "Epoch:35  accuracy:53.97815912636506  loss:1.370869517326355\n",
      "Epoch:36  accuracy:52.730109204368176  loss:1.3416329622268677\n",
      "Epoch:37  accuracy:53.19812792511701  loss:1.3608564138412476\n",
      "Epoch:38  accuracy:53.66614664586584  loss:1.3430672883987427\n",
      "Epoch:39  accuracy:52.730109204368176  loss:1.3608598709106445\n",
      "Epoch:40  accuracy:53.51014040561623  loss:1.3612384796142578\n",
      "Epoch:41  accuracy:53.97815912636506  loss:1.3293614387512207\n",
      "Epoch:42  accuracy:54.13416536661467  loss:1.31849205493927\n",
      "Epoch:43  accuracy:55.38221528861155  loss:1.2928074598312378\n",
      "Epoch:44  accuracy:54.29017160686428  loss:1.334069848060608\n",
      "Epoch:45  accuracy:53.82215288611545  loss:1.318282961845398\n",
      "Epoch:46  accuracy:55.22620904836194  loss:1.2844164371490479\n",
      "Epoch:47  accuracy:56.00624024960999  loss:1.32160484790802\n",
      "Epoch:48  accuracy:54.75819032761311  loss:1.3117209672927856\n",
      "Epoch:49  accuracy:54.75819032761311  loss:1.3511803150177002\n",
      "Epoch:50  accuracy:56.1622464898596  loss:1.264273762702942\n",
      "Epoch:51  accuracy:56.1622464898596  loss:1.2741479873657227\n",
      "Epoch:52  accuracy:56.00624024960999  loss:1.2861613035202026\n",
      "Epoch:53  accuracy:58.34633385335413  loss:1.2404483556747437\n",
      "Epoch:54  accuracy:58.03432137285491  loss:1.2591569423675537\n",
      "Epoch:55  accuracy:59.28237129485179  loss:1.2412168979644775\n",
      "Epoch:56  accuracy:58.19032761310452  loss:1.2849061489105225\n",
      "Epoch:57  accuracy:59.4383775351014  loss:1.2263054847717285\n",
      "Epoch:58  accuracy:60.84243369734789  loss:1.2060872316360474\n",
      "Epoch:59  accuracy:59.28237129485179  loss:1.2310887575149536\n",
      "Epoch:60  accuracy:61.62246489859594  loss:1.2190983295440674\n",
      "Epoch:61  accuracy:59.59438377535101  loss:1.26871657371521\n",
      "Epoch:62  accuracy:61.93447737909516  loss:1.1886271238327026\n",
      "Epoch:63  accuracy:61.31045241809672  loss:1.1662005186080933\n",
      "Epoch:64  accuracy:60.53042121684867  loss:1.1920640468597412\n",
      "Epoch:65  accuracy:62.246489859594384  loss:1.1531363725662231\n",
      "Epoch:66  accuracy:61.77847113884555  loss:1.1845040321350098\n",
      "Epoch:67  accuracy:57.72230889235569  loss:1.294337511062622\n",
      "Epoch:68  accuracy:60.37441497659906  loss:1.197536826133728\n",
      "Epoch:69  accuracy:61.77847113884555  loss:1.1456756591796875\n",
      "Epoch:70  accuracy:59.59438377535101  loss:1.2185766696929932\n",
      "Epoch:71  accuracy:64.58658346333853  loss:1.1407206058502197\n",
      "Epoch:72  accuracy:63.182527301092044  loss:1.1205049753189087\n",
      "Epoch:73  accuracy:64.58658346333853  loss:1.1218997240066528\n",
      "Epoch:74  accuracy:62.402496099843994  loss:1.1201108694076538\n",
      "Epoch:75  accuracy:64.1185647425897  loss:1.1216683387756348\n",
      "Epoch:76  accuracy:61.62246489859594  loss:1.1972894668579102\n",
      "Epoch:77  accuracy:63.494539781591264  loss:1.1198546886444092\n",
      "Epoch:78  accuracy:64.74258970358814  loss:1.072174072265625\n",
      "Epoch:79  accuracy:62.402496099843994  loss:1.104723334312439\n",
      "Epoch:80  accuracy:62.246489859594384  loss:1.10844087600708\n",
      "Epoch:81  accuracy:65.36661466458658  loss:1.0738158226013184\n",
      "Epoch:82  accuracy:64.43057722308892  loss:1.1804254055023193\n",
      "Epoch:83  accuracy:64.58658346333853  loss:1.0933812856674194\n",
      "Epoch:84  accuracy:64.89859594383775  loss:1.0799561738967896\n",
      "Epoch:85  accuracy:64.1185647425897  loss:1.1137335300445557\n",
      "Epoch:86  accuracy:64.43057722308892  loss:1.1439944505691528\n",
      "Epoch:87  accuracy:61.62246489859594  loss:1.095916748046875\n",
      "Epoch:88  accuracy:63.806552262090484  loss:1.115282416343689\n",
      "Epoch:89  accuracy:63.494539781591264  loss:1.0889700651168823\n",
      "Early Stop\n",
      "Worker2 start\n",
      "Epoch:1  accuracy:60.58091286307054  loss:1.4054949283599854\n",
      "Epoch:2  accuracy:60.58091286307054  loss:1.1938711404800415\n",
      "Epoch:3  accuracy:60.58091286307054  loss:1.2173491716384888\n",
      "Epoch:4  accuracy:60.58091286307054  loss:1.236772060394287\n",
      "Epoch:5  accuracy:60.58091286307054  loss:1.16379976272583\n",
      "Epoch:6  accuracy:60.58091286307054  loss:1.155593991279602\n",
      "Epoch:7  accuracy:60.58091286307054  loss:1.132796049118042\n",
      "Epoch:8  accuracy:60.58091286307054  loss:1.124917984008789\n",
      "Epoch:9  accuracy:60.58091286307054  loss:1.140169620513916\n",
      "Epoch:10  accuracy:60.58091286307054  loss:1.1369518041610718\n",
      "Epoch:11  accuracy:60.58091286307054  loss:1.1507163047790527\n",
      "Epoch:12  accuracy:60.58091286307054  loss:1.1198785305023193\n",
      "Epoch:13  accuracy:60.58091286307054  loss:1.1639690399169922\n",
      "Epoch:14  accuracy:60.58091286307054  loss:1.1412196159362793\n",
      "Epoch:15  accuracy:60.58091286307054  loss:1.0997405052185059\n",
      "Epoch:16  accuracy:60.58091286307054  loss:1.1303203105926514\n",
      "Epoch:17  accuracy:60.995850622406635  loss:1.0723145008087158\n",
      "Epoch:18  accuracy:60.995850622406635  loss:1.0730531215667725\n",
      "Epoch:19  accuracy:63.07053941908714  loss:1.0618237257003784\n",
      "Epoch:20  accuracy:66.80497925311204  loss:1.0099899768829346\n",
      "Epoch:21  accuracy:69.08713692946058  loss:0.96666419506073\n",
      "Epoch:22  accuracy:71.57676348547717  loss:0.9899483919143677\n",
      "Epoch:23  accuracy:73.23651452282158  loss:0.9495341777801514\n",
      "Epoch:24  accuracy:73.02904564315352  loss:0.9352792501449585\n",
      "Epoch:25  accuracy:73.44398340248962  loss:0.8505814075469971\n",
      "Epoch:26  accuracy:73.44398340248962  loss:0.8437609076499939\n",
      "Epoch:27  accuracy:73.85892116182572  loss:0.8218534588813782\n",
      "Epoch:28  accuracy:73.85892116182572  loss:0.8862468004226685\n",
      "Epoch:29  accuracy:73.85892116182572  loss:0.8044707179069519\n",
      "Epoch:30  accuracy:74.27385892116183  loss:0.7919009923934937\n",
      "Epoch:31  accuracy:75.10373443983403  loss:0.7868927717208862\n",
      "Epoch:32  accuracy:75.10373443983403  loss:0.7707856893539429\n",
      "Epoch:33  accuracy:76.76348547717842  loss:0.7778257727622986\n",
      "Epoch:34  accuracy:75.10373443983403  loss:0.7627429366111755\n",
      "Epoch:35  accuracy:75.10373443983403  loss:0.7362756729125977\n",
      "Epoch:36  accuracy:75.93360995850622  loss:0.7386975288391113\n",
      "Epoch:37  accuracy:75.51867219917013  loss:0.7405558228492737\n",
      "Epoch:38  accuracy:74.89626556016597  loss:0.772148072719574\n",
      "Epoch:39  accuracy:76.14107883817428  loss:0.7229093313217163\n",
      "Epoch:40  accuracy:75.93360995850622  loss:0.7251630425453186\n",
      "Epoch:41  accuracy:77.17842323651452  loss:0.6957438588142395\n",
      "Epoch:42  accuracy:69.08713692946058  loss:0.8926182389259338\n",
      "Epoch:43  accuracy:74.89626556016597  loss:0.7286621928215027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:44  accuracy:78.21576763485477  loss:0.6721742153167725\n",
      "Epoch:45  accuracy:76.14107883817428  loss:0.6861302256584167\n",
      "Epoch:46  accuracy:76.55601659751038  loss:0.6868011355400085\n",
      "Epoch:47  accuracy:75.10373443983403  loss:0.7324874401092529\n",
      "Epoch:48  accuracy:75.93360995850622  loss:0.6983755230903625\n",
      "Epoch:49  accuracy:78.00829875518673  loss:0.6562207937240601\n",
      "Epoch:50  accuracy:77.38589211618257  loss:0.6823397278785706\n",
      "Epoch:51  accuracy:77.17842323651452  loss:0.6577373743057251\n",
      "Epoch:52  accuracy:76.55601659751038  loss:0.6865141987800598\n",
      "Epoch:53  accuracy:75.72614107883817  loss:0.7130341529846191\n",
      "Epoch:54  accuracy:76.97095435684648  loss:0.6708306670188904\n",
      "Epoch:55  accuracy:73.85892116182572  loss:0.7311116456985474\n",
      "Epoch:56  accuracy:77.17842323651452  loss:0.6728253960609436\n",
      "Epoch:57  accuracy:77.17842323651452  loss:0.6518771052360535\n",
      "Epoch:58  accuracy:78.63070539419087  loss:0.6455055475234985\n",
      "Epoch:59  accuracy:76.55601659751038  loss:0.7007463574409485\n",
      "Epoch:60  accuracy:78.42323651452283  loss:0.6299917101860046\n",
      "Epoch:61  accuracy:79.25311203319502  loss:0.6249363422393799\n",
      "Epoch:62  accuracy:79.25311203319502  loss:0.6508172154426575\n",
      "Epoch:63  accuracy:78.42323651452283  loss:0.6240801215171814\n",
      "Epoch:64  accuracy:78.63070539419087  loss:0.649696409702301\n",
      "Epoch:65  accuracy:79.25311203319502  loss:0.6206984519958496\n",
      "Epoch:66  accuracy:79.04564315352697  loss:0.6239662766456604\n",
      "Epoch:67  accuracy:79.46058091286307  loss:0.6352381706237793\n",
      "Epoch:68  accuracy:79.25311203319502  loss:0.618632972240448\n",
      "Epoch:69  accuracy:79.46058091286307  loss:0.6274058818817139\n",
      "Epoch:70  accuracy:76.97095435684648  loss:0.6767411231994629\n",
      "Epoch:71  accuracy:80.08298755186722  loss:0.6704244613647461\n",
      "Epoch:72  accuracy:79.46058091286307  loss:0.601067304611206\n",
      "Epoch:73  accuracy:79.66804979253112  loss:0.6099991798400879\n",
      "Epoch:74  accuracy:76.76348547717842  loss:0.6620249152183533\n",
      "Epoch:75  accuracy:79.87551867219916  loss:0.6260073781013489\n",
      "Epoch:76  accuracy:80.08298755186722  loss:0.6453086137771606\n",
      "Epoch:77  accuracy:81.95020746887967  loss:0.5834212303161621\n",
      "Epoch:78  accuracy:81.74273858921161  loss:0.5897184014320374\n",
      "Epoch:79  accuracy:81.12033195020747  loss:0.6171379685401917\n",
      "Epoch:80  accuracy:79.87551867219916  loss:0.6606763601303101\n",
      "Epoch:81  accuracy:80.91286307053942  loss:0.6233417987823486\n",
      "Epoch:82  accuracy:80.08298755186722  loss:0.6432603001594543\n",
      "Epoch:83  accuracy:81.32780082987551  loss:0.6172665953636169\n",
      "Epoch:84  accuracy:80.91286307053942  loss:0.6040380597114563\n",
      "Epoch:85  accuracy:81.53526970954357  loss:0.5874185562133789\n",
      "Epoch:86  accuracy:81.74273858921161  loss:0.5984757542610168\n",
      "Epoch:87  accuracy:81.12033195020747  loss:0.585704505443573\n",
      "Epoch:88  accuracy:81.53526970954357  loss:0.5783869028091431\n",
      "Epoch:89  accuracy:81.32780082987551  loss:0.5918291211128235\n",
      "Epoch:90  accuracy:82.15767634854772  loss:0.5746608972549438\n",
      "Epoch:91  accuracy:82.98755186721992  loss:0.598593533039093\n",
      "Epoch:92  accuracy:82.36514522821577  loss:0.5733943581581116\n",
      "Epoch:93  accuracy:81.53526970954357  loss:0.6049319505691528\n",
      "Epoch:94  accuracy:82.78008298755186  loss:0.5784432888031006\n",
      "Epoch:95  accuracy:83.19502074688796  loss:0.5632542371749878\n",
      "Epoch:96  accuracy:83.40248962655602  loss:0.5890043377876282\n",
      "Epoch:97  accuracy:80.49792531120332  loss:0.6057047247886658\n",
      "Epoch:98  accuracy:82.57261410788382  loss:0.6365457773208618\n",
      "Epoch:99  accuracy:83.60995850622406  loss:0.5517120361328125\n",
      "Epoch:100  accuracy:82.36514522821577  loss:0.5592319965362549\n",
      "Epoch:101  accuracy:83.19502074688796  loss:0.5786730051040649\n",
      "Epoch:102  accuracy:82.98755186721992  loss:0.5570661425590515\n",
      "Epoch:103  accuracy:82.98755186721992  loss:0.5802315473556519\n",
      "Epoch:104  accuracy:83.40248962655602  loss:0.5922278165817261\n",
      "Epoch:105  accuracy:83.81742738589212  loss:0.5931807160377502\n",
      "Epoch:106  accuracy:80.49792531120332  loss:0.5991727709770203\n",
      "Epoch:107  accuracy:82.15767634854772  loss:0.6604971289634705\n",
      "Epoch:108  accuracy:82.15767634854772  loss:0.576564610004425\n",
      "Epoch:109  accuracy:84.85477178423237  loss:0.5728392004966736\n",
      "Epoch:110  accuracy:82.78008298755186  loss:0.6372249722480774\n",
      "Early Stop\n",
      "Worker3 start\n",
      "Epoch:1  accuracy:43.75  loss:2.192838668823242\n",
      "Epoch:2  accuracy:43.75  loss:1.735729694366455\n",
      "Epoch:3  accuracy:43.75  loss:1.691295862197876\n",
      "Epoch:4  accuracy:43.75  loss:1.667793869972229\n",
      "Epoch:5  accuracy:43.75  loss:1.687636375427246\n",
      "Epoch:6  accuracy:43.75  loss:1.6470580101013184\n",
      "Epoch:7  accuracy:43.75  loss:1.6519336700439453\n",
      "Epoch:8  accuracy:43.75  loss:1.6251740455627441\n",
      "Epoch:9  accuracy:43.75  loss:1.6159874200820923\n",
      "Epoch:10  accuracy:43.75  loss:1.6058907508850098\n",
      "Epoch:11  accuracy:43.9453125  loss:1.5833942890167236\n",
      "Epoch:12  accuracy:44.3359375  loss:1.5620002746582031\n",
      "Epoch:13  accuracy:47.0703125  loss:1.5527193546295166\n",
      "Epoch:14  accuracy:47.4609375  loss:1.5090956687927246\n",
      "Epoch:15  accuracy:51.3671875  loss:1.4958970546722412\n",
      "Epoch:16  accuracy:55.078125  loss:1.4781262874603271\n",
      "Epoch:17  accuracy:57.421875  loss:1.4780077934265137\n",
      "Epoch:18  accuracy:58.0078125  loss:1.4326581954956055\n",
      "Epoch:19  accuracy:57.6171875  loss:1.3866701126098633\n",
      "Epoch:20  accuracy:57.8125  loss:1.3592857122421265\n",
      "Epoch:21  accuracy:55.46875  loss:1.392569899559021\n",
      "Epoch:22  accuracy:57.2265625  loss:1.3317594528198242\n",
      "Epoch:23  accuracy:57.6171875  loss:1.3370941877365112\n",
      "Epoch:24  accuracy:57.8125  loss:1.3001035451889038\n",
      "Epoch:25  accuracy:57.6171875  loss:1.3514410257339478\n",
      "Epoch:26  accuracy:58.3984375  loss:1.2846111059188843\n",
      "Epoch:27  accuracy:57.8125  loss:1.3214390277862549\n",
      "Epoch:28  accuracy:58.203125  loss:1.278200387954712\n",
      "Epoch:29  accuracy:57.8125  loss:1.2660443782806396\n",
      "Epoch:30  accuracy:57.8125  loss:1.254374384880066\n",
      "Epoch:31  accuracy:58.203125  loss:1.2478793859481812\n",
      "Epoch:32  accuracy:59.1796875  loss:1.244545340538025\n",
      "Epoch:33  accuracy:58.3984375  loss:1.245440125465393\n",
      "Epoch:34  accuracy:57.6171875  loss:1.2839343547821045\n",
      "Epoch:35  accuracy:58.3984375  loss:1.2309234142303467\n",
      "Epoch:36  accuracy:58.203125  loss:1.2404382228851318\n",
      "Epoch:37  accuracy:58.3984375  loss:1.2985929250717163\n",
      "Epoch:38  accuracy:59.1796875  loss:1.2463171482086182\n",
      "Epoch:39  accuracy:59.1796875  loss:1.2570157051086426\n",
      "Epoch:40  accuracy:59.375  loss:1.212708830833435\n",
      "Epoch:41  accuracy:58.7890625  loss:1.2917346954345703\n",
      "Epoch:42  accuracy:59.1796875  loss:1.223445177078247\n",
      "Epoch:43  accuracy:59.1796875  loss:1.2325295209884644\n",
      "Epoch:44  accuracy:59.5703125  loss:1.2196084260940552\n",
      "Epoch:45  accuracy:58.984375  loss:1.2017067670822144\n",
      "Epoch:46  accuracy:58.3984375  loss:1.2810308933258057\n",
      "Epoch:47  accuracy:59.5703125  loss:1.2273932695388794\n",
      "Epoch:48  accuracy:59.375  loss:1.2143114805221558\n",
      "Epoch:49  accuracy:59.375  loss:1.2265969514846802\n",
      "Epoch:50  accuracy:60.15625  loss:1.1767843961715698\n",
      "Epoch:51  accuracy:60.546875  loss:1.1761443614959717\n",
      "Epoch:52  accuracy:60.3515625  loss:1.1711931228637695\n",
      "Epoch:53  accuracy:60.546875  loss:1.1857454776763916\n",
      "Epoch:54  accuracy:59.9609375  loss:1.1748496294021606\n",
      "Epoch:55  accuracy:60.15625  loss:1.2161965370178223\n",
      "Epoch:56  accuracy:60.15625  loss:1.1970587968826294\n",
      "Epoch:57  accuracy:60.7421875  loss:1.1661770343780518\n",
      "Epoch:58  accuracy:59.765625  loss:1.1603763103485107\n",
      "Epoch:59  accuracy:59.1796875  loss:1.1824394464492798\n",
      "Epoch:60  accuracy:62.109375  loss:1.1517337560653687\n",
      "Epoch:61  accuracy:60.7421875  loss:1.1534531116485596\n",
      "Epoch:62  accuracy:62.3046875  loss:1.13689386844635\n",
      "Epoch:63  accuracy:59.375  loss:1.202175259590149\n",
      "Epoch:64  accuracy:61.9140625  loss:1.1271584033966064\n",
      "Epoch:65  accuracy:60.15625  loss:1.1889595985412598\n",
      "Epoch:66  accuracy:61.328125  loss:1.16859769821167\n",
      "Epoch:67  accuracy:61.1328125  loss:1.1621354818344116\n",
      "Epoch:68  accuracy:63.0859375  loss:1.1318371295928955\n",
      "Epoch:69  accuracy:64.84375  loss:1.096820592880249\n",
      "Epoch:70  accuracy:65.0390625  loss:1.135130524635315\n",
      "Epoch:71  accuracy:64.453125  loss:1.1344542503356934\n",
      "Epoch:72  accuracy:66.015625  loss:1.1051700115203857\n",
      "Epoch:73  accuracy:65.0390625  loss:1.1040639877319336\n",
      "Epoch:74  accuracy:65.8203125  loss:1.08766770362854\n",
      "Epoch:75  accuracy:65.8203125  loss:1.092935562133789\n",
      "Epoch:76  accuracy:63.4765625  loss:1.1218774318695068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:77  accuracy:66.015625  loss:1.0796821117401123\n",
      "Epoch:78  accuracy:66.6015625  loss:1.0692459344863892\n",
      "Epoch:79  accuracy:66.6015625  loss:1.063986897468567\n",
      "Epoch:80  accuracy:66.2109375  loss:1.060705542564392\n",
      "Epoch:81  accuracy:64.84375  loss:1.0974315404891968\n",
      "Epoch:82  accuracy:67.1875  loss:1.0692484378814697\n",
      "Epoch:83  accuracy:64.0625  loss:1.093552827835083\n",
      "Epoch:84  accuracy:65.0390625  loss:1.1239569187164307\n",
      "Epoch:85  accuracy:66.015625  loss:1.1100894212722778\n",
      "Epoch:86  accuracy:64.6484375  loss:1.1079164743423462\n",
      "Epoch:87  accuracy:64.84375  loss:1.1014788150787354\n",
      "Epoch:88  accuracy:66.2109375  loss:1.0760153532028198\n",
      "Epoch:89  accuracy:64.6484375  loss:1.0477863550186157\n",
      "Epoch:90  accuracy:67.3828125  loss:1.078123927116394\n",
      "Epoch:91  accuracy:67.578125  loss:1.0270754098892212\n",
      "Epoch:92  accuracy:66.015625  loss:1.0228915214538574\n",
      "Epoch:93  accuracy:66.015625  loss:1.0511009693145752\n",
      "Epoch:94  accuracy:68.1640625  loss:1.066896915435791\n",
      "Epoch:95  accuracy:68.1640625  loss:1.0319268703460693\n",
      "Epoch:96  accuracy:65.8203125  loss:1.0263819694519043\n",
      "Epoch:97  accuracy:67.3828125  loss:1.0092378854751587\n",
      "Epoch:98  accuracy:68.359375  loss:1.0017277002334595\n",
      "Epoch:99  accuracy:66.015625  loss:1.124896764755249\n",
      "Epoch:100  accuracy:68.1640625  loss:1.0014445781707764\n",
      "Epoch:101  accuracy:68.1640625  loss:0.997197151184082\n",
      "Epoch:102  accuracy:67.96875  loss:1.019058346748352\n",
      "Epoch:103  accuracy:67.1875  loss:0.9970827698707581\n",
      "Epoch:104  accuracy:66.015625  loss:1.0186280012130737\n",
      "Epoch:105  accuracy:66.796875  loss:0.9983230829238892\n",
      "Epoch:106  accuracy:67.3828125  loss:0.9943152070045471\n",
      "Epoch:107  accuracy:67.578125  loss:0.9931046962738037\n",
      "Epoch:108  accuracy:65.4296875  loss:1.0899460315704346\n",
      "Epoch:109  accuracy:64.453125  loss:1.0084482431411743\n",
      "Epoch:110  accuracy:67.7734375  loss:1.040584921836853\n",
      "Epoch:111  accuracy:66.9921875  loss:1.0904394388198853\n",
      "Epoch:112  accuracy:67.1875  loss:0.9977535009384155\n",
      "Epoch:113  accuracy:66.40625  loss:1.0608549118041992\n",
      "Epoch:114  accuracy:69.140625  loss:1.041611671447754\n",
      "Epoch:115  accuracy:63.0859375  loss:1.124451756477356\n",
      "Epoch:116  accuracy:67.96875  loss:1.037723183631897\n",
      "Epoch:117  accuracy:68.1640625  loss:1.0417442321777344\n",
      "Epoch:118  accuracy:67.1875  loss:1.0195380449295044\n",
      "Early Stop\n",
      "Worker4 start\n",
      "Epoch:1  accuracy:57.37373737373738  loss:2.0822670459747314\n",
      "Epoch:2  accuracy:57.37373737373738  loss:1.3360713720321655\n",
      "Epoch:3  accuracy:57.37373737373738  loss:1.2039793729782104\n",
      "Epoch:4  accuracy:57.37373737373738  loss:1.194712519645691\n",
      "Epoch:5  accuracy:57.37373737373738  loss:1.1656137704849243\n",
      "Epoch:6  accuracy:57.37373737373738  loss:1.1496409177780151\n",
      "Epoch:7  accuracy:57.37373737373738  loss:1.1528465747833252\n",
      "Epoch:8  accuracy:57.37373737373738  loss:1.1399558782577515\n",
      "Epoch:9  accuracy:57.37373737373738  loss:1.1423956155776978\n",
      "Epoch:10  accuracy:57.37373737373738  loss:1.1073296070098877\n",
      "Epoch:11  accuracy:57.37373737373738  loss:1.1004050970077515\n",
      "Epoch:12  accuracy:57.37373737373738  loss:1.126046895980835\n",
      "Epoch:13  accuracy:57.37373737373738  loss:1.1496050357818604\n",
      "Epoch:14  accuracy:57.37373737373738  loss:1.0894519090652466\n",
      "Epoch:15  accuracy:57.57575757575758  loss:1.1180098056793213\n",
      "Epoch:16  accuracy:57.37373737373738  loss:1.085607886314392\n",
      "Epoch:17  accuracy:57.57575757575758  loss:1.0671466588974\n",
      "Epoch:18  accuracy:58.38383838383838  loss:1.0568699836730957\n",
      "Epoch:19  accuracy:62.02020202020202  loss:1.0752662420272827\n",
      "Epoch:20  accuracy:63.23232323232323  loss:1.0692124366760254\n",
      "Epoch:21  accuracy:62.62626262626262  loss:1.0574194192886353\n",
      "Epoch:22  accuracy:64.04040404040404  loss:1.095971703529358\n",
      "Epoch:23  accuracy:63.23232323232323  loss:1.0254091024398804\n",
      "Epoch:24  accuracy:64.44444444444444  loss:1.033883810043335\n",
      "Epoch:25  accuracy:64.04040404040404  loss:1.0086326599121094\n",
      "Epoch:26  accuracy:64.44444444444444  loss:0.9991792440414429\n",
      "Epoch:27  accuracy:65.25252525252525  loss:0.9938420057296753\n",
      "Epoch:28  accuracy:66.26262626262626  loss:0.965868353843689\n",
      "Epoch:29  accuracy:66.06060606060606  loss:0.9875345826148987\n",
      "Epoch:30  accuracy:67.07070707070707  loss:0.9431817531585693\n",
      "Epoch:31  accuracy:67.07070707070707  loss:0.943507969379425\n",
      "Epoch:32  accuracy:67.27272727272727  loss:0.9179409742355347\n",
      "Epoch:33  accuracy:68.48484848484848  loss:0.9041799306869507\n",
      "Epoch:34  accuracy:66.26262626262626  loss:0.924672544002533\n",
      "Epoch:35  accuracy:68.28282828282828  loss:0.8983832001686096\n",
      "Epoch:36  accuracy:68.28282828282828  loss:0.9077906608581543\n",
      "Epoch:37  accuracy:67.07070707070707  loss:0.8838179111480713\n",
      "Epoch:38  accuracy:62.22222222222222  loss:1.0740208625793457\n",
      "Epoch:39  accuracy:67.07070707070707  loss:0.8946699500083923\n",
      "Epoch:40  accuracy:68.48484848484848  loss:0.8721174597740173\n",
      "Epoch:41  accuracy:67.47474747474747  loss:0.9612616300582886\n",
      "Epoch:42  accuracy:66.66666666666667  loss:0.9240966439247131\n",
      "Epoch:43  accuracy:67.47474747474747  loss:0.8796719312667847\n",
      "Epoch:44  accuracy:67.27272727272727  loss:0.8792708516120911\n",
      "Epoch:45  accuracy:68.28282828282828  loss:0.8522761464118958\n",
      "Epoch:46  accuracy:68.68686868686869  loss:0.8418006300926208\n",
      "Epoch:47  accuracy:65.05050505050505  loss:0.8824952840805054\n",
      "Epoch:48  accuracy:67.27272727272727  loss:0.836417555809021\n",
      "Epoch:49  accuracy:68.88888888888889  loss:0.8303768634796143\n",
      "Epoch:50  accuracy:68.88888888888889  loss:0.8128064870834351\n",
      "Epoch:51  accuracy:67.67676767676768  loss:0.8240143060684204\n",
      "Epoch:52  accuracy:69.0909090909091  loss:0.828476071357727\n",
      "Epoch:53  accuracy:68.48484848484848  loss:0.7905504107475281\n",
      "Epoch:54  accuracy:69.29292929292929  loss:0.8311225771903992\n",
      "Epoch:55  accuracy:68.48484848484848  loss:0.8182693719863892\n",
      "Epoch:56  accuracy:68.08080808080808  loss:0.8400053381919861\n",
      "Epoch:57  accuracy:68.08080808080808  loss:0.8228862285614014\n",
      "Epoch:58  accuracy:69.6969696969697  loss:0.7904881834983826\n",
      "Epoch:59  accuracy:69.6969696969697  loss:0.7662046551704407\n",
      "Epoch:60  accuracy:71.71717171717172  loss:0.7637304067611694\n",
      "Epoch:61  accuracy:70.70707070707071  loss:0.7726200222969055\n",
      "Epoch:62  accuracy:71.31313131313131  loss:0.7793790698051453\n",
      "Epoch:63  accuracy:70.70707070707071  loss:0.7821195721626282\n",
      "Epoch:64  accuracy:71.71717171717172  loss:0.7725456357002258\n",
      "Epoch:65  accuracy:70.5050505050505  loss:0.8252289891242981\n",
      "Epoch:66  accuracy:71.11111111111111  loss:0.7500510215759277\n",
      "Epoch:67  accuracy:69.6969696969697  loss:0.8205450773239136\n",
      "Epoch:68  accuracy:71.31313131313131  loss:0.744992733001709\n",
      "Epoch:69  accuracy:72.32323232323232  loss:0.751675009727478\n",
      "Epoch:70  accuracy:72.72727272727273  loss:0.7362657785415649\n",
      "Epoch:71  accuracy:71.71717171717172  loss:0.7510390281677246\n",
      "Epoch:72  accuracy:71.91919191919192  loss:0.7671430706977844\n",
      "Epoch:73  accuracy:71.91919191919192  loss:0.7378039956092834\n",
      "Epoch:74  accuracy:73.33333333333333  loss:0.7619996070861816\n",
      "Epoch:75  accuracy:73.33333333333333  loss:0.7258406281471252\n",
      "Epoch:76  accuracy:72.72727272727273  loss:0.7416499853134155\n",
      "Epoch:77  accuracy:72.12121212121212  loss:0.7512003779411316\n",
      "Epoch:78  accuracy:74.54545454545455  loss:0.7053348422050476\n",
      "Epoch:79  accuracy:71.51515151515152  loss:0.8142984509468079\n",
      "Epoch:80  accuracy:73.73737373737374  loss:0.7180957794189453\n",
      "Epoch:81  accuracy:74.94949494949495  loss:0.7099610567092896\n",
      "Epoch:82  accuracy:73.93939393939394  loss:0.733533501625061\n",
      "Epoch:83  accuracy:74.34343434343434  loss:0.700929582118988\n",
      "Epoch:84  accuracy:73.73737373737374  loss:0.7339301705360413\n",
      "Epoch:85  accuracy:73.13131313131314  loss:0.7723445892333984\n",
      "Epoch:86  accuracy:74.94949494949495  loss:0.7217018604278564\n",
      "Epoch:87  accuracy:75.55555555555556  loss:0.7138493061065674\n",
      "Epoch:88  accuracy:75.55555555555556  loss:0.7009166479110718\n",
      "Epoch:89  accuracy:73.13131313131314  loss:0.7886255979537964\n",
      "Epoch:90  accuracy:76.36363636363636  loss:0.7310723066329956\n",
      "Epoch:91  accuracy:75.95959595959596  loss:0.7115215063095093\n",
      "Epoch:92  accuracy:76.56565656565657  loss:0.7216552495956421\n",
      "Epoch:93  accuracy:73.13131313131314  loss:0.7865404486656189\n",
      "Epoch:94  accuracy:77.37373737373737  loss:0.6865794062614441\n",
      "Epoch:95  accuracy:76.76767676767676  loss:0.6834612488746643\n",
      "Epoch:96  accuracy:78.38383838383838  loss:0.6970488429069519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:97  accuracy:76.36363636363636  loss:0.7206814289093018\n",
      "Epoch:98  accuracy:76.16161616161617  loss:0.6908677816390991\n",
      "Epoch:99  accuracy:78.38383838383838  loss:0.6671943664550781\n",
      "Epoch:100  accuracy:77.77777777777777  loss:0.7139940857887268\n",
      "Epoch:101  accuracy:76.16161616161617  loss:0.7034269571304321\n",
      "Epoch:102  accuracy:77.17171717171718  loss:0.6964133381843567\n",
      "Epoch:103  accuracy:75.35353535353535  loss:0.7190980911254883\n",
      "Epoch:104  accuracy:79.1919191919192  loss:0.6914488077163696\n",
      "Epoch:105  accuracy:72.32323232323232  loss:0.8140285015106201\n",
      "Epoch:106  accuracy:77.17171717171718  loss:0.6728538274765015\n",
      "Epoch:107  accuracy:76.96969696969697  loss:0.7620608806610107\n",
      "Epoch:108  accuracy:73.13131313131314  loss:0.8237523436546326\n",
      "Epoch:109  accuracy:79.1919191919192  loss:0.6932880282402039\n",
      "Epoch:110  accuracy:77.17171717171718  loss:0.7048206925392151\n",
      "Early Stop\n",
      "Worker5 start\n",
      "Epoch:1  accuracy:20.916334661354583  loss:2.1272647380828857\n",
      "Epoch:2  accuracy:25.99601593625498  loss:1.612458050251007\n",
      "Epoch:3  accuracy:20.916334661354583  loss:1.6792614459991455\n",
      "Epoch:4  accuracy:20.916334661354583  loss:1.6259106993675232\n",
      "Epoch:5  accuracy:29.58167330677291  loss:1.6837257742881775\n",
      "Epoch:6  accuracy:34.462151394422314  loss:1.7046354413032532\n",
      "Epoch:7  accuracy:39.8406374501992  loss:1.610309898853302\n",
      "Epoch:8  accuracy:33.66533864541832  loss:1.6035776734352112\n",
      "Epoch:9  accuracy:34.9601593625498  loss:1.5946629643440247\n",
      "Epoch:10  accuracy:39.8406374501992  loss:1.4936874508857727\n",
      "Epoch:11  accuracy:43.72509960159363  loss:1.426985740661621\n",
      "Epoch:12  accuracy:45.1195219123506  loss:1.2536316514015198\n",
      "Epoch:13  accuracy:49.20318725099602  loss:1.2544992566108704\n",
      "Epoch:14  accuracy:49.701195219123505  loss:1.280402421951294\n",
      "Epoch:15  accuracy:50.99601593625498  loss:1.2208164930343628\n",
      "Epoch:16  accuracy:49.800796812749006  loss:1.4296517968177795\n",
      "Epoch:17  accuracy:51.19521912350598  loss:1.1819868087768555\n",
      "Epoch:18  accuracy:52.49003984063745  loss:1.1429595947265625\n",
      "Epoch:19  accuracy:52.88844621513944  loss:1.088692992925644\n",
      "Epoch:20  accuracy:52.788844621513945  loss:1.180663526058197\n",
      "Epoch:21  accuracy:54.78087649402391  loss:1.0848222374916077\n",
      "Epoch:22  accuracy:53.78486055776892  loss:1.0187854766845703\n",
      "Epoch:23  accuracy:54.48207171314741  loss:0.9587568938732147\n",
      "Epoch:24  accuracy:57.07171314741036  loss:1.0545916557312012\n",
      "Epoch:25  accuracy:56.77290836653386  loss:1.0626370310783386\n",
      "Epoch:26  accuracy:57.569721115537845  loss:1.019924819469452\n",
      "Epoch:27  accuracy:58.167330677290835  loss:0.9236637651920319\n",
      "Epoch:28  accuracy:58.266932270916335  loss:1.1108437180519104\n",
      "Epoch:29  accuracy:57.37051792828685  loss:0.887514054775238\n",
      "Epoch:30  accuracy:60.45816733067729  loss:0.8116329312324524\n",
      "Epoch:31  accuracy:59.26294820717131  loss:0.9983142912387848\n",
      "Epoch:32  accuracy:61.852589641434264  loss:0.9175974130630493\n",
      "Epoch:33  accuracy:61.55378486055777  loss:0.9907887279987335\n",
      "Epoch:34  accuracy:60.756972111553786  loss:0.9975889623165131\n",
      "Epoch:35  accuracy:61.45418326693227  loss:1.0400322079658508\n",
      "Epoch:36  accuracy:63.04780876494024  loss:0.8580797612667084\n",
      "Epoch:37  accuracy:63.04780876494024  loss:0.9993784129619598\n",
      "Epoch:38  accuracy:64.54183266932272  loss:0.7905919849872589\n",
      "Epoch:39  accuracy:63.745019920318725  loss:0.8175368309020996\n",
      "Epoch:40  accuracy:65.63745019920319  loss:0.8962852954864502\n",
      "Epoch:41  accuracy:65.5378486055777  loss:0.7331599593162537\n",
      "Epoch:42  accuracy:65.43824701195219  loss:0.7393461167812347\n",
      "Epoch:43  accuracy:63.844621513944226  loss:1.0020509958267212\n",
      "Epoch:44  accuracy:69.02390438247012  loss:0.8154413998126984\n",
      "Epoch:45  accuracy:66.63346613545816  loss:1.0979554951190948\n",
      "Epoch:46  accuracy:68.82470119521912  loss:0.6550692319869995\n",
      "Epoch:47  accuracy:69.02390438247012  loss:0.9657942354679108\n",
      "Epoch:48  accuracy:67.62948207171314  loss:0.7845270335674286\n",
      "Epoch:49  accuracy:70.3187250996016  loss:0.6680576801300049\n",
      "Epoch:50  accuracy:70.61752988047809  loss:0.6405911296606064\n",
      "Epoch:51  accuracy:69.42231075697211  loss:0.724056750535965\n",
      "Epoch:52  accuracy:70.11952191235059  loss:0.6042405068874359\n",
      "Epoch:53  accuracy:71.81274900398407  loss:0.6026728600263596\n",
      "Epoch:54  accuracy:71.81274900398407  loss:0.7400936782360077\n",
      "Epoch:55  accuracy:71.51394422310757  loss:0.7213180363178253\n",
      "Epoch:56  accuracy:73.60557768924303  loss:0.559830904006958\n",
      "Epoch:57  accuracy:71.61354581673307  loss:1.060551404953003\n",
      "Epoch:58  accuracy:72.01195219123505  loss:1.1458520889282227\n",
      "Epoch:59  accuracy:74.00398406374502  loss:0.8799859583377838\n",
      "Epoch:60  accuracy:72.70916334661355  loss:0.6710857152938843\n",
      "Epoch:61  accuracy:70.71713147410358  loss:0.7673105597496033\n",
      "Epoch:62  accuracy:73.60557768924303  loss:0.6840934455394745\n",
      "Epoch:63  accuracy:74.00398406374502  loss:0.6612968444824219\n",
      "Epoch:64  accuracy:73.20717131474103  loss:0.5063165128231049\n",
      "Epoch:65  accuracy:73.90438247011951  loss:0.5184680372476578\n",
      "Epoch:66  accuracy:74.10358565737052  loss:0.5636628866195679\n",
      "Epoch:67  accuracy:75.39840637450199  loss:0.6361070871353149\n",
      "Epoch:68  accuracy:73.50597609561753  loss:0.47550614178180695\n",
      "Epoch:69  accuracy:71.51394422310757  loss:0.6428105533123016\n",
      "Epoch:70  accuracy:75.0996015936255  loss:0.7717809081077576\n",
      "Epoch:71  accuracy:74.5019920318725  loss:0.6729507744312286\n",
      "Epoch:72  accuracy:72.50996015936255  loss:0.7307019829750061\n",
      "Epoch:73  accuracy:73.50597609561753  loss:0.7375912964344025\n",
      "Epoch:74  accuracy:75.89641434262948  loss:0.7609811127185822\n",
      "Epoch:75  accuracy:74.10358565737052  loss:0.5527300834655762\n",
      "Epoch:76  accuracy:75.99601593625498  loss:0.6347850263118744\n",
      "Epoch:77  accuracy:75.0996015936255  loss:0.43312492221593857\n",
      "Epoch:78  accuracy:77.88844621513944  loss:0.5943704694509506\n",
      "Epoch:79  accuracy:75.89641434262948  loss:0.5352230966091156\n",
      "Epoch:80  accuracy:76.29482071713147  loss:0.4584188610315323\n",
      "Epoch:81  accuracy:75.0996015936255  loss:0.5278293490409851\n",
      "Epoch:82  accuracy:76.29482071713147  loss:0.5163191705942154\n",
      "Epoch:83  accuracy:76.09561752988049  loss:0.5076109915971756\n",
      "Epoch:84  accuracy:75.0996015936255  loss:0.5393883734941483\n",
      "Epoch:85  accuracy:72.90836653386454  loss:0.4722021818161011\n",
      "Epoch:86  accuracy:76.89243027888446  loss:0.5452360659837723\n",
      "Epoch:87  accuracy:75.79681274900399  loss:0.41831813752651215\n",
      "Epoch:88  accuracy:75.0996015936255  loss:0.528038740158081\n",
      "Epoch:89  accuracy:75.4980079681275  loss:0.5303517729043961\n",
      "Epoch:90  accuracy:72.60956175298804  loss:0.5151074975728989\n",
      "Epoch:91  accuracy:76.59362549800797  loss:0.7113783657550812\n",
      "Epoch:92  accuracy:74.00398406374502  loss:0.47473323717713356\n",
      "Epoch:93  accuracy:71.21513944223108  loss:0.7995541393756866\n",
      "Epoch:94  accuracy:74.800796812749  loss:0.521092139184475\n",
      "Epoch:95  accuracy:78.28685258964144  loss:0.5086292326450348\n",
      "Epoch:96  accuracy:76.89243027888446  loss:0.6899235844612122\n",
      "Epoch:97  accuracy:78.28685258964144  loss:0.46258997172117233\n",
      "Epoch:98  accuracy:75.0  loss:0.48275863379240036\n",
      "Early Stop\n",
      "Worker6 start\n",
      "Epoch:1  accuracy:29.261363636363637  loss:2.2419943809509277\n",
      "Epoch:2  accuracy:29.261363636363637  loss:2.1492881774902344\n",
      "Epoch:3  accuracy:29.261363636363637  loss:1.8527523279190063\n",
      "Epoch:4  accuracy:29.261363636363637  loss:1.8277615308761597\n",
      "Epoch:5  accuracy:29.261363636363637  loss:1.822175145149231\n",
      "Epoch:6  accuracy:29.261363636363637  loss:1.8180553913116455\n",
      "Epoch:7  accuracy:29.261363636363637  loss:1.8117867708206177\n",
      "Epoch:8  accuracy:29.261363636363637  loss:1.8264034986495972\n",
      "Epoch:9  accuracy:29.261363636363637  loss:1.8284050226211548\n",
      "Epoch:10  accuracy:29.261363636363637  loss:1.8195503950119019\n",
      "Epoch:11  accuracy:29.261363636363637  loss:1.8191062211990356\n",
      "Epoch:12  accuracy:29.261363636363637  loss:1.8099770545959473\n",
      "Epoch:13  accuracy:29.261363636363637  loss:1.8137589693069458\n",
      "Epoch:14  accuracy:29.261363636363637  loss:1.7917195558547974\n",
      "Epoch:15  accuracy:29.261363636363637  loss:1.7987579107284546\n",
      "Epoch:16  accuracy:29.261363636363637  loss:1.7868119478225708\n",
      "Epoch:17  accuracy:29.261363636363637  loss:1.7694813013076782\n",
      "Epoch:18  accuracy:38.35227272727273  loss:1.750447154045105\n",
      "Epoch:19  accuracy:38.63636363636363  loss:1.7384610176086426\n",
      "Epoch:20  accuracy:41.19318181818182  loss:1.637495517730713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:21  accuracy:41.76136363636363  loss:1.5761581659317017\n",
      "Epoch:22  accuracy:45.17045454545455  loss:1.5921024084091187\n",
      "Epoch:23  accuracy:44.03409090909091  loss:1.5751595497131348\n",
      "Epoch:24  accuracy:40.90909090909091  loss:1.6230403184890747\n",
      "Epoch:25  accuracy:47.15909090909091  loss:1.535473346710205\n",
      "Epoch:26  accuracy:46.875  loss:1.5433160066604614\n",
      "Epoch:27  accuracy:49.71590909090909  loss:1.5008537769317627\n",
      "Epoch:28  accuracy:46.59090909090909  loss:1.5174354314804077\n",
      "Epoch:29  accuracy:49.14772727272727  loss:1.508409857749939\n",
      "Epoch:30  accuracy:49.43181818181818  loss:1.490461826324463\n",
      "Epoch:31  accuracy:50.28409090909091  loss:1.4973315000534058\n",
      "Epoch:32  accuracy:50.85227272727273  loss:1.4765843152999878\n",
      "Epoch:33  accuracy:50.0  loss:1.4812783002853394\n",
      "Epoch:34  accuracy:48.01136363636363  loss:1.4963040351867676\n",
      "Epoch:35  accuracy:45.17045454545455  loss:1.5276786088943481\n",
      "Epoch:36  accuracy:51.42045454545455  loss:1.4883617162704468\n",
      "Epoch:37  accuracy:51.13636363636363  loss:1.484032392501831\n",
      "Epoch:38  accuracy:52.27272727272727  loss:1.4469590187072754\n",
      "Epoch:39  accuracy:52.84090909090909  loss:1.4347447156906128\n",
      "Epoch:40  accuracy:51.98863636363637  loss:1.4274858236312866\n",
      "Epoch:41  accuracy:51.13636363636363  loss:1.4642544984817505\n",
      "Epoch:42  accuracy:53.125  loss:1.4212660789489746\n",
      "Epoch:43  accuracy:50.28409090909091  loss:1.42537522315979\n",
      "Epoch:44  accuracy:50.0  loss:1.4318299293518066\n",
      "Epoch:45  accuracy:51.42045454545455  loss:1.4226629734039307\n",
      "Epoch:46  accuracy:51.70454545454545  loss:1.409889817237854\n",
      "Epoch:47  accuracy:54.26136363636363  loss:1.3768082857131958\n",
      "Epoch:48  accuracy:52.84090909090909  loss:1.3933093547821045\n",
      "Epoch:49  accuracy:54.54545454545455  loss:1.3796485662460327\n",
      "Epoch:50  accuracy:53.69318181818182  loss:1.3744392395019531\n",
      "Epoch:51  accuracy:53.69318181818182  loss:1.3848315477371216\n",
      "Epoch:52  accuracy:56.53409090909091  loss:1.3468999862670898\n",
      "Epoch:53  accuracy:54.54545454545455  loss:1.3568204641342163\n",
      "Epoch:54  accuracy:54.54545454545455  loss:1.3697772026062012\n",
      "Epoch:55  accuracy:53.97727272727273  loss:1.4120433330535889\n",
      "Epoch:56  accuracy:57.67045454545455  loss:1.3280054330825806\n",
      "Epoch:57  accuracy:56.53409090909091  loss:1.3315774202346802\n",
      "Epoch:58  accuracy:57.38636363636363  loss:1.3443747758865356\n",
      "Epoch:59  accuracy:57.10227272727273  loss:1.3293700218200684\n",
      "Epoch:60  accuracy:57.10227272727273  loss:1.3209741115570068\n",
      "Epoch:61  accuracy:55.96590909090909  loss:1.3663115501403809\n",
      "Epoch:62  accuracy:57.95454545454545  loss:1.2962565422058105\n",
      "Epoch:63  accuracy:54.82954545454545  loss:1.3335002660751343\n",
      "Epoch:64  accuracy:57.95454545454545  loss:1.3178530931472778\n",
      "Epoch:65  accuracy:57.67045454545455  loss:1.2963168621063232\n",
      "Epoch:66  accuracy:59.375  loss:1.2773605585098267\n",
      "Epoch:67  accuracy:59.375  loss:1.2982301712036133\n",
      "Epoch:68  accuracy:57.67045454545455  loss:1.3102871179580688\n",
      "Epoch:69  accuracy:59.375  loss:1.244454264640808\n",
      "Epoch:70  accuracy:61.07954545454545  loss:1.240651249885559\n",
      "Epoch:71  accuracy:60.51136363636363  loss:1.232808232307434\n",
      "Epoch:72  accuracy:56.53409090909091  loss:1.3401812314987183\n",
      "Epoch:73  accuracy:58.52272727272727  loss:1.2603236436843872\n",
      "Epoch:74  accuracy:59.65909090909091  loss:1.2483513355255127\n",
      "Epoch:75  accuracy:59.375  loss:1.2582931518554688\n",
      "Epoch:76  accuracy:60.51136363636363  loss:1.2392758131027222\n",
      "Epoch:77  accuracy:58.23863636363637  loss:1.2579119205474854\n",
      "Epoch:78  accuracy:63.35227272727273  loss:1.2198745012283325\n",
      "Epoch:79  accuracy:61.36363636363637  loss:1.240336537361145\n",
      "Epoch:80  accuracy:60.22727272727273  loss:1.231701374053955\n",
      "Epoch:81  accuracy:58.23863636363637  loss:1.3042359352111816\n",
      "Epoch:82  accuracy:57.10227272727273  loss:1.3618134260177612\n",
      "Epoch:83  accuracy:61.36363636363637  loss:1.221450686454773\n",
      "Epoch:84  accuracy:61.64772727272727  loss:1.2153292894363403\n",
      "Epoch:85  accuracy:61.93181818181818  loss:1.2376796007156372\n",
      "Epoch:86  accuracy:62.78409090909091  loss:1.2240749597549438\n",
      "Epoch:87  accuracy:61.64772727272727  loss:1.2412536144256592\n",
      "Epoch:88  accuracy:59.375  loss:1.3563648462295532\n",
      "Epoch:89  accuracy:60.51136363636363  loss:1.274277925491333\n",
      "Epoch:90  accuracy:60.51136363636363  loss:1.2568717002868652\n",
      "Epoch:91  accuracy:61.36363636363637  loss:1.2161731719970703\n",
      "Epoch:92  accuracy:61.07954545454545  loss:1.249064564704895\n",
      "Epoch:93  accuracy:59.09090909090909  loss:1.2595795392990112\n",
      "Epoch:94  accuracy:59.65909090909091  loss:1.2911186218261719\n",
      "Epoch:95  accuracy:59.94318181818182  loss:1.245123028755188\n",
      "Early Stop\n",
      "Worker7 start\n",
      "Epoch:1  accuracy:47.96573875802998  loss:2.0830981731414795\n",
      "Epoch:2  accuracy:42.184154175588866  loss:1.1106878519058228\n",
      "Epoch:3  accuracy:47.96573875802998  loss:1.0394072532653809\n",
      "Epoch:4  accuracy:47.96573875802998  loss:1.0221152305603027\n",
      "Epoch:5  accuracy:47.96573875802998  loss:1.0337823629379272\n",
      "Epoch:6  accuracy:47.96573875802998  loss:1.0196210145950317\n",
      "Epoch:7  accuracy:47.96573875802998  loss:1.020599603652954\n",
      "Epoch:8  accuracy:47.96573875802998  loss:1.0104938745498657\n",
      "Epoch:9  accuracy:47.96573875802998  loss:1.0132652521133423\n",
      "Epoch:10  accuracy:47.96573875802998  loss:1.0154271125793457\n",
      "Epoch:11  accuracy:47.96573875802998  loss:1.0115667581558228\n",
      "Epoch:12  accuracy:41.7558886509636  loss:0.9963193535804749\n",
      "Epoch:13  accuracy:47.96573875802998  loss:0.9989235401153564\n",
      "Epoch:14  accuracy:42.398286937901496  loss:1.0034642219543457\n",
      "Epoch:15  accuracy:47.96573875802998  loss:0.998933732509613\n",
      "Epoch:16  accuracy:47.96573875802998  loss:0.9892951846122742\n",
      "Epoch:17  accuracy:47.96573875802998  loss:0.9887407422065735\n",
      "Epoch:18  accuracy:47.96573875802998  loss:0.998399019241333\n",
      "Epoch:19  accuracy:47.96573875802998  loss:0.990559995174408\n",
      "Epoch:20  accuracy:47.96573875802998  loss:0.9948132038116455\n",
      "Epoch:21  accuracy:47.96573875802998  loss:1.0006433725357056\n",
      "Epoch:22  accuracy:47.96573875802998  loss:0.9847429990768433\n",
      "Epoch:23  accuracy:47.96573875802998  loss:0.9760496020317078\n",
      "Epoch:24  accuracy:47.96573875802998  loss:0.978405773639679\n",
      "Epoch:25  accuracy:47.96573875802998  loss:0.9912881255149841\n",
      "Epoch:26  accuracy:47.96573875802998  loss:0.9705891609191895\n",
      "Epoch:27  accuracy:47.96573875802998  loss:0.9719691276550293\n",
      "Epoch:28  accuracy:47.96573875802998  loss:0.9571152925491333\n",
      "Epoch:29  accuracy:47.96573875802998  loss:1.0120848417282104\n",
      "Epoch:30  accuracy:47.96573875802998  loss:0.9670078754425049\n",
      "Epoch:31  accuracy:47.96573875802998  loss:0.966423749923706\n",
      "Epoch:32  accuracy:47.96573875802998  loss:0.9699884057044983\n",
      "Epoch:33  accuracy:47.96573875802998  loss:0.9604732394218445\n",
      "Epoch:34  accuracy:47.96573875802998  loss:0.9660834074020386\n",
      "Epoch:35  accuracy:47.96573875802998  loss:0.9574266076087952\n",
      "Epoch:36  accuracy:47.96573875802998  loss:0.960675835609436\n",
      "Epoch:37  accuracy:47.96573875802998  loss:0.9585681557655334\n",
      "Epoch:38  accuracy:47.96573875802998  loss:0.9569815993309021\n",
      "Epoch:39  accuracy:47.96573875802998  loss:0.9602807760238647\n",
      "Epoch:40  accuracy:47.96573875802998  loss:0.959583580493927\n",
      "Epoch:41  accuracy:47.96573875802998  loss:0.9712604284286499\n",
      "Epoch:42  accuracy:47.96573875802998  loss:0.9619816541671753\n",
      "Epoch:43  accuracy:47.96573875802998  loss:0.9502354264259338\n",
      "Epoch:44  accuracy:47.96573875802998  loss:0.9559677243232727\n",
      "Epoch:45  accuracy:47.96573875802998  loss:0.9707933068275452\n",
      "Epoch:46  accuracy:47.96573875802998  loss:0.9547159671783447\n",
      "Epoch:47  accuracy:47.96573875802998  loss:0.9419714212417603\n",
      "Epoch:48  accuracy:47.323340471092074  loss:0.9445703625679016\n",
      "Epoch:49  accuracy:47.96573875802998  loss:0.9493405818939209\n",
      "Epoch:50  accuracy:47.96573875802998  loss:0.9420605301856995\n",
      "Epoch:51  accuracy:47.96573875802998  loss:0.938746988773346\n",
      "Epoch:52  accuracy:47.96573875802998  loss:0.9582641124725342\n",
      "Epoch:53  accuracy:47.96573875802998  loss:0.933207631111145\n",
      "Epoch:54  accuracy:47.96573875802998  loss:0.9389891028404236\n",
      "Epoch:55  accuracy:47.96573875802998  loss:0.9362832307815552\n",
      "Epoch:56  accuracy:47.96573875802998  loss:0.9421504139900208\n",
      "Epoch:57  accuracy:47.96573875802998  loss:0.9558053016662598\n",
      "Epoch:58  accuracy:47.96573875802998  loss:0.9411510229110718\n",
      "Epoch:59  accuracy:47.96573875802998  loss:0.9348977208137512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:60  accuracy:47.96573875802998  loss:0.9500992894172668\n",
      "Epoch:61  accuracy:47.96573875802998  loss:0.9310749173164368\n",
      "Epoch:62  accuracy:39.82869379014989  loss:0.9341956973075867\n",
      "Epoch:63  accuracy:41.32762312633833  loss:0.9407156705856323\n",
      "Epoch:64  accuracy:47.96573875802998  loss:0.9364414811134338\n",
      "Epoch:65  accuracy:47.96573875802998  loss:0.9445703029632568\n",
      "Epoch:66  accuracy:41.32762312633833  loss:0.945493757724762\n",
      "Epoch:67  accuracy:47.96573875802998  loss:0.9371464848518372\n",
      "Epoch:68  accuracy:47.96573875802998  loss:0.9442412257194519\n",
      "Epoch:69  accuracy:47.96573875802998  loss:0.9224370718002319\n",
      "Epoch:70  accuracy:49.46466809421842  loss:0.9354288578033447\n",
      "Epoch:71  accuracy:47.96573875802998  loss:0.9257603883743286\n",
      "Epoch:72  accuracy:47.96573875802998  loss:0.9301391243934631\n",
      "Epoch:73  accuracy:47.96573875802998  loss:0.9454692602157593\n",
      "Epoch:74  accuracy:47.96573875802998  loss:0.928007185459137\n",
      "Epoch:75  accuracy:47.96573875802998  loss:0.9401116371154785\n",
      "Epoch:76  accuracy:47.96573875802998  loss:0.9274644255638123\n",
      "Epoch:77  accuracy:47.96573875802998  loss:0.9417014718055725\n",
      "Epoch:78  accuracy:47.96573875802998  loss:0.9206211566925049\n",
      "Epoch:79  accuracy:47.96573875802998  loss:0.9306910634040833\n",
      "Epoch:80  accuracy:49.03640256959315  loss:0.9186360836029053\n",
      "Epoch:81  accuracy:47.96573875802998  loss:0.9146109819412231\n",
      "Epoch:82  accuracy:47.96573875802998  loss:0.928493320941925\n",
      "Epoch:83  accuracy:47.96573875802998  loss:0.9318380355834961\n",
      "Epoch:84  accuracy:47.96573875802998  loss:0.9113046526908875\n",
      "Epoch:85  accuracy:47.96573875802998  loss:0.914091169834137\n",
      "Epoch:86  accuracy:47.96573875802998  loss:0.9069030284881592\n",
      "Epoch:87  accuracy:47.96573875802998  loss:0.9201991558074951\n",
      "Epoch:88  accuracy:47.96573875802998  loss:0.9145005345344543\n",
      "Epoch:89  accuracy:47.96573875802998  loss:0.9273812770843506\n",
      "Epoch:90  accuracy:47.96573875802998  loss:0.9146029353141785\n",
      "Epoch:91  accuracy:51.17773019271949  loss:0.9177868366241455\n",
      "Epoch:92  accuracy:47.96573875802998  loss:0.9074332118034363\n",
      "Epoch:93  accuracy:42.398286937901496  loss:0.9179421067237854\n",
      "Epoch:94  accuracy:47.96573875802998  loss:0.9311679601669312\n",
      "Epoch:95  accuracy:47.96573875802998  loss:0.9051735997200012\n",
      "Epoch:96  accuracy:47.96573875802998  loss:0.8994361758232117\n",
      "Epoch:97  accuracy:47.96573875802998  loss:0.9117416739463806\n",
      "Epoch:98  accuracy:47.96573875802998  loss:0.9095282554626465\n",
      "Epoch:99  accuracy:47.96573875802998  loss:0.917822003364563\n",
      "Epoch:100  accuracy:47.96573875802998  loss:0.91756272315979\n",
      "Epoch:101  accuracy:47.96573875802998  loss:0.9012220501899719\n",
      "Epoch:102  accuracy:48.394004282655246  loss:0.8965087532997131\n",
      "Epoch:103  accuracy:55.24625267665953  loss:0.896278977394104\n",
      "Epoch:104  accuracy:47.96573875802998  loss:0.9144834280014038\n",
      "Epoch:105  accuracy:52.46252676659529  loss:0.9067865014076233\n",
      "Epoch:106  accuracy:52.24839400428265  loss:0.8862712383270264\n",
      "Epoch:107  accuracy:52.46252676659529  loss:0.9121238589286804\n",
      "Epoch:108  accuracy:52.03426124197002  loss:0.9074863195419312\n",
      "Epoch:109  accuracy:50.96359743040685  loss:0.8936083316802979\n",
      "Epoch:110  accuracy:54.17558886509636  loss:0.878853976726532\n",
      "Epoch:111  accuracy:52.46252676659529  loss:0.8821630477905273\n",
      "Epoch:112  accuracy:56.9593147751606  loss:0.8579831123352051\n",
      "Epoch:113  accuracy:57.601713062098504  loss:0.8999249339103699\n",
      "Epoch:114  accuracy:50.53533190578158  loss:0.9239014387130737\n",
      "Epoch:115  accuracy:55.03211991434689  loss:0.8763512969017029\n",
      "Epoch:116  accuracy:57.38758029978587  loss:0.8644033670425415\n",
      "Epoch:117  accuracy:58.886509635974306  loss:0.8487167358398438\n",
      "Epoch:118  accuracy:55.6745182012848  loss:0.8646990060806274\n",
      "Epoch:119  accuracy:57.815845824411134  loss:0.8997496366500854\n",
      "Epoch:120  accuracy:59.528907922912204  loss:0.8528148531913757\n",
      "Epoch:121  accuracy:59.74304068522484  loss:0.8464487195014954\n",
      "Epoch:122  accuracy:52.676659528907926  loss:0.9805216789245605\n",
      "Epoch:123  accuracy:60.599571734475376  loss:0.8260019421577454\n",
      "Epoch:124  accuracy:56.102783725910065  loss:0.8807751536369324\n",
      "Epoch:125  accuracy:61.24197002141327  loss:0.8174804449081421\n",
      "Epoch:126  accuracy:61.24197002141327  loss:0.8208866119384766\n",
      "Epoch:127  accuracy:60.599571734475376  loss:0.8329524397850037\n",
      "Epoch:128  accuracy:61.45610278372591  loss:0.8172432780265808\n",
      "Epoch:129  accuracy:62.312633832976445  loss:0.8036149144172668\n",
      "Epoch:130  accuracy:65.95289079229121  loss:0.7903889417648315\n",
      "Epoch:131  accuracy:61.45610278372591  loss:0.7989038825035095\n",
      "Epoch:132  accuracy:60.813704496788006  loss:0.8045868277549744\n",
      "Epoch:133  accuracy:64.66809421841542  loss:0.8075709342956543\n",
      "Epoch:134  accuracy:64.23982869379014  loss:0.788404643535614\n",
      "Epoch:135  accuracy:67.0235546038544  loss:0.7666152715682983\n",
      "Epoch:136  accuracy:64.66809421841542  loss:0.7849939465522766\n",
      "Epoch:137  accuracy:65.95289079229121  loss:0.8271805644035339\n",
      "Epoch:138  accuracy:64.23982869379014  loss:0.7729386687278748\n",
      "Epoch:139  accuracy:63.811563169164884  loss:0.8182779550552368\n",
      "Epoch:140  accuracy:67.23768736616702  loss:0.7745392322540283\n",
      "Epoch:141  accuracy:66.59528907922912  loss:0.7569994330406189\n",
      "Epoch:142  accuracy:65.09635974304068  loss:0.7826796174049377\n",
      "Epoch:143  accuracy:64.88222698072805  loss:0.7636814117431641\n",
      "Epoch:144  accuracy:69.80728051391863  loss:0.7392288446426392\n",
      "Epoch:145  accuracy:62.098501070663815  loss:0.8413875699043274\n",
      "Epoch:146  accuracy:65.31049250535332  loss:0.7741003632545471\n",
      "Epoch:147  accuracy:65.52462526766595  loss:0.7741771340370178\n",
      "Epoch:148  accuracy:68.73661670235546  loss:0.7044936418533325\n",
      "Epoch:149  accuracy:70.02141327623126  loss:0.7373372912406921\n",
      "Epoch:150  accuracy:65.73875802997858  loss:0.7851007580757141\n",
      "Epoch:151  accuracy:68.52248394004283  loss:0.7232511639595032\n",
      "Epoch:152  accuracy:70.2355460385439  loss:0.7289073467254639\n",
      "Epoch:153  accuracy:65.95289079229121  loss:0.7684594392776489\n",
      "Epoch:154  accuracy:59.95717344753747  loss:0.8764124512672424\n",
      "Epoch:155  accuracy:69.16488222698072  loss:0.7396518588066101\n",
      "Epoch:156  accuracy:68.09421841541756  loss:0.702416181564331\n",
      "Epoch:157  accuracy:66.59528907922912  loss:0.785607099533081\n",
      "Epoch:158  accuracy:65.95289079229121  loss:0.7725295424461365\n",
      "Epoch:159  accuracy:70.66381156316916  loss:0.7092560529708862\n",
      "Epoch:160  accuracy:67.6659528907923  loss:0.7334157824516296\n",
      "Epoch:161  accuracy:70.44967880085653  loss:0.7111361026763916\n",
      "Epoch:162  accuracy:68.52248394004283  loss:0.7385005354881287\n",
      "Epoch:163  accuracy:62.95503211991435  loss:0.8946571946144104\n",
      "Epoch:164  accuracy:65.31049250535332  loss:0.7786562442779541\n",
      "Epoch:165  accuracy:71.94860813704497  loss:0.6812635064125061\n",
      "Epoch:166  accuracy:71.30620985010707  loss:0.7019647359848022\n",
      "Epoch:167  accuracy:69.80728051391863  loss:0.7194795608520508\n",
      "Epoch:168  accuracy:71.09207708779444  loss:0.7521622180938721\n",
      "Epoch:169  accuracy:72.37687366167023  loss:0.7123766541481018\n",
      "Epoch:170  accuracy:71.94860813704497  loss:0.6563044786453247\n",
      "Epoch:171  accuracy:72.8051391862955  loss:0.692914605140686\n",
      "Epoch:172  accuracy:70.66381156316916  loss:0.6880418062210083\n",
      "Epoch:173  accuracy:68.30835117773019  loss:0.7767733931541443\n",
      "Epoch:174  accuracy:74.0899357601713  loss:0.6301173567771912\n",
      "Epoch:175  accuracy:74.0899357601713  loss:0.6609823107719421\n",
      "Epoch:176  accuracy:74.94646680942184  loss:0.6558046936988831\n",
      "Epoch:177  accuracy:66.16702355460386  loss:0.9076709151268005\n",
      "Epoch:178  accuracy:71.94860813704497  loss:0.6908726096153259\n",
      "Epoch:179  accuracy:69.37901498929337  loss:0.8228753805160522\n",
      "Epoch:180  accuracy:69.16488222698072  loss:0.7881643176078796\n",
      "Epoch:181  accuracy:76.01713062098501  loss:0.6384745836257935\n",
      "Epoch:182  accuracy:75.16059957173448  loss:0.6315585374832153\n",
      "Epoch:183  accuracy:73.44753747323341  loss:0.6826719641685486\n",
      "Epoch:184  accuracy:74.7323340471092  loss:0.6853405833244324\n",
      "Epoch:185  accuracy:74.30406852248395  loss:0.6780157089233398\n",
      "Early Stop\n",
      "Worker8 start\n",
      "Epoch:1  accuracy:50.86848635235732  loss:1.3247894048690796\n",
      "Epoch:2  accuracy:50.86848635235732  loss:1.242958664894104\n",
      "Epoch:3  accuracy:50.86848635235732  loss:1.2089660167694092\n",
      "Epoch:4  accuracy:50.86848635235732  loss:1.1976957321166992\n",
      "Epoch:5  accuracy:50.86848635235732  loss:1.1716545820236206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6  accuracy:50.86848635235732  loss:1.1571979522705078\n",
      "Epoch:7  accuracy:50.86848635235732  loss:1.1378607749938965\n",
      "Epoch:8  accuracy:50.86848635235732  loss:1.1088165044784546\n",
      "Epoch:9  accuracy:50.62034739454094  loss:1.1341267824172974\n",
      "Epoch:10  accuracy:50.86848635235732  loss:1.1352747678756714\n",
      "Epoch:11  accuracy:51.116625310173696  loss:1.0607256889343262\n",
      "Epoch:12  accuracy:51.86104218362283  loss:1.051608681678772\n",
      "Epoch:13  accuracy:53.72208436724566  loss:1.0406324863433838\n",
      "Epoch:14  accuracy:57.69230769230769  loss:1.017327904701233\n",
      "Epoch:15  accuracy:58.80893300248139  loss:1.0015180110931396\n",
      "Epoch:16  accuracy:57.81637717121588  loss:1.0027692317962646\n",
      "Epoch:17  accuracy:58.188585607940446  loss:0.9992935657501221\n",
      "Epoch:18  accuracy:62.15880893300248  loss:0.9770705699920654\n",
      "Epoch:19  accuracy:63.15136476426799  loss:0.9422730207443237\n",
      "Epoch:20  accuracy:59.55334987593052  loss:0.9719361662864685\n",
      "Epoch:21  accuracy:63.39950372208437  loss:0.9236592054367065\n",
      "Epoch:22  accuracy:65.26054590570719  loss:0.9438245892524719\n",
      "Epoch:23  accuracy:68.3622828784119  loss:0.8876862525939941\n",
      "Epoch:24  accuracy:63.27543424317618  loss:0.9209820628166199\n",
      "Epoch:25  accuracy:70.09925558312655  loss:0.8427044749259949\n",
      "Epoch:26  accuracy:68.98263027295286  loss:0.8482705950737\n",
      "Epoch:27  accuracy:68.73449131513648  loss:0.86128830909729\n",
      "Epoch:28  accuracy:69.97518610421837  loss:0.830683708190918\n",
      "Epoch:29  accuracy:69.85111662531017  loss:0.8473623394966125\n",
      "Epoch:30  accuracy:72.33250620347394  loss:0.801702082157135\n",
      "Epoch:31  accuracy:73.69727047146402  loss:0.7621692419052124\n",
      "Epoch:32  accuracy:72.20843672456576  loss:0.7710431814193726\n",
      "Epoch:33  accuracy:75.06203473945409  loss:0.7240827679634094\n",
      "Epoch:34  accuracy:74.31761786600497  loss:0.7438850998878479\n",
      "Epoch:35  accuracy:75.06203473945409  loss:0.7415907979011536\n",
      "Epoch:36  accuracy:75.93052109181141  loss:0.7135168313980103\n",
      "Epoch:37  accuracy:77.1712158808933  loss:0.695404589176178\n",
      "Epoch:38  accuracy:73.44913151364764  loss:0.7233343124389648\n",
      "Epoch:39  accuracy:78.53598014888337  loss:0.6388656497001648\n",
      "Epoch:40  accuracy:77.41935483870968  loss:0.68977952003479\n",
      "Epoch:41  accuracy:79.40446650124069  loss:0.6320323944091797\n",
      "Epoch:42  accuracy:76.30272952853598  loss:0.6673319935798645\n",
      "Epoch:43  accuracy:78.78411910669975  loss:0.6304987668991089\n",
      "Epoch:44  accuracy:79.77667493796525  loss:0.6052465438842773\n",
      "Epoch:45  accuracy:80.02481389578163  loss:0.6073333024978638\n",
      "Epoch:46  accuracy:77.91563275434243  loss:0.6499437093734741\n",
      "Epoch:47  accuracy:80.89330024813896  loss:0.5742219090461731\n",
      "Epoch:48  accuracy:81.01736972704714  loss:0.5811248421669006\n",
      "Epoch:49  accuracy:78.66004962779157  loss:0.5941404700279236\n",
      "Epoch:50  accuracy:80.3970223325062  loss:0.5695237517356873\n",
      "Epoch:51  accuracy:80.76923076923077  loss:0.5722442865371704\n",
      "Epoch:52  accuracy:81.76178660049628  loss:0.5648950338363647\n",
      "Epoch:53  accuracy:81.6377171215881  loss:0.5602759718894958\n",
      "Epoch:54  accuracy:80.27295285359801  loss:0.5933941006660461\n",
      "Epoch:55  accuracy:81.5136476426799  loss:0.5722049474716187\n",
      "Epoch:56  accuracy:80.27295285359801  loss:0.5732569098472595\n",
      "Epoch:57  accuracy:82.5062034739454  loss:0.5451406240463257\n",
      "Epoch:58  accuracy:82.13399503722084  loss:0.5278254151344299\n",
      "Epoch:59  accuracy:81.76178660049628  loss:0.5533342957496643\n",
      "Epoch:60  accuracy:81.01736972704714  loss:0.5977765321731567\n",
      "Epoch:61  accuracy:78.287841191067  loss:0.686051070690155\n",
      "Epoch:62  accuracy:81.88585607940446  loss:0.5477814674377441\n",
      "Epoch:63  accuracy:81.76178660049628  loss:0.573979377746582\n",
      "Epoch:64  accuracy:81.14143920595534  loss:0.549667239189148\n",
      "Epoch:65  accuracy:82.00992555831266  loss:0.6047064065933228\n",
      "Epoch:66  accuracy:81.38957816377172  loss:0.5545222759246826\n",
      "Epoch:67  accuracy:83.00248138957816  loss:0.5282658934593201\n",
      "Epoch:68  accuracy:82.75434243176178  loss:0.5370046496391296\n",
      "Epoch:69  accuracy:83.12655086848635  loss:0.5014299154281616\n",
      "Epoch:70  accuracy:78.1637717121588  loss:0.7037506699562073\n",
      "Epoch:71  accuracy:82.00992555831266  loss:0.5283694863319397\n",
      "Epoch:72  accuracy:82.38213399503722  loss:0.5714373588562012\n",
      "Epoch:73  accuracy:82.75434243176178  loss:0.5127550363540649\n",
      "Epoch:74  accuracy:81.76178660049628  loss:0.6011918187141418\n",
      "Epoch:75  accuracy:84.24317617866005  loss:0.5341619253158569\n",
      "Epoch:76  accuracy:84.11910669975187  loss:0.5011245608329773\n",
      "Epoch:77  accuracy:80.89330024813896  loss:0.6432610154151917\n",
      "Epoch:78  accuracy:83.62282878411911  loss:0.5386223196983337\n",
      "Epoch:79  accuracy:82.75434243176178  loss:0.5897222757339478\n",
      "Epoch:80  accuracy:83.87096774193549  loss:0.5066656470298767\n",
      "Epoch:81  accuracy:83.25062034739454  loss:0.5249907374382019\n",
      "Epoch:82  accuracy:83.87096774193549  loss:0.5343607664108276\n",
      "Epoch:83  accuracy:83.37468982630273  loss:0.5075544118881226\n",
      "Epoch:84  accuracy:83.62282878411911  loss:0.5268749594688416\n",
      "Epoch:85  accuracy:83.49875930521092  loss:0.5697183012962341\n",
      "Epoch:86  accuracy:83.99503722084367  loss:0.5247222185134888\n",
      "Epoch:87  accuracy:83.12655086848635  loss:0.5247427225112915\n",
      "Early Stop\n",
      "Worker9 start\n",
      "Epoch:1  accuracy:65.1948051948052  loss:1.2310930490493774\n",
      "Epoch:2  accuracy:65.1948051948052  loss:1.0850036144256592\n",
      "Epoch:3  accuracy:65.1948051948052  loss:1.069136381149292\n",
      "Epoch:4  accuracy:65.1948051948052  loss:1.0173163414001465\n",
      "Epoch:5  accuracy:65.1948051948052  loss:0.9942324161529541\n",
      "Epoch:6  accuracy:65.1948051948052  loss:0.9775590896606445\n",
      "Epoch:7  accuracy:65.1948051948052  loss:0.9608399868011475\n",
      "Epoch:8  accuracy:65.1948051948052  loss:0.9388408660888672\n",
      "Epoch:9  accuracy:65.97402597402598  loss:0.8924533724784851\n",
      "Epoch:10  accuracy:70.9090909090909  loss:0.8648145794868469\n",
      "Epoch:11  accuracy:74.15584415584415  loss:0.7858284115791321\n",
      "Epoch:12  accuracy:75.1948051948052  loss:0.7519831657409668\n",
      "Epoch:13  accuracy:76.88311688311688  loss:0.7266338467597961\n",
      "Epoch:14  accuracy:77.66233766233766  loss:0.6501157283782959\n",
      "Epoch:15  accuracy:78.96103896103897  loss:0.656855583190918\n",
      "Epoch:16  accuracy:77.92207792207792  loss:0.6534167528152466\n",
      "Epoch:17  accuracy:78.7012987012987  loss:0.6540831923484802\n",
      "Epoch:18  accuracy:77.79220779220779  loss:0.6385643482208252\n",
      "Epoch:19  accuracy:78.31168831168831  loss:0.6401770710945129\n",
      "Epoch:20  accuracy:78.57142857142857  loss:0.6202154159545898\n",
      "Epoch:21  accuracy:77.92207792207792  loss:0.6166393756866455\n",
      "Epoch:22  accuracy:77.27272727272727  loss:0.6541765332221985\n",
      "Epoch:23  accuracy:78.05194805194805  loss:0.6286203861236572\n",
      "Epoch:24  accuracy:78.83116883116882  loss:0.6089655160903931\n",
      "Epoch:25  accuracy:77.01298701298701  loss:0.6908589005470276\n",
      "Epoch:26  accuracy:77.66233766233766  loss:0.6431816816329956\n",
      "Epoch:27  accuracy:79.48051948051948  loss:0.6015462279319763\n",
      "Epoch:28  accuracy:79.35064935064935  loss:0.5920919179916382\n",
      "Epoch:29  accuracy:78.96103896103897  loss:0.5830859541893005\n",
      "Epoch:30  accuracy:79.48051948051948  loss:0.5990188121795654\n",
      "Epoch:31  accuracy:78.83116883116882  loss:0.5889531373977661\n",
      "Epoch:32  accuracy:79.22077922077922  loss:0.5826885104179382\n",
      "Epoch:33  accuracy:80.0  loss:0.5838122367858887\n",
      "Epoch:34  accuracy:80.12987012987013  loss:0.5664696097373962\n",
      "Epoch:35  accuracy:79.22077922077922  loss:0.6190057992935181\n",
      "Epoch:36  accuracy:80.64935064935065  loss:0.5659838318824768\n",
      "Epoch:37  accuracy:80.0  loss:0.5775541067123413\n",
      "Epoch:38  accuracy:80.9090909090909  loss:0.5493643879890442\n",
      "Epoch:39  accuracy:80.51948051948052  loss:0.5720404982566833\n",
      "Epoch:40  accuracy:81.2987012987013  loss:0.5665611624717712\n",
      "Epoch:41  accuracy:79.74025974025975  loss:0.5820102691650391\n",
      "Epoch:42  accuracy:80.51948051948052  loss:0.5644195079803467\n",
      "Epoch:43  accuracy:79.48051948051948  loss:0.5913099646568298\n",
      "Epoch:44  accuracy:80.51948051948052  loss:0.556727945804596\n",
      "Epoch:45  accuracy:80.25974025974025  loss:0.6038561463356018\n",
      "Epoch:46  accuracy:81.94805194805195  loss:0.5324947834014893\n",
      "Epoch:47  accuracy:82.07792207792208  loss:0.5271098613739014\n",
      "Epoch:48  accuracy:82.20779220779221  loss:0.527802586555481\n",
      "Epoch:49  accuracy:82.07792207792208  loss:0.565162181854248\n",
      "Epoch:50  accuracy:81.2987012987013  loss:0.5792961120605469\n",
      "Epoch:51  accuracy:82.20779220779221  loss:0.5529479384422302\n",
      "Epoch:52  accuracy:81.2987012987013  loss:0.5593426823616028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:53  accuracy:83.11688311688312  loss:0.5165351033210754\n",
      "Epoch:54  accuracy:83.50649350649351  loss:0.5194207429885864\n",
      "Epoch:55  accuracy:83.37662337662337  loss:0.5332645177841187\n",
      "Epoch:56  accuracy:83.37662337662337  loss:0.5066156983375549\n",
      "Epoch:57  accuracy:83.76623376623377  loss:0.515387773513794\n",
      "Epoch:58  accuracy:82.85714285714286  loss:0.5141118168830872\n",
      "Epoch:59  accuracy:83.63636363636364  loss:0.5010185241699219\n",
      "Epoch:60  accuracy:82.85714285714286  loss:0.5101397037506104\n",
      "Epoch:61  accuracy:83.24675324675324  loss:0.5152795314788818\n",
      "Epoch:62  accuracy:83.63636363636364  loss:0.4963507354259491\n",
      "Epoch:63  accuracy:84.41558441558442  loss:0.5015478134155273\n",
      "Epoch:64  accuracy:83.76623376623377  loss:0.5234408378601074\n",
      "Epoch:65  accuracy:83.76623376623377  loss:0.5240399837493896\n",
      "Epoch:66  accuracy:84.28571428571429  loss:0.5102056264877319\n",
      "Epoch:67  accuracy:84.54545454545455  loss:0.4993908405303955\n",
      "Epoch:68  accuracy:82.98701298701299  loss:0.5484989285469055\n",
      "Epoch:69  accuracy:84.54545454545455  loss:0.4797813892364502\n",
      "Epoch:70  accuracy:84.41558441558442  loss:0.5382677912712097\n",
      "Epoch:71  accuracy:85.32467532467533  loss:0.4919462203979492\n",
      "Epoch:72  accuracy:84.8051948051948  loss:0.5182395577430725\n",
      "Epoch:73  accuracy:85.32467532467533  loss:0.4955592155456543\n",
      "Epoch:74  accuracy:82.72727272727273  loss:0.5414686799049377\n",
      "Epoch:75  accuracy:85.58441558441558  loss:0.48657193779945374\n",
      "Epoch:76  accuracy:84.8051948051948  loss:0.5033055543899536\n",
      "Epoch:77  accuracy:84.41558441558442  loss:0.5019242167472839\n",
      "Epoch:78  accuracy:84.54545454545455  loss:0.502178966999054\n",
      "Epoch:79  accuracy:85.1948051948052  loss:0.4945499897003174\n",
      "Epoch:80  accuracy:83.11688311688312  loss:0.5499230027198792\n",
      "Early Stop\n",
      "Worker10 start\n",
      "Epoch:1  accuracy:64.37246963562752  loss:2.1722629070281982\n",
      "Epoch:2  accuracy:64.37246963562752  loss:1.9279110431671143\n",
      "Epoch:3  accuracy:64.37246963562752  loss:0.9221323728561401\n",
      "Epoch:4  accuracy:64.37246963562752  loss:0.8004514575004578\n",
      "Epoch:5  accuracy:64.37246963562752  loss:0.7854871153831482\n",
      "Epoch:6  accuracy:64.37246963562752  loss:0.7840664982795715\n",
      "Epoch:7  accuracy:64.37246963562752  loss:0.7678871750831604\n",
      "Epoch:8  accuracy:64.37246963562752  loss:0.7685993313789368\n",
      "Epoch:9  accuracy:64.37246963562752  loss:0.7529190182685852\n",
      "Epoch:10  accuracy:64.37246963562752  loss:0.7491580247879028\n",
      "Epoch:11  accuracy:64.37246963562752  loss:0.7430561184883118\n",
      "Epoch:12  accuracy:64.37246963562752  loss:0.7403693199157715\n",
      "Epoch:13  accuracy:64.37246963562752  loss:0.7344902753829956\n",
      "Epoch:14  accuracy:64.37246963562752  loss:0.7305610179901123\n",
      "Epoch:15  accuracy:64.37246963562752  loss:0.7248031497001648\n",
      "Epoch:16  accuracy:64.37246963562752  loss:0.716567873954773\n",
      "Epoch:17  accuracy:64.37246963562752  loss:0.7137601375579834\n",
      "Epoch:18  accuracy:64.37246963562752  loss:0.7341358661651611\n",
      "Epoch:19  accuracy:64.37246963562752  loss:0.703632116317749\n",
      "Epoch:20  accuracy:64.37246963562752  loss:0.7181318998336792\n",
      "Epoch:21  accuracy:64.37246963562752  loss:0.6945542693138123\n",
      "Epoch:22  accuracy:64.37246963562752  loss:0.703320324420929\n",
      "Epoch:23  accuracy:64.37246963562752  loss:0.6821781396865845\n",
      "Epoch:24  accuracy:64.37246963562752  loss:0.693250298500061\n",
      "Epoch:25  accuracy:64.37246963562752  loss:0.697563886642456\n",
      "Epoch:26  accuracy:64.37246963562752  loss:0.678817093372345\n",
      "Epoch:27  accuracy:72.06477732793522  loss:0.7058096528053284\n",
      "Epoch:28  accuracy:64.37246963562752  loss:0.6533200740814209\n",
      "Epoch:29  accuracy:67.20647773279352  loss:0.6652286648750305\n",
      "Epoch:30  accuracy:66.39676113360323  loss:0.6460821032524109\n",
      "Epoch:31  accuracy:67.20647773279352  loss:0.6358384490013123\n",
      "Epoch:32  accuracy:70.04048582995951  loss:0.6185443997383118\n",
      "Epoch:33  accuracy:79.75708502024291  loss:0.6446849703788757\n",
      "Epoch:34  accuracy:78.94736842105263  loss:0.6127205491065979\n",
      "Epoch:35  accuracy:76.11336032388664  loss:0.5900018811225891\n",
      "Epoch:36  accuracy:80.16194331983806  loss:0.5946617126464844\n",
      "Epoch:37  accuracy:76.11336032388664  loss:0.570663332939148\n",
      "Epoch:38  accuracy:80.16194331983806  loss:0.5565919280052185\n",
      "Epoch:39  accuracy:81.37651821862349  loss:0.5407876372337341\n",
      "Epoch:40  accuracy:80.16194331983806  loss:0.5319097638130188\n",
      "Epoch:41  accuracy:80.16194331983806  loss:0.5465389490127563\n",
      "Epoch:42  accuracy:80.97165991902834  loss:0.5094220042228699\n",
      "Epoch:43  accuracy:82.18623481781377  loss:0.5151069164276123\n",
      "Epoch:44  accuracy:80.16194331983806  loss:0.5155571103096008\n",
      "Epoch:45  accuracy:82.18623481781377  loss:0.5062450766563416\n",
      "Epoch:46  accuracy:82.5910931174089  loss:0.49612540006637573\n",
      "Epoch:47  accuracy:81.37651821862349  loss:0.5128690004348755\n",
      "Epoch:48  accuracy:84.21052631578948  loss:0.49317702651023865\n",
      "Epoch:49  accuracy:82.99595141700405  loss:0.48659926652908325\n",
      "Epoch:50  accuracy:78.13765182186235  loss:0.5257419943809509\n",
      "Epoch:51  accuracy:80.97165991902834  loss:0.4793538749217987\n",
      "Epoch:52  accuracy:80.56680161943319  loss:0.5243210792541504\n",
      "Epoch:53  accuracy:82.18623481781377  loss:0.46994277834892273\n",
      "Epoch:54  accuracy:83.80566801619433  loss:0.4859463572502136\n",
      "Epoch:55  accuracy:85.82995951417004  loss:0.4617118537425995\n",
      "Epoch:56  accuracy:81.37651821862349  loss:0.4752139449119568\n",
      "Epoch:57  accuracy:86.63967611336032  loss:0.452785462141037\n",
      "Epoch:58  accuracy:82.18623481781377  loss:0.4959162473678589\n",
      "Epoch:59  accuracy:85.02024291497976  loss:0.4455431401729584\n",
      "Epoch:60  accuracy:77.7327935222672  loss:0.5363983511924744\n",
      "Epoch:61  accuracy:82.99595141700405  loss:0.47731921076774597\n",
      "Epoch:62  accuracy:85.4251012145749  loss:0.4351101517677307\n",
      "Epoch:63  accuracy:85.02024291497976  loss:0.4279417395591736\n",
      "Epoch:64  accuracy:85.02024291497976  loss:0.4211761951446533\n",
      "Epoch:65  accuracy:82.5910931174089  loss:0.46561992168426514\n",
      "Epoch:66  accuracy:85.02024291497976  loss:0.4350941777229309\n",
      "Epoch:67  accuracy:85.02024291497976  loss:0.4083789587020874\n",
      "Epoch:68  accuracy:84.21052631578948  loss:0.44572925567626953\n",
      "Epoch:69  accuracy:85.4251012145749  loss:0.4277157783508301\n",
      "Epoch:70  accuracy:84.61538461538461  loss:0.4108249545097351\n",
      "Epoch:71  accuracy:84.21052631578948  loss:0.4407227039337158\n",
      "Epoch:72  accuracy:82.5910931174089  loss:0.49952390789985657\n",
      "Epoch:73  accuracy:85.82995951417004  loss:0.39317581057548523\n",
      "Epoch:74  accuracy:85.02024291497976  loss:0.4127148985862732\n",
      "Epoch:75  accuracy:84.61538461538461  loss:0.4324410855770111\n",
      "Epoch:76  accuracy:83.40080971659918  loss:0.46532195806503296\n",
      "Epoch:77  accuracy:85.02024291497976  loss:0.41646626591682434\n",
      "Epoch:78  accuracy:81.37651821862349  loss:0.5433982610702515\n",
      "Epoch:79  accuracy:85.4251012145749  loss:0.42358455061912537\n",
      "Epoch:80  accuracy:85.82995951417004  loss:0.39716336131095886\n",
      "Epoch:81  accuracy:83.40080971659918  loss:0.44648098945617676\n",
      "Epoch:82  accuracy:85.82995951417004  loss:0.4140704870223999\n",
      "Epoch:83  accuracy:85.82995951417004  loss:0.4199467599391937\n",
      "Epoch:84  accuracy:84.61538461538461  loss:0.38777002692222595\n",
      "Epoch:85  accuracy:82.18623481781377  loss:0.4904063940048218\n",
      "Epoch:86  accuracy:82.5910931174089  loss:0.484688937664032\n",
      "Epoch:87  accuracy:87.04453441295547  loss:0.38112369179725647\n",
      "Epoch:88  accuracy:86.63967611336032  loss:0.38517773151397705\n",
      "Epoch:89  accuracy:85.4251012145749  loss:0.39394769072532654\n",
      "Epoch:90  accuracy:87.04453441295547  loss:0.3741084933280945\n",
      "Epoch:91  accuracy:86.23481781376518  loss:0.38275179266929626\n",
      "Epoch:92  accuracy:86.23481781376518  loss:0.39293602108955383\n",
      "Epoch:93  accuracy:85.02024291497976  loss:0.4096735417842865\n",
      "Epoch:94  accuracy:86.63967611336032  loss:0.3811984658241272\n",
      "Epoch:95  accuracy:87.04453441295547  loss:0.3685574531555176\n",
      "Epoch:96  accuracy:85.4251012145749  loss:0.40114444494247437\n",
      "Epoch:97  accuracy:88.25910931174089  loss:0.3732321560382843\n",
      "Epoch:98  accuracy:84.61538461538461  loss:0.408901572227478\n",
      "Epoch:99  accuracy:87.04453441295547  loss:0.3736477196216583\n",
      "Epoch:100  accuracy:85.02024291497976  loss:0.41525742411613464\n",
      "Epoch:101  accuracy:85.02024291497976  loss:0.4404536783695221\n",
      "Epoch:102  accuracy:86.63967611336032  loss:0.36057248711586\n",
      "Epoch:103  accuracy:86.63967611336032  loss:0.38148847222328186\n",
      "Epoch:104  accuracy:86.63967611336032  loss:0.38377970457077026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:105  accuracy:85.82995951417004  loss:0.368880033493042\n",
      "Epoch:106  accuracy:87.04453441295547  loss:0.3773353397846222\n",
      "Epoch:107  accuracy:86.23481781376518  loss:0.3775840401649475\n",
      "Epoch:108  accuracy:88.25910931174089  loss:0.37473398447036743\n",
      "Epoch:109  accuracy:83.80566801619433  loss:0.43037229776382446\n",
      "Epoch:110  accuracy:87.04453441295547  loss:0.3573179841041565\n",
      "Epoch:111  accuracy:87.4493927125506  loss:0.37386733293533325\n",
      "Epoch:112  accuracy:88.25910931174089  loss:0.3681524395942688\n",
      "Epoch:113  accuracy:87.04453441295547  loss:0.3839677572250366\n",
      "Epoch:114  accuracy:85.82995951417004  loss:0.39130911231040955\n",
      "Epoch:115  accuracy:87.4493927125506  loss:0.38256406784057617\n",
      "Epoch:116  accuracy:87.85425101214575  loss:0.38217687606811523\n",
      "Epoch:117  accuracy:87.85425101214575  loss:0.39854565262794495\n",
      "Epoch:118  accuracy:87.4493927125506  loss:0.3525361120700836\n",
      "Epoch:119  accuracy:88.25910931174089  loss:0.3698672950267792\n",
      "Epoch:120  accuracy:86.63967611336032  loss:0.38048556447029114\n",
      "Epoch:121  accuracy:87.4493927125506  loss:0.384635329246521\n",
      "Epoch:122  accuracy:86.63967611336032  loss:0.3569803535938263\n",
      "Epoch:123  accuracy:87.4493927125506  loss:0.372368186712265\n",
      "Epoch:124  accuracy:87.85425101214575  loss:0.36189740896224976\n",
      "Epoch:125  accuracy:84.21052631578948  loss:0.44469186663627625\n",
      "Epoch:126  accuracy:87.4493927125506  loss:0.364755243062973\n",
      "Epoch:127  accuracy:87.85425101214575  loss:0.3913377821445465\n",
      "Epoch:128  accuracy:88.66396761133603  loss:0.37095487117767334\n",
      "Epoch:129  accuracy:87.4493927125506  loss:0.35542574524879456\n",
      "Early Stop\n",
      "Worker11 start\n",
      "Epoch:1  accuracy:38.83495145631068  loss:2.2476847171783447\n",
      "Epoch:2  accuracy:38.83495145631068  loss:2.058870792388916\n",
      "Epoch:3  accuracy:38.83495145631068  loss:1.7695958614349365\n",
      "Epoch:4  accuracy:38.83495145631068  loss:1.759238839149475\n",
      "Epoch:5  accuracy:38.83495145631068  loss:1.729560375213623\n",
      "Epoch:6  accuracy:38.83495145631068  loss:1.717357873916626\n",
      "Epoch:7  accuracy:38.83495145631068  loss:1.7090402841567993\n",
      "Epoch:8  accuracy:38.83495145631068  loss:1.7016818523406982\n",
      "Epoch:9  accuracy:38.83495145631068  loss:1.6918061971664429\n",
      "Epoch:10  accuracy:38.83495145631068  loss:1.6839464902877808\n",
      "Epoch:11  accuracy:38.83495145631068  loss:1.669021725654602\n",
      "Epoch:12  accuracy:39.15857605177994  loss:1.671636939048767\n",
      "Epoch:13  accuracy:41.10032362459547  loss:1.652541995048523\n",
      "Epoch:14  accuracy:46.27831715210356  loss:1.6361802816390991\n",
      "Epoch:15  accuracy:44.01294498381877  loss:1.6323573589324951\n",
      "Epoch:16  accuracy:51.77993527508091  loss:1.621091604232788\n",
      "Epoch:17  accuracy:49.51456310679612  loss:1.6097874641418457\n",
      "Epoch:18  accuracy:53.72168284789644  loss:1.5946333408355713\n",
      "Epoch:19  accuracy:53.398058252427184  loss:1.5826085805892944\n",
      "Epoch:20  accuracy:55.33980582524272  loss:1.5636271238327026\n",
      "Epoch:21  accuracy:55.98705501618123  loss:1.5533959865570068\n",
      "Epoch:22  accuracy:54.69255663430421  loss:1.5324974060058594\n",
      "Epoch:23  accuracy:56.957928802588995  loss:1.5010727643966675\n",
      "Epoch:24  accuracy:56.310679611650485  loss:1.4746438264846802\n",
      "Epoch:25  accuracy:56.957928802588995  loss:1.4755128622055054\n",
      "Epoch:26  accuracy:56.957928802588995  loss:1.4147299528121948\n",
      "Epoch:27  accuracy:56.957928802588995  loss:1.3987244367599487\n",
      "Epoch:28  accuracy:56.310679611650485  loss:1.3639856576919556\n",
      "Epoch:29  accuracy:57.28155339805825  loss:1.375347375869751\n",
      "Epoch:30  accuracy:57.605177993527505  loss:1.3331979513168335\n",
      "Epoch:31  accuracy:58.25242718446602  loss:1.3281893730163574\n",
      "Epoch:32  accuracy:58.89967637540453  loss:1.2932864427566528\n",
      "Epoch:33  accuracy:59.54692556634304  loss:1.3060228824615479\n",
      "Epoch:34  accuracy:60.19417475728155  loss:1.3022267818450928\n",
      "Epoch:35  accuracy:59.54692556634304  loss:1.276614785194397\n",
      "Epoch:36  accuracy:59.54692556634304  loss:1.254391074180603\n",
      "Epoch:37  accuracy:61.16504854368932  loss:1.2290655374526978\n",
      "Epoch:38  accuracy:60.19417475728155  loss:1.24075448513031\n",
      "Epoch:39  accuracy:59.22330097087379  loss:1.3051587343215942\n",
      "Epoch:40  accuracy:61.48867313915858  loss:1.2393550872802734\n",
      "Epoch:41  accuracy:60.19417475728155  loss:1.2682147026062012\n",
      "Epoch:42  accuracy:60.84142394822006  loss:1.2510128021240234\n",
      "Epoch:43  accuracy:59.22330097087379  loss:1.2605364322662354\n",
      "Epoch:44  accuracy:59.22330097087379  loss:1.260870099067688\n",
      "Epoch:45  accuracy:60.19417475728155  loss:1.218955159187317\n",
      "Epoch:46  accuracy:60.51779935275081  loss:1.216510534286499\n",
      "Epoch:47  accuracy:61.48867313915858  loss:1.2172526121139526\n",
      "Epoch:48  accuracy:60.84142394822006  loss:1.211288332939148\n",
      "Epoch:49  accuracy:61.48867313915858  loss:1.2131054401397705\n",
      "Epoch:50  accuracy:61.48867313915858  loss:1.2318137884140015\n",
      "Epoch:51  accuracy:62.13592233009709  loss:1.2353439331054688\n",
      "Epoch:52  accuracy:60.51779935275081  loss:1.2063640356063843\n",
      "Epoch:53  accuracy:60.51779935275081  loss:1.198157787322998\n",
      "Epoch:54  accuracy:55.98705501618123  loss:1.2762558460235596\n",
      "Epoch:55  accuracy:62.13592233009709  loss:1.1900476217269897\n",
      "Epoch:56  accuracy:60.51779935275081  loss:1.2126696109771729\n",
      "Epoch:57  accuracy:60.51779935275081  loss:1.24320387840271\n",
      "Epoch:58  accuracy:62.13592233009709  loss:1.2090559005737305\n",
      "Epoch:59  accuracy:61.48867313915858  loss:1.2359108924865723\n",
      "Epoch:60  accuracy:62.13592233009709  loss:1.1704199314117432\n",
      "Epoch:61  accuracy:61.48867313915858  loss:1.2043836116790771\n",
      "Epoch:62  accuracy:59.8705501618123  loss:1.2077670097351074\n",
      "Epoch:63  accuracy:62.13592233009709  loss:1.1868683099746704\n",
      "Epoch:64  accuracy:62.13592233009709  loss:1.2027193307876587\n",
      "Epoch:65  accuracy:62.13592233009709  loss:1.1723958253860474\n",
      "Epoch:66  accuracy:61.16504854368932  loss:1.271180272102356\n",
      "Epoch:67  accuracy:62.13592233009709  loss:1.2100474834442139\n",
      "Epoch:68  accuracy:62.13592233009709  loss:1.1679201126098633\n",
      "Epoch:69  accuracy:62.7831715210356  loss:1.1975151300430298\n",
      "Epoch:70  accuracy:62.13592233009709  loss:1.1867035627365112\n",
      "Epoch:71  accuracy:61.81229773462783  loss:1.1671990156173706\n",
      "Epoch:72  accuracy:62.13592233009709  loss:1.1643540859222412\n",
      "Epoch:73  accuracy:63.10679611650485  loss:1.1507289409637451\n",
      "Epoch:74  accuracy:62.13592233009709  loss:1.1633776426315308\n",
      "Epoch:75  accuracy:61.48867313915858  loss:1.2073136568069458\n",
      "Epoch:76  accuracy:61.81229773462783  loss:1.1557289361953735\n",
      "Epoch:77  accuracy:61.81229773462783  loss:1.1514348983764648\n",
      "Epoch:78  accuracy:61.81229773462783  loss:1.1437087059020996\n",
      "Epoch:79  accuracy:61.16504854368932  loss:1.1076360940933228\n",
      "Epoch:80  accuracy:62.7831715210356  loss:1.1157349348068237\n",
      "Epoch:81  accuracy:62.7831715210356  loss:1.1179791688919067\n",
      "Epoch:82  accuracy:62.13592233009709  loss:1.151144027709961\n",
      "Epoch:83  accuracy:63.75404530744336  loss:1.2451802492141724\n",
      "Epoch:84  accuracy:62.13592233009709  loss:1.1231878995895386\n",
      "Epoch:85  accuracy:63.10679611650485  loss:1.0976014137268066\n",
      "Epoch:86  accuracy:61.81229773462783  loss:1.0873643159866333\n",
      "Epoch:87  accuracy:62.45954692556634  loss:1.122223138809204\n",
      "Epoch:88  accuracy:63.43042071197411  loss:1.1639386415481567\n",
      "Epoch:89  accuracy:64.40129449838187  loss:1.1135882139205933\n",
      "Epoch:90  accuracy:64.07766990291262  loss:1.1093559265136719\n",
      "Epoch:91  accuracy:64.07766990291262  loss:1.1410751342773438\n",
      "Epoch:92  accuracy:63.10679611650485  loss:1.1137561798095703\n",
      "Epoch:93  accuracy:64.72491909385113  loss:1.087464690208435\n",
      "Epoch:94  accuracy:62.13592233009709  loss:1.149963140487671\n",
      "Epoch:95  accuracy:62.7831715210356  loss:1.0994867086410522\n",
      "Epoch:96  accuracy:64.72491909385113  loss:1.077555537223816\n",
      "Epoch:97  accuracy:65.04854368932038  loss:1.1053842306137085\n",
      "Epoch:98  accuracy:63.43042071197411  loss:1.086207389831543\n",
      "Epoch:99  accuracy:64.07766990291262  loss:1.0823743343353271\n",
      "Epoch:100  accuracy:63.75404530744336  loss:1.113102674484253\n",
      "Epoch:101  accuracy:65.04854368932038  loss:1.0875056982040405\n",
      "Epoch:102  accuracy:64.07766990291262  loss:1.0934736728668213\n",
      "Epoch:103  accuracy:65.04854368932038  loss:1.0515977144241333\n",
      "Epoch:104  accuracy:64.40129449838187  loss:1.0872089862823486\n",
      "Epoch:105  accuracy:64.72491909385113  loss:1.0987292528152466\n",
      "Epoch:106  accuracy:65.37216828478964  loss:1.1010539531707764\n",
      "Epoch:107  accuracy:64.72491909385113  loss:1.1109975576400757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:108  accuracy:65.04854368932038  loss:1.0514410734176636\n",
      "Epoch:109  accuracy:65.37216828478964  loss:1.1137349605560303\n",
      "Epoch:110  accuracy:65.04854368932038  loss:1.172960638999939\n",
      "Epoch:111  accuracy:64.07766990291262  loss:1.085951805114746\n",
      "Epoch:112  accuracy:64.40129449838187  loss:1.0999208688735962\n",
      "Epoch:113  accuracy:64.40129449838187  loss:1.06645667552948\n",
      "Epoch:114  accuracy:63.43042071197411  loss:1.1125662326812744\n",
      "Epoch:115  accuracy:65.37216828478964  loss:1.0903379917144775\n",
      "Epoch:116  accuracy:65.6957928802589  loss:1.118165135383606\n",
      "Epoch:117  accuracy:64.72491909385113  loss:1.1490058898925781\n",
      "Epoch:118  accuracy:65.37216828478964  loss:1.183044195175171\n",
      "Epoch:119  accuracy:63.75404530744336  loss:1.148322343826294\n",
      "Early Stop\n",
      "Worker12 start\n",
      "Epoch:1  accuracy:34.50807635829662  loss:1.9726345539093018\n",
      "Epoch:2  accuracy:34.50807635829662  loss:1.5255144834518433\n",
      "Epoch:3  accuracy:34.50807635829662  loss:1.5078673362731934\n",
      "Epoch:4  accuracy:35.242290748898675  loss:1.5075883865356445\n",
      "Epoch:5  accuracy:35.095447870778266  loss:1.5105050802230835\n",
      "Epoch:6  accuracy:34.948604992657856  loss:1.4915262460708618\n",
      "Epoch:7  accuracy:42.290748898678416  loss:1.4833177328109741\n",
      "Epoch:8  accuracy:34.50807635829662  loss:1.4904398918151855\n",
      "Epoch:9  accuracy:37.73861967694567  loss:1.4763193130493164\n",
      "Epoch:10  accuracy:48.458149779735685  loss:1.4875291585922241\n",
      "Epoch:11  accuracy:40.67547723935389  loss:1.4710503816604614\n",
      "Epoch:12  accuracy:40.23494860499266  loss:1.459363579750061\n",
      "Epoch:13  accuracy:38.91336270190896  loss:1.449129581451416\n",
      "Epoch:14  accuracy:52.42290748898679  loss:1.44374680519104\n",
      "Epoch:15  accuracy:45.96182085168869  loss:1.4457272291183472\n",
      "Epoch:16  accuracy:48.89867841409691  loss:1.4133591651916504\n",
      "Epoch:17  accuracy:49.48604992657856  loss:1.411320686340332\n",
      "Epoch:18  accuracy:46.54919236417034  loss:1.3768815994262695\n",
      "Epoch:19  accuracy:48.604992657856094  loss:1.3532119989395142\n",
      "Epoch:20  accuracy:49.19236417033774  loss:1.341220498085022\n",
      "Epoch:21  accuracy:50.36710719530103  loss:1.3338268995285034\n",
      "Epoch:22  accuracy:51.688693098384725  loss:1.3018858432769775\n",
      "Epoch:23  accuracy:50.95447870778267  loss:1.3026647567749023\n",
      "Epoch:24  accuracy:51.98237885462555  loss:1.288313627243042\n",
      "Epoch:25  accuracy:52.27606461086637  loss:1.2799841165542603\n",
      "Epoch:26  accuracy:52.71659324522761  loss:1.2796497344970703\n",
      "Epoch:27  accuracy:49.33920704845815  loss:1.3614726066589355\n",
      "Epoch:28  accuracy:52.42290748898679  loss:1.3006311655044556\n",
      "Epoch:29  accuracy:53.74449339207048  loss:1.2609968185424805\n",
      "Epoch:30  accuracy:54.91923641703377  loss:1.2577091455459595\n",
      "Epoch:31  accuracy:55.80029368575624  loss:1.222805142402649\n",
      "Epoch:32  accuracy:56.5345080763583  loss:1.2002726793289185\n",
      "Epoch:33  accuracy:56.68135095447871  loss:1.196348786354065\n",
      "Epoch:34  accuracy:53.74449339207048  loss:1.241567850112915\n",
      "Epoch:35  accuracy:56.97503671071953  loss:1.2227463722229004\n",
      "Epoch:36  accuracy:60.205580029368576  loss:1.1789567470550537\n",
      "Epoch:37  accuracy:58.00293685756241  loss:1.1729718446731567\n",
      "Epoch:38  accuracy:60.05873715124817  loss:1.1620593070983887\n",
      "Epoch:39  accuracy:59.030837004405285  loss:1.1636134386062622\n",
      "Epoch:40  accuracy:57.415565345080765  loss:1.1787784099578857\n",
      "Epoch:41  accuracy:56.38766519823788  loss:1.1809492111206055\n",
      "Epoch:42  accuracy:57.856093979441994  loss:1.1752732992172241\n",
      "Epoch:43  accuracy:60.352422907488986  loss:1.1323540210723877\n",
      "Epoch:44  accuracy:61.67400881057269  loss:1.09895920753479\n",
      "Epoch:45  accuracy:58.44346549192364  loss:1.1369503736495972\n",
      "Epoch:46  accuracy:61.08663729809104  loss:1.1402838230133057\n",
      "Epoch:47  accuracy:59.61820851688693  loss:1.1145129203796387\n",
      "Epoch:48  accuracy:60.93979441997063  loss:1.0824865102767944\n",
      "Epoch:49  accuracy:57.268722466960355  loss:1.121323585510254\n",
      "Epoch:50  accuracy:61.67400881057269  loss:1.0686217546463013\n",
      "Epoch:51  accuracy:59.91189427312775  loss:1.0854562520980835\n",
      "Epoch:52  accuracy:61.23348017621145  loss:1.0686254501342773\n",
      "Epoch:53  accuracy:61.38032305433187  loss:1.0665557384490967\n",
      "Epoch:54  accuracy:57.562408223201174  loss:1.148295283317566\n",
      "Epoch:55  accuracy:61.23348017621145  loss:1.045597791671753\n",
      "Epoch:56  accuracy:60.05873715124817  loss:1.0512168407440186\n",
      "Epoch:57  accuracy:59.76505139500734  loss:1.0586687326431274\n",
      "Epoch:58  accuracy:62.84875183553598  loss:1.0409486293792725\n",
      "Epoch:59  accuracy:63.436123348017624  loss:1.0154647827148438\n",
      "Epoch:60  accuracy:61.52716593245228  loss:1.0914794206619263\n",
      "Epoch:61  accuracy:60.205580029368576  loss:1.0371475219726562\n",
      "Epoch:62  accuracy:63.28928046989721  loss:0.9997019171714783\n",
      "Epoch:63  accuracy:63.1424375917768  loss:1.0299711227416992\n",
      "Epoch:64  accuracy:63.436123348017624  loss:1.0039525032043457\n",
      "Epoch:65  accuracy:65.63876651982379  loss:0.979758620262146\n",
      "Epoch:66  accuracy:64.90455212922173  loss:1.0143589973449707\n",
      "Epoch:67  accuracy:62.84875183553598  loss:1.0800422430038452\n",
      "Epoch:68  accuracy:66.96035242290749  loss:0.9427178502082825\n",
      "Epoch:69  accuracy:65.34508076358297  loss:0.9842612743377686\n",
      "Epoch:70  accuracy:66.22613803230543  loss:0.9770073294639587\n",
      "Epoch:71  accuracy:66.66666666666667  loss:0.940714955329895\n",
      "Epoch:72  accuracy:65.93245227606461  loss:0.9597824215888977\n",
      "Epoch:73  accuracy:66.37298091042584  loss:0.948554277420044\n",
      "Epoch:74  accuracy:66.66666666666667  loss:0.939187228679657\n",
      "Epoch:75  accuracy:65.34508076358297  loss:1.0196911096572876\n",
      "Epoch:76  accuracy:67.54772393538913  loss:0.9271603226661682\n",
      "Epoch:77  accuracy:66.66666666666667  loss:0.92679363489151\n",
      "Epoch:78  accuracy:66.51982378854626  loss:0.9271472096443176\n",
      "Epoch:79  accuracy:64.17033773861968  loss:1.0589500665664673\n",
      "Epoch:80  accuracy:65.63876651982379  loss:1.0133353471755981\n",
      "Epoch:81  accuracy:66.96035242290749  loss:0.9534220099449158\n",
      "Epoch:82  accuracy:68.57562408223201  loss:0.9143358469009399\n",
      "Epoch:83  accuracy:69.60352422907489  loss:0.885246217250824\n",
      "Epoch:84  accuracy:68.4287812041116  loss:0.9507590532302856\n",
      "Epoch:85  accuracy:68.86930983847283  loss:0.8914338946342468\n",
      "Epoch:86  accuracy:66.51982378854626  loss:0.9781537055969238\n",
      "Epoch:87  accuracy:67.54772393538913  loss:0.9017797112464905\n",
      "Epoch:88  accuracy:69.01615271659324  loss:0.9054295420646667\n",
      "Epoch:89  accuracy:67.54772393538913  loss:0.9694785475730896\n",
      "Epoch:90  accuracy:68.13509544787078  loss:0.9161615967750549\n",
      "Epoch:91  accuracy:68.86930983847283  loss:0.9107804894447327\n",
      "Epoch:92  accuracy:66.96035242290749  loss:0.926994800567627\n",
      "Epoch:93  accuracy:67.98825256975037  loss:0.928109884262085\n",
      "Epoch:94  accuracy:70.19089574155653  loss:0.8881785869598389\n",
      "Early Stop\n",
      "Worker13 start\n",
      "Epoch:1  accuracy:63.56107660455486  loss:1.75294029712677\n",
      "Epoch:2  accuracy:63.56107660455486  loss:1.1567497253417969\n",
      "Epoch:3  accuracy:63.56107660455486  loss:1.1303108930587769\n",
      "Epoch:4  accuracy:63.56107660455486  loss:1.1132732629776\n",
      "Epoch:5  accuracy:63.56107660455486  loss:1.0899165868759155\n",
      "Epoch:6  accuracy:63.56107660455486  loss:1.1155121326446533\n",
      "Epoch:7  accuracy:63.56107660455486  loss:1.108846664428711\n",
      "Epoch:8  accuracy:63.56107660455486  loss:1.065659523010254\n",
      "Epoch:9  accuracy:63.56107660455486  loss:1.0381853580474854\n",
      "Epoch:10  accuracy:63.56107660455486  loss:1.0271716117858887\n",
      "Epoch:11  accuracy:63.56107660455486  loss:1.0192632675170898\n",
      "Epoch:12  accuracy:63.56107660455486  loss:1.0106996297836304\n",
      "Epoch:13  accuracy:63.56107660455486  loss:1.0053735971450806\n",
      "Epoch:14  accuracy:63.56107660455486  loss:0.9737675189971924\n",
      "Epoch:15  accuracy:63.56107660455486  loss:0.9411674737930298\n",
      "Epoch:16  accuracy:63.56107660455486  loss:0.9286811351776123\n",
      "Epoch:17  accuracy:71.01449275362319  loss:0.8969596028327942\n",
      "Epoch:18  accuracy:58.178053830227746  loss:1.0975347757339478\n",
      "Epoch:19  accuracy:71.84265010351967  loss:0.7735475301742554\n",
      "Epoch:20  accuracy:72.46376811594203  loss:0.7667132019996643\n",
      "Epoch:21  accuracy:73.2919254658385  loss:0.7379011511802673\n",
      "Epoch:22  accuracy:73.08488612836439  loss:0.7138041257858276\n",
      "Epoch:23  accuracy:73.91304347826087  loss:0.6924843192100525\n",
      "Epoch:24  accuracy:74.94824016563147  loss:0.6900100111961365\n",
      "Epoch:25  accuracy:74.74120082815735  loss:0.7000352740287781\n",
      "Epoch:26  accuracy:74.53416149068323  loss:0.7708429098129272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:27  accuracy:75.98343685300208  loss:0.6686977744102478\n",
      "Epoch:28  accuracy:72.04968944099379  loss:0.7623876333236694\n",
      "Epoch:29  accuracy:75.77639751552795  loss:0.6694399118423462\n",
      "Epoch:30  accuracy:75.56935817805383  loss:0.668053150177002\n",
      "Epoch:31  accuracy:75.3623188405797  loss:0.6754130721092224\n",
      "Epoch:32  accuracy:76.81159420289855  loss:0.6478107571601868\n",
      "Epoch:33  accuracy:75.98343685300208  loss:0.6440690755844116\n",
      "Epoch:34  accuracy:76.19047619047619  loss:0.626365065574646\n",
      "Epoch:35  accuracy:76.3975155279503  loss:0.6424595713615417\n",
      "Epoch:36  accuracy:76.81159420289855  loss:0.6357445120811462\n",
      "Epoch:37  accuracy:76.60455486542443  loss:0.6545073986053467\n",
      "Epoch:38  accuracy:77.01863354037268  loss:0.6282893419265747\n",
      "Epoch:39  accuracy:77.22567287784679  loss:0.6742347478866577\n",
      "Epoch:40  accuracy:77.01863354037268  loss:0.6857396364212036\n",
      "Epoch:41  accuracy:76.60455486542443  loss:0.6288968920707703\n",
      "Epoch:42  accuracy:77.01863354037268  loss:0.6187373995780945\n",
      "Epoch:43  accuracy:77.63975155279503  loss:0.6176871657371521\n",
      "Epoch:44  accuracy:77.22567287784679  loss:0.60423344373703\n",
      "Epoch:45  accuracy:77.63975155279503  loss:0.6178814172744751\n",
      "Epoch:46  accuracy:76.81159420289855  loss:0.6342045664787292\n",
      "Epoch:47  accuracy:77.22567287784679  loss:0.6120597124099731\n",
      "Epoch:48  accuracy:73.49896480331263  loss:0.647467851638794\n",
      "Epoch:49  accuracy:77.01863354037268  loss:0.6178046464920044\n",
      "Epoch:50  accuracy:70.1863354037267  loss:0.6619062423706055\n",
      "Epoch:51  accuracy:77.63975155279503  loss:0.6134048104286194\n",
      "Epoch:52  accuracy:78.05383022774328  loss:0.5976730585098267\n",
      "Epoch:53  accuracy:71.84265010351967  loss:0.663470447063446\n",
      "Epoch:54  accuracy:73.08488612836439  loss:0.6282808780670166\n",
      "Epoch:55  accuracy:77.22567287784679  loss:0.6312186121940613\n",
      "Epoch:56  accuracy:78.26086956521739  loss:0.6180217862129211\n",
      "Epoch:57  accuracy:76.3975155279503  loss:0.7254429459571838\n",
      "Epoch:58  accuracy:76.60455486542443  loss:0.6315107941627502\n",
      "Epoch:59  accuracy:73.91304347826087  loss:0.5919346213340759\n",
      "Epoch:60  accuracy:78.26086956521739  loss:0.5954663157463074\n",
      "Epoch:61  accuracy:73.91304347826087  loss:0.8118293285369873\n",
      "Epoch:62  accuracy:77.4327122153209  loss:0.6140202283859253\n",
      "Epoch:63  accuracy:78.67494824016563  loss:0.6038877964019775\n",
      "Epoch:64  accuracy:77.4327122153209  loss:0.5908567905426025\n",
      "Epoch:65  accuracy:72.87784679089027  loss:0.5978716611862183\n",
      "Epoch:66  accuracy:78.4679089026915  loss:0.6116953492164612\n",
      "Epoch:67  accuracy:76.19047619047619  loss:0.5784456729888916\n",
      "Epoch:68  accuracy:78.05383022774328  loss:0.5720284581184387\n",
      "Epoch:69  accuracy:77.4327122153209  loss:0.6229920387268066\n",
      "Epoch:70  accuracy:77.01863354037268  loss:0.6250627040863037\n",
      "Epoch:71  accuracy:77.63975155279503  loss:0.6542374491691589\n",
      "Epoch:72  accuracy:77.22567287784679  loss:0.6446692943572998\n",
      "Epoch:73  accuracy:78.26086956521739  loss:0.5825208425521851\n",
      "Epoch:74  accuracy:77.84679089026915  loss:0.5744293332099915\n",
      "Epoch:75  accuracy:76.3975155279503  loss:0.5873959064483643\n",
      "Epoch:76  accuracy:77.63975155279503  loss:0.5956764817237854\n",
      "Epoch:77  accuracy:77.63975155279503  loss:0.6268637180328369\n",
      "Epoch:78  accuracy:74.3271221532091  loss:0.595666229724884\n",
      "Epoch:79  accuracy:77.84679089026915  loss:0.6451140642166138\n",
      "Early Stop\n",
      "Worker14 start\n",
      "Epoch:1  accuracy:36.52482269503546  loss:2.2465336322784424\n",
      "Epoch:2  accuracy:40.42553191489362  loss:2.163073778152466\n",
      "Epoch:3  accuracy:40.780141843971634  loss:1.927011251449585\n",
      "Epoch:4  accuracy:38.652482269503544  loss:1.5874394178390503\n",
      "Epoch:5  accuracy:38.652482269503544  loss:1.613720417022705\n",
      "Epoch:6  accuracy:38.652482269503544  loss:1.5917121171951294\n",
      "Epoch:7  accuracy:43.61702127659574  loss:1.6007447242736816\n",
      "Epoch:8  accuracy:38.652482269503544  loss:1.593895673751831\n",
      "Epoch:9  accuracy:40.42553191489362  loss:1.598883867263794\n",
      "Epoch:10  accuracy:44.680851063829785  loss:1.5842022895812988\n",
      "Epoch:11  accuracy:41.13475177304964  loss:1.5849868059158325\n",
      "Epoch:12  accuracy:51.41843971631206  loss:1.608681082725525\n",
      "Epoch:13  accuracy:48.226950354609926  loss:1.5550100803375244\n",
      "Epoch:14  accuracy:56.02836879432624  loss:1.5678528547286987\n",
      "Epoch:15  accuracy:44.326241134751776  loss:1.5592023134231567\n",
      "Epoch:16  accuracy:46.45390070921986  loss:1.5411895513534546\n",
      "Epoch:17  accuracy:48.58156028368794  loss:1.5172414779663086\n",
      "Epoch:18  accuracy:51.41843971631206  loss:1.5152308940887451\n",
      "Epoch:19  accuracy:55.319148936170215  loss:1.4831732511520386\n",
      "Epoch:20  accuracy:47.87234042553192  loss:1.4651397466659546\n",
      "Epoch:21  accuracy:53.90070921985816  loss:1.392223596572876\n",
      "Epoch:22  accuracy:52.12765957446808  loss:1.3709861040115356\n",
      "Epoch:23  accuracy:58.86524822695036  loss:1.3255642652511597\n",
      "Epoch:24  accuracy:55.673758865248224  loss:1.295380711555481\n",
      "Epoch:25  accuracy:55.673758865248224  loss:1.2698156833648682\n",
      "Epoch:26  accuracy:55.673758865248224  loss:1.2864848375320435\n",
      "Epoch:27  accuracy:56.38297872340426  loss:1.3150336742401123\n",
      "Epoch:28  accuracy:56.737588652482266  loss:1.2857449054718018\n",
      "Epoch:29  accuracy:56.737588652482266  loss:1.275907039642334\n",
      "Epoch:30  accuracy:55.673758865248224  loss:1.2668468952178955\n",
      "Epoch:31  accuracy:59.9290780141844  loss:1.2147611379623413\n",
      "Epoch:32  accuracy:59.219858156028366  loss:1.2895187139511108\n",
      "Epoch:33  accuracy:55.319148936170215  loss:1.329702377319336\n",
      "Epoch:34  accuracy:59.9290780141844  loss:1.2146271467208862\n",
      "Epoch:35  accuracy:59.57446808510638  loss:1.2271490097045898\n",
      "Epoch:36  accuracy:60.99290780141844  loss:1.1689175367355347\n",
      "Epoch:37  accuracy:60.99290780141844  loss:1.1773295402526855\n",
      "Epoch:38  accuracy:60.99290780141844  loss:1.1448733806610107\n",
      "Epoch:39  accuracy:58.86524822695036  loss:1.1893610954284668\n",
      "Epoch:40  accuracy:63.47517730496454  loss:1.1496484279632568\n",
      "Epoch:41  accuracy:59.9290780141844  loss:1.2303755283355713\n",
      "Epoch:42  accuracy:60.283687943262414  loss:1.1726998090744019\n",
      "Epoch:43  accuracy:64.8936170212766  loss:1.075435757637024\n",
      "Epoch:44  accuracy:62.05673758865248  loss:1.0943528413772583\n",
      "Epoch:45  accuracy:65.2482269503546  loss:1.0873159170150757\n",
      "Epoch:46  accuracy:64.53900709219859  loss:1.10285222530365\n",
      "Epoch:47  accuracy:64.18439716312056  loss:1.126199722290039\n",
      "Epoch:48  accuracy:64.18439716312056  loss:1.0756758451461792\n",
      "Epoch:49  accuracy:62.05673758865248  loss:1.1419352293014526\n",
      "Epoch:50  accuracy:61.347517730496456  loss:1.1769158840179443\n",
      "Epoch:51  accuracy:69.14893617021276  loss:1.0622656345367432\n",
      "Epoch:52  accuracy:65.60283687943263  loss:1.027836561203003\n",
      "Epoch:53  accuracy:68.79432624113475  loss:1.0211100578308105\n",
      "Epoch:54  accuracy:64.53900709219859  loss:1.0704798698425293\n",
      "Epoch:55  accuracy:63.47517730496454  loss:1.0658141374588013\n",
      "Epoch:56  accuracy:68.08510638297872  loss:0.952724039554596\n",
      "Epoch:57  accuracy:70.2127659574468  loss:0.9573105573654175\n",
      "Epoch:58  accuracy:69.14893617021276  loss:0.969864547252655\n",
      "Epoch:59  accuracy:69.14893617021276  loss:0.9726802706718445\n",
      "Epoch:60  accuracy:69.8581560283688  loss:0.9786869287490845\n",
      "Epoch:61  accuracy:70.56737588652483  loss:0.9465206265449524\n",
      "Epoch:62  accuracy:69.8581560283688  loss:0.9665529727935791\n",
      "Epoch:63  accuracy:70.92198581560284  loss:0.9479525089263916\n",
      "Epoch:64  accuracy:67.37588652482269  loss:0.9897357225418091\n",
      "Epoch:65  accuracy:68.08510638297872  loss:0.9862130880355835\n",
      "Epoch:66  accuracy:70.2127659574468  loss:0.9725155830383301\n",
      "Epoch:67  accuracy:60.638297872340424  loss:1.1491527557373047\n",
      "Epoch:68  accuracy:67.02127659574468  loss:0.9868290424346924\n",
      "Epoch:69  accuracy:73.04964539007092  loss:0.9106504917144775\n",
      "Epoch:70  accuracy:72.69503546099291  loss:0.908715009689331\n",
      "Epoch:71  accuracy:69.8581560283688  loss:0.8959828615188599\n",
      "Epoch:72  accuracy:70.92198581560284  loss:0.927688479423523\n",
      "Epoch:73  accuracy:72.69503546099291  loss:0.9394350647926331\n",
      "Epoch:74  accuracy:68.08510638297872  loss:1.0079519748687744\n",
      "Epoch:75  accuracy:65.2482269503546  loss:1.0011227130889893\n",
      "Epoch:76  accuracy:71.98581560283688  loss:0.925409197807312\n",
      "Epoch:77  accuracy:70.56737588652483  loss:0.9441216588020325\n",
      "Epoch:78  accuracy:73.75886524822695  loss:0.9075478315353394\n",
      "Epoch:79  accuracy:71.63120567375887  loss:0.9273684024810791\n",
      "Epoch:80  accuracy:69.50354609929079  loss:0.9687614440917969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:81  accuracy:64.53900709219859  loss:1.0644515752792358\n",
      "Epoch:82  accuracy:69.14893617021276  loss:0.928861141204834\n",
      "Early Stop\n",
      "Worker15 start\n",
      "Epoch:1  accuracy:49.2239467849224  loss:1.9829120635986328\n",
      "Epoch:2  accuracy:49.2239467849224  loss:1.3236126899719238\n",
      "Epoch:3  accuracy:49.2239467849224  loss:1.2867668867111206\n",
      "Epoch:4  accuracy:49.2239467849224  loss:1.2448078393936157\n",
      "Epoch:5  accuracy:49.2239467849224  loss:1.239793300628662\n",
      "Epoch:6  accuracy:49.2239467849224  loss:1.2423893213272095\n",
      "Epoch:7  accuracy:49.2239467849224  loss:1.2366023063659668\n",
      "Epoch:8  accuracy:49.2239467849224  loss:1.2477129697799683\n",
      "Epoch:9  accuracy:49.2239467849224  loss:1.235208511352539\n",
      "Epoch:10  accuracy:49.2239467849224  loss:1.2399652004241943\n",
      "Epoch:11  accuracy:49.2239467849224  loss:1.2247426509857178\n",
      "Epoch:12  accuracy:49.2239467849224  loss:1.2273657321929932\n",
      "Epoch:13  accuracy:49.2239467849224  loss:1.2275283336639404\n",
      "Epoch:14  accuracy:49.2239467849224  loss:1.2354069948196411\n",
      "Epoch:15  accuracy:49.2239467849224  loss:1.2154581546783447\n",
      "Epoch:16  accuracy:49.2239467849224  loss:1.202638864517212\n",
      "Epoch:17  accuracy:49.2239467849224  loss:1.2021465301513672\n",
      "Epoch:18  accuracy:57.427937915742795  loss:1.2028605937957764\n",
      "Epoch:19  accuracy:55.87583148558758  loss:1.2013542652130127\n",
      "Epoch:20  accuracy:56.98447893569845  loss:1.188563585281372\n",
      "Epoch:21  accuracy:50.33259423503326  loss:1.1836503744125366\n",
      "Epoch:22  accuracy:50.110864745011085  loss:1.1782444715499878\n",
      "Epoch:23  accuracy:59.42350332594235  loss:1.1661173105239868\n",
      "Epoch:24  accuracy:58.09312638580931  loss:1.1537647247314453\n",
      "Epoch:25  accuracy:57.427937915742795  loss:1.17086923122406\n",
      "Epoch:26  accuracy:58.09312638580931  loss:1.1327719688415527\n",
      "Epoch:27  accuracy:59.42350332594235  loss:1.1213712692260742\n",
      "Epoch:28  accuracy:58.09312638580931  loss:1.1128008365631104\n",
      "Epoch:29  accuracy:59.42350332594235  loss:1.0963923931121826\n",
      "Epoch:30  accuracy:58.09312638580931  loss:1.1156468391418457\n",
      "Epoch:31  accuracy:59.20177383592018  loss:1.092149257659912\n",
      "Epoch:32  accuracy:59.42350332594235  loss:1.086303472518921\n",
      "Epoch:33  accuracy:62.08425720620843  loss:1.069257378578186\n",
      "Epoch:34  accuracy:59.20177383592018  loss:1.0742571353912354\n",
      "Epoch:35  accuracy:66.07538802660754  loss:1.0350109338760376\n",
      "Epoch:36  accuracy:65.85365853658537  loss:1.059064269065857\n",
      "Epoch:37  accuracy:66.07538802660754  loss:1.0311570167541504\n",
      "Epoch:38  accuracy:59.866962305986696  loss:1.107143521308899\n",
      "Epoch:39  accuracy:66.96230598669624  loss:1.0141191482543945\n",
      "Epoch:40  accuracy:60.97560975609756  loss:1.0930923223495483\n",
      "Epoch:41  accuracy:66.51884700665188  loss:0.9916907548904419\n",
      "Epoch:42  accuracy:67.62749445676275  loss:0.9920582175254822\n",
      "Epoch:43  accuracy:66.74057649667405  loss:1.003042459487915\n",
      "Epoch:44  accuracy:63.19290465631929  loss:1.0604588985443115\n",
      "Epoch:45  accuracy:60.532150776053214  loss:1.0856671333312988\n",
      "Epoch:46  accuracy:68.51441241685144  loss:0.9929913878440857\n",
      "Epoch:47  accuracy:69.84478935698448  loss:0.9615446329116821\n",
      "Epoch:48  accuracy:68.51441241685144  loss:0.9867082834243774\n",
      "Epoch:49  accuracy:67.84922394678492  loss:0.977489709854126\n",
      "Epoch:50  accuracy:69.17960088691795  loss:0.9418928623199463\n",
      "Epoch:51  accuracy:66.74057649667405  loss:1.0199031829833984\n",
      "Epoch:52  accuracy:70.509977827051  loss:0.927558958530426\n",
      "Epoch:53  accuracy:69.62305986696231  loss:0.9226976633071899\n",
      "Epoch:54  accuracy:70.73170731707317  loss:0.8981226682662964\n",
      "Epoch:55  accuracy:70.509977827051  loss:0.8997594714164734\n",
      "Epoch:56  accuracy:71.61862527716187  loss:0.914707362651825\n",
      "Epoch:57  accuracy:70.95343680709534  loss:0.9457066655158997\n",
      "Epoch:58  accuracy:68.0709534368071  loss:0.9628368020057678\n",
      "Epoch:59  accuracy:67.40576496674058  loss:0.9747354984283447\n",
      "Epoch:60  accuracy:71.17516629711751  loss:0.8754991888999939\n",
      "Epoch:61  accuracy:71.61862527716187  loss:0.8876641392707825\n",
      "Epoch:62  accuracy:70.73170731707317  loss:0.8628169298171997\n",
      "Epoch:63  accuracy:71.61862527716187  loss:0.8544347286224365\n",
      "Epoch:64  accuracy:71.61862527716187  loss:0.8575159311294556\n",
      "Epoch:65  accuracy:69.17960088691795  loss:0.9335233569145203\n",
      "Epoch:66  accuracy:71.17516629711751  loss:0.8594188690185547\n",
      "Epoch:67  accuracy:69.40133037694014  loss:0.8912001252174377\n",
      "Epoch:68  accuracy:70.28824833702882  loss:0.8683577179908752\n",
      "Epoch:69  accuracy:70.28824833702882  loss:0.8746857643127441\n",
      "Epoch:70  accuracy:69.62305986696231  loss:0.9228296279907227\n",
      "Epoch:71  accuracy:71.61862527716187  loss:0.8711801767349243\n",
      "Epoch:72  accuracy:71.61862527716187  loss:0.8459134101867676\n",
      "Epoch:73  accuracy:73.83592017738358  loss:0.795058012008667\n",
      "Epoch:74  accuracy:73.83592017738358  loss:0.7973613142967224\n",
      "Epoch:75  accuracy:73.39246119733924  loss:0.8148548603057861\n",
      "Epoch:76  accuracy:72.50554323725055  loss:0.8412290811538696\n",
      "Epoch:77  accuracy:75.16629711751663  loss:0.787918746471405\n",
      "Epoch:78  accuracy:67.1840354767184  loss:0.9386225342750549\n",
      "Epoch:79  accuracy:76.05321507760532  loss:0.7644384503364563\n",
      "Epoch:80  accuracy:72.50554323725055  loss:0.8287985920906067\n",
      "Epoch:81  accuracy:76.05321507760532  loss:0.7661063075065613\n",
      "Epoch:82  accuracy:74.27937915742794  loss:0.84195876121521\n",
      "Epoch:83  accuracy:76.05321507760532  loss:0.7669269442558289\n",
      "Epoch:84  accuracy:73.17073170731707  loss:0.8730363845825195\n",
      "Epoch:85  accuracy:76.49667405764967  loss:0.7621288299560547\n",
      "Epoch:86  accuracy:74.50110864745011  loss:0.8011849522590637\n",
      "Epoch:87  accuracy:76.2749445676275  loss:0.7752264142036438\n",
      "Epoch:88  accuracy:70.95343680709534  loss:0.9437254071235657\n",
      "Epoch:89  accuracy:77.8270509977827  loss:0.7345602512359619\n",
      "Epoch:90  accuracy:76.2749445676275  loss:0.7846704125404358\n",
      "Epoch:91  accuracy:75.83148558758315  loss:0.7718818187713623\n",
      "Epoch:92  accuracy:77.60532150776054  loss:0.7288482785224915\n",
      "Epoch:93  accuracy:77.8270509977827  loss:0.7542474865913391\n",
      "Epoch:94  accuracy:75.16629711751663  loss:0.7982797026634216\n",
      "Epoch:95  accuracy:75.83148558758315  loss:0.7882119417190552\n",
      "Epoch:96  accuracy:72.06208425720621  loss:0.9001039266586304\n",
      "Epoch:97  accuracy:77.60532150776054  loss:0.7380479574203491\n",
      "Epoch:98  accuracy:73.17073170731707  loss:0.8805294036865234\n",
      "Epoch:99  accuracy:77.8270509977827  loss:0.7432268857955933\n",
      "Epoch:100  accuracy:79.15742793791574  loss:0.7326620817184448\n",
      "Epoch:101  accuracy:77.60532150776054  loss:0.7566414475440979\n",
      "Epoch:102  accuracy:78.04878048780488  loss:0.7743951678276062\n",
      "Epoch:103  accuracy:77.38359201773837  loss:0.7283450961112976\n",
      "Epoch:104  accuracy:77.60532150776054  loss:0.7548912763595581\n",
      "Epoch:105  accuracy:78.7139689578714  loss:0.7460859417915344\n",
      "Epoch:106  accuracy:78.49223946784923  loss:0.729682207107544\n",
      "Epoch:107  accuracy:75.60975609756098  loss:0.7772166728973389\n",
      "Epoch:108  accuracy:77.8270509977827  loss:0.7412502765655518\n",
      "Epoch:109  accuracy:79.37915742793791  loss:0.7197995185852051\n",
      "Epoch:110  accuracy:76.49667405764967  loss:0.8023974895477295\n",
      "Epoch:111  accuracy:77.8270509977827  loss:0.7798991203308105\n",
      "Epoch:112  accuracy:77.60532150776054  loss:0.8177469968795776\n",
      "Epoch:113  accuracy:73.83592017738358  loss:0.8239173889160156\n",
      "Epoch:114  accuracy:79.37915742793791  loss:0.7318053245544434\n",
      "Epoch:115  accuracy:79.15742793791574  loss:0.7417687773704529\n",
      "Epoch:116  accuracy:78.27050997782705  loss:0.7420322895050049\n",
      "Epoch:117  accuracy:78.04878048780488  loss:0.773072361946106\n",
      "Epoch:118  accuracy:74.50110864745011  loss:0.8683183193206787\n",
      "Epoch:119  accuracy:79.60088691796008  loss:0.7131644487380981\n",
      "Epoch:120  accuracy:75.83148558758315  loss:0.7568452954292297\n",
      "Epoch:121  accuracy:78.04878048780488  loss:0.7887672185897827\n",
      "Epoch:122  accuracy:79.60088691796008  loss:0.7468830347061157\n",
      "Epoch:123  accuracy:79.37915742793791  loss:0.7113342881202698\n",
      "Epoch:124  accuracy:77.60532150776054  loss:0.778875470161438\n",
      "Epoch:125  accuracy:76.71840354767184  loss:0.820874035358429\n",
      "Epoch:126  accuracy:77.60532150776054  loss:0.7681357860565186\n",
      "Epoch:127  accuracy:78.49223946784923  loss:0.857343852519989\n",
      "Epoch:128  accuracy:78.93569844789357  loss:0.7931671738624573\n",
      "Epoch:129  accuracy:77.38359201773837  loss:0.8619788885116577\n",
      "Epoch:130  accuracy:78.93569844789357  loss:0.7869566082954407\n",
      "Epoch:131  accuracy:78.27050997782705  loss:0.8736657500267029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:132  accuracy:78.93569844789357  loss:0.8021411299705505\n",
      "Epoch:133  accuracy:76.71840354767184  loss:0.9111276865005493\n",
      "Epoch:134  accuracy:78.27050997782705  loss:0.8892696499824524\n",
      "Early Stop\n",
      "Worker16 start\n",
      "Epoch:1  accuracy:8.810572687224669  loss:2.29965877532959\n",
      "Epoch:2  accuracy:31.718061674008812  loss:2.2602832317352295\n",
      "Epoch:3  accuracy:31.718061674008812  loss:2.2064056396484375\n",
      "Epoch:4  accuracy:31.718061674008812  loss:2.0898611545562744\n",
      "Epoch:5  accuracy:31.718061674008812  loss:1.8834837675094604\n",
      "Epoch:6  accuracy:31.718061674008812  loss:1.855195164680481\n",
      "Epoch:7  accuracy:31.718061674008812  loss:1.8360410928726196\n",
      "Epoch:8  accuracy:31.718061674008812  loss:1.8233717679977417\n",
      "Epoch:9  accuracy:31.718061674008812  loss:1.8236377239227295\n",
      "Epoch:10  accuracy:31.718061674008812  loss:1.8175534009933472\n",
      "Epoch:11  accuracy:31.718061674008812  loss:1.8175859451293945\n",
      "Epoch:12  accuracy:31.718061674008812  loss:1.8117164373397827\n",
      "Epoch:13  accuracy:31.718061674008812  loss:1.7999324798583984\n",
      "Epoch:14  accuracy:31.718061674008812  loss:1.7980390787124634\n",
      "Epoch:15  accuracy:31.718061674008812  loss:1.7926361560821533\n",
      "Epoch:16  accuracy:31.718061674008812  loss:1.7902297973632812\n",
      "Epoch:17  accuracy:31.718061674008812  loss:1.7856825590133667\n",
      "Epoch:18  accuracy:31.718061674008812  loss:1.7774583101272583\n",
      "Epoch:19  accuracy:31.718061674008812  loss:1.7762173414230347\n",
      "Epoch:20  accuracy:31.718061674008812  loss:1.7715262174606323\n",
      "Epoch:21  accuracy:31.718061674008812  loss:1.7626838684082031\n",
      "Epoch:22  accuracy:31.718061674008812  loss:1.751672387123108\n",
      "Epoch:23  accuracy:31.718061674008812  loss:1.7491748332977295\n",
      "Epoch:24  accuracy:31.718061674008812  loss:1.7429739236831665\n",
      "Epoch:25  accuracy:31.718061674008812  loss:1.7297710180282593\n",
      "Epoch:26  accuracy:33.92070484581498  loss:1.7264198064804077\n",
      "Epoch:27  accuracy:35.68281938325991  loss:1.7391008138656616\n",
      "Epoch:28  accuracy:35.242290748898675  loss:1.7145792245864868\n",
      "Epoch:29  accuracy:38.32599118942731  loss:1.7095422744750977\n",
      "Epoch:30  accuracy:39.647577092511014  loss:1.7028658390045166\n",
      "Epoch:31  accuracy:38.76651982378855  loss:1.7012192010879517\n",
      "Epoch:32  accuracy:41.85022026431718  loss:1.6855813264846802\n",
      "Epoch:33  accuracy:41.409691629955944  loss:1.681436538696289\n",
      "Epoch:34  accuracy:42.290748898678416  loss:1.669777512550354\n",
      "Epoch:35  accuracy:41.85022026431718  loss:1.6631070375442505\n",
      "Epoch:36  accuracy:41.409691629955944  loss:1.6437398195266724\n",
      "Epoch:37  accuracy:42.731277533039645  loss:1.6304090023040771\n",
      "Epoch:38  accuracy:42.290748898678416  loss:1.6243019104003906\n",
      "Epoch:39  accuracy:42.290748898678416  loss:1.6096898317337036\n",
      "Epoch:40  accuracy:42.731277533039645  loss:1.5822561979293823\n",
      "Epoch:41  accuracy:43.61233480176212  loss:1.5644993782043457\n",
      "Epoch:42  accuracy:44.052863436123346  loss:1.5534454584121704\n",
      "Epoch:43  accuracy:46.69603524229075  loss:1.5311394929885864\n",
      "Epoch:44  accuracy:44.49339207048458  loss:1.524298071861267\n",
      "Epoch:45  accuracy:47.57709251101321  loss:1.5091655254364014\n",
      "Epoch:46  accuracy:45.37444933920705  loss:1.5024361610412598\n",
      "Epoch:47  accuracy:44.93392070484582  loss:1.5206102132797241\n",
      "Epoch:48  accuracy:44.49339207048458  loss:1.5328397750854492\n",
      "Epoch:49  accuracy:44.052863436123346  loss:1.5404325723648071\n",
      "Epoch:50  accuracy:45.81497797356828  loss:1.4784094095230103\n",
      "Epoch:51  accuracy:45.37444933920705  loss:1.478440523147583\n",
      "Epoch:52  accuracy:47.136563876651984  loss:1.4721940755844116\n",
      "Epoch:53  accuracy:45.81497797356828  loss:1.4811577796936035\n",
      "Epoch:54  accuracy:43.61233480176212  loss:1.5728182792663574\n",
      "Epoch:55  accuracy:48.01762114537445  loss:1.501375675201416\n",
      "Epoch:56  accuracy:46.25550660792952  loss:1.4644174575805664\n",
      "Epoch:57  accuracy:46.69603524229075  loss:1.4702030420303345\n",
      "Epoch:58  accuracy:45.37444933920705  loss:1.4869252443313599\n",
      "Epoch:59  accuracy:45.81497797356828  loss:1.4849662780761719\n",
      "Epoch:60  accuracy:46.69603524229075  loss:1.46204674243927\n",
      "Epoch:61  accuracy:45.81497797356828  loss:1.4723799228668213\n",
      "Epoch:62  accuracy:46.25550660792952  loss:1.4631484746932983\n",
      "Epoch:63  accuracy:45.37444933920705  loss:1.462636947631836\n",
      "Epoch:64  accuracy:45.37444933920705  loss:1.4815218448638916\n",
      "Epoch:65  accuracy:45.81497797356828  loss:1.4594274759292603\n",
      "Epoch:66  accuracy:48.01762114537445  loss:1.5204006433486938\n",
      "Epoch:67  accuracy:46.25550660792952  loss:1.4677419662475586\n",
      "Epoch:68  accuracy:46.69603524229075  loss:1.4671269655227661\n",
      "Epoch:69  accuracy:45.81497797356828  loss:1.4780961275100708\n",
      "Epoch:70  accuracy:45.81497797356828  loss:1.4785009622573853\n",
      "Epoch:71  accuracy:44.93392070484582  loss:1.471720814704895\n",
      "Epoch:72  accuracy:45.81497797356828  loss:1.483497142791748\n",
      "Epoch:73  accuracy:45.81497797356828  loss:1.4602025747299194\n",
      "Epoch:74  accuracy:44.93392070484582  loss:1.4701485633850098\n",
      "Epoch:75  accuracy:45.37444933920705  loss:1.457869291305542\n",
      "Epoch:76  accuracy:46.69603524229075  loss:1.4681483507156372\n",
      "Epoch:77  accuracy:46.25550660792952  loss:1.4569504261016846\n",
      "Epoch:78  accuracy:37.44493392070485  loss:1.4678053855895996\n",
      "Epoch:79  accuracy:46.25550660792952  loss:1.457161545753479\n",
      "Epoch:80  accuracy:44.49339207048458  loss:1.4897288084030151\n",
      "Epoch:81  accuracy:45.37444933920705  loss:1.46875\n",
      "Epoch:82  accuracy:45.81497797356828  loss:1.448730230331421\n",
      "Epoch:83  accuracy:44.93392070484582  loss:1.4508641958236694\n",
      "Epoch:84  accuracy:45.37444933920705  loss:1.4527018070220947\n",
      "Epoch:85  accuracy:45.81497797356828  loss:1.4580726623535156\n",
      "Epoch:86  accuracy:45.37444933920705  loss:1.4431226253509521\n",
      "Epoch:87  accuracy:44.93392070484582  loss:1.4756240844726562\n",
      "Epoch:88  accuracy:49.33920704845815  loss:1.4609559774398804\n",
      "Epoch:89  accuracy:46.25550660792952  loss:1.4465711116790771\n",
      "Epoch:90  accuracy:48.89867841409691  loss:1.4462809562683105\n",
      "Epoch:91  accuracy:45.81497797356828  loss:1.457288146018982\n",
      "Epoch:92  accuracy:49.779735682819386  loss:1.4477022886276245\n",
      "Epoch:93  accuracy:45.37444933920705  loss:1.4439127445220947\n",
      "Epoch:94  accuracy:45.81497797356828  loss:1.452172040939331\n",
      "Epoch:95  accuracy:45.37444933920705  loss:1.4439038038253784\n",
      "Epoch:96  accuracy:47.136563876651984  loss:1.492545247077942\n",
      "Epoch:97  accuracy:44.49339207048458  loss:1.4476794004440308\n",
      "Early Stop\n",
      "Worker17 start\n",
      "Epoch:1  accuracy:32.1256038647343  loss:2.2501914501190186\n",
      "Epoch:2  accuracy:32.1256038647343  loss:2.15933895111084\n",
      "Epoch:3  accuracy:32.1256038647343  loss:1.8643112182617188\n",
      "Epoch:4  accuracy:32.1256038647343  loss:1.811360239982605\n",
      "Epoch:5  accuracy:32.1256038647343  loss:1.7862755060195923\n",
      "Epoch:6  accuracy:32.1256038647343  loss:1.7848061323165894\n",
      "Epoch:7  accuracy:32.1256038647343  loss:1.7883268594741821\n",
      "Epoch:8  accuracy:32.1256038647343  loss:1.7654855251312256\n",
      "Epoch:9  accuracy:32.1256038647343  loss:1.7652331590652466\n",
      "Epoch:10  accuracy:32.1256038647343  loss:1.7482095956802368\n",
      "Epoch:11  accuracy:32.1256038647343  loss:1.7232484817504883\n",
      "Epoch:12  accuracy:32.1256038647343  loss:1.7132118940353394\n",
      "Epoch:13  accuracy:32.1256038647343  loss:1.6965903043746948\n",
      "Epoch:14  accuracy:32.367149758454104  loss:1.686055064201355\n",
      "Epoch:15  accuracy:33.81642512077295  loss:1.6808741092681885\n",
      "Epoch:16  accuracy:34.29951690821256  loss:1.674648404121399\n",
      "Epoch:17  accuracy:37.92270531400966  loss:1.6613831520080566\n",
      "Epoch:18  accuracy:38.888888888888886  loss:1.6500630378723145\n",
      "Epoch:19  accuracy:38.888888888888886  loss:1.658996343612671\n",
      "Epoch:20  accuracy:40.57971014492754  loss:1.6392722129821777\n",
      "Epoch:21  accuracy:41.06280193236715  loss:1.6556570529937744\n",
      "Epoch:22  accuracy:40.33816425120773  loss:1.626611351966858\n",
      "Epoch:23  accuracy:39.85507246376812  loss:1.6287204027175903\n",
      "Epoch:24  accuracy:42.51207729468599  loss:1.6120407581329346\n",
      "Epoch:25  accuracy:41.30434782608695  loss:1.6009504795074463\n",
      "Epoch:26  accuracy:43.47826086956522  loss:1.6011786460876465\n",
      "Epoch:27  accuracy:44.68599033816425  loss:1.5816069841384888\n",
      "Epoch:28  accuracy:42.99516908212561  loss:1.5417370796203613\n",
      "Epoch:29  accuracy:43.96135265700483  loss:1.539089322090149\n",
      "Epoch:30  accuracy:43.47826086956522  loss:1.5357673168182373\n",
      "Epoch:31  accuracy:43.23671497584541  loss:1.5086143016815186\n",
      "Epoch:32  accuracy:45.169082125603865  loss:1.519657015800476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:33  accuracy:42.7536231884058  loss:1.5309685468673706\n",
      "Epoch:34  accuracy:45.410628019323674  loss:1.4826548099517822\n",
      "Epoch:35  accuracy:43.96135265700483  loss:1.4693647623062134\n",
      "Epoch:36  accuracy:45.65217391304348  loss:1.4544841051101685\n",
      "Epoch:37  accuracy:45.893719806763286  loss:1.4317351579666138\n",
      "Epoch:38  accuracy:42.99516908212561  loss:1.4631965160369873\n",
      "Epoch:39  accuracy:43.23671497584541  loss:1.5582537651062012\n",
      "Epoch:40  accuracy:43.96135265700483  loss:1.5450282096862793\n",
      "Epoch:41  accuracy:43.96135265700483  loss:1.4550058841705322\n",
      "Epoch:42  accuracy:42.51207729468599  loss:1.4787933826446533\n",
      "Epoch:43  accuracy:44.44444444444444  loss:1.445475697517395\n",
      "Epoch:44  accuracy:44.44444444444444  loss:1.3821097612380981\n",
      "Epoch:45  accuracy:44.927536231884055  loss:1.3869438171386719\n",
      "Epoch:46  accuracy:43.71980676328502  loss:1.4050487279891968\n",
      "Epoch:47  accuracy:44.927536231884055  loss:1.3789606094360352\n",
      "Epoch:48  accuracy:46.13526570048309  loss:1.3998483419418335\n",
      "Epoch:49  accuracy:46.3768115942029  loss:1.3705089092254639\n",
      "Epoch:50  accuracy:47.82608695652174  loss:1.3577405214309692\n",
      "Epoch:51  accuracy:47.82608695652174  loss:1.365616798400879\n",
      "Epoch:52  accuracy:46.61835748792271  loss:1.3428736925125122\n",
      "Epoch:53  accuracy:49.033816425120776  loss:1.3435773849487305\n",
      "Epoch:54  accuracy:47.58454106280193  loss:1.348875641822815\n",
      "Epoch:55  accuracy:46.13526570048309  loss:1.3569633960723877\n",
      "Epoch:56  accuracy:50.72463768115942  loss:1.3349789381027222\n",
      "Epoch:57  accuracy:46.85990338164251  loss:1.3453887701034546\n",
      "Epoch:58  accuracy:48.067632850241544  loss:1.35089111328125\n",
      "Epoch:59  accuracy:46.13526570048309  loss:1.342775821685791\n",
      "Epoch:60  accuracy:48.792270531400966  loss:1.3204994201660156\n",
      "Epoch:61  accuracy:47.10144927536232  loss:1.3458471298217773\n",
      "Epoch:62  accuracy:45.169082125603865  loss:1.3430231809616089\n",
      "Epoch:63  accuracy:48.309178743961354  loss:1.2965043783187866\n",
      "Epoch:64  accuracy:46.3768115942029  loss:1.3266839981079102\n",
      "Epoch:65  accuracy:49.033816425120776  loss:1.2649332284927368\n",
      "Epoch:66  accuracy:49.51690821256039  loss:1.2542109489440918\n",
      "Epoch:67  accuracy:49.27536231884058  loss:1.247549057006836\n",
      "Epoch:68  accuracy:51.690821256038646  loss:1.3050613403320312\n",
      "Epoch:69  accuracy:50.966183574879224  loss:1.3139392137527466\n",
      "Epoch:70  accuracy:49.033816425120776  loss:1.2905548810958862\n",
      "Epoch:71  accuracy:52.65700483091788  loss:1.2179152965545654\n",
      "Epoch:72  accuracy:50.24154589371981  loss:1.2345633506774902\n",
      "Epoch:73  accuracy:53.86473429951691  loss:1.2117623090744019\n",
      "Epoch:74  accuracy:51.932367149758456  loss:1.2705425024032593\n",
      "Epoch:75  accuracy:53.14009661835749  loss:1.1968110799789429\n",
      "Epoch:76  accuracy:56.03864734299517  loss:1.192262887954712\n",
      "Epoch:77  accuracy:55.79710144927536  loss:1.1668856143951416\n",
      "Epoch:78  accuracy:53.6231884057971  loss:1.207640290260315\n",
      "Epoch:79  accuracy:55.79710144927536  loss:1.1907721757888794\n",
      "Epoch:80  accuracy:57.729468599033815  loss:1.136480450630188\n",
      "Epoch:81  accuracy:57.971014492753625  loss:1.1590558290481567\n",
      "Epoch:82  accuracy:57.971014492753625  loss:1.169437050819397\n",
      "Epoch:83  accuracy:57.2463768115942  loss:1.1230392456054688\n",
      "Epoch:84  accuracy:59.17874396135266  loss:1.1362645626068115\n",
      "Epoch:85  accuracy:56.28019323671498  loss:1.1587952375411987\n",
      "Epoch:86  accuracy:57.00483091787439  loss:1.1422038078308105\n",
      "Epoch:87  accuracy:57.2463768115942  loss:1.1288490295410156\n",
      "Epoch:88  accuracy:59.17874396135266  loss:1.1827208995819092\n",
      "Epoch:89  accuracy:57.971014492753625  loss:1.1608778238296509\n",
      "Epoch:90  accuracy:58.45410628019324  loss:1.1130236387252808\n",
      "Epoch:91  accuracy:57.729468599033815  loss:1.1243984699249268\n",
      "Epoch:92  accuracy:57.729468599033815  loss:1.088165283203125\n",
      "Epoch:93  accuracy:56.76328502415459  loss:1.093274712562561\n",
      "Epoch:94  accuracy:59.66183574879227  loss:1.0900646448135376\n",
      "Epoch:95  accuracy:60.628019323671495  loss:1.0983246564865112\n",
      "Epoch:96  accuracy:61.83574879227053  loss:1.083707332611084\n",
      "Epoch:97  accuracy:59.90338164251208  loss:1.1135092973709106\n",
      "Epoch:98  accuracy:60.628019323671495  loss:1.0463014841079712\n",
      "Epoch:99  accuracy:59.66183574879227  loss:1.0618953704833984\n",
      "Epoch:100  accuracy:59.66183574879227  loss:1.1081480979919434\n",
      "Epoch:101  accuracy:62.80193236714976  loss:1.064529538154602\n",
      "Epoch:102  accuracy:60.628019323671495  loss:1.103595495223999\n",
      "Epoch:103  accuracy:61.111111111111114  loss:1.110262155532837\n",
      "Epoch:104  accuracy:62.31884057971015  loss:1.1016488075256348\n",
      "Epoch:105  accuracy:62.56038647342995  loss:1.0997854471206665\n",
      "Epoch:106  accuracy:61.83574879227053  loss:1.182512640953064\n",
      "Epoch:107  accuracy:63.04347826086956  loss:1.0719703435897827\n",
      "Epoch:108  accuracy:63.04347826086956  loss:1.0451297760009766\n",
      "Epoch:109  accuracy:61.594202898550726  loss:1.0621681213378906\n",
      "Epoch:110  accuracy:59.42028985507246  loss:1.2086485624313354\n",
      "Epoch:111  accuracy:62.56038647342995  loss:1.019088864326477\n",
      "Epoch:112  accuracy:65.45893719806763  loss:1.0696921348571777\n",
      "Epoch:113  accuracy:61.111111111111114  loss:1.1440764665603638\n",
      "Epoch:114  accuracy:62.80193236714976  loss:1.0930403470993042\n",
      "Epoch:115  accuracy:61.35265700483092  loss:1.1719305515289307\n",
      "Epoch:116  accuracy:61.83574879227053  loss:1.1123673915863037\n",
      "Epoch:117  accuracy:64.73429951690821  loss:1.0095769166946411\n",
      "Epoch:118  accuracy:65.21739130434783  loss:1.3152670860290527\n",
      "Epoch:119  accuracy:66.42512077294685  loss:1.0890846252441406\n",
      "Epoch:120  accuracy:64.97584541062803  loss:1.0972552299499512\n",
      "Epoch:121  accuracy:67.14975845410628  loss:1.0876359939575195\n",
      "Epoch:122  accuracy:65.45893719806763  loss:1.051619291305542\n",
      "Epoch:123  accuracy:61.594202898550726  loss:1.2207739353179932\n",
      "Epoch:124  accuracy:63.52657004830918  loss:1.1847652196884155\n",
      "Epoch:125  accuracy:68.84057971014492  loss:1.0936341285705566\n",
      "Epoch:126  accuracy:66.90821256038647  loss:1.0775123834609985\n",
      "Epoch:127  accuracy:65.21739130434783  loss:1.3246238231658936\n",
      "Epoch:128  accuracy:68.84057971014492  loss:1.108925223350525\n",
      "Early Stop\n",
      "Worker18 start\n",
      "Epoch:1  accuracy:21.00371747211896  loss:2.2515039443969727\n",
      "Epoch:2  accuracy:24.349442379182157  loss:2.1645944118499756\n",
      "Epoch:3  accuracy:24.349442379182157  loss:1.931853175163269\n",
      "Epoch:4  accuracy:24.349442379182157  loss:1.935115098953247\n",
      "Epoch:5  accuracy:24.349442379182157  loss:1.9420216083526611\n",
      "Epoch:6  accuracy:25.46468401486989  loss:1.9273066520690918\n",
      "Epoch:7  accuracy:24.349442379182157  loss:1.9183100461959839\n",
      "Epoch:8  accuracy:24.721189591078065  loss:1.930203914642334\n",
      "Epoch:9  accuracy:24.721189591078065  loss:1.921640396118164\n",
      "Epoch:10  accuracy:24.721189591078065  loss:1.9095470905303955\n",
      "Epoch:11  accuracy:24.721189591078065  loss:1.8977948427200317\n",
      "Epoch:12  accuracy:34.94423791821561  loss:1.8945791721343994\n",
      "Epoch:13  accuracy:31.412639405204462  loss:1.8755415678024292\n",
      "Epoch:14  accuracy:39.5910780669145  loss:1.8547687530517578\n",
      "Epoch:15  accuracy:42.75092936802974  loss:1.8300971984863281\n",
      "Epoch:16  accuracy:42.9368029739777  loss:1.8133653402328491\n",
      "Epoch:17  accuracy:43.86617100371747  loss:1.7900445461273193\n",
      "Epoch:18  accuracy:44.795539033457246  loss:1.7584569454193115\n",
      "Epoch:19  accuracy:47.39776951672862  loss:1.7224359512329102\n",
      "Epoch:20  accuracy:46.28252788104089  loss:1.691643238067627\n",
      "Epoch:21  accuracy:49.44237918215613  loss:1.6296560764312744\n",
      "Epoch:22  accuracy:51.11524163568773  loss:1.606937050819397\n",
      "Epoch:23  accuracy:50.74349442379182  loss:1.5928646326065063\n",
      "Epoch:24  accuracy:51.486988847583646  loss:1.586793065071106\n",
      "Epoch:25  accuracy:51.858736059479554  loss:1.5456682443618774\n",
      "Epoch:26  accuracy:50.74349442379182  loss:1.5488420724868774\n",
      "Epoch:27  accuracy:49.62825278810409  loss:1.5730592012405396\n",
      "Epoch:28  accuracy:53.15985130111524  loss:1.5100723505020142\n",
      "Epoch:29  accuracy:52.973977695167285  loss:1.467294454574585\n",
      "Epoch:30  accuracy:53.71747211895911  loss:1.4592249393463135\n",
      "Epoch:31  accuracy:54.27509293680298  loss:1.4791072607040405\n",
      "Epoch:32  accuracy:52.78810408921933  loss:1.4563446044921875\n",
      "Epoch:33  accuracy:54.646840148698885  loss:1.4239012002944946\n",
      "Epoch:34  accuracy:54.46096654275093  loss:1.4104807376861572\n",
      "Epoch:35  accuracy:55.01858736059479  loss:1.4085909128189087\n",
      "Epoch:36  accuracy:55.01858736059479  loss:1.3754137754440308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:37  accuracy:55.39033457249071  loss:1.38275146484375\n",
      "Epoch:38  accuracy:54.46096654275093  loss:1.3955761194229126\n",
      "Epoch:39  accuracy:57.0631970260223  loss:1.3586597442626953\n",
      "Epoch:40  accuracy:55.204460966542754  loss:1.3751834630966187\n",
      "Epoch:41  accuracy:56.319702602230485  loss:1.39315664768219\n",
      "Epoch:42  accuracy:57.0631970260223  loss:1.3225524425506592\n",
      "Epoch:43  accuracy:56.50557620817844  loss:1.3390922546386719\n",
      "Epoch:44  accuracy:57.99256505576208  loss:1.3172427415847778\n",
      "Epoch:45  accuracy:53.90334572490706  loss:1.4545278549194336\n",
      "Epoch:46  accuracy:54.646840148698885  loss:1.3642055988311768\n",
      "Epoch:47  accuracy:56.50557620817844  loss:1.373696208000183\n",
      "Epoch:48  accuracy:55.94795539033457  loss:1.3377649784088135\n",
      "Epoch:49  accuracy:56.69144981412639  loss:1.307786464691162\n",
      "Epoch:50  accuracy:58.17843866171004  loss:1.2843097448349\n",
      "Epoch:51  accuracy:57.24907063197026  loss:1.3223522901535034\n",
      "Epoch:52  accuracy:56.69144981412639  loss:1.3147344589233398\n",
      "Epoch:53  accuracy:54.46096654275093  loss:1.3564305305480957\n",
      "Epoch:54  accuracy:56.87732342007435  loss:1.3317259550094604\n",
      "Epoch:55  accuracy:59.10780669144982  loss:1.2938947677612305\n",
      "Epoch:56  accuracy:56.87732342007435  loss:1.2791943550109863\n",
      "Epoch:57  accuracy:56.87732342007435  loss:1.2795445919036865\n",
      "Epoch:58  accuracy:58.7360594795539  loss:1.3153642416000366\n",
      "Epoch:59  accuracy:59.66542750929368  loss:1.2501425743103027\n",
      "Epoch:60  accuracy:59.29368029739777  loss:1.3480931520462036\n",
      "Epoch:61  accuracy:59.479553903345725  loss:1.2877882719039917\n",
      "Epoch:62  accuracy:59.85130111524163  loss:1.288388967514038\n",
      "Epoch:63  accuracy:58.921933085501855  loss:1.342960000038147\n",
      "Epoch:64  accuracy:58.55018587360595  loss:1.2468311786651611\n",
      "Epoch:65  accuracy:61.71003717472119  loss:1.2449599504470825\n",
      "Epoch:66  accuracy:60.22304832713755  loss:1.234390377998352\n",
      "Epoch:67  accuracy:58.7360594795539  loss:1.2779624462127686\n",
      "Epoch:68  accuracy:60.22304832713755  loss:1.2382296323776245\n",
      "Epoch:69  accuracy:60.4089219330855  loss:1.2718572616577148\n",
      "Epoch:70  accuracy:60.4089219330855  loss:1.268629789352417\n",
      "Epoch:71  accuracy:62.45353159851301  loss:1.227966070175171\n",
      "Epoch:72  accuracy:59.66542750929368  loss:1.2667311429977417\n",
      "Epoch:73  accuracy:60.96654275092937  loss:1.2327473163604736\n",
      "Epoch:74  accuracy:62.825278810408925  loss:1.235195279121399\n",
      "Epoch:75  accuracy:61.52416356877323  loss:1.2349342107772827\n",
      "Epoch:76  accuracy:58.921933085501855  loss:1.3544882535934448\n",
      "Epoch:77  accuracy:61.71003717472119  loss:1.2023413181304932\n",
      "Epoch:78  accuracy:62.0817843866171  loss:1.2024961709976196\n",
      "Epoch:79  accuracy:60.96654275092937  loss:1.2430452108383179\n",
      "Epoch:80  accuracy:61.52416356877323  loss:1.2106376886367798\n",
      "Epoch:81  accuracy:60.037174721189594  loss:1.2313687801361084\n",
      "Epoch:82  accuracy:58.55018587360595  loss:1.4809736013412476\n",
      "Epoch:83  accuracy:62.267657992565056  loss:1.209496259689331\n",
      "Epoch:84  accuracy:61.52416356877323  loss:1.1923800706863403\n",
      "Epoch:85  accuracy:61.89591078066915  loss:1.2185947895050049\n",
      "Epoch:86  accuracy:63.01115241635688  loss:1.2138668298721313\n",
      "Epoch:87  accuracy:62.639405204460964  loss:1.181965947151184\n",
      "Epoch:88  accuracy:62.0817843866171  loss:1.2222423553466797\n",
      "Epoch:89  accuracy:60.78066914498141  loss:1.21476411819458\n",
      "Epoch:90  accuracy:62.45353159851301  loss:1.2386223077774048\n",
      "Epoch:91  accuracy:64.1263940520446  loss:1.1893011331558228\n",
      "Epoch:92  accuracy:62.639405204460964  loss:1.200764536857605\n",
      "Epoch:93  accuracy:65.4275092936803  loss:1.1648988723754883\n",
      "Epoch:94  accuracy:64.31226765799256  loss:1.18828547000885\n",
      "Epoch:95  accuracy:62.267657992565056  loss:1.210973858833313\n",
      "Epoch:96  accuracy:62.45353159851301  loss:1.2199883460998535\n",
      "Epoch:97  accuracy:63.01115241635688  loss:1.1930737495422363\n",
      "Epoch:98  accuracy:65.98513011152416  loss:1.168890118598938\n",
      "Epoch:99  accuracy:65.79925650557621  loss:1.1552424430847168\n",
      "Epoch:100  accuracy:62.267657992565056  loss:1.1842966079711914\n",
      "Epoch:101  accuracy:64.68401486988847  loss:1.238084077835083\n",
      "Epoch:102  accuracy:63.940520446096656  loss:1.180451512336731\n",
      "Epoch:103  accuracy:61.52416356877323  loss:1.265127420425415\n",
      "Epoch:104  accuracy:60.594795539033456  loss:1.2612574100494385\n",
      "Epoch:105  accuracy:62.639405204460964  loss:1.2313663959503174\n",
      "Epoch:106  accuracy:65.98513011152416  loss:1.151023268699646\n",
      "Epoch:107  accuracy:63.56877323420074  loss:1.2153503894805908\n",
      "Epoch:108  accuracy:65.4275092936803  loss:1.1872272491455078\n",
      "Epoch:109  accuracy:63.56877323420074  loss:1.1857960224151611\n",
      "Epoch:110  accuracy:64.86988847583643  loss:1.186958909034729\n",
      "Epoch:111  accuracy:65.05576208178438  loss:1.194770097732544\n",
      "Epoch:112  accuracy:61.89591078066915  loss:1.2264268398284912\n",
      "Epoch:113  accuracy:63.38289962825279  loss:1.222920298576355\n",
      "Epoch:114  accuracy:63.01115241635688  loss:1.222133994102478\n",
      "Epoch:115  accuracy:63.19702602230483  loss:1.3568496704101562\n",
      "Epoch:116  accuracy:63.38289962825279  loss:1.3832414150238037\n",
      "Epoch:117  accuracy:65.24163568773234  loss:1.2059814929962158\n",
      "Early Stop\n",
      "Worker19 start\n",
      "Epoch:1  accuracy:42.1455938697318  loss:2.2499828338623047\n",
      "Epoch:2  accuracy:42.1455938697318  loss:2.1801772117614746\n",
      "Epoch:3  accuracy:42.1455938697318  loss:2.0699949264526367\n",
      "Epoch:4  accuracy:42.1455938697318  loss:1.8324005603790283\n",
      "Epoch:5  accuracy:42.1455938697318  loss:1.7518813610076904\n",
      "Epoch:6  accuracy:42.1455938697318  loss:1.7336868047714233\n",
      "Epoch:7  accuracy:42.1455938697318  loss:1.7185267210006714\n",
      "Epoch:8  accuracy:42.1455938697318  loss:1.7129062414169312\n",
      "Epoch:9  accuracy:42.1455938697318  loss:1.709801197052002\n",
      "Epoch:10  accuracy:42.1455938697318  loss:1.705065369606018\n",
      "Epoch:11  accuracy:42.1455938697318  loss:1.7112149000167847\n",
      "Epoch:12  accuracy:42.1455938697318  loss:1.6982110738754272\n",
      "Epoch:13  accuracy:42.1455938697318  loss:1.6836134195327759\n",
      "Epoch:14  accuracy:42.1455938697318  loss:1.6889922618865967\n",
      "Epoch:15  accuracy:42.1455938697318  loss:1.6778929233551025\n",
      "Epoch:16  accuracy:42.1455938697318  loss:1.6895672082901\n",
      "Epoch:17  accuracy:42.1455938697318  loss:1.6737278699874878\n",
      "Epoch:18  accuracy:42.1455938697318  loss:1.6695972681045532\n",
      "Epoch:19  accuracy:42.1455938697318  loss:1.6732369661331177\n",
      "Epoch:20  accuracy:42.1455938697318  loss:1.6527762413024902\n",
      "Epoch:21  accuracy:42.1455938697318  loss:1.649856448173523\n",
      "Epoch:22  accuracy:42.1455938697318  loss:1.6465951204299927\n",
      "Epoch:23  accuracy:42.1455938697318  loss:1.655341625213623\n",
      "Epoch:24  accuracy:42.1455938697318  loss:1.6519445180892944\n",
      "Epoch:25  accuracy:42.1455938697318  loss:1.6477723121643066\n",
      "Epoch:26  accuracy:42.1455938697318  loss:1.6467669010162354\n",
      "Epoch:27  accuracy:42.1455938697318  loss:1.6464427709579468\n",
      "Epoch:28  accuracy:42.1455938697318  loss:1.6153984069824219\n",
      "Epoch:29  accuracy:42.1455938697318  loss:1.6190277338027954\n",
      "Epoch:30  accuracy:42.1455938697318  loss:1.6002689599990845\n",
      "Epoch:31  accuracy:42.1455938697318  loss:1.5915131568908691\n",
      "Epoch:32  accuracy:42.1455938697318  loss:1.5799322128295898\n",
      "Epoch:33  accuracy:42.1455938697318  loss:1.5855480432510376\n",
      "Epoch:34  accuracy:42.1455938697318  loss:1.564997911453247\n",
      "Epoch:35  accuracy:42.1455938697318  loss:1.562166690826416\n",
      "Epoch:36  accuracy:42.1455938697318  loss:1.554510235786438\n",
      "Epoch:37  accuracy:42.1455938697318  loss:1.5500434637069702\n",
      "Epoch:38  accuracy:42.1455938697318  loss:1.6449254751205444\n",
      "Epoch:39  accuracy:42.1455938697318  loss:1.5359739065170288\n",
      "Epoch:40  accuracy:42.1455938697318  loss:1.5332194566726685\n",
      "Epoch:41  accuracy:42.52873563218391  loss:1.5265204906463623\n",
      "Epoch:42  accuracy:42.1455938697318  loss:1.5540798902511597\n",
      "Epoch:43  accuracy:42.1455938697318  loss:1.5086506605148315\n",
      "Epoch:44  accuracy:43.29501915708812  loss:1.5068193674087524\n",
      "Epoch:45  accuracy:43.29501915708812  loss:1.5168304443359375\n",
      "Epoch:46  accuracy:42.52873563218391  loss:1.5810613632202148\n",
      "Epoch:47  accuracy:45.97701149425287  loss:1.5046926736831665\n",
      "Epoch:48  accuracy:47.12643678160919  loss:1.5016396045684814\n",
      "Epoch:49  accuracy:47.509578544061306  loss:1.5005947351455688\n",
      "Epoch:50  accuracy:45.593869731800766  loss:1.4803190231323242\n",
      "Epoch:51  accuracy:46.74329501915709  loss:1.4888415336608887\n",
      "Epoch:52  accuracy:47.12643678160919  loss:1.470116376876831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:53  accuracy:47.12643678160919  loss:1.470975637435913\n",
      "Epoch:54  accuracy:44.44444444444444  loss:1.519160270690918\n",
      "Epoch:55  accuracy:49.04214559386973  loss:1.4862064123153687\n",
      "Epoch:56  accuracy:49.42528735632184  loss:1.5051777362823486\n",
      "Epoch:57  accuracy:49.04214559386973  loss:1.446708083152771\n",
      "Epoch:58  accuracy:48.275862068965516  loss:1.432154655456543\n",
      "Epoch:59  accuracy:48.65900383141762  loss:1.4290939569473267\n",
      "Epoch:60  accuracy:46.74329501915709  loss:1.4302477836608887\n",
      "Epoch:61  accuracy:47.509578544061306  loss:1.4263962507247925\n",
      "Epoch:62  accuracy:49.42528735632184  loss:1.4373170137405396\n",
      "Epoch:63  accuracy:49.04214559386973  loss:1.4145522117614746\n",
      "Epoch:64  accuracy:48.275862068965516  loss:1.4102108478546143\n",
      "Epoch:65  accuracy:48.275862068965516  loss:1.443561315536499\n",
      "Epoch:66  accuracy:50.191570881226056  loss:1.3966104984283447\n",
      "Epoch:67  accuracy:45.593869731800766  loss:1.4731919765472412\n",
      "Epoch:68  accuracy:48.65900383141762  loss:1.4305649995803833\n",
      "Epoch:69  accuracy:48.65900383141762  loss:1.4087454080581665\n",
      "Epoch:70  accuracy:49.808429118773944  loss:1.3856110572814941\n",
      "Epoch:71  accuracy:50.95785440613027  loss:1.3603824377059937\n",
      "Epoch:72  accuracy:50.57471264367816  loss:1.3820862770080566\n",
      "Epoch:73  accuracy:51.34099616858238  loss:1.3662049770355225\n",
      "Epoch:74  accuracy:51.34099616858238  loss:1.3490339517593384\n",
      "Epoch:75  accuracy:49.42528735632184  loss:1.412231206893921\n",
      "Epoch:76  accuracy:55.93869731800766  loss:1.3829128742218018\n",
      "Epoch:77  accuracy:52.490421455938694  loss:1.3311947584152222\n",
      "Epoch:78  accuracy:54.406130268199234  loss:1.3354766368865967\n",
      "Epoch:79  accuracy:49.808429118773944  loss:1.5298259258270264\n",
      "Epoch:80  accuracy:60.15325670498084  loss:1.329395055770874\n",
      "Epoch:81  accuracy:58.23754789272031  loss:1.3374005556106567\n",
      "Epoch:82  accuracy:62.83524904214559  loss:1.2865468263626099\n",
      "Epoch:83  accuracy:61.68582375478927  loss:1.3008772134780884\n",
      "Epoch:84  accuracy:61.68582375478927  loss:1.2882603406906128\n",
      "Epoch:85  accuracy:54.78927203065134  loss:1.5339386463165283\n",
      "Epoch:86  accuracy:63.2183908045977  loss:1.286210298538208\n",
      "Epoch:87  accuracy:60.15325670498084  loss:1.3180736303329468\n",
      "Epoch:88  accuracy:62.06896551724138  loss:1.2589175701141357\n",
      "Epoch:89  accuracy:60.53639846743295  loss:1.314017653465271\n",
      "Epoch:90  accuracy:62.83524904214559  loss:1.2866489887237549\n",
      "Epoch:91  accuracy:58.23754789272031  loss:1.3663358688354492\n",
      "Epoch:92  accuracy:64.75095785440612  loss:1.258787989616394\n",
      "Epoch:93  accuracy:62.83524904214559  loss:1.2493208646774292\n",
      "Epoch:94  accuracy:62.83524904214559  loss:1.3030115365982056\n",
      "Epoch:95  accuracy:64.36781609195403  loss:1.2041432857513428\n",
      "Epoch:96  accuracy:61.30268199233716  loss:1.2646270990371704\n",
      "Epoch:97  accuracy:53.63984674329502  loss:1.7984076738357544\n",
      "Epoch:98  accuracy:62.83524904214559  loss:1.2376188039779663\n",
      "Epoch:99  accuracy:62.06896551724138  loss:1.2611885070800781\n",
      "Epoch:100  accuracy:61.68582375478927  loss:1.267698884010315\n",
      "Epoch:101  accuracy:64.36781609195403  loss:1.1998494863510132\n",
      "Epoch:102  accuracy:63.2183908045977  loss:1.2064528465270996\n",
      "Epoch:103  accuracy:62.83524904214559  loss:1.206107497215271\n",
      "Epoch:104  accuracy:60.91954022988506  loss:1.283619999885559\n",
      "Epoch:105  accuracy:65.90038314176245  loss:1.1525720357894897\n",
      "Epoch:106  accuracy:65.51724137931035  loss:1.1686345338821411\n",
      "Epoch:107  accuracy:66.28352490421456  loss:1.1253654956817627\n",
      "Epoch:108  accuracy:60.91954022988506  loss:1.3132938146591187\n",
      "Epoch:109  accuracy:63.2183908045977  loss:1.2259329557418823\n",
      "Epoch:110  accuracy:65.51724137931035  loss:1.177779197692871\n",
      "Epoch:111  accuracy:61.68582375478927  loss:1.3410078287124634\n",
      "Epoch:112  accuracy:62.83524904214559  loss:1.1727752685546875\n",
      "Epoch:113  accuracy:66.66666666666667  loss:1.1129852533340454\n",
      "Epoch:114  accuracy:64.36781609195403  loss:1.188002109527588\n",
      "Epoch:115  accuracy:57.8544061302682  loss:1.492289423942566\n",
      "Epoch:116  accuracy:65.51724137931035  loss:1.1374415159225464\n",
      "Epoch:117  accuracy:66.28352490421456  loss:1.1241528987884521\n",
      "Epoch:118  accuracy:59.38697318007663  loss:1.3068619966506958\n",
      "Epoch:119  accuracy:65.51724137931035  loss:1.1390228271484375\n",
      "Epoch:120  accuracy:68.19923371647509  loss:1.0967034101486206\n",
      "Epoch:121  accuracy:63.984674329501914  loss:1.1555709838867188\n",
      "Epoch:122  accuracy:67.43295019157088  loss:1.0996752977371216\n",
      "Epoch:123  accuracy:66.28352490421456  loss:1.0921380519866943\n",
      "Epoch:124  accuracy:61.30268199233716  loss:1.2823944091796875\n",
      "Epoch:125  accuracy:64.36781609195403  loss:1.2176575660705566\n",
      "Epoch:126  accuracy:63.2183908045977  loss:1.3018105030059814\n",
      "Epoch:127  accuracy:65.51724137931035  loss:1.1075119972229004\n",
      "Epoch:128  accuracy:64.36781609195403  loss:1.2006700038909912\n",
      "Epoch:129  accuracy:63.2183908045977  loss:1.2485884428024292\n",
      "Epoch:130  accuracy:67.43295019157088  loss:1.083828091621399\n",
      "Epoch:131  accuracy:66.66666666666667  loss:1.0982468128204346\n",
      "Epoch:132  accuracy:67.816091954023  loss:1.0764765739440918\n",
      "Epoch:133  accuracy:66.66666666666667  loss:1.0920689105987549\n",
      "Epoch:134  accuracy:66.28352490421456  loss:1.1346979141235352\n",
      "Epoch:135  accuracy:62.83524904214559  loss:1.174961805343628\n",
      "Epoch:136  accuracy:65.90038314176245  loss:1.1257307529449463\n",
      "Epoch:137  accuracy:63.2183908045977  loss:1.2993360757827759\n",
      "Epoch:138  accuracy:66.28352490421456  loss:1.0926331281661987\n",
      "Epoch:139  accuracy:66.66666666666667  loss:1.0895192623138428\n",
      "Epoch:140  accuracy:63.2183908045977  loss:1.1780732870101929\n",
      "Epoch:141  accuracy:64.36781609195403  loss:1.153322696685791\n",
      "Epoch:142  accuracy:68.5823754789272  loss:1.077468752861023\n",
      "Epoch:143  accuracy:63.2183908045977  loss:1.2981904745101929\n",
      "Early Stop\n",
      "Worker20 start\n",
      "Epoch:1  accuracy:36.950904392764855  loss:2.2322163581848145\n",
      "Epoch:2  accuracy:36.950904392764855  loss:2.1049246788024902\n",
      "Epoch:3  accuracy:36.950904392764855  loss:1.6257333755493164\n",
      "Epoch:4  accuracy:36.950904392764855  loss:1.5787522792816162\n",
      "Epoch:5  accuracy:36.950904392764855  loss:1.5587689876556396\n",
      "Epoch:6  accuracy:36.950904392764855  loss:1.5657827854156494\n",
      "Epoch:7  accuracy:36.950904392764855  loss:1.5660865306854248\n",
      "Epoch:8  accuracy:36.950904392764855  loss:1.5582059621810913\n",
      "Epoch:9  accuracy:36.950904392764855  loss:1.5450323820114136\n",
      "Epoch:10  accuracy:36.950904392764855  loss:1.5549243688583374\n",
      "Epoch:11  accuracy:36.950904392764855  loss:1.558010220527649\n",
      "Epoch:12  accuracy:36.950904392764855  loss:1.5406490564346313\n",
      "Epoch:13  accuracy:36.950904392764855  loss:1.52907133102417\n",
      "Epoch:14  accuracy:36.950904392764855  loss:1.5287710428237915\n",
      "Epoch:15  accuracy:36.950904392764855  loss:1.5170822143554688\n",
      "Epoch:16  accuracy:36.950904392764855  loss:1.5124231576919556\n",
      "Epoch:17  accuracy:36.950904392764855  loss:1.5084295272827148\n",
      "Epoch:18  accuracy:36.950904392764855  loss:1.514976978302002\n",
      "Epoch:19  accuracy:36.950904392764855  loss:1.4885960817337036\n",
      "Epoch:20  accuracy:36.950904392764855  loss:1.486542820930481\n",
      "Epoch:21  accuracy:42.63565891472868  loss:1.4688509702682495\n",
      "Epoch:22  accuracy:43.15245478036176  loss:1.4203490018844604\n",
      "Epoch:23  accuracy:42.377260981912144  loss:1.3912752866744995\n",
      "Epoch:24  accuracy:51.42118863049095  loss:1.373399257659912\n",
      "Epoch:25  accuracy:48.57881136950905  loss:1.3472036123275757\n",
      "Epoch:26  accuracy:51.93798449612403  loss:1.3212093114852905\n",
      "Epoch:27  accuracy:50.90439276485788  loss:1.2982697486877441\n",
      "Epoch:28  accuracy:49.354005167958654  loss:1.317628026008606\n",
      "Epoch:29  accuracy:52.713178294573645  loss:1.300858497619629\n",
      "Epoch:30  accuracy:51.42118863049095  loss:1.2583909034729004\n",
      "Epoch:31  accuracy:53.229974160206716  loss:1.3120037317276\n",
      "Epoch:32  accuracy:53.746770025839794  loss:1.2246849536895752\n",
      "Epoch:33  accuracy:52.45478036175711  loss:1.2096914052963257\n",
      "Epoch:34  accuracy:51.93798449612403  loss:1.2664564847946167\n",
      "Epoch:35  accuracy:57.622739018087856  loss:1.17868173122406\n",
      "Epoch:36  accuracy:54.263565891472865  loss:1.1827393770217896\n",
      "Epoch:37  accuracy:55.55555555555556  loss:1.1413519382476807\n",
      "Epoch:38  accuracy:57.622739018087856  loss:1.1318719387054443\n",
      "Epoch:39  accuracy:59.43152454780362  loss:1.1012325286865234\n",
      "Epoch:40  accuracy:58.39793281653747  loss:1.102388620376587\n",
      "Epoch:41  accuracy:60.20671834625323  loss:1.1128932237625122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:42  accuracy:60.46511627906977  loss:1.05287766456604\n",
      "Epoch:43  accuracy:59.43152454780362  loss:1.150733470916748\n",
      "Epoch:44  accuracy:55.81395348837209  loss:1.1776515245437622\n",
      "Epoch:45  accuracy:63.049095607235145  loss:1.054133653640747\n",
      "Epoch:46  accuracy:66.40826873385014  loss:1.027456521987915\n",
      "Epoch:47  accuracy:64.34108527131782  loss:1.0179654359817505\n",
      "Epoch:48  accuracy:65.37467700258398  loss:1.0326298475265503\n",
      "Epoch:49  accuracy:66.66666666666667  loss:1.016062617301941\n",
      "Epoch:50  accuracy:59.43152454780362  loss:1.1401026248931885\n",
      "Epoch:51  accuracy:66.14987080103359  loss:0.988311767578125\n",
      "Epoch:52  accuracy:65.37467700258398  loss:1.0377569198608398\n",
      "Epoch:53  accuracy:67.70025839793281  loss:0.9616113901138306\n",
      "Epoch:54  accuracy:67.44186046511628  loss:0.9528276324272156\n",
      "Epoch:55  accuracy:70.80103359173127  loss:0.9329350590705872\n",
      "Epoch:56  accuracy:65.11627906976744  loss:0.9465048909187317\n",
      "Epoch:57  accuracy:64.85788113695091  loss:1.021567463874817\n",
      "Epoch:58  accuracy:68.21705426356588  loss:0.9195433855056763\n",
      "Epoch:59  accuracy:68.47545219638243  loss:0.9394119381904602\n",
      "Epoch:60  accuracy:68.9922480620155  loss:0.9401891827583313\n",
      "Epoch:61  accuracy:68.9922480620155  loss:0.9098566770553589\n",
      "Epoch:62  accuracy:70.02583979328165  loss:0.8871203064918518\n",
      "Epoch:63  accuracy:65.11627906976744  loss:1.0303502082824707\n",
      "Epoch:64  accuracy:70.02583979328165  loss:0.8732438683509827\n",
      "Epoch:65  accuracy:68.73385012919897  loss:0.919735848903656\n",
      "Epoch:66  accuracy:70.02583979328165  loss:0.838592529296875\n",
      "Epoch:67  accuracy:65.37467700258398  loss:1.0548572540283203\n",
      "Epoch:68  accuracy:70.2842377260982  loss:0.9005570411682129\n",
      "Epoch:69  accuracy:70.80103359173127  loss:0.8999428153038025\n",
      "Epoch:70  accuracy:72.86821705426357  loss:0.8052114248275757\n",
      "Epoch:71  accuracy:67.95865633074935  loss:0.9422550797462463\n",
      "Epoch:72  accuracy:71.57622739018088  loss:0.8240728378295898\n",
      "Epoch:73  accuracy:74.16020671834626  loss:0.7953100204467773\n",
      "Epoch:74  accuracy:71.83462532299741  loss:0.8499933481216431\n",
      "Epoch:75  accuracy:72.60981912144703  loss:0.7878174185752869\n",
      "Epoch:76  accuracy:73.64341085271317  loss:0.8360080718994141\n",
      "Epoch:77  accuracy:73.1266149870801  loss:0.8169369697570801\n",
      "Epoch:78  accuracy:73.64341085271317  loss:0.8037338256835938\n",
      "Epoch:79  accuracy:72.86821705426357  loss:0.8048697113990784\n",
      "Epoch:80  accuracy:72.60981912144703  loss:0.799384593963623\n",
      "Epoch:81  accuracy:74.4186046511628  loss:0.778674304485321\n",
      "Epoch:82  accuracy:71.57622739018088  loss:0.8160678744316101\n",
      "Epoch:83  accuracy:74.16020671834626  loss:0.771335244178772\n",
      "Epoch:84  accuracy:72.86821705426357  loss:0.8386707305908203\n",
      "Epoch:85  accuracy:74.67700258397933  loss:0.784722626209259\n",
      "Epoch:86  accuracy:74.67700258397933  loss:0.7580631971359253\n",
      "Epoch:87  accuracy:71.31782945736434  loss:0.8729186654090881\n",
      "Epoch:88  accuracy:73.90180878552971  loss:0.7830018997192383\n",
      "Epoch:89  accuracy:74.4186046511628  loss:0.7904090881347656\n",
      "Epoch:90  accuracy:73.1266149870801  loss:0.814333975315094\n",
      "Epoch:91  accuracy:74.67700258397933  loss:0.7796682119369507\n",
      "Epoch:92  accuracy:74.4186046511628  loss:0.7599211931228638\n",
      "Epoch:93  accuracy:75.45219638242894  loss:0.7466970086097717\n",
      "Epoch:94  accuracy:72.86821705426357  loss:0.8022441864013672\n",
      "Epoch:95  accuracy:75.1937984496124  loss:0.7546728253364563\n",
      "Epoch:96  accuracy:76.74418604651163  loss:0.7398191690444946\n",
      "Epoch:97  accuracy:74.16020671834626  loss:0.7623988389968872\n",
      "Epoch:98  accuracy:72.3514211886305  loss:0.8116807341575623\n",
      "Epoch:99  accuracy:73.1266149870801  loss:0.7800284028053284\n",
      "Epoch:100  accuracy:73.38501291989664  loss:0.7830032110214233\n",
      "Epoch:101  accuracy:74.4186046511628  loss:0.7737910151481628\n",
      "Epoch:102  accuracy:76.22739018087856  loss:0.7147524952888489\n",
      "Epoch:103  accuracy:76.22739018087856  loss:0.7602705359458923\n",
      "Epoch:104  accuracy:77.2609819121447  loss:0.7185022234916687\n",
      "Epoch:105  accuracy:75.71059431524547  loss:0.7086869478225708\n",
      "Epoch:106  accuracy:77.51937984496124  loss:0.6965497136116028\n",
      "Epoch:107  accuracy:76.74418604651163  loss:0.7269352674484253\n",
      "Epoch:108  accuracy:76.74418604651163  loss:0.7237810492515564\n",
      "Epoch:109  accuracy:76.22739018087856  loss:0.8019416332244873\n",
      "Epoch:110  accuracy:75.45219638242894  loss:0.838024377822876\n",
      "Epoch:111  accuracy:76.22739018087856  loss:0.7856281399726868\n",
      "Epoch:112  accuracy:76.74418604651163  loss:0.733023464679718\n",
      "Epoch:113  accuracy:77.51937984496124  loss:0.686380922794342\n",
      "Epoch:114  accuracy:75.45219638242894  loss:0.7767228484153748\n",
      "Epoch:115  accuracy:76.22739018087856  loss:0.7397546768188477\n",
      "Epoch:116  accuracy:73.38501291989664  loss:0.884269118309021\n",
      "Epoch:117  accuracy:75.1937984496124  loss:0.8403657674789429\n",
      "Epoch:118  accuracy:79.328165374677  loss:0.6914966106414795\n",
      "Epoch:119  accuracy:77.51937984496124  loss:0.7354812026023865\n",
      "Epoch:120  accuracy:78.03617571059432  loss:0.702813982963562\n",
      "Epoch:121  accuracy:74.16020671834626  loss:0.8223351836204529\n",
      "Epoch:122  accuracy:77.2609819121447  loss:0.727676510810852\n",
      "Epoch:123  accuracy:78.55297157622739  loss:0.7353525757789612\n",
      "Epoch:124  accuracy:76.22739018087856  loss:0.7591961026191711\n",
      "Early Stop\n"
     ]
    }
   ],
   "source": [
    "server = Server()\n",
    "workers = server.create_worker(federated_trainset,federated_valset,federated_testset)\n",
    "acc_valid = []\n",
    "loss_valid = []\n",
    "\n",
    "early_stopping = Early_Stopping(args.partience)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "    print('Worker{} start'.format(i+1))\n",
    "    worker.model = vgg13()\n",
    "    worker.model = worker.model.to(args.device)\n",
    "    acc_tmp,loss_tmp = worker.local_train()\n",
    "    acc_valid.append(acc_tmp)\n",
    "    loss_valid.append(loss_tmp)\n",
    "    worker.model = worker.model.to('cpu')\n",
    "    \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:67.28110599078342  loss:1.033393383026123\n",
      "Worker2 accuracy:81.9672131147541  loss:0.6227041482925415\n",
      "Worker3 accuracy:65.9047619047619  loss:1.058107614517212\n",
      "Worker4 accuracy:79.16666666666667  loss:0.6506220698356628\n",
      "Worker5 accuracy:77.46341463414635  loss:0.43201246578246355\n",
      "Worker6 accuracy:57.938718662952645  loss:1.2745777368545532\n",
      "Worker7 accuracy:73.89473684210526  loss:0.6818184852600098\n",
      "Worker8 accuracy:81.60779537149817  loss:0.5994413495063782\n",
      "Worker9 accuracy:83.94904458598727  loss:0.5988562107086182\n",
      "Worker10 accuracy:83.33333333333333  loss:0.40492624044418335\n",
      "Worker11 accuracy:68.57142857142857  loss:1.0044238567352295\n",
      "Worker12 accuracy:69.20863309352518  loss:0.9387714862823486\n",
      "Worker13 accuracy:77.55102040816327  loss:0.6488577127456665\n",
      "Worker14 accuracy:68.62068965517241  loss:1.1223710775375366\n",
      "Worker15 accuracy:77.12418300653594  loss:1.0529385805130005\n",
      "Worker16 accuracy:44.54148471615721  loss:1.3932582139968872\n",
      "Worker17 accuracy:65.56603773584905  loss:1.030508279800415\n",
      "Worker18 accuracy:59.23217550274223  loss:1.3431272506713867\n",
      "Worker19 accuracy:61.42322097378277  loss:1.333012580871582\n",
      "Worker20 accuracy:75.68922305764411  loss:0.7701165080070496\n"
     ]
    }
   ],
   "source": [
    "acc_test = []\n",
    "loss_test = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "    worker.model = worker.model.to(args.device)\n",
    "    acc_tmp,loss_tmp = test(worker.model,args.criterion,worker.testloader)\n",
    "    acc_test.append(acc_tmp)\n",
    "    loss_test.append(loss_tmp)\n",
    "    print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    worker.model = worker.model.to('cpu')\n",
    "    \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation  loss:0.8803130548447371  accuracy:71.54032417602966\n",
      "Test  loss:0.8996922625694423  accuracy:71.00174439139948\n"
     ]
    }
   ],
   "source": [
    "acc_valid_avg = sum(acc_valid)/len(acc_valid)\n",
    "loss_valid_avg = sum(loss_valid)/len(loss_valid)\n",
    "print('Validation  loss:{}  accuracy:{}'.format(loss_valid_avg,acc_valid_avg))\n",
    "\n",
    "acc_test_avg = sum(acc_test)/len(acc_test)\n",
    "loss_test_avg = sum(loss_test)/len(loss_test)\n",
    "print('Test  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FedAvg_femnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
