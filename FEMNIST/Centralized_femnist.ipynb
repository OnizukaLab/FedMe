{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "vkZxat4Y-IsQ",
    "outputId": "da86392c-66e8-4b60-b471-086e745cdcbc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from torch import nn, optim\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O0TfzOhU-QlG"
   },
   "outputs": [],
   "source": [
    "class Argments():\n",
    "  def __init__(self):\n",
    "    self.batch_size = 20\n",
    "    self.test_batch = 1000\n",
    "    self.global_epochs = 300\n",
    "    self.local_epochs = 2\n",
    "    self.lr = None\n",
    "    self.momentum = 0.9\n",
    "    self.weight_decay = 10**-4.0\n",
    "    self.clip = 20.0\n",
    "    self.partience = 10\n",
    "    self.worker_num = 20\n",
    "    self.sample_num = 20\n",
    "    self.device = device = torch.device('cuda:0'if torch.cuda.is_available() else'cpu')\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "args = Argments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(10**-3.0)\n",
    "lr_list.append(10**-2.5)\n",
    "lr_list.append(10**-2.0)\n",
    "lr_list.append(10**-1.5)\n",
    "lr_list.append(10**-1.0)\n",
    "lr_list.append(10**-0.5)\n",
    "lr_list.append(10**0.0)\n",
    "lr_list.append(10**0.5)\n",
    "\n",
    "args.lr = lr_list[lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r5PuCcqmJNUQ"
   },
   "outputs": [],
   "source": [
    "class LocalDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,dataset,worker_id):\n",
    "    self.data = []\n",
    "    self.target = []\n",
    "    self.id = worker_id\n",
    "    for data in dataset.take(len(dataset)):\n",
    "      self.data.append(torch.tensor([data['pixels'].numpy()]))\n",
    "      self.target.append(torch.tensor(data['label'].numpy().astype(np.int64)))\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.data[index],self.target[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/federated_trainset_femnist.pickle', 'rb') as f:\n",
    "    all_federated_trainset = pickle.load(f)\n",
    "with open('../data/federated_testset_femnist.pickle', 'rb') as f:\n",
    "    all_federated_testset = pickle.load(f)\n",
    "all_worker_num = len(all_federated_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2619, 456, 102, 3037, 1126, 1003, 914, 571, 3016, 419, 2771, 3033, 2233, 356, 2418, 1728, 130, 122, 383, 895]\n"
     ]
    }
   ],
   "source": [
    "worker_id_list = random.sample(range(all_worker_num),args.worker_num)\n",
    "print(worker_id_list)\n",
    "federated_trainset = []\n",
    "federated_testset = []\n",
    "for i in worker_id_list:\n",
    "    federated_trainset.append(all_federated_trainset[i])\n",
    "    federated_testset.append(all_federated_testset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_valset = [None]*args.worker_num\n",
    "for i in range(args.worker_num):\n",
    "  n_samples = len(federated_trainset[i])\n",
    "  if n_samples==1:\n",
    "    federated_valset[i] = copy.deepcopy(federated_trainset[i])\n",
    "  else:\n",
    "    train_size = int(len(federated_trainset[i]) * 0.7) \n",
    "    val_size = n_samples - train_size \n",
    "    federated_trainset[i],federated_valset[i] = torch.utils.data.random_split(federated_trainset[i], [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,federated_dataset):\n",
    "    self.data = []\n",
    "    self.target = []\n",
    "    for dataset in federated_dataset:\n",
    "      for (data,target) in dataset:\n",
    "        self.data.append(data)\n",
    "        self.target.append(target)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.data[index],self.target[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_trainset = GlobalDataset(federated_trainset)\n",
    "global_valset = GlobalDataset(federated_valset)\n",
    "global_testset =  GlobalDataset(federated_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_trainloader = torch.utils.data.DataLoader(global_trainset,batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "global_valloader = torch.utils.data.DataLoader(global_valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "global_testloader = torch.utils.data.DataLoader(global_testset,batch_size=args.test_batch,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZU3vAAb9-6SD"
   },
   "outputs": [],
   "source": [
    "class CNN1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(5408, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "class CNN2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(9216, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "class CNN3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(15488, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "    \n",
    "class CNN4(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN4, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv2d_4 = torch.nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(25600, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = self.conv2d_4(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Yu90X1TWJVKJ"
   },
   "outputs": [],
   "source": [
    "class Server():\n",
    "  def __init__(self):\n",
    "    self.model = CNN2()\n",
    "\n",
    "  def create_worker(self,federated_trainset,federated_valset,federated_testset):\n",
    "    workers = []\n",
    "    for i in range(args.worker_num):\n",
    "      workers.append(Worker(federated_trainset[i],federated_valset[i],federated_testset[i]))\n",
    "    return workers\n",
    "\n",
    "  def sample_worker(self,workers):\n",
    "    sample_worker = []\n",
    "    sample_worker_num = random.sample(range(args.worker_num),args.sample_num)\n",
    "    for i in sample_worker_num:\n",
    "      sample_worker.append(workers[i])\n",
    "    return sample_worker\n",
    "\n",
    "\n",
    "  def send_model(self,workers):\n",
    "    nums = 0\n",
    "    for worker in workers:\n",
    "      nums += worker.train_data_num\n",
    "\n",
    "    for worker in workers:\n",
    "      worker.aggregation_weight = 1.0*worker.train_data_num/nums\n",
    "      worker.model = copy.deepcopy(self.model)\n",
    "      worker.model = worker.model.to(args.device)\n",
    "\n",
    "  def aggregate_model(self,workers):   \n",
    "    new_params = OrderedDict()\n",
    "    for i,worker in enumerate(workers):\n",
    "      worker_state = worker.model.state_dict()\n",
    "      for key in worker_state.keys():\n",
    "        if i==0:\n",
    "          new_params[key] = worker_state[key]*worker.aggregation_weight\n",
    "        else:\n",
    "          new_params[key] += worker_state[key]*worker.aggregation_weight\n",
    "      worker.model = worker.model.to('cpu')\n",
    "      del worker.model\n",
    "    self.model.load_state_dict(new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LDWEBjgfJYFc"
   },
   "outputs": [],
   "source": [
    "class Worker():\n",
    "  def __init__(self,trainset,valset,testset):\n",
    "    self.trainloader = torch.utils.data.DataLoader(trainset,batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.valloader = torch.utils.data.DataLoader(valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.testloader = torch.utils.data.DataLoader(testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.model = None\n",
    "    self.train_data_num = len(trainset)\n",
    "    self.test_data_num = len(testset)\n",
    "    self.aggregation_weight = None\n",
    "\n",
    "  def local_train(self):\n",
    "    acc_train,loss_train = local_train(self.model,args.criterion,self.trainloader,args.local_epochs)\n",
    "    acc_valid,loss_valid = test(self.model,args.criterion,self.valloader)\n",
    "    return acc_train,loss_train,acc_valid,loss_valid\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7-GY66gROuEU"
   },
   "outputs": [],
   "source": [
    "def local_train(model,criterion,trainloader,epochs):\n",
    "  optimizer = optim.SGD(model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "  model.train()\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for (data,labels) in trainloader:\n",
    "      data,labels = Variable(data),Variable(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      count += len(labels)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "      optimizer.step()\n",
    "\n",
    "  return 100.0*correct/count,running_loss/len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_train(model,criterion,trainloader,valloader,epochs,partience=0,early_stop=False):\n",
    "  if early_stop:\n",
    "    early_stopping = Early_Stopping(partience)\n",
    "\n",
    "  acc_train = []\n",
    "  loss_train = []\n",
    "  acc_valid = []\n",
    "  loss_valid = []\n",
    "  optimizer = optim.SGD(model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    model.train()\n",
    "    for (data,labels) in trainloader:\n",
    "      count += len(labels)\n",
    "      data,labels = Variable(data),Variable(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "      optimizer.step()\n",
    "    acc_train.append(100.0*correct/count)\n",
    "    loss_train.append(running_loss/len(trainloader))\n",
    "        \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    for (data,labels) in valloader:\n",
    "      count += len(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      \n",
    "    print('Epoch:{}  accuracy:{}  loss:{}'.format(epoch+1,100.0*correct/count,running_loss/len(valloader)))\n",
    "    acc_valid.append(100.0*correct/count)\n",
    "    loss_valid.append(running_loss/len(valloader))\n",
    "    if early_stop:\n",
    "      if early_stopping.validate(running_loss):\n",
    "        print('Early Stop')\n",
    "        return acc_train,loss_train,acc_valid,loss_valid\n",
    "\n",
    "  return acc_train,loss_train,acc_valid,loss_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "oA4URv9mQ3xV"
   },
   "outputs": [],
   "source": [
    "def test(model,criterion,testloader):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  count = 0\n",
    "  for (data,labels) in testloader:\n",
    "    data,labels = data.to(args.device),labels.to(args.device)\n",
    "    outputs = model(data)\n",
    "    running_loss += criterion(outputs,labels).item()\n",
    "    predicted = torch.argmax(outputs,dim=1)\n",
    "    correct += (predicted==labels).sum().item()\n",
    "    count += len(labels)\n",
    "\n",
    "  accuracy = 100.0*correct/count\n",
    "  loss = running_loss/len(testloader)\n",
    "\n",
    "\n",
    "  return accuracy,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "WMO7_WSLHeGl"
   },
   "outputs": [],
   "source": [
    "class Early_Stopping():\n",
    "  def __init__(self,partience):\n",
    "    self.step = 0\n",
    "    self.loss = float('inf')\n",
    "    self.partience = partience\n",
    "\n",
    "  def validate(self,loss):\n",
    "    if self.loss<loss:\n",
    "      self.step += 1\n",
    "      if self.step>self.partience:\n",
    "        return True\n",
    "    else:\n",
    "      self.step = 0\n",
    "      self.loss = loss\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1  accuracy:2.8612303290414878  loss:3.7910149097442627\n",
      "Epoch:2  accuracy:6.36623748211731  loss:3.7714728116989136\n",
      "Epoch:3  accuracy:5.364806866952789  loss:3.7510420083999634\n",
      "Epoch:4  accuracy:5.5078683834048645  loss:3.7319881916046143\n",
      "Epoch:5  accuracy:11.587982832618026  loss:3.6789921522140503\n",
      "Epoch:6  accuracy:10.44349070100143  loss:3.5750285387039185\n",
      "Epoch:7  accuracy:20.314735336194563  loss:3.336100935935974\n",
      "Epoch:8  accuracy:29.82832618025751  loss:3.0529645681381226\n",
      "Epoch:9  accuracy:36.19456366237482  loss:2.7195905447006226\n",
      "Epoch:10  accuracy:42.989985693848354  loss:2.412811756134033\n",
      "Epoch:11  accuracy:47.85407725321888  loss:2.18495774269104\n",
      "Epoch:12  accuracy:52.93276108726752  loss:2.0187483429908752\n",
      "Epoch:13  accuracy:55.43633762517883  loss:1.8291654586791992\n",
      "Epoch:14  accuracy:58.86981402002861  loss:1.7027303576469421\n",
      "Epoch:15  accuracy:61.587982832618025  loss:1.5824919939041138\n",
      "Epoch:16  accuracy:61.802575107296136  loss:1.4757599234580994\n",
      "Epoch:17  accuracy:63.73390557939914  loss:1.3820486068725586\n",
      "Epoch:18  accuracy:64.5922746781116  loss:1.3294314742088318\n",
      "Epoch:19  accuracy:66.95278969957081  loss:1.2398239970207214\n",
      "Epoch:20  accuracy:68.31187410586553  loss:1.168899118900299\n",
      "Epoch:21  accuracy:69.52789699570816  loss:1.1088157296180725\n",
      "Epoch:22  accuracy:70.24320457796853  loss:1.0724964141845703\n",
      "Epoch:23  accuracy:71.67381974248927  loss:1.0299452245235443\n",
      "Epoch:24  accuracy:73.4620886981402  loss:0.9949294030666351\n",
      "Epoch:25  accuracy:73.03290414878397  loss:0.9798968732357025\n",
      "Epoch:26  accuracy:73.96280400572246  loss:0.9509598910808563\n",
      "Epoch:27  accuracy:73.39055793991416  loss:0.9302942454814911\n",
      "Epoch:28  accuracy:74.53505007153076  loss:0.9003465175628662\n",
      "Epoch:29  accuracy:74.39198855507868  loss:0.88853320479393\n",
      "Epoch:30  accuracy:73.67668097281832  loss:0.8861725032329559\n",
      "Epoch:31  accuracy:74.53505007153076  loss:0.8902137875556946\n",
      "Epoch:32  accuracy:75.67954220314735  loss:0.8650360107421875\n",
      "Epoch:33  accuracy:74.32045779685265  loss:0.8638481497764587\n",
      "Epoch:34  accuracy:76.03719599427754  loss:0.8540028631687164\n",
      "Epoch:35  accuracy:77.18168812589414  loss:0.8267224431037903\n",
      "Epoch:36  accuracy:76.68097281831187  loss:0.8079079687595367\n",
      "Epoch:37  accuracy:78.2546494992847  loss:0.7875511646270752\n",
      "Epoch:38  accuracy:76.7525035765379  loss:0.8099026679992676\n",
      "Epoch:39  accuracy:76.96709585121603  loss:0.810194194316864\n",
      "Epoch:40  accuracy:77.18168812589414  loss:0.8213184177875519\n",
      "Epoch:41  accuracy:77.39628040057225  loss:0.8061580955982208\n",
      "Epoch:42  accuracy:76.60944206008584  loss:0.8284356892108917\n",
      "Epoch:43  accuracy:77.8969957081545  loss:0.7909900546073914\n",
      "Epoch:44  accuracy:78.4692417739628  loss:0.7971456050872803\n",
      "Epoch:45  accuracy:77.3247496423462  loss:0.7923685014247894\n",
      "Epoch:46  accuracy:77.03862660944206  loss:0.8105321228504181\n",
      "Epoch:47  accuracy:76.46638054363376  loss:0.8110809922218323\n",
      "Epoch:48  accuracy:77.96852646638054  loss:0.7667977809906006\n",
      "Epoch:49  accuracy:78.89842632331903  loss:0.7742120623588562\n",
      "Epoch:50  accuracy:76.7525035765379  loss:0.823252946138382\n",
      "Epoch:51  accuracy:78.75536480686695  loss:0.8025830090045929\n",
      "Epoch:52  accuracy:79.11301859799714  loss:0.7812701165676117\n",
      "Epoch:53  accuracy:77.6824034334764  loss:0.8115624189376831\n",
      "Epoch:54  accuracy:76.46638054363376  loss:0.846388041973114\n",
      "Epoch:55  accuracy:78.61230329041487  loss:0.7890978157520294\n",
      "Epoch:56  accuracy:78.89842632331903  loss:0.8251161277294159\n",
      "Epoch:57  accuracy:78.61230329041487  loss:0.7963593304157257\n",
      "Epoch:58  accuracy:78.61230329041487  loss:0.8083494603633881\n",
      "Epoch:59  accuracy:78.96995708154506  loss:0.8220648169517517\n",
      "Early Stop\n"
     ]
    }
   ],
   "source": [
    "model = CNN2()\n",
    "model = model.to(args.device)\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "acc_train,loss_train,acc_valid,loss_valid = global_train(model,args.criterion,global_trainloader,global_valloader,args.global_epochs,partience=args.partience,early_stop=True)\n",
    "end = time.time()#終了時刻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習時間：157.90964365005493秒\n"
     ]
    }
   ],
   "source": [
    "print('学習時間：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = Server()\n",
    "workers = server.create_worker(federated_trainset,federated_valset,federated_testset)\n",
    "server.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "mi_uceyoptLP",
    "outputId": "bc067e09-01bc-4e65-daf9-ac2f42373cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:70.58823529411765  loss:0.9494462609291077\n",
      "Worker2 accuracy:94.28571428571429  loss:0.1838645190000534\n",
      "Worker3 accuracy:77.5  loss:0.757978081703186\n",
      "Worker4 accuracy:72.22222222222223  loss:1.5084679126739502\n",
      "Worker5 accuracy:79.41176470588235  loss:0.6983450055122375\n",
      "Worker6 accuracy:80.95238095238095  loss:0.642073929309845\n",
      "Worker7 accuracy:73.6842105263158  loss:0.9906824231147766\n",
      "Worker8 accuracy:84.375  loss:0.4335269033908844\n",
      "Worker9 accuracy:47.36842105263158  loss:1.7057507038116455\n",
      "Worker10 accuracy:75.60975609756098  loss:0.6409780383110046\n",
      "Worker11 accuracy:77.77777777777777  loss:0.7760308980941772\n",
      "Worker12 accuracy:78.94736842105263  loss:0.6195851564407349\n",
      "Worker13 accuracy:78.94736842105263  loss:0.7724058032035828\n",
      "Worker14 accuracy:76.66666666666667  loss:1.6078630685806274\n",
      "Worker15 accuracy:84.21052631578948  loss:0.5556695461273193\n",
      "Worker16 accuracy:82.3529411764706  loss:0.7818105220794678\n",
      "Worker17 accuracy:72.72727272727273  loss:1.6295963525772095\n",
      "Worker18 accuracy:70.96774193548387  loss:0.8177315592765808\n",
      "Worker19 accuracy:88.23529411764706  loss:0.5935520529747009\n",
      "Worker20 accuracy:77.77777777777777  loss:0.8827023506164551\n",
      "Test  loss:0.8774030543863773  accuracy:77.23042202369085\n"
     ]
    }
   ],
   "source": [
    "acc_test = []\n",
    "loss_test = []\n",
    "\n",
    "server.model.to(args.device)\n",
    "\n",
    "nums = 0\n",
    "for worker in workers:\n",
    "  nums += worker.test_data_num\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "  worker.aggregation_weight = 1.0*worker.test_data_num/nums\n",
    "  acc_tmp,loss_tmp = test(server.model,args.criterion,worker.testloader)\n",
    "  acc_test.append(acc_tmp)\n",
    "  loss_test.append(loss_tmp)\n",
    "  print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "\n",
    "end = time.time()#終了時刻\n",
    "\n",
    "acc_test_avg = sum(acc_test)/len(acc_test)\n",
    "loss_test_avg = sum(loss_test)/len(loss_test)\n",
    "print('Test  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推論時間：16.488682746887207秒\n"
     ]
    }
   ],
   "source": [
    "print('推論時間：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 Valid accuracy:86.04651162790698  loss:0.31840115785598755\n",
      "Worker1 Test accuracy:82.3529411764706  loss:0.8582797050476074\n",
      "Worker2 Valid accuracy:87.23404255319149  loss:0.6121088266372681\n",
      "Worker2 Test accuracy:94.28571428571429  loss:0.17410723865032196\n",
      "Worker3 Valid accuracy:75.23809523809524  loss:0.9452593922615051\n",
      "Worker3 Test accuracy:82.5  loss:0.5617423057556152\n",
      "Worker4 Valid accuracy:84.78260869565217  loss:0.6278173327445984\n",
      "Worker4 Test accuracy:72.22222222222223  loss:1.3909858465194702\n",
      "Worker5 Valid accuracy:83.51648351648352  loss:0.4485121965408325\n",
      "Worker5 Test accuracy:85.29411764705883  loss:0.48553428053855896\n",
      "Worker6 Valid accuracy:72.72727272727273  loss:0.9799725413322449\n",
      "Worker6 Test accuracy:80.95238095238095  loss:0.8291905522346497\n",
      "Worker7 Valid accuracy:81.0  loss:0.6946359276771545\n",
      "Worker7 Test accuracy:71.05263157894737  loss:0.9714431762695312\n",
      "Worker8 Valid accuracy:76.47058823529412  loss:0.8884298801422119\n",
      "Worker8 Test accuracy:84.375  loss:0.4168745279312134\n",
      "Worker9 Valid accuracy:75.51020408163265  loss:0.607490062713623\n",
      "Worker9 Test accuracy:47.36842105263158  loss:1.3027783632278442\n",
      "Worker10 Valid accuracy:84.40366972477064  loss:0.4436260163784027\n",
      "Worker10 Test accuracy:82.92682926829268  loss:0.48772621154785156\n",
      "Worker11 Valid accuracy:76.08695652173913  loss:1.1920661926269531\n",
      "Worker11 Test accuracy:72.22222222222223  loss:0.8192550539970398\n",
      "Worker12 Valid accuracy:87.75510204081633  loss:0.3783058226108551\n",
      "Worker12 Test accuracy:78.94736842105263  loss:0.6879623532295227\n",
      "Worker13 Valid accuracy:77.55102040816327  loss:0.9178012013435364\n",
      "Worker13 Test accuracy:84.21052631578948  loss:0.7230766415596008\n",
      "Worker14 Valid accuracy:80.76923076923077  loss:1.1521742343902588\n",
      "Worker14 Test accuracy:73.33333333333333  loss:1.7323232889175415\n",
      "Worker15 Valid accuracy:81.63265306122449  loss:0.6950213313102722\n",
      "Worker15 Test accuracy:89.47368421052632  loss:0.47825488448143005\n",
      "Worker16 Valid accuracy:84.44444444444444  loss:0.6272264122962952\n",
      "Worker16 Test accuracy:82.3529411764706  loss:0.8222494721412659\n",
      "Worker17 Valid accuracy:73.86363636363636  loss:0.894938051700592\n",
      "Worker17 Test accuracy:72.72727272727273  loss:1.620172142982483\n",
      "Worker18 Valid accuracy:76.82926829268293  loss:1.0455344915390015\n",
      "Worker18 Test accuracy:77.41935483870968  loss:0.7066317796707153\n",
      "Worker19 Valid accuracy:90.0  loss:0.529486894607544\n",
      "Worker19 Test accuracy:91.17647058823529  loss:0.5308390855789185\n",
      "Worker20 Valid accuracy:66.66666666666667  loss:1.0382483005523682\n",
      "Worker20 Test accuracy:72.22222222222223  loss:0.8719128370285034\n",
      "Validation(tune)  loss:0.7518528133630753  accuracy:80.12642274844521\n",
      "Test(tune)  loss:0.8235669873654843  accuracy:78.87078271197764\n"
     ]
    }
   ],
   "source": [
    "acc_tune_test = []\n",
    "loss_tune_test = []\n",
    "acc_tune_valid = []\n",
    "loss_tune_valid = []\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "    worker.model = copy.deepcopy(server.model)\n",
    "    worker.model = worker.model.to(args.device)\n",
    "    _,_,acc_tmp,loss_tmp = worker.local_train()\n",
    "    acc_tune_valid.append(acc_tmp)\n",
    "    loss_tune_valid.append(loss_tmp)\n",
    "    print('Worker{} Valid accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    \n",
    "    acc_tmp,loss_tmp = test(worker.model,args.criterion,worker.testloader)\n",
    "    acc_tune_test.append(acc_tmp)\n",
    "    loss_tune_test.append(loss_tmp)\n",
    "    print('Worker{} Test accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    worker.model = worker.model.to('cpu')\n",
    "    del worker.model\n",
    "\n",
    "end = time.time()#終了時刻\n",
    "\n",
    "acc_valid_avg = sum(acc_tune_valid)/len(acc_tune_valid)\n",
    "loss_valid_avg = sum(loss_tune_valid)/len(loss_tune_valid)\n",
    "print('Validation(tune)  loss:{}  accuracy:{}'.format(loss_valid_avg,acc_valid_avg))\n",
    "acc_test_avg = sum(acc_tune_test)/len(acc_tune_test)\n",
    "loss_test_avg = sum(loss_tune_test)/len(loss_tune_test)\n",
    "print('Test(tune)  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習・推論時間（fine-tune）：69.1464204788208秒\n"
     ]
    }
   ],
   "source": [
    "print('学習・推論時間（fine-tune）：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FedAvg_femnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
