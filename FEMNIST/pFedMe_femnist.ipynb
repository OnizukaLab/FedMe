{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "vkZxat4Y-IsQ",
    "outputId": "da86392c-66e8-4b60-b471-086e745cdcbc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from torch import nn, optim\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O0TfzOhU-QlG"
   },
   "outputs": [],
   "source": [
    "class Argments():\n",
    "  def __init__(self):\n",
    "    self.batch_size = 20\n",
    "    self.test_batch = 1000\n",
    "    self.global_epochs = 300\n",
    "    self.local_epochs = 2\n",
    "    self.lamda = 15\n",
    "    self.K = 5\n",
    "    self.lr = None\n",
    "    self.momentum = 0.9\n",
    "    self.weight_decay = 10**-4.0\n",
    "    self.clip = 20.0\n",
    "    self.partience = 300\n",
    "    self.worker_num = 20\n",
    "    self.sample_num = 20\n",
    "    self.device = device = torch.device('cuda:0'if torch.cuda.is_available() else'cpu')\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "args = Argments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(10**-3.0)\n",
    "lr_list.append(10**-2.5)\n",
    "lr_list.append(10**-2.0)\n",
    "lr_list.append(10**-1.5)\n",
    "lr_list.append(10**-1.0)\n",
    "lr_list.append(10**-0.5)\n",
    "lr_list.append(10**0.0)\n",
    "lr_list.append(10**0.5)\n",
    "\n",
    "args.lr = lr_list[lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,dataset,worker_id):\n",
    "    self.data = []\n",
    "    self.target = []\n",
    "    self.id = worker_id\n",
    "    for data in dataset.take(len(dataset)):\n",
    "      self.data.append(torch.tensor([data['pixels'].numpy()]))\n",
    "      self.target.append(torch.tensor(data['label'].numpy().astype(np.int64)))\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.data[index],self.target[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/federated_trainset_femnist.pickle', 'rb') as f:\n",
    "    all_federated_trainset = pickle.load(f)\n",
    "with open('../data/federated_testset_femnist.pickle', 'rb') as f:\n",
    "    all_federated_testset = pickle.load(f)\n",
    "all_worker_num = len(all_federated_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2619, 456, 102, 3037, 1126, 1003, 914, 571, 3016, 419, 2771, 3033, 2233, 356, 2418, 1728, 130, 122, 383, 895]\n"
     ]
    }
   ],
   "source": [
    "worker_id_list = random.sample(range(all_worker_num),args.worker_num)\n",
    "print(worker_id_list)\n",
    "federated_trainset = []\n",
    "federated_testset = []\n",
    "for i in worker_id_list:\n",
    "    federated_trainset.append(all_federated_trainset[i])\n",
    "    federated_testset.append(all_federated_testset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_valset = [None]*args.worker_num\n",
    "for i in range(args.worker_num):\n",
    "  n_samples = len(federated_trainset[i])\n",
    "  if n_samples==1:\n",
    "    federated_valset[i] = copy.deepcopy(federated_trainset[i])\n",
    "  else:\n",
    "    train_size = int(len(federated_trainset[i]) * 0.7) \n",
    "    val_size = n_samples - train_size \n",
    "    federated_trainset[i],federated_valset[i] = torch.utils.data.random_split(federated_trainset[i], [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(5408, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "class CNN2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(9216, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "class CNN3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(15488, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "    \n",
    "class CNN4(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN4, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv2d_4 = torch.nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(25600, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = self.conv2d_4(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pFedMeOptimizer(torch.optim.Optimizer):\n",
    "    def __init__(self, params, lr=0.01, lamda=0.1 , mu = 0.001):\n",
    "        #self.local_weight_updated = local_weight # w_i,K\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        defaults = dict(lr=lr, lamda=lamda, mu = mu)\n",
    "        super(pFedMeOptimizer, self).__init__(params, defaults)\n",
    "    \n",
    "    def step(self, local_weight_updated, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure\n",
    "        weight_update = local_weight_updated.copy()\n",
    "        for group in self.param_groups:\n",
    "            for p, localweight in zip( group['params'], weight_update):\n",
    "                localweight.data = localweight.data.to(args.device)\n",
    "                p.data = p.data - group['lr'] * (p.grad.data + group['lamda'] * (p.data - localweight.data) + group['mu']*p.data)\n",
    "                localweight.data = localweight.data.to('cpu')\n",
    "        return  group['params'], loss\n",
    "    \n",
    "    def update_param(self, local_weight_updated, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure\n",
    "        weight_update = local_weight_updated.copy()\n",
    "        for group in self.param_groups:\n",
    "            for p, localweight in zip( group['params'], weight_update):\n",
    "                p.data = localweight.data\n",
    "        #return  p.data\n",
    "        return  group['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Yu90X1TWJVKJ"
   },
   "outputs": [],
   "source": [
    "class Server():\n",
    "  def __init__(self):\n",
    "    self.model = CNN2()\n",
    "\n",
    "  def create_worker(self,federated_trainset,federated_valset,federated_testset):\n",
    "    workers = []\n",
    "    for i in range(args.worker_num):\n",
    "      workers.append(Worker(federated_trainset[i],federated_valset[i],federated_testset[i]))\n",
    "    return workers\n",
    "\n",
    "  def sample_worker(self,workers):\n",
    "    sample_worker = []\n",
    "    sample_worker_num = random.sample(range(args.worker_num),args.sample_num)\n",
    "    for i in sample_worker_num:\n",
    "      sample_worker.append(workers[i])\n",
    "    return sample_worker\n",
    "\n",
    "\n",
    "  def send_model(self,workers):\n",
    "    nums = 0\n",
    "    for worker in workers:\n",
    "      nums += worker.train_data_num\n",
    "\n",
    "    for worker in workers:\n",
    "      worker.aggregation_weight = 1.0*worker.train_data_num/nums\n",
    "      worker.model = copy.deepcopy(self.model)\n",
    "      worker.personalized_model = copy.deepcopy(self.model)\n",
    "      worker.local_model = copy.deepcopy(self.model)\n",
    "\n",
    "  def aggregate_model(self,workers):   \n",
    "    new_params = OrderedDict()\n",
    "    for i,worker in enumerate(workers):\n",
    "      worker_state = worker.model.state_dict()\n",
    "      for key in worker_state.keys():\n",
    "        if i==0:\n",
    "          new_params[key] = worker_state[key]*worker.aggregation_weight\n",
    "        else:\n",
    "          new_params[key] += worker_state[key]*worker.aggregation_weight\n",
    "    self.model.load_state_dict(new_params)\n",
    "    \n",
    "  def send_parameters(self,workers):\n",
    "    nums = 0\n",
    "    for worker in workers:\n",
    "      nums += worker.train_data_num\n",
    "    for worker in workers:\n",
    "        worker.aggregation_weight = 1.0*worker.train_data_num/nums\n",
    "        worker.set_parameters(self.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LDWEBjgfJYFc"
   },
   "outputs": [],
   "source": [
    "class Worker():\n",
    "  def __init__(self,trainset,valset,testset):\n",
    "    self.trainloader = torch.utils.data.DataLoader(trainset,batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.valloader = torch.utils.data.DataLoader(valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.testloader = torch.utils.data.DataLoader(testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    #self.iter_trainloader = iter(self.trainloader)\n",
    "    self.model = CNN2()\n",
    "    self.local_model = copy.deepcopy(list(self.model.parameters()))\n",
    "    self.persionalized_model = copy.deepcopy(list(self.model.parameters()))\n",
    "    self.persionalized_model_bar = copy.deepcopy(list(self.model.parameters()))\n",
    "    self.train_data_num = len(trainset)\n",
    "    self.test_data_num = len(testset)\n",
    "    \n",
    "    self.optimizer = pFedMeOptimizer(self.model.parameters(),lr=args.lr,lamda=args.lamda)\n",
    "    \n",
    "  def set_parameters(self, model):\n",
    "    for old_param, new_param, local_param in zip(self.model.parameters(), model.parameters(), self.local_model):\n",
    "        old_param.data = new_param.data.clone()\n",
    "        local_param.data = new_param.data.clone()\n",
    "    #self.local_weight_updated = copy.deepcopy(self.optimizer.param_groups[0]['params'])\n",
    "    \n",
    "  def get_next_train_batch(self):\n",
    "    try:\n",
    "        # Samples a new batch for persionalizing\n",
    "        (X, y) = next(self.iter_trainloader)\n",
    "    except StopIteration:\n",
    "        # restart the generator if the previous generator is exhausted.\n",
    "        self.iter_trainloader = iter(self.trainloader)\n",
    "        (X, y) = next(self.iter_trainloader)\n",
    "    return (X.to(args.device), y.to(args.device))    \n",
    "  '''\n",
    "  def local_train(self):\n",
    "    self.model.train()\n",
    "    optimizer = pFedMeOptimizer(self.model.parameters(),lr=args.lr,lamda=args.lamda)\n",
    "    for epoch in range(args.local_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        count = 0\n",
    "        data,labels = self.get_next_train_batch()\n",
    "        for i in range(args.K):\n",
    "            self.model = self.model.to(args.device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.model(data)\n",
    "            loss = args.criterion(outputs,labels)\n",
    "            running_loss += loss.item()\n",
    "            predicted = torch.argmax(outputs,dim=1)\n",
    "            correct += (predicted==labels).sum().item()\n",
    "            count += len(labels)\n",
    "            loss.backward()\n",
    "            #torch.nn.utils.clip_grad_norm_(self.model.parameters(), args.clip)\n",
    "            self.model = self.model.to('cpu')\n",
    "            personal_model,_ = optimizer.step(self.local_model)\n",
    "        \n",
    "        for new_param,localweight in zip(personal_model,self.local_model.parameters()):\n",
    "            localweight.data = localweight.data - args.lamda * args.lr * (localweight.data - new_param.data)    \n",
    "    \n",
    "    del self.model\n",
    "    \n",
    "    update_parameters(self.personalized_model,personal_model)\n",
    "    return 100.0*correct/count,running_loss/len(self.trainloader)\n",
    "  '''\n",
    "\n",
    "  def local_train(self):\n",
    "    self.model.train() \n",
    "    self.model = self.model.to(args.device)       \n",
    "    for epoch in range(args.local_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        count = 0\n",
    "        for (data,labels) in self.trainloader:\n",
    "            self.model.train()\n",
    "            data,labels = Variable(data),Variable(labels)\n",
    "            data,labels = data.to(args.device),labels.to(args.device)\n",
    "            for k in range(args.K):\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(data)\n",
    "                loss = args.criterion(outputs,labels)\n",
    "                if k==(args.K-1):\n",
    "                    running_loss += loss.item()\n",
    "                    predicted = torch.argmax(outputs,dim=1)\n",
    "                    correct += (predicted==labels).sum().item()\n",
    "                    count += len(labels)\n",
    "                loss.backward()\n",
    "                #torch.nn.utils.clip_grad_norm_(self.model.parameters(), args.clip)\n",
    "                self.persionalized_model_bar,_ = self.optimizer.step(self.local_model)\n",
    "        \n",
    "            for new_param, localweight in zip(self.persionalized_model_bar, self.local_model):\n",
    "                localweight.data = localweight.data.to(args.device)\n",
    "                localweight.data = localweight.data - args.lamda* args.lr * (localweight.data - new_param.data)\n",
    "                localweight.data = localweight.data.to('cpu')\n",
    "    \n",
    "    self.update_parameters(self.local_model)\n",
    "    \n",
    "    self.model = self.model.to('cpu')\n",
    "    for personal_weight, localweight in zip(self.persionalized_model_bar, self.local_model):\n",
    "        personal_weight.data = personal_weight.data.to('cpu')\n",
    "        localweight.data = localweight.data.to('cpu')\n",
    "        \n",
    "    return 100.0*correct/count,running_loss/len(self.trainloader)\n",
    "\n",
    "\n",
    "  def validate(self):\n",
    "    self.model.eval()\n",
    "    self.update_parameters(self.persionalized_model_bar)\n",
    "    self.model = self.model.to(args.device)\n",
    "    acc,loss = test(self.model,args.criterion,self.valloader)\n",
    "    self.model = self.model.to('cpu')\n",
    "    self.update_parameters(self.local_model)\n",
    "    return acc,loss\n",
    "\n",
    "\n",
    "  def test(self):\n",
    "    self.model.eval()\n",
    "    self.update_parameters(self.persionalized_model_bar)\n",
    "    self.model = self.model.to(args.device)\n",
    "    acc,loss = test(self.model,args.criterion,self.testloader)\n",
    "    self.model = self.model.to('cpu')\n",
    "    self.update_parameters(self.local_model)\n",
    "    return acc,loss\n",
    "\n",
    "\n",
    "  def update_parameters(self, new_params):\n",
    "    for param , new_param in zip(self.model.parameters(), new_params):\n",
    "      param.data = new_param.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "7-GY66gROuEU"
   },
   "outputs": [],
   "source": [
    "def train(model,criterion,trainloader,epochs):\n",
    "  optimizer = optim.SGD(model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "  model.train()\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for (data,labels) in trainloader:\n",
    "      data,labels = Variable(data),Variable(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      count += len(labels)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "      optimizer.step()\n",
    "\n",
    "  return 100.0*correct/count,running_loss/len(trainloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oA4URv9mQ3xV"
   },
   "outputs": [],
   "source": [
    "def test(model,criterion,testloader):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  count = 0\n",
    "  for (data,labels) in testloader:\n",
    "    data,labels = data.to(args.device),labels.to(args.device)\n",
    "    outputs = model(data)\n",
    "    running_loss += criterion(outputs,labels).item()\n",
    "    predicted = torch.argmax(outputs,dim=1)\n",
    "    correct += (predicted==labels).sum().item()\n",
    "    count += len(labels)\n",
    "\n",
    "  accuracy = 100.0*correct/count\n",
    "  loss = running_loss/len(testloader)\n",
    "\n",
    "\n",
    "  return accuracy,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WMO7_WSLHeGl"
   },
   "outputs": [],
   "source": [
    "class Early_Stopping():\n",
    "  def __init__(self,partience):\n",
    "    self.step = 0\n",
    "    self.loss = float('inf')\n",
    "    self.partience = partience\n",
    "\n",
    "  def validate(self,loss):\n",
    "    if self.loss<loss:\n",
    "      self.step += 1\n",
    "      if self.step>self.partience:\n",
    "        return True\n",
    "    else:\n",
    "      self.step = 0\n",
    "      self.loss = loss\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "-noG_98IR-nZ",
    "outputId": "78a6ebe2-854a-4f83-dc45-5c4ac35b69e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1  loss:4.13703670501709  accuracy:2.0569695731677236\n",
      "Epoch2  loss:4.120308327674866  accuracy:2.648791925787419\n",
      "Epoch3  loss:4.1025719165801995  accuracy:2.6487919257874184\n",
      "Epoch4  loss:4.086331701278686  accuracy:2.5932363702318635\n",
      "Epoch5  loss:4.07083797454834  accuracy:2.593236370231863\n",
      "Epoch6  loss:4.05720729827881  accuracy:2.593236370231862\n",
      "Epoch7  loss:4.044193887710572  accuracy:2.593236370231863\n",
      "Epoch8  loss:4.032093775272369  accuracy:2.593236370231863\n",
      "Epoch9  loss:4.021188199520111  accuracy:2.5932363702318635\n",
      "Epoch10  loss:4.010584497451781  accuracy:2.593236370231863\n",
      "Epoch11  loss:3.9999088168144223  accuracy:2.5932363702318626\n",
      "Epoch12  loss:3.9908419847488403  accuracy:2.5932363702318635\n",
      "Epoch13  loss:3.982397389411927  accuracy:2.593236370231863\n",
      "Epoch14  loss:3.9734476804733276  accuracy:2.5932363702318626\n",
      "Epoch15  loss:3.9653611183166504  accuracy:2.5932363702318635\n",
      "Epoch16  loss:3.9574843287467956  accuracy:2.5932363702318635\n",
      "Epoch17  loss:3.9495299696922306  accuracy:2.593236370231863\n",
      "Epoch18  loss:3.941661500930787  accuracy:2.646427859593565\n",
      "Epoch19  loss:3.9345619440078736  accuracy:2.757538970704677\n",
      "Epoch20  loss:3.927372395992279  accuracy:2.6464278595935653\n",
      "Epoch21  loss:3.920694851875305  accuracy:2.857164328094009\n",
      "Epoch22  loss:3.9138099193573  accuracy:2.8069963183708935\n",
      "Epoch23  loss:3.90772397518158  accuracy:3.5536608756666794\n",
      "Epoch24  loss:3.9017117857933044  accuracy:3.7486722135351607\n",
      "Epoch25  loss:3.895417070388794  accuracy:4.236052672965309\n",
      "Epoch26  loss:3.88934463262558  accuracy:4.277016884736974\n",
      "Epoch27  loss:3.8839395284652714  accuracy:4.496823648022\n",
      "Epoch28  loss:3.8794255495071415  accuracy:4.249612525810876\n",
      "Epoch29  loss:3.8744613647460935  accuracy:4.781545465617624\n",
      "Epoch30  loss:3.8696214795112613  accuracy:4.393743756898629\n",
      "Epoch31  loss:3.8642271161079402  accuracy:4.43173223536961\n",
      "Epoch32  loss:3.8596699357032773  accuracy:5.066354616711178\n",
      "Epoch33  loss:3.8547407269477847  accuracy:4.272466863060759\n",
      "Epoch34  loss:3.851342964172364  accuracy:4.431162515234672\n",
      "Epoch35  loss:3.8460513710975643  accuracy:4.538084216721592\n",
      "Epoch36  loss:3.84337877035141  accuracy:4.111893740531116\n",
      "Epoch37  loss:3.8407724142074584  accuracy:3.9687119223492977\n",
      "Epoch38  loss:3.836127007007599  accuracy:4.450205790799688\n",
      "Epoch39  loss:3.8336399316787726  accuracy:4.329285044878942\n",
      "Epoch40  loss:3.8305804491043096  accuracy:4.601617060689218\n",
      "Epoch41  loss:3.826076722145081  accuracy:4.386103226697124\n",
      "Epoch42  loss:3.8238149642944337  accuracy:4.444798878871037\n",
      "Epoch43  loss:3.8205186486244203  accuracy:4.336103226697124\n",
      "Epoch44  loss:3.817808675765991  accuracy:4.386103226697123\n",
      "Epoch45  loss:3.814916825294495  accuracy:4.494798878871037\n",
      "Epoch46  loss:3.8118801355361938  accuracy:4.487980697052855\n",
      "Epoch47  loss:3.809752404689789  accuracy:4.329285044878942\n",
      "Epoch48  loss:3.8068671345710756  accuracy:4.336103226697124\n",
      "Epoch49  loss:3.804712975025177  accuracy:4.386103226697124\n",
      "Epoch50  loss:3.802493274211884  accuracy:4.4433876089815065\n",
      "Epoch51  loss:3.799655282497405  accuracy:4.431325861205472\n",
      "Epoch52  loss:3.7976710677146905  accuracy:4.859897289776901\n",
      "Epoch53  loss:3.7962935805320743  accuracy:5.014266729860626\n",
      "Epoch54  loss:3.794416415691376  accuracy:4.518465782840167\n",
      "Epoch55  loss:3.7922062397003176  accuracy:4.7256743698396955\n",
      "Epoch56  loss:3.7905501723289494  accuracy:4.754235094828991\n",
      "Epoch57  loss:3.788232529163361  accuracy:4.837315885673759\n",
      "Epoch58  loss:3.786813294887543  accuracy:4.955671434331534\n",
      "Epoch59  loss:3.784752774238586  accuracy:5.16587185351544\n",
      "Epoch60  loss:3.783048152923584  accuracy:5.090679283625097\n",
      "Epoch61  loss:3.781612002849579  accuracy:4.919028634622532\n",
      "Epoch62  loss:3.779736769199371  accuracy:5.413437296202833\n",
      "Epoch63  loss:3.7780632734298707  accuracy:5.27516654433187\n",
      "Epoch64  loss:3.777366042137146  accuracy:4.889581541099807\n",
      "Epoch65  loss:3.7762500166893007  accuracy:5.229552844306404\n",
      "Epoch66  loss:3.7747805714607243  accuracy:5.204815326921829\n",
      "Epoch67  loss:3.773617208003998  accuracy:5.242836555480143\n",
      "Epoch68  loss:3.772511553764343  accuracy:5.412298320119109\n",
      "Epoch69  loss:3.771189260482788  accuracy:5.453040464805551\n",
      "Epoch70  loss:3.769961750507355  accuracy:5.449713286105503\n",
      "Epoch71  loss:3.768809366226196  accuracy:5.406316839593555\n",
      "Epoch72  loss:3.7671581864356987  accuracy:5.508707096395575\n",
      "Epoch73  loss:3.7664060711860654  accuracy:5.419882904208966\n",
      "Epoch74  loss:3.7648632645606996  accuracy:6.318080991223048\n",
      "Epoch75  loss:3.7642291545867925  accuracy:6.799070934529401\n",
      "Epoch76  loss:3.761887621879578  accuracy:7.3941621554208\n",
      "Epoch77  loss:3.7624084949493404  accuracy:6.932532044113175\n",
      "Epoch78  loss:3.760910916328431  accuracy:7.345650429792536\n",
      "Epoch79  loss:3.759807026386261  accuracy:7.2690839815621375\n",
      "Epoch80  loss:3.7580507993698116  accuracy:7.114642355246789\n",
      "Epoch81  loss:3.7574636816978453  accuracy:7.233278521299713\n",
      "Epoch82  loss:3.7553488612174992  accuracy:6.897662542974861\n",
      "Epoch83  loss:3.7555659890174864  accuracy:6.992636417427967\n",
      "Epoch84  loss:3.7540998578071583  accuracy:7.619433622037065\n",
      "Epoch85  loss:3.7529274344444272  accuracy:7.474741492394236\n",
      "Epoch86  loss:3.752257490158081  accuracy:7.712151778585009\n",
      "Epoch87  loss:3.7510802984237674  accuracy:7.799304463298671\n",
      "Epoch88  loss:3.7509337186813347  accuracy:7.406679884696767\n",
      "Epoch89  loss:3.7500006794929504  accuracy:7.318544035433194\n",
      "Epoch90  loss:3.7488063812255863  accuracy:7.407502695820426\n",
      "Epoch91  loss:3.7478449940681453  accuracy:7.3168070480690295\n",
      "Epoch92  loss:3.7474874019622804  accuracy:7.99825669598209\n",
      "Epoch93  loss:3.74698634147644  accuracy:7.2821723061172134\n",
      "Epoch94  loss:3.7460511684417725  accuracy:6.9014814191341625\n",
      "Epoch95  loss:3.745095360279083  accuracy:7.557453890916295\n",
      "Epoch96  loss:3.744455802440644  accuracy:7.694301843246751\n",
      "Epoch97  loss:3.7428020954132077  accuracy:7.7878284772786115\n",
      "Epoch98  loss:3.742852485179901  accuracy:7.4521148297182735\n",
      "Epoch99  loss:3.742899250984192  accuracy:7.479655146544305\n",
      "Epoch100  loss:3.7417918443679814  accuracy:7.663925715309648\n",
      "Epoch101  loss:3.7405591130256655  accuracy:7.597884851164772\n",
      "Epoch102  loss:3.7400235891342155  accuracy:8.090293385579756\n",
      "Epoch103  loss:3.740175020694733  accuracy:8.975444819511678\n",
      "Epoch104  loss:3.7389365315437315  accuracy:8.373130235141346\n",
      "Epoch105  loss:3.738789522647857  accuracy:7.983766346996968\n",
      "Epoch106  loss:3.7375073671340933  accuracy:7.579118838266746\n",
      "Epoch107  loss:3.7362261056900024  accuracy:8.499416008988094\n",
      "Epoch108  loss:3.735517144203187  accuracy:8.549441535146025\n",
      "Epoch109  loss:3.7346206188201907  accuracy:8.831417340989425\n",
      "Epoch110  loss:3.734017467498779  accuracy:8.154393822502493\n",
      "Epoch111  loss:3.7338315963745115  accuracy:8.012385424396536\n",
      "Epoch112  loss:3.7330380916595463  accuracy:8.200284111075709\n",
      "Epoch113  loss:3.7321658968925484  accuracy:8.610139973370595\n",
      "Epoch114  loss:3.731538712978363  accuracy:8.756001332298156\n",
      "Epoch115  loss:3.7304686546325687  accuracy:8.537388740863264\n",
      "Epoch116  loss:3.7301726937294006  accuracy:9.44671512876108\n",
      "Epoch117  loss:3.7289201140403754  accuracy:8.768861530895364\n",
      "Epoch118  loss:3.7283240556716915  accuracy:8.568181896940468\n",
      "Epoch119  loss:3.728326368331909  accuracy:9.360709018178262\n",
      "Epoch120  loss:3.7269437789916995  accuracy:9.471838685538932\n",
      "Epoch121  loss:3.7266057848930347  accuracy:9.885372987423485\n",
      "Epoch122  loss:3.7258275151252747  accuracy:9.989330485260696\n",
      "Epoch123  loss:3.7251887917518616  accuracy:9.193772713570523\n",
      "Epoch124  loss:3.7249147057533265  accuracy:9.158939374489277\n",
      "Epoch125  loss:3.7244445562362674  accuracy:9.782506623536065\n",
      "Epoch126  loss:3.7240906476974494  accuracy:9.27760849434616\n",
      "Epoch127  loss:3.723725891113282  accuracy:9.81519785460633\n",
      "Epoch128  loss:3.7227162480354306  accuracy:10.120522611150596\n",
      "Epoch129  loss:3.721350383758545  accuracy:11.171482348445739\n",
      "Epoch130  loss:3.7205285191535946  accuracy:11.111384439991518\n",
      "Epoch131  loss:3.7209469556808465  accuracy:10.668914985988836\n",
      "Epoch132  loss:3.7199964404106143  accuracy:10.97275425139308\n",
      "Epoch133  loss:3.7194824695587156  accuracy:10.049213734365276\n",
      "Epoch134  loss:3.7195123195648194  accuracy:10.795799076845181\n",
      "Epoch135  loss:3.7176488757133486  accuracy:11.01608363162451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch136  loss:3.7187142968177795  accuracy:10.29275657910491\n",
      "Epoch137  loss:3.7180507302284242  accuracy:10.63232864500632\n",
      "Epoch138  loss:3.7168899416923527  accuracy:10.454279632462535\n",
      "Epoch139  loss:3.716241884231567  accuracy:10.756797343168397\n",
      "Epoch140  loss:3.715255975723266  accuracy:11.256136892507948\n",
      "Epoch141  loss:3.71541029214859  accuracy:10.124179419087058\n",
      "Epoch142  loss:3.7151982665061953  accuracy:10.629057873965515\n",
      "Epoch143  loss:3.714275693893432  accuracy:11.206999676645992\n",
      "Epoch144  loss:3.7131517291069027  accuracy:10.85558158665944\n",
      "Epoch145  loss:3.7128818869590763  accuracy:10.762484203733308\n",
      "Epoch146  loss:3.7117318630218508  accuracy:10.948619651715445\n",
      "Epoch147  loss:3.712245678901673  accuracy:11.016951242695121\n",
      "Epoch148  loss:3.7111969351768495  accuracy:10.820420711669819\n",
      "Epoch149  loss:3.711075258255005  accuracy:11.51869727057355\n",
      "Epoch150  loss:3.7107816100120545  accuracy:11.37766766525823\n",
      "Epoch151  loss:3.7104048848152154  accuracy:11.12342795203503\n",
      "Epoch152  loss:3.709379398822785  accuracy:11.231867709940781\n",
      "Epoch153  loss:3.7092488169670106  accuracy:10.977178053301106\n",
      "Epoch154  loss:3.708819365501404  accuracy:10.778541085295414\n",
      "Epoch155  loss:3.7079834699630734  accuracy:11.277554372154354\n",
      "Epoch156  loss:3.7074667930603034  accuracy:10.990375998349839\n",
      "Epoch157  loss:3.7063100934028625  accuracy:10.891394654984186\n",
      "Epoch158  loss:3.706097400188446  accuracy:10.903672148579789\n",
      "Epoch159  loss:3.7058213472366335  accuracy:11.747956296151315\n",
      "Epoch160  loss:3.7054032444953933  accuracy:11.612297397228387\n",
      "Epoch161  loss:3.703819561004639  accuracy:11.135682113557358\n",
      "Epoch162  loss:3.704035246372223  accuracy:11.104857150676644\n",
      "Epoch163  loss:3.704173672199249  accuracy:10.693585487273616\n",
      "Epoch164  loss:3.7034901976585384  accuracy:11.381326712860494\n",
      "Epoch165  loss:3.7020891666412354  accuracy:11.248319951415747\n",
      "Epoch166  loss:3.70244538784027  accuracy:10.891545386453027\n",
      "Epoch167  loss:3.702304983139038  accuracy:10.93629853986062\n",
      "Epoch168  loss:3.7014485716819765  accuracy:11.200661597212928\n",
      "Epoch169  loss:3.7005598425865167  accuracy:10.802512274771832\n",
      "Epoch170  loss:3.700554728507996  accuracy:11.544034399569217\n",
      "Epoch171  loss:3.6992750167846684  accuracy:11.572847968888015\n",
      "Epoch172  loss:3.6997985482215885  accuracy:11.277394535368376\n",
      "Epoch173  loss:3.6990633010864262  accuracy:11.314602246356573\n",
      "Epoch174  loss:3.6985585451126104  accuracy:11.196789898532737\n",
      "Epoch175  loss:3.6982970952987664  accuracy:11.051487747614901\n",
      "Epoch176  loss:3.698165905475617  accuracy:10.589962049155403\n",
      "Epoch177  loss:3.6973153710365296  accuracy:11.333328438863257\n",
      "Epoch178  loss:3.696671044826508  accuracy:12.160970077132072\n",
      "Epoch179  loss:3.6959034681320184  accuracy:11.8718364823672\n",
      "Epoch180  loss:3.694445967674256  accuracy:11.679009763566706\n",
      "Epoch181  loss:3.6945758700370788  accuracy:11.743112327669271\n",
      "Epoch182  loss:3.6940651774406423  accuracy:11.659423894954612\n",
      "Epoch183  loss:3.6930601358413693  accuracy:12.072879881970536\n",
      "Epoch184  loss:3.6918469309806823  accuracy:11.627899388209556\n",
      "Epoch185  loss:3.6919031858444216  accuracy:12.24595027562917\n",
      "Epoch186  loss:3.690882730484009  accuracy:11.721758815277852\n",
      "Epoch187  loss:3.6896326661109926  accuracy:12.11564866666902\n",
      "Epoch188  loss:3.6895130276679993  accuracy:12.03669529897821\n",
      "Epoch189  loss:3.6897792577743527  accuracy:10.992908220783464\n",
      "Epoch190  loss:3.688920187950134  accuracy:11.341902527433245\n",
      "Epoch191  loss:3.688557696342468  accuracy:11.609078403678389\n",
      "Epoch192  loss:3.688686501979828  accuracy:11.010803745453028\n",
      "Epoch193  loss:3.6885340690612787  accuracy:11.805869620591555\n",
      "Epoch194  loss:3.6878401517868036  accuracy:11.443704824603229\n",
      "Epoch195  loss:3.6871812701225273  accuracy:11.642108166179803\n",
      "Epoch196  loss:3.6856310129165655  accuracy:11.536569850538555\n",
      "Epoch197  loss:3.685104346275329  accuracy:11.475487137145027\n",
      "Epoch198  loss:3.685587954521179  accuracy:11.737609628551075\n",
      "Epoch199  loss:3.6845633268356326  accuracy:12.02197286216108\n",
      "Epoch200  loss:3.6841031551361083  accuracy:12.04845711439856\n",
      "Epoch201  loss:3.683905172348022  accuracy:11.780924515481457\n",
      "Epoch202  loss:3.682460951805115  accuracy:11.74723418620289\n",
      "Epoch203  loss:3.6820353507995605  accuracy:11.641711456899673\n",
      "Epoch204  loss:3.681721901893615  accuracy:11.639940705212835\n",
      "Epoch205  loss:3.6806772232055667  accuracy:11.778543563100502\n",
      "Epoch206  loss:3.6812311530113218  accuracy:12.136745117643521\n",
      "Epoch207  loss:3.6805892467498778  accuracy:11.382527251502214\n",
      "Epoch208  loss:3.6795560479164124  accuracy:11.149468405833096\n",
      "Epoch209  loss:3.6791115045547484  accuracy:11.844569335510784\n",
      "Epoch210  loss:3.677962458133697  accuracy:11.901983001673154\n",
      "Epoch211  loss:3.67802175283432  accuracy:11.806748391389242\n",
      "Epoch212  loss:3.6766300201416016  accuracy:11.90124078457821\n",
      "Epoch213  loss:3.676880204677582  accuracy:12.581960207311244\n",
      "Epoch214  loss:3.6752794861793525  accuracy:11.88836494556677\n",
      "Epoch215  loss:3.6757409811019905  accuracy:12.134545594186445\n",
      "Epoch216  loss:3.6752574086189274  accuracy:12.3939010761029\n",
      "Epoch217  loss:3.6753602147102358  accuracy:12.048680478909565\n",
      "Epoch218  loss:3.67485271692276  accuracy:11.686802519470632\n",
      "Epoch219  loss:3.6741658210754395  accuracy:12.309442039204844\n",
      "Epoch220  loss:3.673426520824432  accuracy:12.492069574271401\n",
      "Epoch221  loss:3.6729693174362184  accuracy:12.125109131557728\n",
      "Epoch222  loss:3.672805666923523  accuracy:11.647963000669153\n",
      "Epoch223  loss:3.6720402479171756  accuracy:12.15003095769907\n",
      "Epoch224  loss:3.672458410263061  accuracy:11.873035356456695\n",
      "Epoch225  loss:3.6704024910926827  accuracy:12.202747611085039\n",
      "Epoch226  loss:3.6701695561408996  accuracy:11.526290434711777\n",
      "Epoch227  loss:3.670455741882324  accuracy:11.981262292122658\n",
      "Epoch228  loss:3.6691457509994505  accuracy:11.47838721538318\n",
      "Epoch229  loss:3.6687218666076657  accuracy:12.459149984417111\n",
      "Epoch230  loss:3.668274819850922  accuracy:11.572879308655763\n",
      "Epoch231  loss:3.667863619327545  accuracy:11.988677367603032\n",
      "Epoch232  loss:3.6666120052337647  accuracy:11.57232985810631\n",
      "Epoch233  loss:3.666402518749237  accuracy:11.996213600976406\n",
      "Epoch234  loss:3.6676335334777828  accuracy:11.492340371266035\n",
      "Epoch235  loss:3.665922927856446  accuracy:11.207128392904846\n",
      "Epoch236  loss:3.6650961279869083  accuracy:11.856184118263997\n",
      "Epoch237  loss:3.6655605792999273  accuracy:11.661724345611967\n",
      "Epoch238  loss:3.6623075604438786  accuracy:11.632740894820769\n",
      "Epoch239  loss:3.663835167884826  accuracy:11.752026690326074\n",
      "Epoch240  loss:3.6620306372642517  accuracy:11.657288537517626\n",
      "Epoch241  loss:3.6612624883651734  accuracy:11.696438566648634\n",
      "Epoch242  loss:3.6614520907402035  accuracy:12.019952702620813\n",
      "Epoch243  loss:3.6611162781715394  accuracy:12.386830743279342\n",
      "Epoch244  loss:3.659646093845368  accuracy:12.211853564219448\n",
      "Epoch245  loss:3.660251951217651  accuracy:12.458259314707913\n",
      "Epoch246  loss:3.6599824070930485  accuracy:11.87013175599212\n",
      "Epoch247  loss:3.6589868187904355  accuracy:12.019354281434158\n",
      "Epoch248  loss:3.6591073393821723  accuracy:12.26010315409371\n",
      "Epoch249  loss:3.6586572647094733  accuracy:11.572980003538142\n",
      "Epoch250  loss:3.657367038726807  accuracy:12.608315762325338\n",
      "Epoch251  loss:3.6558953881263734  accuracy:12.359218875770406\n",
      "Epoch252  loss:3.6565768718719482  accuracy:11.656780712009798\n",
      "Epoch253  loss:3.6535464763641365  accuracy:12.276448394219436\n",
      "Epoch254  loss:3.6533497095108034  accuracy:12.075420405649496\n",
      "Epoch255  loss:3.652913117408752  accuracy:12.507721989083482\n",
      "Epoch256  loss:3.6527808904647814  accuracy:12.386607389397453\n",
      "Epoch257  loss:3.653456628322601  accuracy:12.053810105380654\n",
      "Epoch258  loss:3.6522301197052007  accuracy:12.597230100020164\n",
      "Epoch259  loss:3.650013077259064  accuracy:12.325814929824505\n",
      "Epoch260  loss:3.6515718460083013  accuracy:11.946003075012651\n",
      "Epoch261  loss:3.650263559818268  accuracy:12.570489535126288\n",
      "Epoch262  loss:3.649136066436767  accuracy:12.357248333818882\n",
      "Epoch263  loss:3.649372565746308  accuracy:12.320165497955557\n",
      "Epoch264  loss:3.648560667037964  accuracy:12.404909006479555\n",
      "Epoch265  loss:3.6479609131813047  accuracy:12.296563867298183\n",
      "Epoch266  loss:3.647087836265564  accuracy:11.989930895159981\n",
      "Epoch267  loss:3.6458173632621764  accuracy:12.83130673766823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch268  loss:3.6470594763755804  accuracy:12.53760369274567\n",
      "Epoch269  loss:3.6462381005287168  accuracy:12.561651393012884\n",
      "Epoch270  loss:3.644699859619141  accuracy:12.180338981389337\n",
      "Epoch271  loss:3.645521163940429  accuracy:12.739684093511462\n",
      "Epoch272  loss:3.6445984482765192  accuracy:12.489752492455448\n",
      "Epoch273  loss:3.643868112564087  accuracy:12.584700092281095\n",
      "Epoch274  loss:3.6425904035568233  accuracy:12.850878304451598\n",
      "Epoch275  loss:3.642225015163421  accuracy:12.595111428911943\n",
      "Epoch276  loss:3.641817915439606  accuracy:12.833370705762524\n",
      "Epoch277  loss:3.64133540391922  accuracy:12.719443600805091\n",
      "Epoch278  loss:3.6396702289581295  accuracy:12.675063745186701\n",
      "Epoch279  loss:3.6392205476760866  accuracy:13.204264131363837\n",
      "Epoch280  loss:3.6383398294448854  accuracy:12.887080840400056\n",
      "Epoch281  loss:3.638421654701233  accuracy:13.150824361282384\n",
      "Epoch282  loss:3.636988544464111  accuracy:13.390767185115877\n",
      "Epoch283  loss:3.6368739485740664  accuracy:12.919034707372944\n",
      "Epoch284  loss:3.6360659122467047  accuracy:13.009388797727036\n",
      "Epoch285  loss:3.6354850172996525  accuracy:13.695753071534968\n",
      "Epoch286  loss:3.633990883827209  accuracy:12.977329432392409\n",
      "Epoch287  loss:3.633218276500702  accuracy:13.777319511999208\n",
      "Epoch288  loss:3.633323884010315  accuracy:13.016116429367555\n",
      "Epoch289  loss:3.6329145312309263  accuracy:13.213580987730381\n",
      "Epoch290  loss:3.632263553142548  accuracy:13.360468273806509\n",
      "Epoch291  loss:3.6315493822097773  accuracy:13.096319665752267\n",
      "Epoch292  loss:3.6304252505302426  accuracy:13.10031176365\n",
      "Epoch293  loss:3.630366063117982  accuracy:12.65694545129414\n",
      "Epoch294  loss:3.6289232254028314  accuracy:13.318049523196407\n",
      "Epoch295  loss:3.627782332897186  accuracy:13.192884891426127\n",
      "Epoch296  loss:3.627664566040039  accuracy:13.171048732827192\n",
      "Epoch297  loss:3.6268346071243287  accuracy:13.377523324478862\n",
      "Epoch298  loss:3.625344502925873  accuracy:13.271552002223137\n",
      "Epoch299  loss:3.624732685089111  accuracy:13.051332510050823\n",
      "Epoch300  loss:3.6247962594032286  accuracy:13.710757183236968\n"
     ]
    }
   ],
   "source": [
    "server = Server()\n",
    "workers = server.create_worker(federated_trainset,federated_valset,federated_testset)\n",
    "acc_train = []\n",
    "loss_train = []\n",
    "acc_valid = []\n",
    "loss_valid = []\n",
    "\n",
    "early_stopping = Early_Stopping(args.partience)\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for epoch in range(args.global_epochs):\n",
    "  sample_worker = server.sample_worker(workers)\n",
    "  server.send_parameters(sample_worker)\n",
    "\n",
    "  acc_train_avg = 0.0\n",
    "  loss_train_avg = 0.0\n",
    "  acc_valid_avg = 0.0\n",
    "  loss_valid_avg = 0.0\n",
    "  for worker in sample_worker:\n",
    "    acc_train_tmp,loss_train_tmp = worker.local_train()\n",
    "    acc_valid_tmp,loss_valid_tmp = worker.validate()\n",
    "    acc_train_avg += acc_train_tmp/len(sample_worker)\n",
    "    loss_train_avg += loss_train_tmp/len(sample_worker)\n",
    "    acc_valid_avg += acc_valid_tmp/len(sample_worker)\n",
    "    loss_valid_avg += loss_valid_tmp/len(sample_worker)\n",
    "  server.aggregate_model(sample_worker)\n",
    "  '''\n",
    "  server.model.to(args.device)\n",
    "  for worker in workers:\n",
    "    acc_valid_tmp,loss_valid_tmp = test(server.model,args.criterion,worker.valloader)\n",
    "    acc_valid_avg += acc_valid_tmp/len(workers)\n",
    "    loss_valid_avg += loss_valid_tmp/len(workers)\n",
    "  server.model.to('cpu')\n",
    "  '''\n",
    "  print('Epoch{}  loss:{}  accuracy:{}'.format(epoch+1,loss_valid_avg,acc_valid_avg))\n",
    "  acc_train.append(acc_train_avg)\n",
    "  loss_train.append(loss_train_avg)\n",
    "  acc_valid.append(acc_valid_avg)\n",
    "  loss_valid.append(loss_valid_avg)\n",
    "\n",
    "  if early_stopping.validate(loss_valid_avg):\n",
    "    print('Early Stop')\n",
    "    break\n",
    "    \n",
    "end = time.time()#終了時刻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習時間：19069.10147500038秒\n"
     ]
    }
   ],
   "source": [
    "print('学習時間：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:11.764705882352942  loss:3.626681327819824\n",
      "Worker2 accuracy:22.857142857142858  loss:3.5399868488311768\n",
      "Worker3 accuracy:15.0  loss:3.5284180641174316\n",
      "Worker4 accuracy:16.666666666666668  loss:3.752781391143799\n",
      "Worker5 accuracy:5.882352941176471  loss:3.56485652923584\n",
      "Worker6 accuracy:23.80952380952381  loss:3.454990863800049\n",
      "Worker7 accuracy:21.05263157894737  loss:3.6168129444122314\n",
      "Worker8 accuracy:12.5  loss:3.6710546016693115\n",
      "Worker9 accuracy:21.05263157894737  loss:3.63863205909729\n",
      "Worker10 accuracy:12.195121951219512  loss:3.499849319458008\n",
      "Worker11 accuracy:0.0  loss:3.895113229751587\n",
      "Worker12 accuracy:31.57894736842105  loss:3.4048798084259033\n",
      "Worker13 accuracy:15.789473684210526  loss:3.549311637878418\n",
      "Worker14 accuracy:10.0  loss:3.8056797981262207\n",
      "Worker15 accuracy:31.57894736842105  loss:3.5425455570220947\n",
      "Worker16 accuracy:11.764705882352942  loss:3.4685235023498535\n",
      "Worker17 accuracy:18.181818181818183  loss:3.486377239227295\n",
      "Worker18 accuracy:16.129032258064516  loss:3.511859178543091\n",
      "Worker19 accuracy:11.764705882352942  loss:3.7338497638702393\n",
      "Worker20 accuracy:11.11111111111111  loss:3.6112942695617676\n",
      "Test(personalized)  loss:3.5951748967170714  accuracy:16.033975950136462\n"
     ]
    }
   ],
   "source": [
    "acc_test_personalized = []\n",
    "loss_test_personalized = []\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "  acc_tmp,loss_tmp = worker.test()\n",
    "  acc_test_personalized.append(acc_tmp)\n",
    "  loss_test_personalized.append(loss_tmp)\n",
    "  print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "\n",
    "end = time.time()#終了時刻\n",
    "\n",
    "acc_test_personalized_avg = sum(acc_test_personalized)/len(acc_test_personalized)\n",
    "loss_test_personalized_avg = sum(loss_test_personalized)/len(loss_test_personalized)\n",
    "print('Test(personalized)  loss:{}  accuracy:{}'.format(loss_test_personalized_avg,acc_test_personalized_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推論時間：15.378531455993652秒\n"
     ]
    }
   ],
   "source": [
    "print('推論時間：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:11.764705882352942  loss:3.6528284549713135\n",
      "Worker2 accuracy:25.714285714285715  loss:3.604044198989868\n",
      "Worker3 accuracy:15.0  loss:3.5448813438415527\n",
      "Worker4 accuracy:16.666666666666668  loss:3.775890350341797\n",
      "Worker5 accuracy:5.882352941176471  loss:3.578462600708008\n",
      "Worker6 accuracy:14.285714285714286  loss:3.4692904949188232\n",
      "Worker7 accuracy:10.526315789473685  loss:3.622075080871582\n",
      "Worker8 accuracy:12.5  loss:3.6884396076202393\n",
      "Worker9 accuracy:15.789473684210526  loss:3.663530111312866\n",
      "Worker10 accuracy:4.878048780487805  loss:3.548125743865967\n",
      "Worker11 accuracy:0.0  loss:3.927037477493286\n",
      "Worker12 accuracy:21.05263157894737  loss:3.429694652557373\n",
      "Worker13 accuracy:15.789473684210526  loss:3.557819128036499\n",
      "Worker14 accuracy:10.0  loss:3.8104965686798096\n",
      "Worker15 accuracy:21.05263157894737  loss:3.5714282989501953\n",
      "Worker16 accuracy:11.764705882352942  loss:3.4876160621643066\n",
      "Worker17 accuracy:3.0303030303030303  loss:3.511375665664673\n",
      "Worker18 accuracy:12.903225806451612  loss:3.544710397720337\n",
      "Worker19 accuracy:11.764705882352942  loss:3.781994104385376\n",
      "Worker20 accuracy:16.666666666666668  loss:3.60705828666687\n",
      "Test(global)  loss:3.6188399314880373  accuracy:12.851595392730028\n"
     ]
    }
   ],
   "source": [
    "acc_test_global = []\n",
    "loss_test_global = []\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "  server.model = server.model.to(args.device)\n",
    "  acc_tmp,loss_tmp = test(server.model,args.criterion,worker.testloader)\n",
    "  acc_test_global.append(acc_tmp)\n",
    "  loss_test_global.append(loss_tmp)\n",
    "  print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "\n",
    "server.model = server.model.to('cpu')\n",
    "\n",
    "end = time.time()#終了時刻\n",
    "\n",
    "acc_test_global_avg = sum(acc_test_global)/len(acc_test_global)\n",
    "loss_test_global_avg = sum(loss_test_global)/len(loss_test_global)\n",
    "print('Test(global)  loss:{}  accuracy:{}'.format(loss_test_global_avg,acc_test_global_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推論時間：14.885394096374512秒\n"
     ]
    }
   ],
   "source": [
    "print('推論時間：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:5.882352941176471  loss:3.5585062503814697\n",
      "Worker2 accuracy:2.857142857142857  loss:3.388286590576172\n",
      "Worker3 accuracy:12.5  loss:3.5617835521698\n",
      "Worker4 accuracy:5.555555555555555  loss:3.939203977584839\n",
      "Worker5 accuracy:14.705882352941176  loss:3.6461002826690674\n",
      "Worker6 accuracy:4.761904761904762  loss:3.4343273639678955\n",
      "Worker7 accuracy:10.526315789473685  loss:3.684765577316284\n",
      "Worker8 accuracy:9.375  loss:3.651965379714966\n",
      "Worker9 accuracy:0.0  loss:3.760240316390991\n",
      "Worker10 accuracy:12.195121951219512  loss:3.4825937747955322\n",
      "Worker11 accuracy:5.555555555555555  loss:3.8849945068359375\n",
      "Worker12 accuracy:5.2631578947368425  loss:3.448474168777466\n",
      "Worker13 accuracy:0.0  loss:3.7474770545959473\n",
      "Worker14 accuracy:3.3333333333333335  loss:3.892516613006592\n",
      "Worker15 accuracy:5.2631578947368425  loss:3.469998359680176\n",
      "Worker16 accuracy:11.764705882352942  loss:3.4498631954193115\n",
      "Worker17 accuracy:18.181818181818183  loss:3.50374174118042\n",
      "Worker18 accuracy:12.903225806451612  loss:3.4611101150512695\n",
      "Worker19 accuracy:11.764705882352942  loss:3.733745813369751\n",
      "Worker20 accuracy:5.555555555555555  loss:3.7123477458953857\n",
      "Test_fine-tune(global)  loss:3.6206021189689634  accuracy:7.897224609815391\n"
     ]
    }
   ],
   "source": [
    "acc_tune_test_global = []\n",
    "loss_tune_test_global = []\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "  worker.model = copy.deepcopy(server.model)\n",
    "  worker.model = worker.model.to(args.device)\n",
    "  _,_ = train(worker.model,args.criterion,worker.trainloader,args.local_epochs)\n",
    "  acc_tmp,loss_tmp = test(worker.model,args.criterion,worker.testloader)\n",
    "  acc_tune_test_global.append(acc_tmp)\n",
    "  loss_tune_test_global.append(loss_tmp)\n",
    "  print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "  worker.model = worker.model.to('cpu')\n",
    "  del worker.model\n",
    "\n",
    "end = time.time()#終了時刻\n",
    "\n",
    "acc_tune_test_global_avg = sum(acc_tune_test_global)/len(acc_tune_test_global)\n",
    "loss_tune_test_global_avg = sum(loss_tune_test_global)/len(loss_tune_test_global)\n",
    "print('Test_fine-tune(global)  loss:{}  accuracy:{}'.format(loss_tune_test_global_avg,acc_tune_test_global_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習・推論時間（fine-tune）：46.49528503417969秒\n"
     ]
    }
   ],
   "source": [
    "print('学習・推論時間（fine-tune）：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FedAvg_femnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
