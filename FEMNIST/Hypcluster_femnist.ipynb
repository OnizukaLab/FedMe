{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "vkZxat4Y-IsQ",
    "outputId": "da86392c-66e8-4b60-b471-086e745cdcbc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from torch import nn, optim\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O0TfzOhU-QlG"
   },
   "outputs": [],
   "source": [
    "class Argments():\n",
    "  def __init__(self):\n",
    "    self.batch_size = 20\n",
    "    self.test_batch = 1000\n",
    "    self.global_epochs = 300\n",
    "    self.local_epochs = 2\n",
    "    self.lr = None\n",
    "    self.momentum = 0.9\n",
    "    self.weight_decay = 10**-4.0\n",
    "    self.clip = 20.0\n",
    "    self.partience = 300\n",
    "    self.worker_num = 20\n",
    "    self.sample_num = 20\n",
    "    self.cluster_num = 2\n",
    "    self.device = device = torch.device('cuda:0'if torch.cuda.is_available() else'cpu')\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "args = Argments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(10**-3.0)\n",
    "lr_list.append(10**-2.5)\n",
    "lr_list.append(10**-2.0)\n",
    "lr_list.append(10**-1.5)\n",
    "lr_list.append(10**-1.0)\n",
    "lr_list.append(10**-0.5)\n",
    "lr_list.append(10**0.0)\n",
    "lr_list.append(10**0.5)\n",
    "\n",
    "args.lr = lr_list[lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r5PuCcqmJNUQ"
   },
   "outputs": [],
   "source": [
    "class LocalDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,dataset,worker_id):\n",
    "    self.data = []\n",
    "    self.target = []\n",
    "    self.id = worker_id\n",
    "    for data in dataset.take(len(dataset)):\n",
    "      self.data.append(torch.tensor([data['pixels'].numpy()]))\n",
    "      self.target.append(torch.tensor(data['label'].numpy().astype(np.int64)))\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.data[index],self.target[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/federated_trainset_femnist.pickle', 'rb') as f:\n",
    "    all_federated_trainset = pickle.load(f)\n",
    "with open('../data/federated_testset_femnist.pickle', 'rb') as f:\n",
    "    all_federated_testset = pickle.load(f)\n",
    "all_worker_num = len(all_federated_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2619, 456, 102, 3037, 1126, 1003, 914, 571, 3016, 419, 2771, 3033, 2233, 356, 2418, 1728, 130, 122, 383, 895]\n"
     ]
    }
   ],
   "source": [
    "worker_id_list = random.sample(range(all_worker_num),args.worker_num)\n",
    "print(worker_id_list)\n",
    "federated_trainset = []\n",
    "federated_testset = []\n",
    "for i in worker_id_list:\n",
    "    federated_trainset.append(all_federated_trainset[i])\n",
    "    federated_testset.append(all_federated_testset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_valset = [None]*args.worker_num\n",
    "for i in range(args.worker_num):\n",
    "  n_samples = len(federated_trainset[i])\n",
    "  if n_samples==1:\n",
    "    federated_valset[i] = copy.deepcopy(federated_trainset[i])\n",
    "  else:\n",
    "    train_size = int(len(federated_trainset[i]) * 0.7) \n",
    "    val_size = n_samples - train_size \n",
    "    federated_trainset[i],federated_valset[i] = torch.utils.data.random_split(federated_trainset[i], [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZU3vAAb9-6SD"
   },
   "outputs": [],
   "source": [
    "class CNN1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(5408, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "class CNN2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(9216, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "class CNN3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(15488, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "    \n",
    "class CNN4(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN4, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv2d_4 = torch.nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(25600, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = self.conv2d_4(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Yu90X1TWJVKJ"
   },
   "outputs": [],
   "source": [
    "class Server():\n",
    "  def __init__(self):\n",
    "    self.models = []\n",
    "    for i in range(args.cluster_num):\n",
    "      self.models.append(CNN2())\n",
    "\n",
    "  def model_initialize(self,workers):\n",
    "    sample_worker = self.sample_worker(workers)\n",
    "    self.send_models(sample_worker)\n",
    "    for i,worker in enumerate(sample_worker):\n",
    "      worker.cluster = i%args.cluster_num\n",
    "      _ = worker.local_train()\n",
    "    self.aggregate_models(sample_worker)\n",
    "\n",
    "  def create_worker(self,federated_trainset,federated_valset,federated_testset):\n",
    "    workers = []\n",
    "    for i in range(args.worker_num):\n",
    "      workers.append(Worker(federated_trainset[i],federated_valset[i],federated_testset[i]))\n",
    "    return workers\n",
    "\n",
    "  def sample_worker(self,workers):\n",
    "    sample_worker = []\n",
    "    sample_worker_num = random.sample(range(args.worker_num),args.sample_num)\n",
    "    for i in sample_worker_num:\n",
    "      sample_worker.append(workers[i])\n",
    "    return sample_worker\n",
    "\n",
    "\n",
    "  def send_models(self,workers):\n",
    "    nums = 0\n",
    "    for worker in workers:\n",
    "      nums += worker.train_data_num\n",
    "\n",
    "    for worker in workers:\n",
    "      worker.aggregation_weight = 1.0*worker.train_data_num/nums\n",
    "      worker.models = copy.deepcopy(self.models)\n",
    "      for i in range(args.cluster_num):\n",
    "        worker.models[i] = worker.models[i].to(args.device)\n",
    "\n",
    "  def aggregate_models(self,workers):\n",
    "    new_params = []\n",
    "    for i in range(args.cluster_num):   \n",
    "      new_params.append(OrderedDict())\n",
    "    total_num = [0]*args.cluster_num\n",
    "    for worker in workers:\n",
    "      total_num[worker.cluster] += worker.train_data_num\n",
    "    count = [0]*args.cluster_num    \n",
    "    for worker in workers:\n",
    "      worker_state = worker.models[worker.cluster].state_dict()\n",
    "      for key in worker_state.keys():\n",
    "        if count[worker.cluster]==0:\n",
    "          new_params[worker.cluster][key] = 1.0*worker_state[key]*worker.train_data_num/total_num[worker.cluster]\n",
    "        else:\n",
    "          new_params[worker.cluster][key] += 1.0*worker_state[key]*worker.train_data_num/total_num[worker.cluster]\n",
    "      count[worker.cluster] += 1\n",
    "      for i in range(args.cluster_num):\n",
    "        worker.models[i] = worker.models[i].to('cpu')\n",
    "      del worker.models\n",
    "\n",
    "    for i in range(args.cluster_num):\n",
    "      if total_num[i]!=0:\n",
    "        self.models[i].load_state_dict(new_params[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LDWEBjgfJYFc"
   },
   "outputs": [],
   "source": [
    "class Worker():\n",
    "  def __init__(self,trainset,valset,testset):\n",
    "    self.trainloader = torch.utils.data.DataLoader(trainset,batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.valloader = torch.utils.data.DataLoader(valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.testloader = torch.utils.data.DataLoader(testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.models = None\n",
    "    self.cluster = None\n",
    "    self.train_data_num = len(trainset)\n",
    "    self.test_data_num = len(testset)\n",
    "    self.aggregation_weight = None\n",
    "\n",
    "  def local_train(self):\n",
    "    acc_train,loss_train = train(self.models[self.cluster],args.criterion,self.trainloader,args.local_epochs)\n",
    "    acc_valid,loss_valid = test(self.models[self.cluster],args.criterion,self.valloader)\n",
    "    return acc_train,loss_train,acc_valid,loss_valid\n",
    "\n",
    "  def clustering(self,models):\n",
    "    for i in range(args.cluster_num):\n",
    "      if i==0:\n",
    "        cluster = 0\n",
    "        _,loss = test(models[i],args.criterion,self.trainloader)\n",
    "      else:\n",
    "        _,tmp = test(models[i],args.criterion,self.trainloader)\n",
    "        if tmp<loss:\n",
    "          cluster = i\n",
    "    self.cluster = cluster\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7-GY66gROuEU"
   },
   "outputs": [],
   "source": [
    "def train(model,criterion,trainloader,epochs):\n",
    "  optimizer = optim.SGD(model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "  model.train()\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for (data,labels) in trainloader:\n",
    "      data,labels = Variable(data),Variable(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      count += len(labels)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "      optimizer.step()\n",
    "\n",
    "  return 100.0*correct/count,running_loss/len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "oA4URv9mQ3xV"
   },
   "outputs": [],
   "source": [
    "def test(model,criterion,testloader):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  count = 0\n",
    "  for (data,labels) in testloader:\n",
    "    data,labels = data.to(args.device),labels.to(args.device)\n",
    "    outputs = model(data)\n",
    "    running_loss += criterion(outputs,labels).item()\n",
    "    predicted = torch.argmax(outputs,dim=1)\n",
    "    correct += (predicted==labels).sum().item()\n",
    "    count += len(labels)\n",
    "\n",
    "  accuracy = 100.0*correct/count\n",
    "  loss = running_loss/len(testloader)\n",
    "\n",
    "\n",
    "  return accuracy,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WMO7_WSLHeGl"
   },
   "outputs": [],
   "source": [
    "class Early_Stopping():\n",
    "  def __init__(self,partience):\n",
    "    self.step = 0\n",
    "    self.loss = float('inf')\n",
    "    self.partience = partience\n",
    "\n",
    "  def validate(self,loss):\n",
    "    if self.loss<loss:\n",
    "      self.step += 1\n",
    "      if self.step>self.partience:\n",
    "        return True\n",
    "    else:\n",
    "      self.step = 0\n",
    "      self.loss = loss\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "-noG_98IR-nZ",
    "outputId": "78a6ebe2-854a-4f83-dc45-5c4ac35b69e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1  loss:3.8949894070625306  accuracy:4.464105107995978\n",
      "Epoch2  loss:3.787770712375641  accuracy:5.020098242243181\n",
      "Epoch3  loss:3.7427849531173707  accuracy:5.172259488629352\n",
      "Epoch4  loss:3.7163455724716186  accuracy:5.077942462256575\n",
      "Epoch5  loss:3.6984432458877574  accuracy:5.306792976821377\n",
      "Epoch6  loss:3.6842944979667664  accuracy:5.455144625173024\n",
      "Epoch7  loss:3.6734286427497866  accuracy:5.152580754664903\n",
      "Epoch8  loss:3.6598856329917906  accuracy:5.11891600671444\n",
      "Epoch9  loss:3.6575195908546454  accuracy:6.128868939172069\n",
      "Epoch10  loss:3.6442091584205625  accuracy:5.2178171056155405\n",
      "Epoch11  loss:3.650455701351165  accuracy:5.522837482064488\n",
      "Epoch12  loss:3.6430820941925046  accuracy:6.171331844844565\n",
      "Epoch13  loss:3.6310708284378053  accuracy:6.037164424962859\n",
      "Epoch14  loss:3.6323269844055175  accuracy:5.8605763982006165\n",
      "Epoch15  loss:3.6335554122924805  accuracy:5.8969237132935755\n",
      "Epoch16  loss:3.61643728017807  accuracy:5.731390833474982\n",
      "Epoch17  loss:3.6191269516944886  accuracy:6.477410719642879\n",
      "Epoch18  loss:3.609748780727386  accuracy:6.394407259557611\n",
      "Epoch19  loss:3.6090760946273805  accuracy:6.986170765196473\n",
      "Epoch20  loss:3.6090109705924993  accuracy:7.5491114445086644\n",
      "Epoch21  loss:3.6012134432792666  accuracy:6.662903764987913\n",
      "Epoch22  loss:3.5916208744049065  accuracy:7.386889834848399\n",
      "Epoch23  loss:3.595840334892274  accuracy:6.469028635421224\n",
      "Epoch24  loss:3.59678612947464  accuracy:7.49746074729169\n",
      "Epoch25  loss:3.583392596244812  accuracy:6.987277803647667\n",
      "Epoch26  loss:3.5846716880798333  accuracy:5.927311254764222\n",
      "Epoch27  loss:3.5710782885551455  accuracy:7.685875625560137\n",
      "Epoch28  loss:3.5685021758079527  accuracy:7.119887459384057\n",
      "Epoch29  loss:3.57129521369934  accuracy:8.764460034042983\n",
      "Epoch30  loss:3.569650149345397  accuracy:7.658554435092533\n",
      "Epoch31  loss:3.5578210473060605  accuracy:9.555802364982906\n",
      "Epoch32  loss:3.5437112212181088  accuracy:7.2658813345308335\n",
      "Epoch33  loss:3.538291084766388  accuracy:7.994133433355159\n",
      "Epoch34  loss:3.5487277865409848  accuracy:7.654360467690817\n",
      "Epoch35  loss:3.528402328491211  accuracy:9.93451441403444\n",
      "Epoch36  loss:3.530796492099762  accuracy:8.657046721712183\n",
      "Epoch37  loss:3.5167698860168466  accuracy:9.45015156402482\n",
      "Epoch38  loss:3.5187651872634884  accuracy:10.77953600981165\n",
      "Epoch39  loss:3.497075235843658  accuracy:10.485838421365921\n",
      "Epoch40  loss:3.4895659804344175  accuracy:9.105582759339953\n",
      "Epoch41  loss:3.4849427819252012  accuracy:10.44341669738616\n",
      "Epoch42  loss:3.4646289110183717  accuracy:10.202820400592902\n",
      "Epoch43  loss:3.444367790222168  accuracy:12.70557201576164\n",
      "Epoch44  loss:3.431098484992981  accuracy:11.279233860780222\n",
      "Epoch45  loss:3.413209962844848  accuracy:12.76950016804732\n",
      "Epoch46  loss:3.414721429347992  accuracy:15.0172083666135\n",
      "Epoch47  loss:3.386839294433593  accuracy:14.782616338248097\n",
      "Epoch48  loss:3.36948207616806  accuracy:15.473365700265095\n",
      "Epoch49  loss:3.354719889163971  accuracy:17.52766648105423\n",
      "Epoch50  loss:3.330032908916473  accuracy:16.1327812127644\n",
      "Epoch51  loss:3.308413159847259  accuracy:17.942754459122995\n",
      "Epoch52  loss:3.2876448988914486  accuracy:19.45142128217016\n",
      "Epoch53  loss:3.2646091938018795  accuracy:17.768975899462514\n",
      "Epoch54  loss:3.2424057364463805  accuracy:20.994711715639912\n",
      "Epoch55  loss:3.2055996298789977  accuracy:20.57816160875891\n",
      "Epoch56  loss:3.187102961540222  accuracy:21.568549286772722\n",
      "Epoch57  loss:3.1698798656463625  accuracy:22.598161037527976\n",
      "Epoch58  loss:3.1451101899147034  accuracy:21.425706321052772\n",
      "Epoch59  loss:3.1128130078315728  accuracy:24.348996851850274\n",
      "Epoch60  loss:3.070527482032776  accuracy:25.212806343970588\n",
      "Epoch61  loss:3.049070584774017  accuracy:26.369128815892932\n",
      "Epoch62  loss:3.0128098011016844  accuracy:26.709137887756732\n",
      "Epoch63  loss:2.9925921797752384  accuracy:28.38508199644991\n",
      "Epoch64  loss:2.91777331829071  accuracy:30.416463203364\n",
      "Epoch65  loss:2.894386315345764  accuracy:33.29302499009469\n",
      "Epoch66  loss:2.8688977718353277  accuracy:31.33794269575795\n",
      "Epoch67  loss:2.8370011210441586  accuracy:36.32203095290701\n",
      "Epoch68  loss:2.806818115711212  accuracy:35.490323627092195\n",
      "Epoch69  loss:2.7722767353057867  accuracy:35.63180119036904\n",
      "Epoch70  loss:2.719187891483307  accuracy:38.53027622105252\n",
      "Epoch71  loss:2.701434028148651  accuracy:38.76248902971354\n",
      "Epoch72  loss:2.6889272212982176  accuracy:39.75419589360894\n",
      "Epoch73  loss:2.65283396244049  accuracy:40.59903347187955\n",
      "Epoch74  loss:2.648726606369019  accuracy:39.649215997198894\n",
      "Epoch75  loss:2.584626448154449  accuracy:40.70309374352194\n",
      "Epoch76  loss:2.543444985151291  accuracy:42.60515825832844\n",
      "Epoch77  loss:2.515371179580689  accuracy:44.24646728707742\n",
      "Epoch78  loss:2.502081620693207  accuracy:44.80128241892821\n",
      "Epoch79  loss:2.4635791659355166  accuracy:47.449705736630946\n",
      "Epoch80  loss:2.4239793419837947  accuracy:48.49414974945392\n",
      "Epoch81  loss:2.4129598200321203  accuracy:48.11962819640698\n",
      "Epoch82  loss:2.399589693546295  accuracy:49.02466060658814\n",
      "Epoch83  loss:2.375731348991394  accuracy:48.515833847763524\n",
      "Epoch84  loss:2.349441093206406  accuracy:49.24708402501418\n",
      "Epoch85  loss:2.3177614986896513  accuracy:50.16575323377294\n",
      "Epoch86  loss:2.3165910720825194  accuracy:50.397490303927675\n",
      "Epoch87  loss:2.2769332408905023  accuracy:51.36740900011369\n",
      "Epoch88  loss:2.2575711190700534  accuracy:50.83602629542955\n",
      "Epoch89  loss:2.2433607399463655  accuracy:53.46280389459848\n",
      "Epoch90  loss:2.2078184247016908  accuracy:53.72446692295093\n",
      "Epoch91  loss:2.193856930732727  accuracy:53.40218611068306\n",
      "Epoch92  loss:2.175038224458695  accuracy:53.450749658893706\n",
      "Epoch93  loss:2.146030920743942  accuracy:54.714954437569126\n",
      "Epoch94  loss:2.132708722352982  accuracy:55.79275391820065\n",
      "Epoch95  loss:2.121091169118881  accuracy:55.57800659766476\n",
      "Epoch96  loss:2.0837343156337735  accuracy:56.275823577891764\n",
      "Epoch97  loss:2.077525609731674  accuracy:56.575446177487535\n",
      "Epoch98  loss:2.056030201911926  accuracy:56.401923699129874\n",
      "Epoch99  loss:2.046248632669449  accuracy:55.54840959667565\n",
      "Epoch100  loss:2.0233214974403375  accuracy:57.2971682988742\n",
      "Epoch101  loss:2.016624593734741  accuracy:56.58431896719849\n",
      "Epoch102  loss:1.9983747303485868  accuracy:57.078635364706535\n",
      "Epoch103  loss:1.9824839413166047  accuracy:58.802000351394724\n",
      "Epoch104  loss:1.969606900215149  accuracy:59.43885924779876\n",
      "Epoch105  loss:1.944232004880905  accuracy:58.26768050239077\n",
      "Epoch106  loss:1.9274837970733643  accuracy:59.1082078416415\n",
      "Epoch107  loss:1.9293999791145322  accuracy:59.1059009993285\n",
      "Epoch108  loss:1.8860972225666048  accuracy:60.05290989660803\n",
      "Epoch109  loss:1.8873647391796113  accuracy:60.591652869645046\n",
      "Epoch110  loss:1.8825230598449707  accuracy:60.61117351430857\n",
      "Epoch111  loss:1.8760778427124023  accuracy:59.27233832876805\n",
      "Epoch112  loss:1.864094913005829  accuracy:59.744476611943924\n",
      "Epoch113  loss:1.8282358527183535  accuracy:61.36941785526561\n",
      "Epoch114  loss:1.8257605016231535  accuracy:60.94543173406228\n",
      "Epoch115  loss:1.8151848137378697  accuracy:61.39483162270719\n",
      "Epoch116  loss:1.8134679317474367  accuracy:61.13431235423085\n",
      "Epoch117  loss:1.774284267425537  accuracy:62.252278914589496\n",
      "Epoch118  loss:1.7677216172218317  accuracy:61.647301518231366\n",
      "Epoch119  loss:1.7612123668193822  accuracy:63.19455723243046\n",
      "Epoch120  loss:1.733652132749557  accuracy:62.34268464363985\n",
      "Epoch121  loss:1.7364255368709565  accuracy:62.960670766256904\n",
      "Epoch122  loss:1.7253977179527284  accuracy:62.24740181245764\n",
      "Epoch123  loss:1.7183747649192809  accuracy:62.75676670647645\n",
      "Epoch124  loss:1.7012691438198089  accuracy:64.20578776542156\n",
      "Epoch125  loss:1.697450149059296  accuracy:62.673663158130566\n",
      "Epoch126  loss:1.6804398775100706  accuracy:63.88592638735438\n",
      "Epoch127  loss:1.6728774666786195  accuracy:64.93801463729736\n",
      "Epoch128  loss:1.652954161167145  accuracy:63.959491346606335\n",
      "Epoch129  loss:1.6546539008617402  accuracy:64.03333065482124\n",
      "Epoch130  loss:1.6494898676872252  accuracy:64.4204695557662\n",
      "Epoch131  loss:1.6469532489776613  accuracy:64.22427478243685\n",
      "Epoch132  loss:1.6201393008232121  accuracy:64.70556386599326\n",
      "Epoch133  loss:1.6201281726360321  accuracy:64.17039358422382\n",
      "Epoch134  loss:1.6063104748725892  accuracy:64.12522839274665\n",
      "Epoch135  loss:1.6052232861518858  accuracy:64.51036534375349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch136  loss:1.6023478090763088  accuracy:65.38430488390881\n",
      "Epoch137  loss:1.5715823829174043  accuracy:65.53544983605961\n",
      "Epoch138  loss:1.5697800159454347  accuracy:65.45749073291398\n",
      "Epoch139  loss:1.5511331617832185  accuracy:65.98384003994363\n",
      "Epoch140  loss:1.5640383660793302  accuracy:65.22441582606969\n",
      "Epoch141  loss:1.5545913696289062  accuracy:65.87604541976948\n",
      "Epoch142  loss:1.5384962260723116  accuracy:66.5584941424252\n",
      "Epoch143  loss:1.5340894401073457  accuracy:66.13075896180399\n",
      "Epoch144  loss:1.5218837797641753  accuracy:66.95257281692668\n",
      "Epoch145  loss:1.5166381537914277  accuracy:66.2580762079841\n",
      "Epoch146  loss:1.5122770130634307  accuracy:66.85086575761278\n",
      "Epoch147  loss:1.4982816427946088  accuracy:66.10176594143906\n",
      "Epoch148  loss:1.4990354388952256  accuracy:66.70898004718676\n",
      "Epoch149  loss:1.4929478436708452  accuracy:66.4080315466061\n",
      "Epoch150  loss:1.4810477912425992  accuracy:66.99560672607694\n",
      "Epoch151  loss:1.4641760379076005  accuracy:66.60272328158032\n",
      "Epoch152  loss:1.4780787914991378  accuracy:66.91521220460346\n",
      "Epoch153  loss:1.4542723864316938  accuracy:67.367132837461\n",
      "Epoch154  loss:1.4366501569747927  accuracy:68.22539464322169\n",
      "Epoch155  loss:1.4444341421127318  accuracy:67.60077796078423\n",
      "Epoch156  loss:1.451901304721832  accuracy:66.74712119287437\n",
      "Epoch157  loss:1.4390695154666904  accuracy:66.5879386522598\n",
      "Epoch158  loss:1.419921970367432  accuracy:67.5748413781523\n",
      "Epoch159  loss:1.4194906920194625  accuracy:68.18257118136162\n",
      "Epoch160  loss:1.4208295315504074  accuracy:68.32511223777281\n",
      "Epoch161  loss:1.409277582168579  accuracy:67.69372452800113\n",
      "Epoch162  loss:1.4034330427646635  accuracy:68.23666262602484\n",
      "Epoch163  loss:1.3969386070966723  accuracy:67.64175820554726\n",
      "Epoch164  loss:1.394660359621048  accuracy:67.51056041136968\n",
      "Epoch165  loss:1.3801883339881897  accuracy:68.65970041459185\n",
      "Epoch166  loss:1.3705845087766646  accuracy:68.48505987880901\n",
      "Epoch167  loss:1.3698588162660597  accuracy:68.24698207361621\n",
      "Epoch168  loss:1.3654981762170793  accuracy:68.9845244025296\n",
      "Epoch169  loss:1.365525096654892  accuracy:68.50040174969372\n",
      "Epoch170  loss:1.3565947651863097  accuracy:68.76986132656276\n",
      "Epoch171  loss:1.364467671513557  accuracy:68.46237655964451\n",
      "Epoch172  loss:1.351807752251625  accuracy:69.1705914205663\n",
      "Epoch173  loss:1.3348280280828475  accuracy:68.86511708097837\n",
      "Epoch174  loss:1.3402489960193633  accuracy:69.12787663681011\n",
      "Epoch175  loss:1.3231060922145848  accuracy:68.95898086804036\n",
      "Epoch176  loss:1.3321112513542175  accuracy:69.11293402689981\n",
      "Epoch177  loss:1.3256647229194642  accuracy:69.30318640517596\n",
      "Epoch178  loss:1.3113436579704283  accuracy:69.47159153049265\n",
      "Epoch179  loss:1.3211818605661392  accuracy:68.57231561669607\n",
      "Epoch180  loss:1.30814608335495  accuracy:69.79473834513321\n",
      "Epoch181  loss:1.2940790981054306  accuracy:69.4539671341414\n",
      "Epoch182  loss:1.297787380218506  accuracy:69.13631492704847\n",
      "Epoch183  loss:1.305911546945572  accuracy:69.47146730366572\n",
      "Epoch184  loss:1.292686140537262  accuracy:69.81873774177886\n",
      "Epoch185  loss:1.2834375977516175  accuracy:70.54292343473927\n",
      "Epoch186  loss:1.2823672860860826  accuracy:69.8227525463458\n",
      "Epoch187  loss:1.2818368881940843  accuracy:69.69982337527951\n",
      "Epoch188  loss:1.265886527299881  accuracy:69.59267146784052\n",
      "Epoch189  loss:1.2471508502960205  accuracy:69.96509979257064\n",
      "Epoch190  loss:1.2726725161075592  accuracy:69.65311575119274\n",
      "Epoch191  loss:1.2589779227972033  accuracy:69.86051510689376\n",
      "Epoch192  loss:1.257679983973503  accuracy:70.8137164492325\n",
      "Epoch193  loss:1.2503910303115844  accuracy:70.23706156794404\n",
      "Epoch194  loss:1.238123172521591  accuracy:70.49002959242897\n",
      "Epoch195  loss:1.2313914209604264  accuracy:69.86374691256592\n",
      "Epoch196  loss:1.2372163593769072  accuracy:70.40132034286117\n",
      "Epoch197  loss:1.2311729937791824  accuracy:70.48945365089673\n",
      "Epoch198  loss:1.2349811613559722  accuracy:70.1881143573181\n",
      "Epoch199  loss:1.2200664758682254  accuracy:71.20356621797173\n",
      "Epoch200  loss:1.2207193851470948  accuracy:70.1615674788446\n",
      "Epoch201  loss:1.219564461708069  accuracy:70.36544612735403\n",
      "Epoch202  loss:1.2179982095956803  accuracy:70.3895160109107\n",
      "Epoch203  loss:1.2066291123628619  accuracy:70.25232978158546\n",
      "Epoch204  loss:1.198994114995003  accuracy:70.72556390302182\n",
      "Epoch205  loss:1.2024981081485748  accuracy:70.88883347266089\n",
      "Epoch206  loss:1.1845648527145385  accuracy:71.2529870364309\n",
      "Epoch207  loss:1.2013632208108904  accuracy:70.6083487598742\n",
      "Epoch208  loss:1.191617476940155  accuracy:71.05199773442655\n",
      "Epoch209  loss:1.1789291560649875  accuracy:71.67754867500713\n",
      "Epoch210  loss:1.1910440772771835  accuracy:70.80792181759438\n",
      "Epoch211  loss:1.1930840373039246  accuracy:70.59676047309173\n",
      "Epoch212  loss:1.1713800102472305  accuracy:71.52252080132416\n",
      "Epoch213  loss:1.1784547924995423  accuracy:70.683277705941\n",
      "Epoch214  loss:1.1790465801954266  accuracy:70.65386599628738\n",
      "Epoch215  loss:1.161128497123718  accuracy:71.80518733571289\n",
      "Epoch216  loss:1.1729352295398712  accuracy:70.55162283659243\n",
      "Epoch217  loss:1.156061628460884  accuracy:70.94913272105919\n",
      "Epoch218  loss:1.1561580508947373  accuracy:71.56050799404953\n",
      "Epoch219  loss:1.1514082372188568  accuracy:71.63737449065486\n",
      "Epoch220  loss:1.1554677695035935  accuracy:71.53642246607829\n",
      "Epoch221  loss:1.1539319574832916  accuracy:70.82187874106747\n",
      "Epoch222  loss:1.1480637550354005  accuracy:71.39093758518324\n",
      "Epoch223  loss:1.140526655316353  accuracy:72.00739396628016\n",
      "Epoch224  loss:1.145745199918747  accuracy:71.67400961994048\n",
      "Epoch225  loss:1.1446333557367323  accuracy:71.4802623656428\n",
      "Epoch226  loss:1.1439861685037611  accuracy:72.1433674292966\n",
      "Epoch227  loss:1.1384489268064502  accuracy:70.98902566317878\n",
      "Epoch228  loss:1.1374115645885465  accuracy:70.89716584694676\n",
      "Epoch229  loss:1.138582193851471  accuracy:70.94408981358225\n",
      "Epoch230  loss:1.1296031028032303  accuracy:72.17681963074473\n",
      "Epoch231  loss:1.1181608974933623  accuracy:72.24040041133837\n",
      "Epoch232  loss:1.1357592642307284  accuracy:71.50479460018914\n",
      "Epoch233  loss:1.1352421641349795  accuracy:71.72976496935367\n",
      "Epoch234  loss:1.1172815918922423  accuracy:71.90543958845596\n",
      "Epoch235  loss:1.1131794810295104  accuracy:72.16437174382392\n",
      "Epoch236  loss:1.1210023254156114  accuracy:72.57307544226076\n",
      "Epoch237  loss:1.1211318492889404  accuracy:71.9017051810804\n",
      "Epoch238  loss:1.1109435349702836  accuracy:71.90187935125941\n",
      "Epoch239  loss:1.1091832935810086  accuracy:72.5946521176751\n",
      "Epoch240  loss:1.1078763097524644  accuracy:71.24382444378428\n",
      "Epoch241  loss:1.0888412058353425  accuracy:72.57016243448834\n",
      "Epoch242  loss:1.1027013719081877  accuracy:71.93487638588523\n",
      "Epoch243  loss:1.0962698340415955  accuracy:72.27486011071919\n",
      "Epoch244  loss:1.0863391667604445  accuracy:72.45093575181643\n",
      "Epoch245  loss:1.0911127775907516  accuracy:72.73423588744757\n",
      "Epoch246  loss:1.0846623599529268  accuracy:71.99200959996574\n",
      "Epoch247  loss:1.081783875823021  accuracy:72.28170856656024\n",
      "Epoch248  loss:1.0686895638704301  accuracy:72.68802972632172\n",
      "Epoch249  loss:1.091360184550285  accuracy:73.10838239001598\n",
      "Epoch250  loss:1.0780839413404464  accuracy:72.83471481054204\n",
      "Epoch251  loss:1.0857126384973526  accuracy:72.5750613033481\n",
      "Epoch252  loss:1.0695043951272964  accuracy:72.69185305145395\n",
      "Epoch253  loss:1.0689463675022126  accuracy:72.5024786824435\n",
      "Epoch254  loss:1.0808052211999895  accuracy:72.77062582221112\n",
      "Epoch255  loss:1.0737179905176162  accuracy:72.49276233542047\n",
      "Epoch256  loss:1.062252587080002  accuracy:73.1994501985001\n",
      "Epoch257  loss:1.0725858002901079  accuracy:73.08003122251819\n",
      "Epoch258  loss:1.0702742189168932  accuracy:72.65674596220106\n",
      "Epoch259  loss:1.0724626600742342  accuracy:72.90414829016542\n",
      "Epoch260  loss:1.0550797671079635  accuracy:73.06878912742748\n",
      "Epoch261  loss:1.0550423353910445  accuracy:73.25060363876659\n",
      "Epoch262  loss:1.0542375117540361  accuracy:72.43749213723066\n",
      "Epoch263  loss:1.0485930025577543  accuracy:73.31538853738121\n",
      "Epoch264  loss:1.0596333891153336  accuracy:73.00252371979006\n",
      "Epoch265  loss:1.054713687300682  accuracy:73.0780206800748\n",
      "Epoch266  loss:1.0560353219509124  accuracy:72.56170936477011\n",
      "Epoch267  loss:1.0483545750379561  accuracy:73.57643093701574\n",
      "Epoch268  loss:1.0556374579668044  accuracy:72.91222939981297\n",
      "Epoch269  loss:1.0567938923835756  accuracy:72.97733733855094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch270  loss:1.0425945550203322  accuracy:72.94632295012633\n",
      "Epoch271  loss:1.0378105103969575  accuracy:73.6001781441965\n",
      "Epoch272  loss:1.0431677758693696  accuracy:73.09865952472742\n",
      "Epoch273  loss:1.036410677433014  accuracy:73.04876748039918\n",
      "Epoch274  loss:1.0345722913742066  accuracy:73.42126902646308\n",
      "Epoch275  loss:1.0239732652902602  accuracy:73.67227828868346\n",
      "Epoch276  loss:1.0353278309106824  accuracy:73.63252034083546\n",
      "Epoch277  loss:1.0284751236438752  accuracy:73.70030022478291\n",
      "Epoch278  loss:1.0389308035373688  accuracy:73.49830877431584\n",
      "Epoch279  loss:1.0252762943506242  accuracy:73.55235940304371\n",
      "Epoch280  loss:1.02361426949501  accuracy:73.48355479081404\n",
      "Epoch281  loss:1.0319464772939682  accuracy:73.79734426810636\n",
      "Epoch282  loss:1.0223186641931536  accuracy:74.25082522878361\n",
      "Epoch283  loss:1.0156314611434938  accuracy:73.0377664237617\n",
      "Epoch284  loss:1.0306550920009612  accuracy:73.21862960984728\n",
      "Epoch285  loss:1.0245941072702407  accuracy:73.58752688770254\n",
      "Epoch286  loss:1.0302741914987563  accuracy:73.2130475796715\n",
      "Epoch287  loss:1.0212375432252885  accuracy:73.19333247933098\n",
      "Epoch288  loss:1.0035143554210662  accuracy:73.89420341621884\n",
      "Epoch289  loss:1.0199934184551238  accuracy:74.03326742425597\n",
      "Epoch290  loss:1.0189757257699965  accuracy:73.65571331003068\n",
      "Epoch291  loss:1.0132558017969133  accuracy:72.80769821202995\n",
      "Epoch292  loss:0.9963964521884918  accuracy:74.33225977077404\n",
      "Epoch293  loss:1.0020983666181564  accuracy:74.01493136834145\n",
      "Epoch294  loss:1.0062360763549805  accuracy:73.73798016355641\n",
      "Epoch295  loss:1.0106375515460968  accuracy:73.62077555946138\n",
      "Epoch296  loss:1.0040925830602645  accuracy:74.67513022760976\n",
      "Epoch297  loss:1.0036745876073838  accuracy:74.1260785455232\n",
      "Epoch298  loss:0.9897668659687043  accuracy:74.80007678016408\n",
      "Epoch299  loss:1.0029062688350678  accuracy:73.76235796608232\n",
      "Epoch300  loss:1.0025305032730103  accuracy:74.45246677298812\n"
     ]
    }
   ],
   "source": [
    "server = Server()\n",
    "workers = server.create_worker(federated_trainset,federated_valset,federated_testset)\n",
    "acc_train = []\n",
    "loss_train = []\n",
    "acc_valid = []\n",
    "loss_valid = []\n",
    "\n",
    "early_stopping = Early_Stopping(args.partience)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(args.global_epochs):\n",
    "  sample_worker = server.sample_worker(workers)\n",
    "  server.send_models(sample_worker)\n",
    "\n",
    "  acc_train_avg = 0.0\n",
    "  loss_train_avg = 0.0\n",
    "  acc_valid_avg = 0.0\n",
    "  loss_valid_avg = 0.0\n",
    "  for worker in sample_worker:\n",
    "    worker.clustering(worker.models)\n",
    "    acc_train_tmp,loss_train_tmp,acc_valid_tmp,loss_valid_tmp = worker.local_train()\n",
    "    acc_train_avg += acc_train_tmp/len(sample_worker)\n",
    "    loss_train_avg += loss_train_tmp/len(sample_worker)\n",
    "    acc_valid_avg += acc_valid_tmp/len(sample_worker)\n",
    "    loss_valid_avg += loss_valid_tmp/len(sample_worker)\n",
    "  server.aggregate_models(sample_worker)\n",
    "  '''\n",
    "  for i in range(args.cluster_num):\n",
    "    server.models[i].to(args.device)\n",
    "  for worker in workers:\n",
    "    worker.clustering(server.models)\n",
    "    acc_valid_tmp,loss_valid_tmp = test(server.models[worker.cluster],args.criterion,worker.valloader)\n",
    "    acc_valid_avg += acc_valid_tmp/len(workers)\n",
    "    loss_valid_avg += loss_valid_tmp/len(workers)\n",
    "  for i in range(args.cluster_num):\n",
    "    server.models[i].to('cpu')\n",
    "  '''\n",
    "  print('Epoch{}  loss:{}  accuracy:{}'.format(epoch+1,loss_valid_avg,acc_valid_avg))\n",
    "  acc_train.append(acc_train_avg)\n",
    "  loss_train.append(loss_train_avg)\n",
    "  acc_valid.append(acc_valid_avg)\n",
    "  loss_valid.append(loss_valid_avg)\n",
    "\n",
    "  if early_stopping.validate(loss_valid_avg):\n",
    "    print('Early Stop')\n",
    "    break\n",
    "    \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "mi_uceyoptLP",
    "outputId": "bc067e09-01bc-4e65-daf9-ac2f42373cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:64.70588235294117  loss:1.3955684900283813\n",
      "Worker2 accuracy:85.71428571428571  loss:0.4342481195926666\n",
      "Worker3 accuracy:77.5  loss:0.8516443371772766\n",
      "Worker4 accuracy:66.66666666666667  loss:1.7213053703308105\n",
      "Worker5 accuracy:82.3529411764706  loss:0.5433621406555176\n",
      "Worker6 accuracy:76.19047619047619  loss:0.6007764339447021\n",
      "Worker7 accuracy:68.42105263157895  loss:0.9520846009254456\n",
      "Worker8 accuracy:81.25  loss:0.60696941614151\n",
      "Worker9 accuracy:57.89473684210526  loss:2.0450634956359863\n",
      "Worker10 accuracy:82.92682926829268  loss:0.5586618781089783\n",
      "Worker11 accuracy:72.22222222222223  loss:1.538760781288147\n",
      "Worker12 accuracy:68.42105263157895  loss:1.3560235500335693\n",
      "Worker13 accuracy:73.6842105263158  loss:1.2801992893218994\n",
      "Worker14 accuracy:56.666666666666664  loss:1.9344562292099\n",
      "Worker15 accuracy:78.94736842105263  loss:0.9946979880332947\n",
      "Worker16 accuracy:88.23529411764706  loss:0.691483736038208\n",
      "Worker17 accuracy:66.66666666666667  loss:1.4780722856521606\n",
      "Worker18 accuracy:77.41935483870968  loss:0.6984713673591614\n",
      "Worker19 accuracy:85.29411764705883  loss:0.8405219912528992\n",
      "Worker20 accuracy:55.55555555555556  loss:1.280927300453186\n",
      "Test  loss:1.090164940059185  accuracy:73.33676900681458\n"
     ]
    }
   ],
   "source": [
    "acc_test = []\n",
    "loss_test = []\n",
    "\n",
    "for i in range(args.cluster_num):\n",
    "  server.models[i].to(args.device)\n",
    "\n",
    "nums = 0\n",
    "for worker in workers:\n",
    "  nums += worker.test_data_num\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "  worker.aggregation_weight = 1.0*worker.test_data_num/nums\n",
    "  worker.clustering(server.models)\n",
    "  acc_tmp,loss_tmp = test(server.models[worker.cluster],args.criterion,worker.testloader)\n",
    "  acc_test.append(acc_tmp)\n",
    "  loss_test.append(loss_tmp)\n",
    "  print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "acc_test_avg = sum(acc_test)/len(acc_test)\n",
    "loss_test_avg = sum(loss_test)/len(loss_test)\n",
    "print('Test  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 Valid accuracy:74.4186046511628  loss:0.6290313601493835\n",
      "Worker1 Test accuracy:82.3529411764706  loss:1.0059294700622559\n",
      "Worker2 Valid accuracy:81.91489361702128  loss:0.6034848690032959\n",
      "Worker2 Test accuracy:88.57142857142857  loss:0.3817615509033203\n",
      "Worker3 Valid accuracy:68.57142857142857  loss:0.9337775111198425\n",
      "Worker3 Test accuracy:80.0  loss:0.741433322429657\n",
      "Worker4 Valid accuracy:69.56521739130434  loss:1.4920322895050049\n",
      "Worker4 Test accuracy:66.66666666666667  loss:1.7271791696548462\n",
      "Worker5 Valid accuracy:81.31868131868131  loss:0.6119040250778198\n",
      "Worker5 Test accuracy:85.29411764705883  loss:0.4559059739112854\n",
      "Worker6 Valid accuracy:70.9090909090909  loss:0.9951586723327637\n",
      "Worker6 Test accuracy:71.42857142857143  loss:0.7637213468551636\n",
      "Worker7 Valid accuracy:80.0  loss:0.7972589731216431\n",
      "Worker7 Test accuracy:73.6842105263158  loss:0.967278003692627\n",
      "Worker8 Valid accuracy:72.94117647058823  loss:0.9024269580841064\n",
      "Worker8 Test accuracy:81.25  loss:0.6584511995315552\n",
      "Worker9 Valid accuracy:69.38775510204081  loss:1.2604296207427979\n",
      "Worker9 Test accuracy:57.89473684210526  loss:2.0274553298950195\n",
      "Worker10 Valid accuracy:82.56880733944953  loss:0.5848775506019592\n",
      "Worker10 Test accuracy:87.8048780487805  loss:0.48659563064575195\n",
      "Worker11 Valid accuracy:58.69565217391305  loss:2.479853630065918\n",
      "Worker11 Test accuracy:66.66666666666667  loss:1.4330072402954102\n",
      "Worker12 Valid accuracy:81.63265306122449  loss:0.7766880393028259\n",
      "Worker12 Test accuracy:68.42105263157895  loss:1.3909687995910645\n",
      "Worker13 Valid accuracy:69.38775510204081  loss:1.337345004081726\n",
      "Worker13 Test accuracy:73.6842105263158  loss:1.2288751602172852\n",
      "Worker14 Valid accuracy:79.48717948717949  loss:1.121355652809143\n",
      "Worker14 Test accuracy:60.0  loss:2.1682374477386475\n",
      "Worker15 Valid accuracy:67.34693877551021  loss:1.0955593585968018\n",
      "Worker15 Test accuracy:73.6842105263158  loss:1.0283035039901733\n",
      "Worker16 Valid accuracy:77.77777777777777  loss:0.8490505814552307\n",
      "Worker16 Test accuracy:88.23529411764706  loss:0.710038423538208\n",
      "Worker17 Valid accuracy:75.0  loss:0.793351411819458\n",
      "Worker17 Test accuracy:63.63636363636363  loss:1.4773832559585571\n",
      "Worker18 Valid accuracy:74.39024390243902  loss:1.1838135719299316\n",
      "Worker18 Test accuracy:77.41935483870968  loss:0.6322446465492249\n",
      "Worker19 Valid accuracy:78.88888888888889  loss:0.7192753553390503\n",
      "Worker19 Test accuracy:76.47058823529412  loss:0.66655033826828\n",
      "Worker20 Valid accuracy:62.22222222222222  loss:1.2669256925582886\n",
      "Worker20 Test accuracy:72.22222222222223  loss:1.1249605417251587\n",
      "Validation(tune)  loss:1.0216800063848495  accuracy:73.82124833809819\n",
      "Test(tune)  loss:1.0538140177726745  accuracy:74.7693757154256\n"
     ]
    }
   ],
   "source": [
    "acc_tune_test = []\n",
    "loss_tune_test = []\n",
    "acc_tune_valid = []\n",
    "loss_tune_valid = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "    worker.models = copy.deepcopy(server.models)\n",
    "    worker.models[worker.cluster] = worker.models[worker.cluster].to(args.device)\n",
    "    _,_,acc_tmp,loss_tmp = worker.local_train()\n",
    "    acc_tune_valid.append(acc_tmp)\n",
    "    loss_tune_valid.append(loss_tmp)\n",
    "    print('Worker{} Valid accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    \n",
    "    acc_tmp,loss_tmp = test(worker.models[worker.cluster],args.criterion,worker.testloader)\n",
    "    acc_tune_test.append(acc_tmp)\n",
    "    loss_tune_test.append(loss_tmp)\n",
    "    print('Worker{} Test accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    for i in range(args.cluster_num):\n",
    "        worker.models[i] = worker.models[i].to('cpu')\n",
    "    del worker.models\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "acc_valid_avg = sum(acc_tune_valid)/len(acc_tune_valid)\n",
    "loss_valid_avg = sum(loss_tune_valid)/len(loss_tune_valid)\n",
    "print('Validation(tune)  loss:{}  accuracy:{}'.format(loss_valid_avg,acc_valid_avg))\n",
    "acc_test_avg = sum(acc_tune_test)/len(acc_tune_test)\n",
    "loss_test_avg = sum(loss_tune_test)/len(loss_tune_test)\n",
    "print('Test(tune)  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 6]\n"
     ]
    }
   ],
   "source": [
    "cluster = [0]*args.cluster_num\n",
    "for worker in workers:\n",
    "  cluster[worker.cluster] += 1\n",
    "\n",
    "print(cluster)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FedAvg_femnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
