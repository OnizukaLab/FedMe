{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "vkZxat4Y-IsQ",
    "outputId": "da86392c-66e8-4b60-b471-086e745cdcbc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from torch import nn, optim\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O0TfzOhU-QlG"
   },
   "outputs": [],
   "source": [
    "class Argments():\n",
    "  def __init__(self):\n",
    "    self.batch_size = 20\n",
    "    self.test_batch = 1000\n",
    "    self.global_epochs = 300\n",
    "    self.local_epochs = 2\n",
    "    self.lr = None\n",
    "    self.momentum = 0.9\n",
    "    self.weight_decay = 10**-4.0\n",
    "    self.clip = 20.0\n",
    "    self.partience = 300\n",
    "    self.worker_num = 20\n",
    "    self.sample_num = 20\n",
    "    self.device = device = torch.device('cuda:0'if torch.cuda.is_available() else'cpu')\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "args = Argments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned value\n",
    "lr = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(10**-3.0)\n",
    "lr_list.append(10**-2.5)\n",
    "lr_list.append(10**-2.0)\n",
    "lr_list.append(10**-1.5)\n",
    "lr_list.append(10**-1.0)\n",
    "lr_list.append(10**-0.5)\n",
    "lr_list.append(10**0.0)\n",
    "lr_list.append(10**0.5)\n",
    "\n",
    "args.lr = lr_list[lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r5PuCcqmJNUQ"
   },
   "outputs": [],
   "source": [
    "class LocalDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,dataset,worker_id):\n",
    "    self.data = []\n",
    "    self.target = []\n",
    "    self.id = worker_id\n",
    "    for data in dataset.take(len(dataset)):\n",
    "      self.data.append(torch.tensor([data['pixels'].numpy()]))\n",
    "      self.target.append(torch.tensor(data['label'].numpy().astype(np.int64)))\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.data[index],self.target[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/federated_trainset_femnist.pickle', 'rb') as f:\n",
    "    all_federated_trainset = pickle.load(f)\n",
    "with open('../data/federated_testset_femnist.pickle', 'rb') as f:\n",
    "    all_federated_testset = pickle.load(f)\n",
    "all_worker_num = len(all_federated_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2619, 456, 102, 3037, 1126, 1003, 914, 571, 3016, 419, 2771, 3033, 2233, 356, 2418, 1728, 130, 122, 383, 895]\n"
     ]
    }
   ],
   "source": [
    "worker_id_list = random.sample(range(all_worker_num),args.worker_num)\n",
    "print(worker_id_list)\n",
    "federated_trainset = []\n",
    "federated_testset = []\n",
    "for i in worker_id_list:\n",
    "    federated_trainset.append(all_federated_trainset[i])\n",
    "    federated_testset.append(all_federated_testset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_valset = [None]*args.worker_num\n",
    "for i in range(args.worker_num):\n",
    "  n_samples = len(federated_trainset[i])\n",
    "  if n_samples==1:\n",
    "    federated_valset[i] = copy.deepcopy(federated_trainset[i])\n",
    "  else:\n",
    "    train_size = int(len(federated_trainset[i]) * 0.7) \n",
    "    val_size = n_samples - train_size \n",
    "    federated_trainset[i],federated_valset[i] = torch.utils.data.random_split(federated_trainset[i], [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZU3vAAb9-6SD"
   },
   "outputs": [],
   "source": [
    "class CNN1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(5408, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "class CNN2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(9216, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "class CNN3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(15488, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "    \n",
    "class CNN4(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN4, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv2d_4 = torch.nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(25600, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = self.conv2d_4(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Yu90X1TWJVKJ"
   },
   "outputs": [],
   "source": [
    "class Server():\n",
    "  def __init__(self):\n",
    "    self.global_model = CNN2()\n",
    " \n",
    "\n",
    "  def create_worker(self,federated_trainset,federated_valset,federated_testset):\n",
    "    workers = []\n",
    "    for i in range(args.worker_num):\n",
    "      workers.append(Worker(federated_trainset[i],federated_valset[i],federated_testset[i]))\n",
    "    return workers\n",
    "\n",
    "  def sample_worker(self,workers):\n",
    "    sample_worker = []\n",
    "    sample_num = random.sample(range(args.worker_num),args.sample_num)\n",
    "    for i in sample_num:\n",
    "      sample_worker.append(workers[i])\n",
    "    return sample_worker\n",
    "\n",
    "\n",
    "  def send_model(self,workers):\n",
    "    nums = 0\n",
    "    for worker in workers:\n",
    "      nums += worker.train_data_num\n",
    "\n",
    "    for worker in workers:\n",
    "      worker.aggregation_weight = 1.0*worker.train_data_num/nums\n",
    "      worker.global_model = copy.deepcopy(self.global_model)\n",
    "\n",
    "\n",
    "  def aggregate_model(self,workers):   \n",
    "    new_params = OrderedDict()\n",
    "    for i,worker in enumerate(workers):\n",
    "      worker_state = worker.global_model.state_dict()\n",
    "      for key in worker_state.keys():\n",
    "        if i==0:\n",
    "          new_params[key] = worker_state[key]*worker.aggregation_weight\n",
    "        else:\n",
    "          new_params[key] += worker_state[key]*worker.aggregation_weight\n",
    "      del worker.global_model \n",
    "    self.global_model.load_state_dict(new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LDWEBjgfJYFc"
   },
   "outputs": [],
   "source": [
    "class Worker():\n",
    "  def __init__(self,trainset,valset,testset):\n",
    "    self.train_data_num = len(trainset)\n",
    "    self.test_data_num = len(testset)\n",
    "    if len(trainset)<=2 :\n",
    "      trainset = [trainset,copy.deepcopy(trainset),copy.deepcopy(trainset)]\n",
    "    else:\n",
    "      split_len = [(len(trainset) + i) // 3 for i in range(3)]\n",
    "      trainset = torch.utils.data.random_split(trainset,split_len)\n",
    "    self.trainloader_local = torch.utils.data.DataLoader(trainset[0],batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.trainloader_lambda = torch.utils.data.DataLoader(trainset[1],batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.trainloader_global = torch.utils.data.DataLoader(trainset[2],batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.valloader = torch.utils.data.DataLoader(valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.testloader = torch.utils.data.DataLoader(testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.global_model = None\n",
    "    self.local_model = CNN2()\n",
    "    self.mix_model = None\n",
    "    self.lmd = None\n",
    "    self.aggregation_weight = None\n",
    "\n",
    "\n",
    "  def local_train(self):\n",
    "    loss = float('inf')\n",
    "    self.mix_model = CNN2()\n",
    "    model_tmp = CNN2()\n",
    "    for lmd in np.arange(0.0,1.1,0.1):\n",
    "      new_params = OrderedDict()\n",
    "      global_state = self.global_model.state_dict()\n",
    "      local_state = self.local_model.state_dict()\n",
    "      for key in global_state.keys():\n",
    "        new_params[key] = lmd*local_state[key] + (1.0-lmd)*global_state[key]     \n",
    "      model_tmp.load_state_dict(new_params)\n",
    "      model_tmp = model_tmp.to(args.device)\n",
    "      if lmd!=0.0:\n",
    "        _,_ = train(model_tmp,args.criterion,self.trainloader_local,args.local_epochs)\n",
    "\n",
    "      _,tmp = test(model_tmp,args.criterion,self.trainloader_lambda)\n",
    "      if tmp<loss:\n",
    "        loss = tmp\n",
    "        self.lmd = lmd\n",
    "        self.mix_model = copy.deepcopy(model_tmp)\n",
    "\n",
    "    if self.lmd!=0.0:\n",
    "      self.mix_model = self.mix_model.to('cpu')\n",
    "      new_params = OrderedDict()\n",
    "      mix_state = self.mix_model.state_dict()\n",
    "      global_state = self.global_model.state_dict()\n",
    "      for key in global_state.keys():\n",
    "        new_params[key] = (mix_state[key] - (1.0-self.lmd)*global_state[key])/self.lmd    \n",
    "      self.local_model.load_state_dict(new_params)\n",
    "      self.mix_model = self.mix_model.to(args.device)\n",
    "    \n",
    "    model_tmp = model_tmp.to('cpu')\n",
    "    del model_tmp\n",
    "\n",
    "\n",
    "  def global_train(self):\n",
    "    model_tmp = copy.deepcopy(self.mix_model)\n",
    "    model_tmp = model_tmp.to('cpu')\n",
    "    acc_train,loss_train = train(self.mix_model,args.criterion,self.trainloader_global,args.local_epochs)\n",
    "    acc_valid,loss_valid = test(self.mix_model,args.criterion,self.valloader)\n",
    "    self.mix_model = self.mix_model.to('cpu')\n",
    "    new_params = OrderedDict()\n",
    "    new_state = self.mix_model.state_dict()\n",
    "    old_state = model_tmp.state_dict()\n",
    "    global_state = self.global_model.state_dict()\n",
    "    for key in new_state.keys():\n",
    "        new_params[key] = global_state[key]+new_state[key]-old_state[key]  \n",
    "    self.global_model.load_state_dict(new_params)\n",
    "    del self.mix_model\n",
    "    del model_tmp\n",
    "    return acc_train,loss_train,acc_valid,loss_valid\n",
    "\n",
    "\n",
    "  def test_step(self):\n",
    "    self.local_train()\n",
    "    mix_model = CNN2()\n",
    "    new_params = OrderedDict()\n",
    "    global_state = self.global_model.state_dict()\n",
    "    local_state = self.local_model.state_dict()\n",
    "    for key in global_state.keys():\n",
    "      new_params[key] = self.lmd*local_state[key] + (1.0-self.lmd)*global_state[key]     \n",
    "    mix_model.load_state_dict(new_params)\n",
    "    mix_model = mix_model.to(args.device)\n",
    "    acc,loss = test(mix_model,args.criterion,self.testloader)\n",
    "    return acc,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7-GY66gROuEU"
   },
   "outputs": [],
   "source": [
    "def train(model,criterion,trainloader,epochs):\n",
    "  optimizer = optim.SGD(model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "  model.train()\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for (data,labels) in trainloader:\n",
    "      data,labels = Variable(data),Variable(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      count += len(labels)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "      optimizer.step()\n",
    "\n",
    "  return 100.0*correct/count,running_loss/len(trainloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "oA4URv9mQ3xV"
   },
   "outputs": [],
   "source": [
    "def test(model,criterion,testloader):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  count = 0\n",
    "  for (data,labels) in testloader:\n",
    "    data,labels = data.to(args.device),labels.to(args.device)\n",
    "    outputs = model(data)\n",
    "    running_loss += criterion(outputs,labels).item()\n",
    "    predicted = torch.argmax(outputs,dim=1)\n",
    "    correct += (predicted==labels).sum().item()\n",
    "    count += len(labels)\n",
    "\n",
    "  accuracy = 100.0*correct/count\n",
    "  loss = running_loss/len(testloader)\n",
    "\n",
    "\n",
    "  return accuracy,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WMO7_WSLHeGl"
   },
   "outputs": [],
   "source": [
    "class Early_Stopping():\n",
    "  def __init__(self,partience):\n",
    "    self.step = 0\n",
    "    self.loss = float('inf')\n",
    "    self.partience = partience\n",
    "\n",
    "  def validate(self,loss):\n",
    "    if self.loss<loss:\n",
    "      self.step += 1\n",
    "      if self.step>self.partience:\n",
    "        return True\n",
    "    else:\n",
    "      self.step = 0\n",
    "      self.loss = loss\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "-noG_98IR-nZ",
    "outputId": "78a6ebe2-854a-4f83-dc45-5c4ac35b69e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1  loss:4.059211182594299  accuracy:5.549832671338785\n",
      "Epoch2  loss:4.027985322475433  accuracy:6.0927671324820265\n",
      "Epoch3  loss:4.007205903530121  accuracy:5.4057809920075135\n",
      "Epoch4  loss:3.974003493785859  accuracy:6.106197055868956\n",
      "Epoch5  loss:3.961781740188598  accuracy:5.800641500313399\n",
      "Epoch6  loss:3.9369140028953558  accuracy:5.83031246491142\n",
      "Epoch7  loss:3.913912427425385  accuracy:6.123063749845623\n",
      "Epoch8  loss:3.9010895013809206  accuracy:5.992762462717568\n",
      "Epoch9  loss:3.8925145268440247  accuracy:5.707121149029074\n",
      "Epoch10  loss:3.8845389723777766  accuracy:5.476773718681644\n",
      "Epoch11  loss:3.881003987789154  accuracy:5.9444171863251105\n",
      "Epoch12  loss:3.859368467330934  accuracy:6.380576265341333\n",
      "Epoch13  loss:3.8683642983436584  accuracy:5.429677957300168\n",
      "Epoch14  loss:3.854019463062286  accuracy:6.015556280260558\n",
      "Epoch15  loss:3.856330084800721  accuracy:6.53281937107281\n",
      "Epoch16  loss:3.846015954017639  accuracy:6.2701296798116894\n",
      "Epoch17  loss:3.8370972990989682  accuracy:6.872641785646055\n",
      "Epoch18  loss:3.849799478054047  accuracy:7.318674698212542\n",
      "Epoch19  loss:3.8377162933349607  accuracy:6.4434008530828635\n",
      "Epoch20  loss:3.8356778740882875  accuracy:7.060878362339549\n",
      "Epoch21  loss:3.8218924045562748  accuracy:5.92180458376623\n",
      "Epoch22  loss:3.8232855916023247  accuracy:5.768179249289831\n",
      "Epoch23  loss:3.8210733056068413  accuracy:6.288851083915155\n",
      "Epoch24  loss:3.8287586092948915  accuracy:6.165572553659881\n",
      "Epoch25  loss:3.823388397693634  accuracy:6.641536559402671\n",
      "Epoch26  loss:3.8226508378982547  accuracy:5.8167353443575545\n",
      "Epoch27  loss:3.8116999745368947  accuracy:5.764558838692678\n",
      "Epoch28  loss:3.8109045028686523  accuracy:6.020969095102934\n",
      "Epoch29  loss:3.8184777617454526  accuracy:6.052450283202731\n",
      "Epoch30  loss:3.8135254025459293  accuracy:5.878635238483362\n",
      "Epoch31  loss:3.8018296241760257  accuracy:5.731449091297216\n",
      "Epoch32  loss:3.8094259738922114  accuracy:5.632324638514226\n",
      "Epoch33  loss:3.813327848911285  accuracy:5.549962382287569\n",
      "Epoch34  loss:3.801955878734588  accuracy:5.689324549172672\n",
      "Epoch35  loss:3.8040975689887997  accuracy:5.497016856864981\n",
      "Epoch36  loss:3.7922009348869326  accuracy:6.123473733321856\n",
      "Epoch37  loss:3.8014423608779904  accuracy:6.505236756734798\n",
      "Epoch38  loss:3.818132126331329  accuracy:4.987304347152472\n",
      "Epoch39  loss:3.8042687892913816  accuracy:6.081963656097495\n",
      "Epoch40  loss:3.795998191833496  accuracy:5.94831952245336\n",
      "Epoch41  loss:3.7902424693107606  accuracy:6.111878186012026\n",
      "Epoch42  loss:3.793375551700592  accuracy:5.651417078492092\n",
      "Epoch43  loss:3.781520998477936  accuracy:6.325108045583346\n",
      "Epoch44  loss:3.7874047756195064  accuracy:5.604526014374138\n",
      "Epoch45  loss:3.787134826183319  accuracy:5.051793884119072\n",
      "Epoch46  loss:3.7967341780662536  accuracy:5.943903303751428\n",
      "Epoch47  loss:3.7820579767227174  accuracy:5.438185444375031\n",
      "Epoch48  loss:3.782080864906311  accuracy:5.757589617437741\n",
      "Epoch49  loss:3.7756820201873778  accuracy:5.992806781226333\n",
      "Epoch50  loss:3.7844009876251214  accuracy:5.436054010187849\n",
      "Epoch51  loss:3.762011814117431  accuracy:6.157719558852086\n",
      "Epoch52  loss:3.762137162685394  accuracy:5.264278580648443\n",
      "Epoch53  loss:3.7756556749343875  accuracy:5.2754923496261865\n",
      "Epoch54  loss:3.7916350960731497  accuracy:5.515823447100142\n",
      "Epoch55  loss:3.7850694656372075  accuracy:5.512308328678191\n",
      "Epoch56  loss:3.7738479018211364  accuracy:5.489002243987146\n",
      "Epoch57  loss:3.7856679081916806  accuracy:5.402049732486091\n",
      "Epoch58  loss:3.7577001333236693  accuracy:5.2912519523423125\n",
      "Epoch59  loss:3.774869608879089  accuracy:5.8748517878914015\n",
      "Epoch60  loss:3.757413768768311  accuracy:5.566008596664173\n",
      "Epoch61  loss:3.7808703541755677  accuracy:6.478757338605463\n",
      "Epoch62  loss:3.781932556629181  accuracy:5.960975867042477\n",
      "Epoch63  loss:3.7598518610000617  accuracy:5.715750504170057\n",
      "Epoch64  loss:3.7903142690658567  accuracy:6.274714654121418\n",
      "Epoch65  loss:3.758331191539764  accuracy:5.758912830883904\n",
      "Epoch66  loss:3.7643127441406246  accuracy:5.289049506498958\n",
      "Epoch67  loss:3.7847989559173585  accuracy:7.1085085803406285\n",
      "Epoch68  loss:3.753490388393402  accuracy:6.306618433943761\n",
      "Epoch69  loss:3.7997112154960626  accuracy:6.593736078204263\n",
      "Epoch70  loss:3.762884426116944  accuracy:6.252071326205163\n",
      "Epoch71  loss:3.7934518456459045  accuracy:5.704412635689331\n",
      "Epoch72  loss:3.7554569244384766  accuracy:5.838153093137994\n",
      "Epoch73  loss:3.767142558097839  accuracy:5.78325835837557\n",
      "Epoch74  loss:3.7895048618316647  accuracy:5.8570362700758825\n",
      "Epoch75  loss:3.7654634594917296  accuracy:5.539788784730078\n",
      "Epoch76  loss:3.7508906960487365  accuracy:6.108268350469415\n",
      "Epoch77  loss:3.772949254512787  accuracy:5.999510994256324\n",
      "Epoch78  loss:3.78940360546112  accuracy:5.845978700194784\n",
      "Epoch79  loss:3.776761043071747  accuracy:5.880636176452754\n",
      "Epoch80  loss:3.8191683888435364  accuracy:6.533032116879183\n",
      "Epoch81  loss:3.8014693260192867  accuracy:6.465197890990247\n",
      "Epoch82  loss:3.8083891153335574  accuracy:5.889976986907177\n",
      "Epoch83  loss:3.804351484775543  accuracy:6.60763622736277\n",
      "Epoch84  loss:3.7838973402976985  accuracy:6.736014434768334\n",
      "Epoch85  loss:3.811579358577729  accuracy:6.413234040559368\n",
      "Epoch86  loss:3.8059823036193854  accuracy:6.682861238757994\n",
      "Epoch87  loss:3.7643417954444884  accuracy:7.568047481087095\n",
      "Epoch88  loss:3.8011480093002317  accuracy:6.9419024249091565\n",
      "Epoch89  loss:3.7738761901855464  accuracy:7.027048797231268\n",
      "Epoch90  loss:3.7703678250312804  accuracy:6.879946004958482\n",
      "Epoch91  loss:3.748322534561157  accuracy:7.490437672808872\n",
      "Epoch92  loss:3.7979227185249327  accuracy:7.34116381720945\n",
      "Epoch93  loss:3.77062668800354  accuracy:7.15487723034471\n",
      "Epoch94  loss:3.7617042899131774  accuracy:6.8491832177867655\n",
      "Epoch95  loss:3.760874772071839  accuracy:7.510607868201865\n",
      "Epoch96  loss:3.815802907943726  accuracy:6.96075701320877\n",
      "Epoch97  loss:3.7896390795707706  accuracy:7.917553187335913\n",
      "Epoch98  loss:3.770280766487122  accuracy:7.869602416549944\n",
      "Epoch99  loss:3.7783707737922665  accuracy:6.952304931299872\n",
      "Epoch100  loss:3.7718258976936343  accuracy:7.581474933140678\n",
      "Epoch101  loss:3.753570222854614  accuracy:7.52922712270152\n",
      "Epoch102  loss:3.7464678883552542  accuracy:8.64783678722129\n",
      "Epoch103  loss:3.75603848695755  accuracy:6.41844018937396\n",
      "Epoch104  loss:3.7639765381813044  accuracy:7.767079697302487\n",
      "Epoch105  loss:3.75051839351654  accuracy:8.405395871210693\n",
      "Epoch106  loss:3.75299733877182  accuracy:7.608925056921078\n",
      "Epoch107  loss:3.7358805656433107  accuracy:7.623747640859382\n",
      "Epoch108  loss:3.7496018052101134  accuracy:7.547364835200796\n",
      "Epoch109  loss:3.745757186412811  accuracy:6.743252551642804\n",
      "Epoch110  loss:3.7550719380378723  accuracy:7.969059676241542\n",
      "Epoch111  loss:3.7430127501487727  accuracy:8.12191633150015\n",
      "Epoch112  loss:3.7407056212425234  accuracy:7.951237098572235\n",
      "Epoch113  loss:3.7329719662666325  accuracy:7.575209711541252\n",
      "Epoch114  loss:3.7342198133468623  accuracy:7.793108473885486\n",
      "Epoch115  loss:3.740624642372132  accuracy:6.856535960833872\n",
      "Epoch116  loss:3.7640427589416507  accuracy:6.998569792708271\n",
      "Epoch117  loss:3.727984368801117  accuracy:7.692880807452643\n",
      "Epoch118  loss:3.711027145385742  accuracy:7.145571979738214\n",
      "Epoch119  loss:3.717163991928101  accuracy:8.382004075911649\n",
      "Epoch120  loss:3.742992091178894  accuracy:7.608501187244849\n",
      "Epoch121  loss:3.7275182485580447  accuracy:8.19486290238164\n",
      "Epoch122  loss:3.740478491783143  accuracy:7.502646234512625\n",
      "Epoch123  loss:3.7176187276840205  accuracy:7.691831264030263\n",
      "Epoch124  loss:3.728286623954773  accuracy:7.851413118854614\n",
      "Epoch125  loss:3.707851076126099  accuracy:8.133000640145434\n",
      "Epoch126  loss:3.7135698080062864  accuracy:7.55799393568074\n",
      "Epoch127  loss:3.712380313873291  accuracy:8.681385705354415\n",
      "Epoch128  loss:3.7201269626617433  accuracy:7.676659511258922\n",
      "Epoch129  loss:3.730077099800109  accuracy:8.433735249296083\n",
      "Epoch130  loss:3.7127067565917966  accuracy:8.922606016583623\n",
      "Epoch131  loss:3.722807919979096  accuracy:7.590999300142782\n",
      "Epoch132  loss:3.7077079772949215  accuracy:7.814083066483459\n",
      "Epoch133  loss:3.717808127403259  accuracy:8.243610423840883\n",
      "Epoch134  loss:3.736353886127472  accuracy:7.653211520652253\n",
      "Epoch135  loss:3.699173593521118  accuracy:7.994698565315958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch136  loss:3.717536747455597  accuracy:8.000074089540865\n",
      "Epoch137  loss:3.691079139709472  accuracy:9.307444416692823\n",
      "Epoch138  loss:3.695162439346314  accuracy:7.917212909503564\n",
      "Epoch139  loss:3.7022746324539186  accuracy:8.866801353355054\n",
      "Epoch140  loss:3.702975308895111  accuracy:9.302527724047088\n",
      "Epoch141  loss:3.6879076838493345  accuracy:8.686531604647099\n",
      "Epoch142  loss:3.688350057601928  accuracy:9.142314547133724\n",
      "Epoch143  loss:3.6863347768783576  accuracy:9.358799820699033\n",
      "Epoch144  loss:3.674365317821503  accuracy:8.366600382903258\n",
      "Epoch145  loss:3.6721840262413035  accuracy:8.9532016900928\n",
      "Epoch146  loss:3.6749199986457826  accuracy:8.952774211435278\n",
      "Epoch147  loss:3.6782338500022895  accuracy:9.346722396733602\n",
      "Epoch148  loss:3.670982682704925  accuracy:8.865408393673667\n",
      "Epoch149  loss:3.691080284118653  accuracy:8.720411592203433\n",
      "Epoch150  loss:3.6680558443069455  accuracy:8.87949051011806\n",
      "Epoch151  loss:3.6860258102416994  accuracy:8.108078681192733\n",
      "Epoch152  loss:3.6844306588172913  accuracy:8.818074903694539\n",
      "Epoch153  loss:3.652631950378419  accuracy:9.123122566422204\n",
      "Epoch154  loss:3.678587543964386  accuracy:8.657326228632275\n",
      "Epoch155  loss:3.6637221574783325  accuracy:9.192468011817741\n",
      "Epoch156  loss:3.6631647109985352  accuracy:9.547894054466017\n",
      "Epoch157  loss:3.65548609495163  accuracy:8.694309986320807\n",
      "Epoch158  loss:3.6583592057228085  accuracy:9.533289543659333\n",
      "Epoch159  loss:3.652956020832062  accuracy:9.638864793113763\n",
      "Epoch160  loss:3.664174926280975  accuracy:8.54531220564849\n",
      "Epoch161  loss:3.6510321497917175  accuracy:8.670896138523547\n",
      "Epoch162  loss:3.635466778278351  accuracy:10.29425500541558\n",
      "Epoch164  loss:3.639696168899536  accuracy:10.466927869676057\n",
      "Epoch165  loss:3.6473762750625616  accuracy:9.129181000490464\n",
      "Epoch166  loss:3.6343296289443967  accuracy:9.291039152846354\n",
      "Epoch167  loss:3.6504804849624635  accuracy:9.836872233069368\n",
      "Epoch168  loss:3.646707844734191  accuracy:9.820890263479262\n",
      "Epoch169  loss:3.639000308513641  accuracy:10.3757940375013\n",
      "Epoch170  loss:3.628562641143799  accuracy:11.260997687305812\n",
      "Epoch171  loss:3.6240226268768314  accuracy:11.321469384973463\n",
      "Epoch172  loss:3.628284776210785  accuracy:11.108031591698396\n",
      "Epoch173  loss:3.6230196833610533  accuracy:11.6564555653692\n",
      "Epoch174  loss:3.631411600112914  accuracy:10.751045763483175\n",
      "Epoch175  loss:3.6071209192276004  accuracy:10.074080445131237\n",
      "Epoch176  loss:3.6174217343330377  accuracy:10.042998518619479\n",
      "Epoch177  loss:3.6158136963844294  accuracy:10.380366521551613\n",
      "Epoch178  loss:3.6001782059669494  accuracy:10.661678959488444\n",
      "Epoch179  loss:3.6169669389724723  accuracy:10.167076042460863\n",
      "Epoch180  loss:3.592890095710754  accuracy:11.87610082412072\n",
      "Epoch181  loss:3.6009220361709593  accuracy:11.504958563502504\n",
      "Epoch182  loss:3.595502662658691  accuracy:11.690401582386023\n",
      "Epoch183  loss:3.586085438728332  accuracy:12.48368220596887\n",
      "Epoch184  loss:3.597032678127288  accuracy:11.45636573595736\n",
      "Epoch185  loss:3.5880567193031307  accuracy:11.911667500714836\n",
      "Epoch186  loss:3.57562255859375  accuracy:12.439497182137163\n",
      "Epoch187  loss:3.5992030620574953  accuracy:11.122307931782512\n",
      "Epoch188  loss:3.5709102630615233  accuracy:11.897865765471302\n",
      "Epoch189  loss:3.5898422479629515  accuracy:11.73518006642162\n",
      "Epoch190  loss:3.5779154419898984  accuracy:12.548320781806057\n",
      "Epoch191  loss:3.560043382644653  accuracy:13.98792369841758\n",
      "Epoch192  loss:3.568823432922364  accuracy:11.640943460056587\n",
      "Epoch193  loss:3.553038656711579  accuracy:12.542914163657972\n",
      "Epoch194  loss:3.554735732078552  accuracy:13.056028856352818\n",
      "Epoch195  loss:3.566366696357727  accuracy:13.212601004712356\n",
      "Epoch196  loss:3.555735826492309  accuracy:12.77301931788261\n",
      "Epoch197  loss:3.5547921299934386  accuracy:12.920268477127184\n",
      "Epoch198  loss:3.553144156932831  accuracy:13.214425463185165\n",
      "Epoch199  loss:3.549088990688324  accuracy:13.186420036680657\n",
      "Epoch200  loss:3.555243682861328  accuracy:13.00854907098633\n",
      "Epoch201  loss:3.5605476021766655  accuracy:11.777019958904186\n",
      "Epoch202  loss:3.5478565096855155  accuracy:13.054346607810206\n",
      "Epoch203  loss:3.54742785692215  accuracy:12.73152874148202\n",
      "Epoch204  loss:3.5371363639831537  accuracy:13.258420447633174\n",
      "Epoch205  loss:3.53343757390976  accuracy:13.209750435464793\n",
      "Epoch206  loss:3.5285665392875676  accuracy:13.321077618242443\n",
      "Epoch207  loss:3.546505415439606  accuracy:12.912089333746865\n",
      "Epoch208  loss:3.5277759432792664  accuracy:14.591230516552386\n",
      "Epoch209  loss:3.5217249751091  accuracy:14.295154113785856\n",
      "Epoch210  loss:3.525440227985382  accuracy:14.612304501273076\n",
      "Epoch211  loss:3.525097513198853  accuracy:13.798644226113867\n",
      "Epoch212  loss:3.5075480341911316  accuracy:14.314541868285698\n",
      "Epoch213  loss:3.506614744663239  accuracy:15.480492170003448\n",
      "Epoch214  loss:3.510687601566315  accuracy:14.847634982248094\n",
      "Epoch215  loss:3.514487755298615  accuracy:14.148086139498643\n",
      "Epoch216  loss:3.495310604572296  accuracy:15.447503195181085\n",
      "Epoch217  loss:3.5074534535408017  accuracy:14.097300086162308\n",
      "Epoch218  loss:3.5004347801208495  accuracy:14.524617190123667\n",
      "Epoch219  loss:3.5018475174903867  accuracy:14.041380904578729\n",
      "Epoch220  loss:3.516427493095398  accuracy:13.33468877229309\n",
      "Epoch221  loss:3.4946361184120174  accuracy:14.3104652420454\n",
      "Epoch222  loss:3.4840733289718626  accuracy:14.537129202922687\n",
      "Epoch223  loss:3.486180031299591  accuracy:15.090013358699697\n",
      "Epoch224  loss:3.4777578473091117  accuracy:15.352456693690515\n",
      "Epoch225  loss:3.4749791026115413  accuracy:15.208414068058358\n",
      "Epoch226  loss:3.475230634212494  accuracy:14.919382179749848\n",
      "Epoch227  loss:3.4639204740524296  accuracy:14.789090753040147\n",
      "Epoch228  loss:3.46396176815033  accuracy:15.359347715056616\n",
      "Epoch229  loss:3.4619765281677246  accuracy:14.802170781094054\n",
      "Epoch230  loss:3.4650766253471375  accuracy:16.153145007717217\n",
      "Epoch231  loss:3.4485885977745063  accuracy:15.514248755637237\n",
      "Epoch232  loss:3.4428568303585054  accuracy:16.12994162699389\n",
      "Epoch233  loss:3.4396580696105956  accuracy:15.262336951940132\n",
      "Epoch234  loss:3.4378093421459193  accuracy:16.582574175878865\n",
      "Epoch235  loss:3.439454585313797  accuracy:16.26164932768918\n",
      "Epoch236  loss:3.4296497821807863  accuracy:16.159936275510876\n",
      "Epoch237  loss:3.447324430942535  accuracy:15.06820105751537\n",
      "Epoch238  loss:3.4262993276119222  accuracy:17.081396524443587\n",
      "Epoch239  loss:3.4332009553909306  accuracy:16.817688034925506\n",
      "Epoch240  loss:3.428906852006912  accuracy:16.57761423870774\n",
      "Epoch241  loss:3.4079773247241976  accuracy:17.512487159716173\n",
      "Epoch242  loss:3.4410497784614567  accuracy:16.022413762668727\n",
      "Epoch243  loss:3.4180986583232884  accuracy:17.71792545509907\n",
      "Epoch244  loss:3.413306987285614  accuracy:17.054632925552117\n",
      "Epoch245  loss:3.437651520967484  accuracy:17.129478635658206\n",
      "Epoch246  loss:3.4163672149181363  accuracy:17.196296276449402\n",
      "Epoch247  loss:3.4197863519191736  accuracy:18.38709992542625\n",
      "Epoch248  loss:3.398194402456284  accuracy:19.38648588092818\n",
      "Epoch249  loss:3.398637503385544  accuracy:18.17624157928467\n",
      "Epoch250  loss:3.4118829846382144  accuracy:17.62974199493404\n",
      "Epoch251  loss:3.4114040970802297  accuracy:17.89367396643539\n",
      "Epoch252  loss:3.3916146636009215  accuracy:19.392408920768972\n",
      "Epoch253  loss:3.3951415777206426  accuracy:18.514246829404254\n",
      "Epoch254  loss:3.3929518818855287  accuracy:18.682512344000198\n",
      "Epoch255  loss:3.378213125467301  accuracy:20.534415133330473\n",
      "Epoch256  loss:3.3610793590545653  accuracy:20.367122498639382\n",
      "Epoch257  loss:3.386853903532028  accuracy:18.295852475748568\n",
      "Epoch258  loss:3.3784779608249664  accuracy:19.358061929443796\n",
      "Epoch259  loss:3.3931995153427126  accuracy:18.789998816479237\n",
      "Epoch260  loss:3.3811597466468815  accuracy:19.749261675964384\n",
      "Epoch261  loss:3.362284970283508  accuracy:20.552559528218207\n",
      "Epoch262  loss:3.356888043880463  accuracy:20.81346928192567\n",
      "Epoch263  loss:3.371977889537811  accuracy:20.25583364332195\n",
      "Epoch264  loss:3.352406913042068  accuracy:19.241197109233617\n",
      "Epoch265  loss:3.3376970708370206  accuracy:20.901763118105034\n",
      "Epoch266  loss:3.35321260690689  accuracy:20.916225172900234\n",
      "Epoch267  loss:3.357942575216294  accuracy:20.136364124526235\n",
      "Epoch268  loss:3.3429023087024694  accuracy:21.716221032918952\n",
      "Epoch269  loss:3.3251618921756747  accuracy:21.23071846658133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch270  loss:3.3247191786766055  accuracy:22.916949631678136\n",
      "Epoch271  loss:3.333003640174865  accuracy:21.645243254642537\n",
      "Epoch272  loss:3.3244764745235442  accuracy:23.783534064305638\n",
      "Epoch273  loss:3.3068979859352114  accuracy:22.90360394092968\n",
      "Epoch274  loss:3.30413174033165  accuracy:22.440409451588145\n",
      "Epoch275  loss:3.320740073919296  accuracy:22.833053845193593\n",
      "Epoch276  loss:3.31528360247612  accuracy:21.349671959625258\n",
      "Epoch277  loss:3.3140181064605714  accuracy:22.22409794413408\n",
      "Epoch278  loss:3.3040868043899536  accuracy:23.068913497277144\n",
      "Epoch279  loss:3.292915242910385  accuracy:23.648739626751052\n",
      "Epoch280  loss:3.290546989440918  accuracy:23.103444954471858\n",
      "Epoch281  loss:3.309772771596908  accuracy:23.212843989048988\n",
      "Epoch282  loss:3.30612096786499  accuracy:23.7437597165926\n",
      "Epoch283  loss:3.302870506048202  accuracy:24.4162324338409\n",
      "Epoch284  loss:3.278311902284622  accuracy:23.851359802270125\n",
      "Epoch285  loss:3.2840368866920473  accuracy:23.971004071560312\n",
      "Epoch286  loss:3.2880497872829433  accuracy:23.523236618846997\n",
      "Epoch287  loss:3.2706158041954034  accuracy:25.403377202515603\n",
      "Epoch288  loss:3.299170279502868  accuracy:25.168197627008755\n",
      "Epoch289  loss:3.2418454170227045  accuracy:25.587040810189105\n",
      "Epoch290  loss:3.2745589196681975  accuracy:24.283300251959144\n",
      "Epoch291  loss:3.2746734321117406  accuracy:24.306996199380706\n",
      "Epoch292  loss:3.2575297176837914  accuracy:26.21567643421394\n",
      "Epoch293  loss:3.251387393474578  accuracy:25.213806079953365\n",
      "Epoch294  loss:3.2532427132129667  accuracy:25.81919998460106\n",
      "Epoch295  loss:3.2381396353244782  accuracy:26.3677210474341\n",
      "Epoch296  loss:3.217941981554032  accuracy:26.513086786030858\n",
      "Epoch297  loss:3.2318023860454557  accuracy:27.31000271078366\n",
      "Epoch298  loss:3.2280588448047633  accuracy:25.790560559567137\n",
      "Epoch299  loss:3.207305669784546  accuracy:25.737194403689703\n",
      "Epoch300  loss:3.2511223495006556  accuracy:25.519572374529822\n"
     ]
    }
   ],
   "source": [
    "server = Server()\n",
    "workers = server.create_worker(federated_trainset,federated_valset,federated_testset)\n",
    "acc_train = []\n",
    "loss_train = []\n",
    "acc_valid = []\n",
    "loss_valid = []\n",
    "\n",
    "early_stopping = Early_Stopping(args.partience)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(args.global_epochs):\n",
    "  sample_worker = server.sample_worker(workers)\n",
    "  server.send_model(sample_worker)\n",
    "\n",
    "  acc_train_avg = 0.0\n",
    "  loss_train_avg = 0.0\n",
    "  acc_valid_avg = 0.0\n",
    "  loss_valid_avg = 0.0\n",
    "  for worker in sample_worker:\n",
    "    worker.local_train()\n",
    "    acc_train_tmp,loss_train_tmp,acc_valid_tmp,loss_valid_tmp = worker.global_train()\n",
    "    acc_train_avg += acc_train_tmp/len(sample_worker)\n",
    "    loss_train_avg += loss_train_tmp/len(sample_worker)\n",
    "    acc_valid_avg += acc_valid_tmp/len(sample_worker)\n",
    "    loss_valid_avg += loss_valid_tmp/len(sample_worker)\n",
    "  server.aggregate_model(sample_worker)\n",
    "  '''\n",
    "  server.model.to(args.device)\n",
    "  for worker in workers:\n",
    "    acc_valid_tmp,loss_valid_tmp = test(server.model,args.criterion,worker.valloader)\n",
    "    acc_valid_avg += acc_valid_tmp/len(workers)\n",
    "    loss_valid_avg += loss_valid_tmp/len(workers)\n",
    "  server.model.to('cpu')\n",
    "  '''\n",
    "  print('Epoch{}  loss:{}  accuracy:{}'.format(epoch+1,loss_valid_avg,acc_valid_avg))\n",
    "  acc_train.append(acc_train_avg)\n",
    "  loss_train.append(loss_train_avg)\n",
    "  acc_valid.append(acc_valid_avg)\n",
    "  loss_valid.append(loss_valid_avg)\n",
    "\n",
    "  if early_stopping.validate(loss_valid_avg):\n",
    "    print('Early Stop')\n",
    "    break\n",
    "    \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "mi_uceyoptLP",
    "outputId": "bc067e09-01bc-4e65-daf9-ac2f42373cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:11.764705882352942  loss:3.4357078075408936\n",
      "Worker2 accuracy:80.0  loss:1.3443061113357544\n",
      "Worker3 accuracy:47.5  loss:2.2990972995758057\n",
      "Worker4 accuracy:11.11111111111111  loss:3.8096609115600586\n",
      "Worker5 accuracy:26.470588235294116  loss:3.3714046478271484\n",
      "Worker6 accuracy:19.047619047619047  loss:3.4812235832214355\n",
      "Worker7 accuracy:21.05263157894737  loss:3.5776937007904053\n",
      "Worker8 accuracy:31.25  loss:3.1965279579162598\n",
      "Worker9 accuracy:0.0  loss:3.6245222091674805\n",
      "Worker10 accuracy:46.34146341463415  loss:2.8203229904174805\n",
      "Worker11 accuracy:16.666666666666668  loss:3.916609048843384\n",
      "Worker12 accuracy:10.526315789473685  loss:3.3269546031951904\n",
      "Worker13 accuracy:15.789473684210526  loss:3.2606372833251953\n",
      "Worker14 accuracy:10.0  loss:3.789907217025757\n",
      "Worker15 accuracy:26.31578947368421  loss:3.3726754188537598\n",
      "Worker16 accuracy:17.647058823529413  loss:3.722712278366089\n",
      "Worker17 accuracy:54.54545454545455  loss:2.1526758670806885\n",
      "Worker18 accuracy:38.70967741935484  loss:3.240612506866455\n",
      "Worker19 accuracy:41.1764705882353  loss:3.534677743911743\n",
      "Worker20 accuracy:16.666666666666668  loss:3.6650896072387695\n",
      "Test  loss:3.247150939702988  accuracy:27.129084646361726\n"
     ]
    }
   ],
   "source": [
    "acc_test = []\n",
    "loss_test = []\n",
    "\n",
    "nums = 0\n",
    "for worker in workers:\n",
    "  nums += worker.test_data_num\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "  worker.aggregation_weight = 1.0*worker.test_data_num/nums\n",
    "  worker.global_model = copy.deepcopy(server.global_model)\n",
    "  worker.local_train()\n",
    "  acc_tmp,loss_tmp = test(worker.mix_model,args.criterion,worker.testloader)\n",
    "  acc_test.append(acc_tmp)\n",
    "  loss_test.append(loss_tmp)\n",
    "  print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "  worker.mix_model = worker.mix_model.to('cpu')\n",
    "  del worker.mix_model,worker.global_model\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "acc_test_avg = sum(acc_test)/len(acc_test)\n",
    "loss_test_avg = sum(loss_test)/len(loss_test)\n",
    "print('Test  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FedAvg_femnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
