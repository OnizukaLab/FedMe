{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "vkZxat4Y-IsQ",
    "outputId": "da86392c-66e8-4b60-b471-086e745cdcbc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from torch import nn, optim\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O0TfzOhU-QlG"
   },
   "outputs": [],
   "source": [
    "class Argments():\n",
    "  def __init__(self):\n",
    "    self.batch_size = 20\n",
    "    self.test_batch = 1000\n",
    "    self.global_epochs = 300\n",
    "    self.local_epochs = 2\n",
    "    self.lr = None\n",
    "    self.momentum = 0.9\n",
    "    self.weight_decay = 10**-4.0\n",
    "    self.clip = 20.0\n",
    "    self.partience = 300\n",
    "    self.worker_num = 20\n",
    "    self.sample_num = 20\n",
    "    self.cluster_list = [1,2,3,4]\n",
    "    self.cluster_num = None\n",
    "    self.turn_of_cluster_num = [0,150,225,275]\n",
    "    self.turn_of_replacement_model = list(range(self.global_epochs))\n",
    "    self.unlabeleddata_size = 1000\n",
    "    self.device = device = torch.device('cuda:0'if torch.cuda.is_available() else'cpu')\n",
    "    self.criterion_ce = nn.CrossEntropyLoss()\n",
    "    self.criterion_kl = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "args = Argments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(10**-3.0)\n",
    "lr_list.append(10**-2.5)\n",
    "lr_list.append(10**-2.0)\n",
    "lr_list.append(10**-1.5)\n",
    "lr_list.append(10**-1.0)\n",
    "lr_list.append(10**-0.5)\n",
    "lr_list.append(10**0.0)\n",
    "lr_list.append(10**0.5)\n",
    "\n",
    "args.lr = lr_list[lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r5PuCcqmJNUQ"
   },
   "outputs": [],
   "source": [
    "class LocalDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,dataset,worker_id):\n",
    "    self.data = []\n",
    "    self.target = []\n",
    "    self.id = worker_id\n",
    "    for data in dataset.take(len(dataset)):\n",
    "      self.data.append(torch.tensor([data['pixels'].numpy()]))\n",
    "      self.target.append(torch.tensor(data['label'].numpy().astype(np.int64)))\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.data[index],self.target[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/federated_trainset_femnist.pickle', 'rb') as f:\n",
    "    all_federated_trainset = pickle.load(f)\n",
    "with open('../data/federated_testset_femnist.pickle', 'rb') as f:\n",
    "    all_federated_testset = pickle.load(f)\n",
    "all_worker_num = len(all_federated_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2619, 456, 102, 3037, 1126, 1003, 914, 571, 3016, 419, 2771, 3033, 2233, 356, 2418, 1728, 130, 122, 383, 895]\n"
     ]
    }
   ],
   "source": [
    "worker_id_list = random.sample(range(all_worker_num),args.worker_num)\n",
    "print(worker_id_list)\n",
    "federated_trainset = []\n",
    "federated_testset = []\n",
    "for i in worker_id_list:\n",
    "    federated_trainset.append(all_federated_trainset[i])\n",
    "    federated_testset.append(all_federated_testset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_valset = [None]*args.worker_num\n",
    "for i in range(args.worker_num):\n",
    "  n_samples = len(federated_trainset[i])\n",
    "  if n_samples==1:\n",
    "    federated_valset[i] = copy.deepcopy(federated_trainset[i])\n",
    "  else:\n",
    "    train_size = int(len(federated_trainset[i]) * 0.7) \n",
    "    val_size = n_samples - train_size \n",
    "    federated_trainset[i],federated_valset[i] = torch.utils.data.random_split(federated_trainset[i], [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnlabeledDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self):\n",
    "    self.data = []\n",
    "    self.target = None\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.data[index],'unlabeled'\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_dataset = UnlabeledDataset()\n",
    "\n",
    "for i in range(all_worker_num):\n",
    "    if i not in worker_id_list:\n",
    "        unlabeled_dataset.data = unlabeled_dataset.data + all_federated_trainset[i].data\n",
    "        \n",
    "unlabeled_dataset,_ = torch.utils.data.random_split(unlabeled_dataset, [args.unlabeleddata_size, len(unlabeled_dataset)-args.unlabeleddata_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZU3vAAb9-6SD"
   },
   "outputs": [],
   "source": [
    "class CNN1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(5408, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "class CNN2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(9216, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "class CNN3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(15488, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "    \n",
    "class CNN4(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN4, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv2d_4 = torch.nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(25600, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = self.conv2d_4(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans(object):\n",
    "    \"\"\"KMeans 法でクラスタリングするクラス\"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters=2, max_iter=300):\n",
    "        \"\"\"コンストラクタ\n",
    "\n",
    "        Args:\n",
    "            n_clusters (int): クラスタ数\n",
    "            max_iter (int): 最大イテレーション数\n",
    "        \"\"\"\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        self.cluster_centers_ = None\n",
    "\n",
    "    def fit_predict(self, features):\n",
    "        \"\"\"クラスタリングを実施する\n",
    "\n",
    "        Args:\n",
    "            features (numpy.ndarray): ラベル付けするデータ\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: ラベルデータ\n",
    "        \"\"\"\n",
    "            \n",
    "        # 要素の中からセントロイド (重心) の初期値となる候補をクラスタ数だけ選び出す\n",
    "        feature_indexes = np.arange(len(features))\n",
    "        np.random.shuffle(feature_indexes)\n",
    "        initial_centroid_indexes = feature_indexes[:self.n_clusters]\n",
    "        self.cluster_centers_ = features[initial_centroid_indexes]\n",
    "\n",
    "        # ラベル付けした結果となる配列はゼロで初期化しておく\n",
    "        pred = np.zeros(features.shape)\n",
    "        \n",
    "\n",
    "        # クラスタリングをアップデートする\n",
    "        for _ in range(self.max_iter):\n",
    "\n",
    "            # 各特徴ベクトルから最短距離となるセントロイドを基準に新しいラベルをつける\n",
    "            new_pred = np.array([\n",
    "                np.array([\n",
    "                    self.Euclidean_distance(p, centroid)\n",
    "                    for centroid in self.cluster_centers_\n",
    "                ]).argmin()\n",
    "                for p in features\n",
    "            ])\n",
    "\n",
    "            if np.all(new_pred == pred):\n",
    "                # 更新前と内容を比較して、もし同じなら終了\n",
    "                break\n",
    "\n",
    "            pred = new_pred\n",
    "            \n",
    "            # 各クラスタごとにセントロイド (重心) を再計算する\n",
    "            self.cluster_centers_ = np.array([features[pred == i].mean(axis=0)\n",
    "                                              for i in range(self.n_clusters)])\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def KLD(self, p0, p1):\n",
    "        P = torch.from_numpy(p0.astype(np.float32)).clone()\n",
    "        Q = torch.from_numpy(p1.astype(np.float32)).clone()\n",
    "        P = F.softmax(Variable(P), dim=1)\n",
    "        Q = F.softmax(Variable(Q), dim=1)\n",
    "        kld = ((P/(P+Q))*(P * (P / ((P/(P+Q))*P + (Q/(P+Q))*Q)).log())).sum() + ((Q/(P+Q))*(Q * (Q / ((P/(P+Q))*P + (Q/(P+Q))*Q)).log())).sum()\n",
    "        return kld\n",
    "    \n",
    "    def Euclidean_distance(self, p0, p1):\n",
    "        return np.sum((p0 - p1) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Yu90X1TWJVKJ"
   },
   "outputs": [],
   "source": [
    "class Server():\n",
    "  def __init__(self,unlabeled_dataset):\n",
    "    self.cluster = None\n",
    "    self.models = None\n",
    "    self.unlabeled_dataloader = torch.utils.data.DataLoader(unlabeled_dataset,batch_size=args.batch_size,shuffle=False,num_workers=2)\n",
    "\n",
    "  def create_worker(self,federated_trainset,federated_valset,federated_testset,client_best_model):\n",
    "    workers = []\n",
    "    for i in range(args.worker_num):\n",
    "      workers.append(Worker(i,federated_trainset[i],federated_valset[i],federated_testset[i],client_best_model[i]))\n",
    "    return workers\n",
    "\n",
    "  def sample_worker(self,workers):\n",
    "    sample_worker = []\n",
    "    sample_worker_num = random.sample(range(args.worker_num),args.sample_num)\n",
    "    for i in sample_worker_num:\n",
    "      sample_worker.append(workers[i])\n",
    "    return sample_worker\n",
    "\n",
    "  def collect_model(self,workers):\n",
    "    self.models = [None]*args.worker_num\n",
    "    for worker in workers:\n",
    "      self.models[worker.id] = copy.deepcopy(worker.local_model)\n",
    "\n",
    "  def send_model(self,workers):\n",
    "    for worker in workers:\n",
    "      worker.local_model = copy.deepcopy(self.models[worker.id])\n",
    "      worker.other_model = copy.deepcopy(self.models[worker.other_model_id])\n",
    "        \n",
    "  def return_model(self,workers):\n",
    "    for worker in workers:\n",
    "      worker.local_model = copy.deepcopy(self.models[worker.local_model_id])\n",
    "      worker.local_model_id = worker.id\n",
    "    del self.models\n",
    "    \n",
    "  def aggregate_model(self,workers):   \n",
    "    new_params = []\n",
    "    train_model_id = []\n",
    "    train_model_id_count = []\n",
    "    for worker in workers:\n",
    "      worker_state = worker.local_model.state_dict()\n",
    "      if worker.id in train_model_id:\n",
    "        i = train_model_id.index(worker.id)\n",
    "        for key in worker_state.keys():\n",
    "          new_params[i][key] += worker_state[key]\n",
    "        train_model_id_count[i] += 1\n",
    "      else:\n",
    "        new_params.append(OrderedDict())\n",
    "        train_model_id.append(worker.id)\n",
    "        train_model_id_count.append(1)\n",
    "        i = train_model_id.index(worker.id)\n",
    "        for key in worker_state.keys():\n",
    "          new_params[i][key] = worker_state[key]\n",
    "        \n",
    "      worker_state = worker.other_model.state_dict()\n",
    "      if worker.other_model_id in train_model_id:\n",
    "        i = train_model_id.index(worker.other_model_id)\n",
    "        for key in worker_state.keys():\n",
    "          new_params[i][key] += worker_state[key]\n",
    "        train_model_id_count[i] += 1\n",
    "      else:\n",
    "        new_params.append(OrderedDict())\n",
    "        train_model_id.append(worker.other_model_id)\n",
    "        train_model_id_count.append(1)\n",
    "        i = train_model_id.index(worker.other_model_id)\n",
    "        for key in worker_state.keys():\n",
    "          new_params[i][key] = worker_state[key]\n",
    "        \n",
    "      worker.local_model = worker.local_model.to('cpu')\n",
    "      worker.other_model = worker.other_model.to('cpu')\n",
    "      del worker.local_model,worker.other_model\n",
    "    \n",
    "    for i,model_id in enumerate(train_model_id):\n",
    "      for key in new_params[i].keys():\n",
    "        new_params[i][key] = new_params[i][key]/train_model_id_count[i]\n",
    "      self.models[model_id].load_state_dict(new_params[i])\n",
    "      \n",
    "  '''clustering by kmeans'''  \n",
    "  def clustering(self,workers):\n",
    "    if args.cluster_num==1:\n",
    "        pred = [0]*len(workers)\n",
    "        worker_id_list = []\n",
    "        for worker in workers:\n",
    "            worker_id_list.append(worker.id)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            worker_softmax_targets = [[] for i in range(len(workers))]\n",
    "            worker_id_list = []\n",
    "            count = 0\n",
    "            for i,model in enumerate(self.models):\n",
    "              if model==None:\n",
    "                pass\n",
    "              else:\n",
    "                model = model.to(args.device)\n",
    "                model.eval()\n",
    "                for data,_ in self.unlabeled_dataloader:\n",
    "                  data = data.to(args.device)\n",
    "                  worker_softmax_targets[count].append(model(data).to('cpu').detach().numpy())\n",
    "                worker_softmax_targets[count] = np.array(worker_softmax_targets[count])\n",
    "                model = model.to('cpu')\n",
    "                worker_id_list.append(i)\n",
    "                count += 1\n",
    "            worker_softmax_targets = np.array(worker_softmax_targets)\n",
    "            kmeans = KMeans(n_clusters=args.cluster_num)\n",
    "            pred = kmeans.fit_predict(worker_softmax_targets)\n",
    "    self.cluster = []\n",
    "    for i in range(args.cluster_num):\n",
    "      self.cluster.append([])\n",
    "    for i,cls in enumerate(pred):\n",
    "      self.cluster[cls].append(worker_id_list[i])\n",
    "    for worker in workers:\n",
    "      idx = worker_id_list.index(worker.id)\n",
    "      worker.cluster_num = pred[idx]\n",
    "        \n",
    "  def decide_other_model(self,workers):\n",
    "    for worker in workers:\n",
    "      cls = worker.cluster_num\n",
    "      '''if number of worker in cluster is one, other model is decided by random in all workers. '''\n",
    "      if len(self.cluster[cls])==1:\n",
    "        while True:\n",
    "          other_worker = random.choice(workers)\n",
    "          other_model_id = other_worker.id\n",
    "          if worker.id!=other_model_id:\n",
    "            break\n",
    "      else:\n",
    "        while True:\n",
    "          other_model_id = random.choice(self.cluster[cls])\n",
    "          if worker.id!=other_model_id:\n",
    "            break\n",
    "      worker.other_model_id = other_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LDWEBjgfJYFc"
   },
   "outputs": [],
   "source": [
    "class Worker():\n",
    "  def __init__(self,i,trainset,valset,testset,best_model):\n",
    "    self.id = i\n",
    "    self.cluster_num = None\n",
    "    self.trainloader = torch.utils.data.DataLoader(trainset,batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.valloader = torch.utils.data.DataLoader(valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.testloader = torch.utils.data.DataLoader(testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    if best_model==1:\n",
    "      self.local_model = CNN1()\n",
    "    elif best_model==2:\n",
    "      self.local_model = CNN2()\n",
    "    elif best_model==3:\n",
    "      self.local_model = CNN3()\n",
    "    elif best_model==4:\n",
    "      self.local_model = CNN4()\n",
    "    self.local_model_id = i\n",
    "    self.other_model = None\n",
    "    self.other_model_id = None\n",
    "    self.train_data_num = len(trainset)\n",
    "    self.test_data_num = len(testset)\n",
    "\n",
    "  def local_train(self):\n",
    "    self.local_model = self.local_model.to(args.device)\n",
    "    self.other_model = self.other_model.to(args.device)\n",
    "    local_optimizer = optim.SGD(self.local_model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "    other_optimizer = optim.SGD(self.other_model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "    self.local_model.train()\n",
    "    self.other_model.train()\n",
    "    for epoch in range(args.local_epochs):\n",
    "      running_loss = 0.0\n",
    "      correct = 0\n",
    "      count = 0\n",
    "      for (data,labels) in self.trainloader:\n",
    "        data,labels = Variable(data),Variable(labels)\n",
    "        data,labels = data.to(args.device),labels.to(args.device)\n",
    "        local_optimizer.zero_grad()\n",
    "        other_optimizer.zero_grad()\n",
    "        local_outputs = self.local_model(data)\n",
    "        other_outputs = self.other_model(data)\n",
    "        #train local_model\n",
    "        ce_loss = args.criterion_ce(local_outputs,labels)\n",
    "        kl_loss = args.criterion_kl(F.log_softmax(local_outputs, dim = 1),F.softmax(Variable(other_outputs), dim=1))\n",
    "        loss = ce_loss + kl_loss\n",
    "        running_loss += loss.item()\n",
    "        predicted = torch.argmax(local_outputs,dim=1)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "        count += len(labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.local_model.parameters(), args.clip)\n",
    "        local_optimizer.step()\n",
    "\n",
    "        #train other_model\n",
    "        ce_loss = args.criterion_ce(other_outputs,labels)\n",
    "        kl_loss = args.criterion_kl(F.log_softmax(other_outputs, dim = 1),F.softmax(Variable(local_outputs), dim=1))\n",
    "        loss = ce_loss + kl_loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.other_model.parameters(), args.clip)\n",
    "        other_optimizer.step()\n",
    "        \n",
    "    return 100.0*correct/count,running_loss/len(self.trainloader)\n",
    "\n",
    "        \n",
    "  def validate(self):\n",
    "    acc,loss = test(self.local_model,args.criterion_ce,self.valloader)\n",
    "    return acc,loss\n",
    "\n",
    "\n",
    "  def model_replacement(self):\n",
    "    _,loss_local = test(self.local_model,args.criterion_ce,self.valloader)\n",
    "    _,loss_other = test(self.other_model,args.criterion_ce,self.valloader)\n",
    "    if loss_other<loss_local:\n",
    "        self.local_model_id = self.other_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7-GY66gROuEU"
   },
   "outputs": [],
   "source": [
    "def train(model,criterion,trainloader,epochs):\n",
    "  optimizer = optim.SGD(model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "  model.train()\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for (data,labels) in trainloader:\n",
    "      data,labels = Variable(data),Variable(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      count += len(labels)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "      optimizer.step()\n",
    "\n",
    "  return 100.0*correct/count,running_loss/len(trainloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "oA4URv9mQ3xV"
   },
   "outputs": [],
   "source": [
    "def test(model,criterion,testloader):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  count = 0\n",
    "  for (data,labels) in testloader:\n",
    "    data,labels = data.to(args.device),labels.to(args.device)\n",
    "    outputs = model(data)\n",
    "    running_loss += criterion(outputs,labels).item()\n",
    "    predicted = torch.argmax(outputs,dim=1)\n",
    "    correct += (predicted==labels).sum().item()\n",
    "    count += len(labels)\n",
    "\n",
    "  accuracy = 100.0*correct/count\n",
    "  loss = running_loss/len(testloader)\n",
    "\n",
    "\n",
    "  return accuracy,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "WMO7_WSLHeGl"
   },
   "outputs": [],
   "source": [
    "class Early_Stopping():\n",
    "  def __init__(self,partience):\n",
    "    self.step = 0\n",
    "    self.loss = float('inf')\n",
    "    self.partience = partience\n",
    "\n",
    "  def validate(self,loss):\n",
    "    if self.loss<loss:\n",
    "      self.step += 1\n",
    "      if self.step>self.partience:\n",
    "        return True\n",
    "    else:\n",
    "      self.step = 0\n",
    "      self.loss = loss\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../client_best_model/client_best_model_femnist_42.csv') as fp:\n",
    "    csvList = list(csv.reader(fp))\n",
    "client_best_model = [int(item) for subList in csvList for item in subList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "-noG_98IR-nZ",
    "outputId": "78a6ebe2-854a-4f83-dc45-5c4ac35b69e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1  loss:4.0051945567131035  accuracy:5.876749915470376\n",
      "Epoch2  loss:3.8954055190086363  accuracy:5.754684343684445\n",
      "Epoch3  loss:3.831409931182861  accuracy:6.335507727843882\n",
      "Epoch4  loss:3.811757743358612  accuracy:6.642949078763494\n",
      "Epoch5  loss:3.7782390713691707  accuracy:6.371958505787191\n",
      "Epoch6  loss:3.7626258015632628  accuracy:6.664542030745779\n",
      "Epoch7  loss:3.749310159683227  accuracy:6.234297552852456\n",
      "Epoch8  loss:3.7319972634315497  accuracy:6.430966082884119\n",
      "Epoch9  loss:3.6980793476104736  accuracy:5.567734076794969\n",
      "Epoch10  loss:3.700629305839538  accuracy:6.281527238045111\n",
      "Epoch11  loss:3.692843234539032  accuracy:7.336936758396965\n",
      "Epoch12  loss:3.694174611568451  accuracy:7.339690759085998\n",
      "Epoch13  loss:3.6989389419555665  accuracy:6.313135039803905\n",
      "Epoch14  loss:3.6791916728019713  accuracy:7.4666842638657025\n",
      "Epoch15  loss:3.6734932661056523  accuracy:7.7073199254710865\n",
      "Epoch16  loss:3.6720670461654663  accuracy:7.190765647572414\n",
      "Epoch17  loss:3.678414165973663  accuracy:6.515543414307417\n",
      "Epoch18  loss:3.6627148509025576  accuracy:7.110219894989842\n",
      "Epoch19  loss:3.660434341430664  accuracy:6.688216219322863\n",
      "Epoch20  loss:3.650111985206604  accuracy:7.98185755788516\n",
      "Epoch21  loss:3.6427616000175487  accuracy:7.373257107339421\n",
      "Epoch22  loss:3.646017396450042  accuracy:8.363881930978508\n",
      "Epoch23  loss:3.626709008216858  accuracy:7.782931254577511\n",
      "Epoch24  loss:3.6431105494499207  accuracy:8.312448615993326\n",
      "Epoch25  loss:3.631406044960022  accuracy:8.341926708034471\n",
      "Epoch26  loss:3.63076604604721  accuracy:8.282261785552482\n",
      "Epoch27  loss:3.6325016021728516  accuracy:7.1323602427136565\n",
      "Epoch28  loss:3.622562384605408  accuracy:9.33518303677419\n",
      "Epoch29  loss:3.6153904914855954  accuracy:7.520917861466556\n",
      "Epoch30  loss:3.6120614290237425  accuracy:9.800034903544846\n",
      "Epoch31  loss:3.5859920978546143  accuracy:8.253467541751428\n",
      "Epoch32  loss:3.588180148601532  accuracy:10.488293826142062\n",
      "Epoch33  loss:3.577799105644226  accuracy:9.4506393509245\n",
      "Epoch34  loss:3.564267182350159  accuracy:10.620800739410393\n",
      "Epoch35  loss:3.5604354619979857  accuracy:10.468624843887177\n",
      "Epoch36  loss:3.551219284534455  accuracy:12.479943567791471\n",
      "Epoch37  loss:3.5453740954399104  accuracy:12.031267578383106\n",
      "Epoch38  loss:3.5255977630615236  accuracy:11.826738723313841\n",
      "Epoch39  loss:3.512459135055542  accuracy:13.081250439127862\n",
      "Epoch40  loss:3.5005148291587833  accuracy:13.46769112274151\n",
      "Epoch41  loss:3.479845416545868  accuracy:14.285821556370621\n",
      "Epoch42  loss:3.4514342546463017  accuracy:15.32071082459525\n",
      "Epoch43  loss:3.4211239457130436  accuracy:16.179961088864168\n",
      "Epoch44  loss:3.3921149611473083  accuracy:16.665803491663038\n",
      "Epoch45  loss:3.3669336557388307  accuracy:17.618580677536272\n",
      "Epoch46  loss:3.3480515480041504  accuracy:18.93236372314837\n",
      "Epoch47  loss:3.317614924907685  accuracy:20.901319959812767\n",
      "Epoch48  loss:3.2944380402565003  accuracy:22.379724645824965\n",
      "Epoch49  loss:3.2671385884284976  accuracy:24.02764595859684\n",
      "Epoch50  loss:3.2356251955032347  accuracy:22.657603067500684\n",
      "Epoch51  loss:3.2063735008239744  accuracy:24.719825239346676\n",
      "Epoch52  loss:3.1827664256095884  accuracy:26.425537798123056\n",
      "Epoch53  loss:3.1510550260543826  accuracy:26.512640879732146\n",
      "Epoch54  loss:3.1093192100524902  accuracy:28.00515983006219\n",
      "Epoch55  loss:3.0965497970581057  accuracy:28.466889829728718\n",
      "Epoch56  loss:3.04640166759491  accuracy:31.396606549804922\n",
      "Epoch57  loss:3.0172562003135686  accuracy:31.042650496133295\n",
      "Epoch58  loss:2.9919896841049196  accuracy:34.73633155238646\n",
      "Epoch59  loss:2.962637066841126  accuracy:34.130445515891985\n",
      "Epoch60  loss:2.928620970249176  accuracy:35.102734235645286\n",
      "Epoch61  loss:2.8991435885429384  accuracy:36.91680809568591\n",
      "Epoch62  loss:2.867086613178253  accuracy:38.06532784718654\n",
      "Epoch63  loss:2.8455826044082637  accuracy:38.78308116104844\n",
      "Epoch64  loss:2.8165332555770877  accuracy:40.171423820104465\n",
      "Epoch65  loss:2.7802642345428468  accuracy:42.351120061456285\n",
      "Epoch66  loss:2.749116241931915  accuracy:42.294362205536736\n",
      "Epoch67  loss:2.7184192419052127  accuracy:44.196536852758165\n",
      "Epoch68  loss:2.6813568830490113  accuracy:44.18900139779663\n",
      "Epoch69  loss:2.6604972958564757  accuracy:46.421259014228816\n",
      "Epoch70  loss:2.6307405352592466  accuracy:45.5211668891735\n",
      "Epoch71  loss:2.592244231700897  accuracy:48.26635353908567\n",
      "Epoch72  loss:2.5746199965476992  accuracy:48.652590152770884\n",
      "Epoch73  loss:2.544398438930511  accuracy:49.435603741224604\n",
      "Epoch74  loss:2.514716899394989  accuracy:51.160083866471055\n",
      "Epoch75  loss:2.4931497335433956  accuracy:49.55197161457247\n",
      "Epoch76  loss:2.4688154578208925  accuracy:52.010648377767524\n",
      "Epoch77  loss:2.4258210062980656  accuracy:51.95178116555202\n",
      "Epoch78  loss:2.41255145072937  accuracy:54.44320805132472\n",
      "Epoch79  loss:2.36775838136673  accuracy:53.70380946144418\n",
      "Epoch80  loss:2.341129523515702  accuracy:54.57945024631657\n",
      "Epoch81  loss:2.338407188653946  accuracy:55.62879188045268\n",
      "Epoch82  loss:2.3115859627723694  accuracy:55.31541504692792\n",
      "Epoch83  loss:2.2893591821193695  accuracy:56.627421275438515\n",
      "Epoch84  loss:2.26289302110672  accuracy:57.33774390056469\n",
      "Epoch85  loss:2.2296553134918216  accuracy:57.667549634225125\n",
      "Epoch86  loss:2.226046854257583  accuracy:56.627024068106984\n",
      "Epoch87  loss:2.2043345749378207  accuracy:57.63706965251591\n",
      "Epoch88  loss:2.179947471618652  accuracy:58.57919581074325\n",
      "Epoch89  loss:2.1706848859786985  accuracy:58.8776500823934\n",
      "Epoch90  loss:2.166588068008423  accuracy:59.26723957784652\n",
      "Epoch91  loss:2.1218513071537015  accuracy:59.1754189422568\n",
      "Epoch92  loss:2.1154245376586913  accuracy:60.07695247709221\n",
      "Epoch93  loss:2.0836952567100524  accuracy:60.49549679442464\n",
      "Epoch94  loss:2.0761822462081905  accuracy:60.96104911122719\n",
      "Epoch95  loss:2.0576294302940363  accuracy:61.14201659804383\n",
      "Epoch96  loss:2.0444882988929747  accuracy:61.143984948078284\n",
      "Epoch97  loss:2.0229237675666814  accuracy:61.56196002803176\n",
      "Epoch98  loss:1.9843318045139313  accuracy:62.11391945377623\n",
      "Epoch99  loss:1.998365533351898  accuracy:62.313581918858006\n",
      "Epoch100  loss:1.9848388969898219  accuracy:62.28410254968849\n",
      "Epoch101  loss:1.9680713176727291  accuracy:61.994918822170675\n",
      "Epoch102  loss:1.938117301464081  accuracy:62.2348554810768\n",
      "Epoch103  loss:1.9399120092391966  accuracy:62.47178868795102\n",
      "Epoch104  loss:1.9143889009952546  accuracy:62.778977849893316\n",
      "Epoch105  loss:1.9064418852329257  accuracy:64.60257874029556\n",
      "Epoch106  loss:1.906375569105148  accuracy:63.740588671362794\n",
      "Epoch107  loss:1.8886621117591857  accuracy:63.99083188986772\n",
      "Epoch108  loss:1.8757601261138914  accuracy:63.51209585244165\n",
      "Epoch109  loss:1.8767546117305756  accuracy:64.26821282619072\n",
      "Epoch110  loss:1.8554112255573272  accuracy:63.91036362462391\n",
      "Epoch111  loss:1.8543901264667508  accuracy:64.43466920266349\n",
      "Epoch112  loss:1.8402960300445557  accuracy:64.09129637597701\n",
      "Epoch113  loss:1.828582799434662  accuracy:64.25834716928833\n",
      "Epoch114  loss:1.815742981433869  accuracy:64.66081647273967\n",
      "Epoch115  loss:1.8091176331043242  accuracy:64.83967788192824\n",
      "Epoch116  loss:1.8170229256153105  accuracy:65.15892725534637\n",
      "Epoch117  loss:1.8071054220199585  accuracy:65.10203621324577\n",
      "Epoch118  loss:1.7873546957969666  accuracy:65.17174528873267\n",
      "Epoch119  loss:1.774743366241455  accuracy:65.40316062416629\n",
      "Epoch120  loss:1.7518907248973845  accuracy:65.18675170245882\n",
      "Epoch121  loss:1.7600281834602352  accuracy:65.7954223551072\n",
      "Epoch122  loss:1.745436978340149  accuracy:65.80129890314757\n",
      "Epoch123  loss:1.740546274185181  accuracy:65.16582159698389\n",
      "Epoch124  loss:1.7406089365482331  accuracy:65.95918509448208\n",
      "Epoch125  loss:1.743851387500763  accuracy:66.00834281914297\n",
      "Epoch126  loss:1.7106331527233125  accuracy:66.12842256924148\n",
      "Epoch127  loss:1.7168732821941377  accuracy:66.94411930120164\n",
      "Epoch128  loss:1.6953927338123322  accuracy:66.02357528817662\n",
      "Epoch129  loss:1.6988160729408264  accuracy:66.33913575019164\n",
      "Epoch130  loss:1.6884747385978702  accuracy:66.14327991144214\n",
      "Epoch131  loss:1.6951508820056913  accuracy:66.88092259710365\n",
      "Epoch132  loss:1.6812696337699886  accuracy:67.06663702223801\n",
      "Epoch133  loss:1.6646806299686436  accuracy:66.63957836787047\n",
      "Epoch134  loss:1.6722913801670076  accuracy:66.78490671652492\n",
      "Epoch135  loss:1.6617450535297396  accuracy:66.97415971894469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch136  loss:1.6468112230300904  accuracy:66.75875976705751\n",
      "Epoch137  loss:1.6574361920356748  accuracy:66.66744854460647\n",
      "Epoch138  loss:1.6314379990100862  accuracy:67.86413389884243\n",
      "Epoch139  loss:1.630495315790176  accuracy:67.55215390321688\n",
      "Epoch140  loss:1.6273400843143462  accuracy:67.8074623757512\n",
      "Epoch141  loss:1.6179823219776153  accuracy:68.27628058892114\n",
      "Epoch142  loss:1.6313174188137054  accuracy:68.63266441662824\n",
      "Epoch143  loss:1.6101988613605498  accuracy:67.17164937549018\n",
      "Epoch144  loss:1.5908301532268523  accuracy:67.71177731057105\n",
      "Epoch145  loss:1.5991706907749172  accuracy:67.80763178664337\n",
      "Epoch146  loss:1.5768540918827056  accuracy:68.16042790870408\n",
      "Epoch147  loss:1.579812031984329  accuracy:68.55974612667504\n",
      "Epoch148  loss:1.5727613031864167  accuracy:68.23834789915517\n",
      "Epoch149  loss:1.5734138667583466  accuracy:67.38561748864939\n",
      "Epoch150  loss:1.549539363384247  accuracy:67.37775458048634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acc12212vx/jupyter_env/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch151  loss:1.5401683032512663  accuracy:67.98176505454995\n",
      "Epoch152  loss:1.542090892791748  accuracy:68.77130429312113\n",
      "Epoch153  loss:1.5329599261283875  accuracy:68.74119593864323\n",
      "Epoch154  loss:1.5306429862976076  accuracy:68.59215552443888\n",
      "Epoch155  loss:1.5319107949733735  accuracy:68.77619911254864\n",
      "Epoch156  loss:1.5277054607868197  accuracy:68.51912080998534\n",
      "Epoch157  loss:1.5245430767536163  accuracy:68.14074871076599\n",
      "Epoch158  loss:1.5201799690723419  accuracy:68.5165507875572\n",
      "Epoch159  loss:1.500540918111801  accuracy:68.72167263540133\n",
      "Epoch160  loss:1.499469131231308  accuracy:68.63326062103448\n",
      "Epoch161  loss:1.4896495640277863  accuracy:68.78823531435685\n",
      "Epoch162  loss:1.4806180655956267  accuracy:68.55418428054952\n",
      "Epoch163  loss:1.4799287140369417  accuracy:69.29489783676563\n",
      "Epoch164  loss:1.4635453224182127  accuracy:69.22185562497988\n",
      "Epoch165  loss:1.4811067938804625  accuracy:68.19939202492588\n",
      "Epoch166  loss:1.4755980908870698  accuracy:69.88853762601815\n",
      "Epoch167  loss:1.4625751495361328  accuracy:68.62759788537183\n",
      "Epoch168  loss:1.457684761285782  accuracy:68.50199034652981\n",
      "Epoch169  loss:1.46646494269371  accuracy:68.71593089384152\n",
      "Epoch170  loss:1.4537414371967314  accuracy:69.03891111210996\n",
      "Epoch171  loss:1.441534227132797  accuracy:69.12083751713669\n",
      "Epoch172  loss:1.4607932209968566  accuracy:69.15292072457292\n",
      "Epoch173  loss:1.4244440972805026  accuracy:69.43391089062673\n",
      "Epoch174  loss:1.4163715004920963  accuracy:69.89704695745382\n",
      "Epoch175  loss:1.417714959383011  accuracy:69.54965064695753\n",
      "Epoch176  loss:1.4238345801830297  accuracy:69.3385866675831\n",
      "Epoch177  loss:1.433518689870834  accuracy:69.26569225736594\n",
      "Epoch178  loss:1.4034965991973876  accuracy:69.5162954970344\n",
      "Epoch179  loss:1.408877170085907  accuracy:70.3581352122806\n",
      "Epoch180  loss:1.4057498872280119  accuracy:69.82529271077945\n",
      "Epoch181  loss:1.4184609413146971  accuracy:69.4191946209539\n",
      "Epoch182  loss:1.4078356862068178  accuracy:69.71315872411958\n",
      "Epoch183  loss:1.394929176568985  accuracy:69.84532243204617\n",
      "Epoch184  loss:1.3817847371101382  accuracy:69.95556810463813\n",
      "Epoch185  loss:1.3676318287849425  accuracy:70.88697914893295\n",
      "Epoch186  loss:1.390591889619827  accuracy:70.22684616027388\n",
      "Epoch187  loss:1.3854116380214692  accuracy:70.81323034081207\n",
      "Epoch188  loss:1.3790926694869996  accuracy:70.67620391580596\n",
      "Epoch189  loss:1.3686532378196716  accuracy:70.0741754178598\n",
      "Epoch190  loss:1.3409293532371518  accuracy:70.59108993885395\n",
      "Epoch191  loss:1.3711339712142945  accuracy:71.15642980132301\n",
      "Epoch192  loss:1.34995356798172  accuracy:70.86631760293909\n",
      "Epoch193  loss:1.3531508684158327  accuracy:70.46980003093006\n",
      "Epoch194  loss:1.3509882509708404  accuracy:70.75152220357242\n",
      "Epoch195  loss:1.325167989730835  accuracy:70.9512575583176\n",
      "Epoch196  loss:1.3314258724451065  accuracy:70.88802181691587\n",
      "Epoch197  loss:1.3222967058420183  accuracy:70.7168568519082\n",
      "Epoch198  loss:1.321728414297104  accuracy:70.70841905576496\n",
      "Epoch199  loss:1.331412422657013  accuracy:71.25320351887368\n",
      "Epoch200  loss:1.3134139448404314  accuracy:71.11845031213244\n",
      "Epoch201  loss:1.316025733947754  accuracy:71.08745479335758\n",
      "Epoch202  loss:1.2890218049287796  accuracy:70.72759659291546\n",
      "Epoch203  loss:1.2819059044122698  accuracy:71.47404825366756\n",
      "Epoch204  loss:1.2921069115400314  accuracy:70.79439756605142\n",
      "Epoch205  loss:1.3004038751125333  accuracy:71.12062307661236\n",
      "Epoch206  loss:1.2918083399534226  accuracy:70.83725794656263\n",
      "Epoch207  loss:1.2831014424562455  accuracy:70.93520571106731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acc12212vx/jupyter_env/lib/python3.6/site-packages/ipykernel_launcher.py:56: RuntimeWarning: Mean of empty slice.\n",
      "/home/acc12212vx/jupyter_env/lib/python3.6/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch208  loss:1.3204728782176969  accuracy:71.24629383640226\n",
      "Epoch209  loss:1.2796892732381822  accuracy:71.06687847313026\n",
      "Epoch210  loss:1.2754454374313358  accuracy:71.6452924500822\n",
      "Epoch211  loss:1.2718292385339738  accuracy:71.39920990246668\n",
      "Epoch212  loss:1.2741100817918776  accuracy:72.0822761027109\n",
      "Epoch213  loss:1.2618150472640992  accuracy:72.29423436513522\n",
      "Epoch214  loss:1.268881341814995  accuracy:71.22930011605894\n",
      "Epoch215  loss:1.2539768069982526  accuracy:72.17589764217679\n",
      "Epoch216  loss:1.2668285816907885  accuracy:71.48729732970729\n",
      "Epoch217  loss:1.2398518145084383  accuracy:71.20321652687217\n",
      "Epoch218  loss:1.2382011979818344  accuracy:72.37186483296816\n",
      "Epoch219  loss:1.2452979803085324  accuracy:72.10648980481376\n",
      "Epoch220  loss:1.2373915046453479  accuracy:71.44619028088037\n",
      "Epoch221  loss:1.2321339040994643  accuracy:71.51457019283932\n",
      "Epoch222  loss:1.2364871233701709  accuracy:71.1450801280876\n",
      "Epoch223  loss:1.2345329761505126  accuracy:72.16998626390807\n",
      "Epoch224  loss:1.222110390663147  accuracy:71.94624776474701\n",
      "Epoch225  loss:1.2176218271255492  accuracy:72.31777095211281\n",
      "Epoch226  loss:1.2362688809633253  accuracy:72.61668871092137\n",
      "Epoch227  loss:1.2051204830408098  accuracy:73.29309873336534\n",
      "Epoch228  loss:1.21283218562603  accuracy:72.8795029232623\n",
      "Epoch229  loss:1.2037997752428053  accuracy:72.66673535264472\n",
      "Epoch230  loss:1.186487001180649  accuracy:73.25740789522075\n",
      "Epoch231  loss:1.1961993783712386  accuracy:72.63476559373407\n",
      "Epoch232  loss:1.179718914628029  accuracy:72.00679005466421\n",
      "Epoch233  loss:1.1920512080192567  accuracy:72.36641061674074\n",
      "Epoch234  loss:1.163083863258362  accuracy:72.39735244941218\n",
      "Epoch235  loss:1.165016919374466  accuracy:73.1045150425448\n",
      "Epoch236  loss:1.1604842573404313  accuracy:72.84734349043354\n",
      "Epoch237  loss:1.2229091316461564  accuracy:72.95472958796842\n",
      "Epoch238  loss:1.1705681771039962  accuracy:72.12036578038101\n",
      "Epoch239  loss:1.1603012919425966  accuracy:73.80292844327718\n",
      "Epoch240  loss:1.1690101265907284  accuracy:73.54825614779833\n",
      "Epoch241  loss:1.1623683393001556  accuracy:72.71375366480288\n",
      "Epoch242  loss:1.1535367310047153  accuracy:73.7794184931619\n",
      "Epoch243  loss:1.1633673876523971  accuracy:73.50030772729414\n",
      "Epoch244  loss:1.1377977848052976  accuracy:73.07441198883137\n",
      "Epoch245  loss:1.154005938768387  accuracy:72.89857726523381\n",
      "Epoch246  loss:1.128702825307846  accuracy:73.42460530760304\n",
      "Epoch247  loss:1.1256145000457762  accuracy:73.81570364110432\n",
      "Epoch248  loss:1.1152975648641585  accuracy:73.26374325588168\n",
      "Epoch249  loss:1.1411071121692657  accuracy:73.82233765928514\n",
      "Epoch250  loss:1.1368724226951596  accuracy:73.1521006962641\n",
      "Epoch251  loss:1.123469492793083  accuracy:73.04404565750627\n",
      "Epoch252  loss:1.1351783663034438  accuracy:73.76950146349579\n",
      "Epoch253  loss:1.1140150576829912  accuracy:73.51374406939686\n",
      "Epoch254  loss:1.1748754024505617  accuracy:74.15913485784598\n",
      "Epoch255  loss:1.128749433159828  accuracy:73.56801563626456\n",
      "Epoch256  loss:1.1156579613685609  accuracy:74.10056617429096\n",
      "Epoch257  loss:1.0969333827495575  accuracy:73.45550761479686\n",
      "Epoch258  loss:1.1112933993339538  accuracy:73.74391861387869\n",
      "Epoch259  loss:1.1296679705381394  accuracy:74.34389153479705\n",
      "Epoch260  loss:1.117762887477875  accuracy:73.92488110423243\n",
      "Epoch261  loss:1.105061087012291  accuracy:73.62125578048195\n",
      "Epoch262  loss:1.0898982018232346  accuracy:74.00083822798938\n",
      "Epoch263  loss:1.082947987318039  accuracy:73.96099960639597\n",
      "Epoch264  loss:1.111401891708374  accuracy:74.32259804963721\n",
      "Epoch265  loss:1.078368166089058  accuracy:74.61141112912247\n",
      "Epoch266  loss:1.0953499883413316  accuracy:74.643785487661\n",
      "Epoch267  loss:1.1515184044837954  accuracy:73.76280196183808\n",
      "Epoch268  loss:1.1383281260728835  accuracy:74.31730384838157\n",
      "Epoch269  loss:1.0915903806686402  accuracy:73.84001092206023\n",
      "Epoch270  loss:1.0857837021350862  accuracy:74.14015928128526\n",
      "Epoch271  loss:1.0718547910451888  accuracy:73.9363085953068\n",
      "Epoch272  loss:1.1414965599775315  accuracy:74.33684303316998\n",
      "Epoch273  loss:1.0765330970287323  accuracy:73.84846908691495\n",
      "Epoch274  loss:1.0749753117561338  accuracy:74.94884819469553\n",
      "Epoch275  loss:1.0653920859098434  accuracy:74.35925533037022\n",
      "Epoch276  loss:1.0584400057792662  accuracy:74.60982201192124\n",
      "Epoch277  loss:1.0522809833288191  accuracy:74.004740283526\n",
      "Epoch278  loss:1.0555000603199005  accuracy:73.98728476557231\n",
      "Epoch279  loss:1.1535622626543045  accuracy:75.38407880492721\n",
      "Epoch280  loss:1.078886032104492  accuracy:74.03810944064044\n",
      "Epoch281  loss:1.061554518342018  accuracy:73.93759230250947\n",
      "Epoch282  loss:1.068278321623802  accuracy:74.27031609984627\n",
      "Epoch283  loss:1.0518541157245638  accuracy:73.6768785740799\n",
      "Epoch284  loss:1.0430356711149216  accuracy:74.48367483004961\n",
      "Epoch285  loss:1.0395212680101393  accuracy:73.84361467450336\n",
      "Epoch286  loss:1.0285426378250122  accuracy:74.98315109364142\n",
      "Epoch287  loss:1.0316905707120896  accuracy:74.46344694766765\n",
      "Epoch288  loss:1.0244648247957229  accuracy:74.99622559236236\n",
      "Epoch289  loss:1.1136976480484009  accuracy:74.26953102849596\n",
      "Epoch290  loss:1.0293439120054244  accuracy:73.91204354814118\n",
      "Epoch291  loss:1.0302492231130598  accuracy:75.13455414002456\n",
      "Epoch292  loss:1.04572192132473  accuracy:74.9595288799198\n",
      "Epoch293  loss:1.1018952935934065  accuracy:74.73518467780313\n",
      "Epoch294  loss:1.1407914966344834  accuracy:74.86744904198397\n",
      "Epoch295  loss:1.041561296582222  accuracy:74.37884509358108\n",
      "Epoch296  loss:1.0354718834161758  accuracy:74.46000049877114\n",
      "Epoch297  loss:1.1198970973491669  accuracy:74.89066921918949\n",
      "Epoch298  loss:1.0435469180345536  accuracy:74.85162959083786\n",
      "Epoch299  loss:1.0277090579271317  accuracy:75.21450871879624\n",
      "Epoch300  loss:1.0989026188850404  accuracy:75.06956823951812\n"
     ]
    }
   ],
   "source": [
    "server = Server(unlabeled_dataset)\n",
    "workers = server.create_worker(federated_trainset,federated_valset,federated_testset,client_best_model)\n",
    "acc_train = []\n",
    "loss_train = []\n",
    "acc_valid = []\n",
    "loss_valid = []\n",
    "\n",
    "early_stopping = Early_Stopping(args.partience)\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for epoch in range(args.global_epochs):\n",
    "  if epoch in args.turn_of_cluster_num:\n",
    "    idx = args.turn_of_cluster_num.index(epoch)\n",
    "    args.cluster_num = args.cluster_list[idx]\n",
    "  sample_worker = server.sample_worker(workers)\n",
    "  server.collect_model(sample_worker)\n",
    "  server.clustering(sample_worker)\n",
    "  server.decide_other_model(sample_worker)\n",
    "  server.send_model(sample_worker)\n",
    "\n",
    "  acc_train_avg = 0.0\n",
    "  loss_train_avg = 0.0\n",
    "  acc_valid_avg = 0.0\n",
    "  loss_valid_avg = 0.0\n",
    "  for worker in sample_worker:\n",
    "    acc_train_tmp,loss_train_tmp = worker.local_train()\n",
    "    acc_valid_tmp,loss_valid_tmp = worker.validate()\n",
    "    acc_train_avg += acc_train_tmp/len(sample_worker)\n",
    "    loss_train_avg += loss_train_tmp/len(sample_worker)\n",
    "    acc_valid_avg += acc_valid_tmp/len(sample_worker)\n",
    "    loss_valid_avg += loss_valid_tmp/len(sample_worker)\n",
    "  if epoch in args.turn_of_replacement_model:\n",
    "    for worker in sample_worker:\n",
    "      worker.model_replacement()\n",
    "  server.aggregate_model(sample_worker)\n",
    "  server.return_model(sample_worker)\n",
    "  '''\n",
    "  server.model.to(args.device)\n",
    "  for worker in workers:\n",
    "    acc_valid_tmp,loss_valid_tmp = test(server.model,args.criterion,worker.valloader)\n",
    "    acc_valid_avg += acc_valid_tmp/len(workers)\n",
    "    loss_valid_avg += loss_valid_tmp/len(workers)\n",
    "  server.model.to('cpu')\n",
    "  '''\n",
    "  print('Epoch{}  loss:{}  accuracy:{}'.format(epoch+1,loss_valid_avg,acc_valid_avg))\n",
    "  acc_train.append(acc_train_avg)\n",
    "  loss_train.append(loss_train_avg)\n",
    "  acc_valid.append(acc_valid_avg)\n",
    "  loss_valid.append(loss_valid_avg)\n",
    "\n",
    "  if early_stopping.validate(loss_valid_avg):\n",
    "    print('Early Stop')\n",
    "    break\n",
    "    \n",
    "end = time.time()#終了時刻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習時間：12320.034575939178秒\n"
     ]
    }
   ],
   "source": [
    "print('学習時間：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:76.47058823529412  loss:1.3427379131317139\n",
      "Worker2 accuracy:85.71428571428571  loss:0.5027276277542114\n",
      "Worker3 accuracy:82.5  loss:0.9414807558059692\n",
      "Worker4 accuracy:66.66666666666667  loss:1.77033269405365\n",
      "Worker5 accuracy:91.17647058823529  loss:0.5614816546440125\n",
      "Worker6 accuracy:80.95238095238095  loss:1.0939338207244873\n",
      "Worker7 accuracy:68.42105263157895  loss:1.0617470741271973\n",
      "Worker8 accuracy:78.125  loss:0.8840042352676392\n",
      "Worker9 accuracy:52.63157894736842  loss:1.7317153215408325\n",
      "Worker10 accuracy:78.04878048780488  loss:0.9648281931877136\n",
      "Worker11 accuracy:66.66666666666667  loss:1.4878454208374023\n",
      "Worker12 accuracy:73.6842105263158  loss:0.9826846718788147\n",
      "Worker13 accuracy:84.21052631578948  loss:0.963140606880188\n",
      "Worker14 accuracy:56.666666666666664  loss:1.873410701751709\n",
      "Worker15 accuracy:78.94736842105263  loss:0.7993667125701904\n",
      "Worker16 accuracy:70.58823529411765  loss:1.132392168045044\n",
      "Worker17 accuracy:63.63636363636363  loss:1.3797324895858765\n",
      "Worker18 accuracy:83.87096774193549  loss:0.9862439632415771\n",
      "Worker19 accuracy:85.29411764705883  loss:1.012283444404602\n",
      "Worker20 accuracy:72.22222222222223  loss:1.529364824295044\n",
      "Test  loss:1.1500727146863938  accuracy:74.82470746809021\n"
     ]
    }
   ],
   "source": [
    "acc_test = []\n",
    "loss_test = []\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "  worker.local_model = worker.local_model.to(args.device)\n",
    "  acc_tmp,loss_tmp = test(worker.local_model,args.criterion_ce,worker.testloader)\n",
    "  acc_test.append(acc_tmp)\n",
    "  loss_test.append(loss_tmp)\n",
    "  print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "  worker.local_model = worker.local_model.to('cpu')\n",
    "\n",
    "end = time.time()#終了時刻\n",
    "\n",
    "acc_test_avg = sum(acc_test)/len(acc_test)\n",
    "loss_test_avg = sum(loss_test)/len(loss_test)\n",
    "print('Test  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推論時間：6.750147581100464秒\n"
     ]
    }
   ],
   "source": [
    "print('推論時間：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 Valid accuracy:79.06976744186046  loss:0.8725739121437073\n",
      "Worker1 Test accuracy:76.47058823529412  loss:1.3105943202972412\n",
      "Worker2 Valid accuracy:84.04255319148936  loss:0.7584352493286133\n",
      "Worker2 Test accuracy:88.57142857142857  loss:0.33251848816871643\n",
      "Worker3 Valid accuracy:71.42857142857143  loss:1.0110368728637695\n",
      "Worker3 Test accuracy:80.0  loss:0.7700222134590149\n",
      "Worker4 Valid accuracy:73.91304347826087  loss:1.0164458751678467\n",
      "Worker4 Test accuracy:66.66666666666667  loss:1.738160252571106\n",
      "Worker5 Valid accuracy:78.02197802197803  loss:0.8186147212982178\n",
      "Worker5 Test accuracy:91.17647058823529  loss:0.5031121373176575\n",
      "Worker6 Valid accuracy:70.9090909090909  loss:1.311125636100769\n",
      "Worker6 Test accuracy:76.19047619047619  loss:0.9257825016975403\n",
      "Worker7 Valid accuracy:81.0  loss:0.881182849407196\n",
      "Worker7 Test accuracy:68.42105263157895  loss:1.061694622039795\n",
      "Worker8 Valid accuracy:77.6470588235294  loss:0.8096266984939575\n",
      "Worker8 Test accuracy:81.25  loss:0.7133128643035889\n",
      "Worker9 Valid accuracy:75.51020408163265  loss:1.0415408611297607\n",
      "Worker9 Test accuracy:63.1578947368421  loss:1.5215896368026733\n",
      "Worker10 Valid accuracy:81.65137614678899  loss:0.7481107711791992\n",
      "Worker10 Test accuracy:75.60975609756098  loss:0.8115368485450745\n",
      "Worker11 Valid accuracy:67.3913043478261  loss:1.3938976526260376\n",
      "Worker11 Test accuracy:66.66666666666667  loss:1.4126631021499634\n",
      "Worker12 Valid accuracy:79.59183673469387  loss:0.6683816909790039\n",
      "Worker12 Test accuracy:73.6842105263158  loss:0.9155802726745605\n",
      "Worker13 Valid accuracy:73.46938775510205  loss:1.1943663358688354\n",
      "Worker13 Test accuracy:84.21052631578948  loss:0.9286938905715942\n",
      "Worker14 Valid accuracy:74.35897435897436  loss:0.9461799263954163\n",
      "Worker14 Test accuracy:53.333333333333336  loss:1.9309790134429932\n",
      "Worker15 Valid accuracy:79.59183673469387  loss:0.8271805047988892\n",
      "Worker15 Test accuracy:78.94736842105263  loss:0.6804640889167786\n",
      "Worker16 Valid accuracy:71.11111111111111  loss:1.0703767538070679\n",
      "Worker16 Test accuracy:76.47058823529412  loss:1.170851469039917\n",
      "Worker17 Valid accuracy:71.5909090909091  loss:1.003696322441101\n",
      "Worker17 Test accuracy:63.63636363636363  loss:1.1322680711746216\n",
      "Worker18 Valid accuracy:69.51219512195122  loss:1.1628018617630005\n",
      "Worker18 Test accuracy:87.09677419354838  loss:0.8110296130180359\n",
      "Worker19 Valid accuracy:77.77777777777777  loss:0.9357081651687622\n",
      "Worker19 Test accuracy:85.29411764705883  loss:0.709937334060669\n",
      "Worker20 Valid accuracy:53.333333333333336  loss:1.5066131353378296\n",
      "Worker20 Test accuracy:72.22222222222223  loss:1.423997402191162\n",
      "Validation(tune)  loss:0.9988947898149491  accuracy:74.54611549447876\n",
      "Test(tune)  loss:1.0402394071221353  accuracy:75.4538252457864\n"
     ]
    }
   ],
   "source": [
    "acc_tune_test = []\n",
    "loss_tune_test = []\n",
    "acc_tune_valid = []\n",
    "loss_tune_valid = []\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "    worker.local_model = worker.local_model.to(args.device)\n",
    "    _,_ = train(worker.local_model,args.criterion_ce,worker.trainloader,args.local_epochs)\n",
    "    acc_tmp,loss_tmp = test(worker.local_model,args.criterion_ce,worker.valloader)\n",
    "    acc_tune_valid.append(acc_tmp)\n",
    "    loss_tune_valid.append(loss_tmp)\n",
    "    print('Worker{} Valid accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    \n",
    "    acc_tmp,loss_tmp = test(worker.local_model,args.criterion_ce,worker.testloader)\n",
    "    acc_tune_test.append(acc_tmp)\n",
    "    loss_tune_test.append(loss_tmp)\n",
    "    print('Worker{} Test accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    worker.local_model = worker.local_model.to('cpu')\n",
    "\n",
    "end = time.time()#終了時刻\n",
    "\n",
    "acc_valid_avg = sum(acc_tune_valid)/len(acc_tune_valid)\n",
    "loss_valid_avg = sum(loss_tune_valid)/len(loss_tune_valid)\n",
    "print('Validation(tune)  loss:{}  accuracy:{}'.format(loss_valid_avg,acc_valid_avg))\n",
    "acc_test_avg = sum(acc_tune_test)/len(acc_tune_test)\n",
    "loss_test_avg = sum(loss_tune_test)/len(loss_tune_test)\n",
    "print('Test(tune)  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習＋推論時間：28.86422610282898秒\n"
     ]
    }
   ],
   "source": [
    "print('学習＋推論時間：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FedAvg_femnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
