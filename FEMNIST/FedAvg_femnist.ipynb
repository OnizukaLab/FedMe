{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "vkZxat4Y-IsQ",
    "outputId": "da86392c-66e8-4b60-b471-086e745cdcbc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from torch import nn, optim\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "O0TfzOhU-QlG"
   },
   "outputs": [],
   "source": [
    "class Argments():\n",
    "  def __init__(self):\n",
    "    self.batch_size = 20\n",
    "    self.test_batch = 1000\n",
    "    self.global_epochs = 300\n",
    "    self.local_epochs = 2\n",
    "    self.lr = None\n",
    "    self.momentum = 0.9\n",
    "    self.weight_decay = 10**-4.0\n",
    "    self.clip = 20.0\n",
    "    self.partience = 300\n",
    "    self.worker_num = 20\n",
    "    self.sample_num = 20\n",
    "    self.device = device = torch.device('cuda:0'if torch.cuda.is_available() else'cpu')\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "args = Argments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(10**-3.0)\n",
    "lr_list.append(10**-2.5)\n",
    "lr_list.append(10**-2.0)\n",
    "lr_list.append(10**-1.5)\n",
    "lr_list.append(10**-1.0)\n",
    "lr_list.append(10**-0.5)\n",
    "lr_list.append(10**0.0)\n",
    "lr_list.append(10**0.5)\n",
    "\n",
    "args.lr = lr_list[lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "r5PuCcqmJNUQ"
   },
   "outputs": [],
   "source": [
    "class LocalDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,dataset,worker_id):\n",
    "    self.data = []\n",
    "    self.target = []\n",
    "    self.id = worker_id\n",
    "    for data in dataset.take(len(dataset)):\n",
    "      self.data.append(torch.tensor([data['pixels'].numpy()]))\n",
    "      self.target.append(torch.tensor(data['label'].numpy().astype(np.int64)))\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.data[index],self.target[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/federated_trainset_femnist.pickle', 'rb') as f:\n",
    "    all_federated_trainset = pickle.load(f)\n",
    "with open('../data/federated_testset_femnist.pickle', 'rb') as f:\n",
    "    all_federated_testset = pickle.load(f)\n",
    "all_worker_num = len(all_federated_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2619, 456, 102, 3037, 1126, 1003, 914, 571, 3016, 419, 2771, 3033, 2233, 356, 2418, 1728, 130, 122, 383, 895]\n"
     ]
    }
   ],
   "source": [
    "worker_id_list = random.sample(range(all_worker_num),args.worker_num)\n",
    "print(worker_id_list)\n",
    "federated_trainset = []\n",
    "federated_testset = []\n",
    "for i in worker_id_list:\n",
    "    federated_trainset.append(all_federated_trainset[i])\n",
    "    federated_testset.append(all_federated_testset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_valset = [None]*args.worker_num\n",
    "for i in range(args.worker_num):\n",
    "  n_samples = len(federated_trainset[i])\n",
    "  if n_samples==1:\n",
    "    federated_valset[i] = copy.deepcopy(federated_trainset[i])\n",
    "  else:\n",
    "    train_size = int(len(federated_trainset[i]) * 0.7) \n",
    "    val_size = n_samples - train_size \n",
    "    federated_trainset[i],federated_valset[i] = torch.utils.data.random_split(federated_trainset[i], [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "ZU3vAAb9-6SD"
   },
   "outputs": [],
   "source": [
    "class CNN1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(5408, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "class CNN2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(9216, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "class CNN3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(15488, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "    \n",
    "class CNN4(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN4, self).__init__()\n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv2d_4 = torch.nn.Conv2d(128, 256, kernel_size=3)\n",
    "        self.dropout_1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_1 = nn.Linear(25600, 128)\n",
    "        self.dropout_2 = nn.Dropout(0.5)\n",
    "        self.linear_2 = nn.Linear(128,62)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.conv2d_3(x)\n",
    "        x = self.conv2d_4(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Yu90X1TWJVKJ"
   },
   "outputs": [],
   "source": [
    "class Server():\n",
    "  def __init__(self):\n",
    "    self.model = CNN2()\n",
    "\n",
    "  def create_worker(self,federated_trainset,federated_valset,federated_testset):\n",
    "    workers = []\n",
    "    for i in range(args.worker_num):\n",
    "      workers.append(Worker(federated_trainset[i],federated_valset[i],federated_testset[i]))\n",
    "    return workers\n",
    "\n",
    "  def sample_worker(self,workers):\n",
    "    sample_worker = []\n",
    "    sample_worker_num = random.sample(range(args.worker_num),args.sample_num)\n",
    "    for i in sample_worker_num:\n",
    "      sample_worker.append(workers[i])\n",
    "    return sample_worker\n",
    "\n",
    "\n",
    "  def send_model(self,workers):\n",
    "    nums = 0\n",
    "    for worker in workers:\n",
    "      nums += worker.train_data_num\n",
    "\n",
    "    for worker in workers:\n",
    "      worker.aggregation_weight = 1.0*worker.train_data_num/nums\n",
    "      worker.model = copy.deepcopy(self.model)\n",
    "      worker.model = worker.model.to(args.device)\n",
    "\n",
    "  def aggregate_model(self,workers):   \n",
    "    new_params = OrderedDict()\n",
    "    for i,worker in enumerate(workers):\n",
    "      worker_state = worker.model.state_dict()\n",
    "      for key in worker_state.keys():\n",
    "        if i==0:\n",
    "          new_params[key] = worker_state[key]*worker.aggregation_weight\n",
    "        else:\n",
    "          new_params[key] += worker_state[key]*worker.aggregation_weight\n",
    "      worker.model = worker.model.to('cpu')\n",
    "      del worker.model\n",
    "    self.model.load_state_dict(new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "LDWEBjgfJYFc"
   },
   "outputs": [],
   "source": [
    "class Worker():\n",
    "  def __init__(self,trainset,valset,testset):\n",
    "    self.trainloader = torch.utils.data.DataLoader(trainset,batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.valloader = torch.utils.data.DataLoader(valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.testloader = torch.utils.data.DataLoader(testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.model = None\n",
    "    self.train_data_num = len(trainset)\n",
    "    self.test_data_num = len(testset)\n",
    "    self.aggregation_weight = None\n",
    "\n",
    "  def local_train(self):\n",
    "    acc_train,loss_train = train(self.model,args.criterion,self.trainloader,args.local_epochs)\n",
    "    acc_valid,loss_valid = test(self.model,args.criterion,self.valloader)\n",
    "    return acc_train,loss_train,acc_valid,loss_valid\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "7-GY66gROuEU"
   },
   "outputs": [],
   "source": [
    "def train(model,criterion,trainloader,epochs):\n",
    "  optimizer = optim.SGD(model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "  model.train()\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for (data,labels) in trainloader:\n",
    "      data,labels = Variable(data),Variable(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      count += len(labels)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "      optimizer.step()\n",
    "\n",
    "  return 100.0*correct/count,running_loss/len(trainloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "oA4URv9mQ3xV"
   },
   "outputs": [],
   "source": [
    "def test(model,criterion,testloader):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  count = 0\n",
    "  for (data,labels) in testloader:\n",
    "    data,labels = data.to(args.device),labels.to(args.device)\n",
    "    outputs = model(data)\n",
    "    running_loss += criterion(outputs,labels).item()\n",
    "    predicted = torch.argmax(outputs,dim=1)\n",
    "    correct += (predicted==labels).sum().item()\n",
    "    count += len(labels)\n",
    "\n",
    "  accuracy = 100.0*correct/count\n",
    "  loss = running_loss/len(testloader)\n",
    "\n",
    "\n",
    "  return accuracy,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "WMO7_WSLHeGl"
   },
   "outputs": [],
   "source": [
    "class Early_Stopping():\n",
    "  def __init__(self,partience):\n",
    "    self.step = 0\n",
    "    self.loss = float('inf')\n",
    "    self.partience = partience\n",
    "\n",
    "  def validate(self,loss):\n",
    "    if self.loss<loss:\n",
    "      self.step += 1\n",
    "      if self.step>self.partience:\n",
    "        return True\n",
    "    else:\n",
    "      self.step = 0\n",
    "      self.loss = loss\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "-noG_98IR-nZ",
    "outputId": "78a6ebe2-854a-4f83-dc45-5c4ac35b69e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1  loss:3.991999185085297  accuracy:4.837568947141925\n",
      "Epoch2  loss:3.896000647544861  accuracy:5.676406166527012\n",
      "Epoch3  loss:3.817688703536987  accuracy:6.156123506871529\n",
      "Epoch4  loss:3.7792619228363034  accuracy:5.842471396472004\n",
      "Epoch5  loss:3.747075366973877  accuracy:6.165615146725727\n",
      "Epoch6  loss:3.727268695831298  accuracy:6.187896153100055\n",
      "Epoch7  loss:3.70428203344345  accuracy:6.026246578785733\n",
      "Epoch8  loss:3.7050479054450998  accuracy:7.211237740364301\n",
      "Epoch9  loss:3.6906812906265256  accuracy:6.962124614114873\n",
      "Epoch10  loss:3.6829524874687194  accuracy:6.513399522460415\n",
      "Epoch11  loss:3.685239803791046  accuracy:6.907495612064233\n",
      "Epoch12  loss:3.683282315731049  accuracy:6.769938263543429\n",
      "Epoch13  loss:3.6716830730438232  accuracy:7.0810850187895635\n",
      "Epoch14  loss:3.6805065393447873  accuracy:7.715754803501799\n",
      "Epoch15  loss:3.671628868579864  accuracy:6.246049109219492\n",
      "Epoch16  loss:3.664927935600281  accuracy:7.210918471965497\n",
      "Epoch17  loss:3.6609030842781065  accuracy:5.820768264377482\n",
      "Epoch18  loss:3.660692775249481  accuracy:7.05723290191419\n",
      "Epoch19  loss:3.6547550082206732  accuracy:6.175288358262294\n",
      "Epoch20  loss:3.650274908542633  accuracy:7.900336372195362\n",
      "Epoch21  loss:3.6505022644996643  accuracy:5.894723071558052\n",
      "Epoch22  loss:3.6426930546760565  accuracy:7.728423942054209\n",
      "Epoch23  loss:3.6452654004096985  accuracy:7.212309838997378\n",
      "Epoch24  loss:3.6339003920555113  accuracy:6.782434768110767\n",
      "Epoch25  loss:3.6319106101989744  accuracy:6.400698270224278\n",
      "Epoch26  loss:3.623711335659027  accuracy:6.545610268794814\n",
      "Epoch27  loss:3.633827662467957  accuracy:6.1904551934493535\n",
      "Epoch28  loss:3.6322266936302183  accuracy:6.562007153529748\n",
      "Epoch29  loss:3.62112649679184  accuracy:6.875869599288429\n",
      "Epoch30  loss:3.616952300071717  accuracy:7.0555176533913535\n",
      "Epoch31  loss:3.6098807454109196  accuracy:7.27843969388879\n",
      "Epoch32  loss:3.6160008430480954  accuracy:6.348197351353572\n",
      "Epoch33  loss:3.607159519195557  accuracy:8.9500804939705\n",
      "Epoch34  loss:3.5974166989326473  accuracy:8.127599107119135\n",
      "Epoch35  loss:3.5985050559043876  accuracy:6.891778324215197\n",
      "Epoch36  loss:3.5902804255485536  accuracy:8.940083270107895\n",
      "Epoch37  loss:3.585946500301361  accuracy:7.910473043735872\n",
      "Epoch38  loss:3.574857127666473  accuracy:8.244777073118154\n",
      "Epoch39  loss:3.571133160591126  accuracy:8.573703676689846\n",
      "Epoch40  loss:3.568211889266968  accuracy:8.862443921951828\n",
      "Epoch41  loss:3.5642900347709654  accuracy:8.133993008979367\n",
      "Epoch42  loss:3.552042210102081  accuracy:9.120804901055877\n",
      "Epoch43  loss:3.5384468078613276  accuracy:10.1963472415752\n",
      "Epoch44  loss:3.534304869174957  accuracy:9.66183068747793\n",
      "Epoch45  loss:3.5284389615058904  accuracy:10.205106261054725\n",
      "Epoch46  loss:3.5203079223632807  accuracy:9.62918197670557\n",
      "Epoch47  loss:3.5008946061134343  accuracy:10.12667701973521\n",
      "Epoch48  loss:3.4925165534019467  accuracy:10.961877485713595\n",
      "Epoch49  loss:3.4822491645812987  accuracy:11.994887956761342\n",
      "Epoch50  loss:3.4653655290603647  accuracy:12.336050399195463\n",
      "Epoch51  loss:3.4560412764549255  accuracy:12.615738652871604\n",
      "Epoch52  loss:3.4485391259193414  accuracy:12.153170322679058\n",
      "Epoch53  loss:3.421495187282562  accuracy:14.204748205453791\n",
      "Epoch54  loss:3.4180184960365296  accuracy:13.902817804389878\n",
      "Epoch55  loss:3.3898372530937197  accuracy:15.13963434694355\n",
      "Epoch56  loss:3.3610165715217586  accuracy:14.412115947983652\n",
      "Epoch57  loss:3.3648512125015255  accuracy:15.880534861933446\n",
      "Epoch58  loss:3.3284993052482608  accuracy:18.336551355672427\n",
      "Epoch59  loss:3.2985500216484076  accuracy:17.498250966315116\n",
      "Epoch60  loss:3.2896376729011534  accuracy:19.209068970528946\n",
      "Epoch61  loss:3.259207117557525  accuracy:18.038663338053286\n",
      "Epoch62  loss:3.2340197205543513  accuracy:19.108791143032178\n",
      "Epoch63  loss:3.2055299520492553  accuracy:20.92293881938379\n",
      "Epoch64  loss:3.17270770072937  accuracy:21.013435440047388\n",
      "Epoch65  loss:3.139653015136718  accuracy:24.378340150694896\n",
      "Epoch66  loss:3.1032392024993896  accuracy:24.015999974602824\n",
      "Epoch67  loss:3.0970817923545835  accuracy:22.011575025327062\n",
      "Epoch68  loss:3.0603760838508607  accuracy:26.3816767209188\n",
      "Epoch69  loss:3.038214659690857  accuracy:29.06392605615602\n",
      "Epoch70  loss:3.0093149662017824  accuracy:29.61897967898526\n",
      "Epoch71  loss:2.9760312676429748  accuracy:29.079213919817857\n",
      "Epoch72  loss:2.93005702495575  accuracy:32.0021969771308\n",
      "Epoch73  loss:2.9183982133865354  accuracy:30.837376201428558\n",
      "Epoch74  loss:2.8874986529350286  accuracy:30.589861165115654\n",
      "Epoch75  loss:2.8291999578475955  accuracy:36.08754932075106\n",
      "Epoch76  loss:2.8108780264854434  accuracy:36.27854902503776\n",
      "Epoch77  loss:2.7740466594696045  accuracy:36.91401981994687\n",
      "Epoch78  loss:2.7534857153892522  accuracy:37.03788363533512\n",
      "Epoch79  loss:2.7186323046684264  accuracy:39.29691724898628\n",
      "Epoch80  loss:2.6880475282669063  accuracy:37.63182634223844\n",
      "Epoch81  loss:2.656075727939606  accuracy:40.32308659294431\n",
      "Epoch82  loss:2.632797455787659  accuracy:39.12967424268027\n",
      "Epoch83  loss:2.600385534763336  accuracy:43.42473286649833\n",
      "Epoch84  loss:2.5669212102890016  accuracy:43.1622587081861\n",
      "Epoch85  loss:2.545982468128204  accuracy:42.337153378748255\n",
      "Epoch86  loss:2.5083707094192507  accuracy:44.113219386207696\n",
      "Epoch87  loss:2.474001479148865  accuracy:45.832220447555265\n",
      "Epoch88  loss:2.4653192758560185  accuracy:46.028372159389846\n",
      "Epoch89  loss:2.4217534124851228  accuracy:47.114468582828444\n",
      "Epoch90  loss:2.3944296360015866  accuracy:47.475811550910784\n",
      "Epoch91  loss:2.370326817035675  accuracy:49.15513459552967\n",
      "Epoch92  loss:2.3402024447917937  accuracy:49.065987797012475\n",
      "Epoch93  loss:2.326132047176361  accuracy:48.40135417527343\n",
      "Epoch94  loss:2.3062560975551607  accuracy:49.568946370756045\n",
      "Epoch95  loss:2.259744209051132  accuracy:52.09869838088376\n",
      "Epoch96  loss:2.2451038658618927  accuracy:53.1881076325265\n",
      "Epoch97  loss:2.2183354735374445  accuracy:52.874801679245444\n",
      "Epoch98  loss:2.191352039575577  accuracy:53.078832547697026\n",
      "Epoch99  loss:2.1709177076816557  accuracy:53.75830900383122\n",
      "Epoch100  loss:2.1640382170677186  accuracy:52.560158900609956\n",
      "Epoch101  loss:2.1454521477222444  accuracy:53.724985275589404\n",
      "Epoch102  loss:2.123916721343994  accuracy:53.13109984719689\n",
      "Epoch103  loss:2.1004978001117705  accuracy:54.390445142278\n",
      "Epoch104  loss:2.071910351514816  accuracy:55.03400653751195\n",
      "Epoch105  loss:2.0428530871868134  accuracy:55.555901878876206\n",
      "Epoch106  loss:2.041970652341843  accuracy:55.654340750836425\n",
      "Epoch107  loss:2.017086493968964  accuracy:56.95678300822591\n",
      "Epoch108  loss:2.0015377700328827  accuracy:57.13618985744366\n",
      "Epoch109  loss:1.9891470789909358  accuracy:56.839154301598775\n",
      "Epoch110  loss:1.9640334427356716  accuracy:56.22484845244548\n",
      "Epoch111  loss:1.949876725673676  accuracy:56.383816874065\n",
      "Epoch112  loss:1.936122232675552  accuracy:57.58162331880172\n",
      "Epoch113  loss:1.9210867762565615  accuracy:58.083423332067426\n",
      "Epoch114  loss:1.9021178066730497  accuracy:57.66870579575429\n",
      "Epoch115  loss:1.8921902179718018  accuracy:58.92413454815867\n",
      "Epoch116  loss:1.8678845703601838  accuracy:58.73843341064826\n",
      "Epoch117  loss:1.8406868755817416  accuracy:58.533639067154056\n",
      "Epoch118  loss:1.8469062387943265  accuracy:58.889755777733264\n",
      "Epoch119  loss:1.8187002718448637  accuracy:59.48211152950907\n",
      "Epoch120  loss:1.8023768782615661  accuracy:58.36695206313302\n",
      "Epoch121  loss:1.805840826034546  accuracy:59.13011661534468\n",
      "Epoch122  loss:1.7832195639610293  accuracy:59.46721214398408\n",
      "Epoch123  loss:1.773112738132477  accuracy:60.19541946294568\n",
      "Epoch124  loss:1.7534138917922972  accuracy:60.1421072351375\n",
      "Epoch125  loss:1.747198349237442  accuracy:60.373866024082204\n",
      "Epoch126  loss:1.7286820650100705  accuracy:60.86094292096459\n",
      "Epoch127  loss:1.7313550889492033  accuracy:60.87914934875385\n",
      "Epoch128  loss:1.7099718809127809  accuracy:61.58361552937421\n",
      "Epoch129  loss:1.702129566669464  accuracy:61.53911722923702\n",
      "Epoch130  loss:1.684786307811737  accuracy:61.45356152043454\n",
      "Epoch131  loss:1.6866591870784764  accuracy:61.203653178185284\n",
      "Epoch132  loss:1.6731942951679228  accuracy:60.3540119698166\n",
      "Epoch133  loss:1.6449955940246581  accuracy:62.63386364292535\n",
      "Epoch134  loss:1.6323210656642915  accuracy:62.02068609016158\n",
      "Epoch135  loss:1.6262432754039764  accuracy:62.39830943283734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch136  loss:1.6265403747558593  accuracy:62.64216679319585\n",
      "Epoch137  loss:1.6072122454643252  accuracy:62.138876018116484\n",
      "Epoch138  loss:1.5986374497413636  accuracy:62.80107630651581\n",
      "Epoch139  loss:1.5804342210292814  accuracy:63.31705246257577\n",
      "Epoch140  loss:1.5740407764911648  accuracy:63.44010345774331\n",
      "Epoch141  loss:1.5717752635478976  accuracy:63.265797552925854\n",
      "Epoch142  loss:1.5469716489315033  accuracy:63.89711010754093\n",
      "Epoch143  loss:1.544756144285202  accuracy:64.36679688417813\n",
      "Epoch144  loss:1.5423519730567932  accuracy:63.91269258293166\n",
      "Epoch145  loss:1.5411623418331148  accuracy:63.69094240278793\n",
      "Epoch146  loss:1.5205180644989011  accuracy:63.753893334270884\n",
      "Epoch147  loss:1.5059996485710145  accuracy:64.83133084691882\n",
      "Epoch148  loss:1.499684923887253  accuracy:64.87217288619921\n",
      "Epoch149  loss:1.4942011535167692  accuracy:64.14862909394087\n",
      "Epoch150  loss:1.4899069160223006  accuracy:64.26220381743828\n",
      "Epoch151  loss:1.4821888029575347  accuracy:64.10380452575383\n",
      "Epoch152  loss:1.4660194039344785  accuracy:65.79347410247328\n",
      "Epoch153  loss:1.4570545554161072  accuracy:65.56327113441681\n",
      "Epoch154  loss:1.4517710059881213  accuracy:65.72411958728858\n",
      "Epoch155  loss:1.440586373209953  accuracy:65.39802421720343\n",
      "Epoch156  loss:1.4339757561683657  accuracy:66.65318142483386\n",
      "Epoch157  loss:1.4258673310279844  accuracy:66.01276415308737\n",
      "Epoch158  loss:1.4257390648126602  accuracy:66.0224636712884\n",
      "Epoch159  loss:1.416677576303482  accuracy:65.94407323330438\n",
      "Epoch160  loss:1.397736319899559  accuracy:67.11649328623267\n",
      "Epoch161  loss:1.398831018805504  accuracy:66.20849295645857\n",
      "Epoch162  loss:1.396031552553177  accuracy:66.31409650334692\n",
      "Epoch163  loss:1.377972891926765  accuracy:66.48319373846176\n",
      "Epoch164  loss:1.374425825476646  accuracy:66.4091418890004\n",
      "Epoch165  loss:1.3749564349651335  accuracy:67.04837706607056\n",
      "Epoch166  loss:1.3636988848447802  accuracy:67.13829527249723\n",
      "Epoch167  loss:1.3581344574689866  accuracy:67.41111581536357\n",
      "Epoch168  loss:1.3575262069702148  accuracy:65.9646928614779\n",
      "Epoch169  loss:1.339312627911568  accuracy:67.40076036180261\n",
      "Epoch170  loss:1.3326670110225678  accuracy:67.81290583628594\n",
      "Epoch171  loss:1.3290684312582015  accuracy:67.57976071277298\n",
      "Epoch172  loss:1.3169543296098707  accuracy:67.62238807059835\n",
      "Epoch173  loss:1.3001754015684126  accuracy:67.98472209687958\n",
      "Epoch174  loss:1.3081309288740157  accuracy:67.16313558448701\n",
      "Epoch175  loss:1.2972931653261184  accuracy:68.83211717348391\n",
      "Epoch176  loss:1.2965518325567245  accuracy:68.25477369969222\n",
      "Epoch177  loss:1.2890692919492721  accuracy:68.2808899333624\n",
      "Epoch178  loss:1.275127324461937  accuracy:69.18629365519654\n",
      "Epoch179  loss:1.2740448564291  accuracy:68.25979938299321\n",
      "Epoch180  loss:1.2670963793992995  accuracy:68.8277873807334\n",
      "Epoch181  loss:1.2499268531799317  accuracy:69.61290644188084\n",
      "Epoch182  loss:1.2607242971658703  accuracy:68.8783999680368\n",
      "Epoch183  loss:1.2486340999603274  accuracy:68.80460468617065\n",
      "Epoch184  loss:1.2433110505342484  accuracy:68.7901582616781\n",
      "Epoch185  loss:1.2366776138544084  accuracy:69.79692632967635\n",
      "Epoch186  loss:1.2267900198698047  accuracy:69.2011871958448\n",
      "Epoch187  loss:1.2268251985311507  accuracy:69.50672534266705\n",
      "Epoch188  loss:1.2278592497110368  accuracy:68.79696217321205\n",
      "Epoch189  loss:1.2157590210437779  accuracy:69.52198751891079\n",
      "Epoch190  loss:1.2096540063619614  accuracy:69.46285191826112\n",
      "Epoch191  loss:1.214272516965866  accuracy:69.34916059547544\n",
      "Epoch192  loss:1.2052994281053542  accuracy:70.20621165977997\n",
      "Epoch193  loss:1.1929966807365417  accuracy:69.6205313939855\n",
      "Epoch194  loss:1.1840113192796706  accuracy:70.11676447329606\n",
      "Epoch195  loss:1.1907605081796646  accuracy:70.26543034486066\n",
      "Epoch196  loss:1.1930117726325986  accuracy:69.92563463662634\n",
      "Epoch197  loss:1.1741098046302796  accuracy:70.50209706381035\n",
      "Epoch198  loss:1.1743961125612261  accuracy:70.84883151235195\n",
      "Epoch199  loss:1.1670368552207946  accuracy:70.46139616270197\n",
      "Epoch200  loss:1.1697621524333954  accuracy:69.80411712168275\n",
      "Epoch201  loss:1.1645404607057572  accuracy:70.3632145403129\n",
      "Epoch202  loss:1.1587831586599353  accuracy:70.3563442931291\n",
      "Epoch203  loss:1.15049574971199  accuracy:70.1687809839974\n",
      "Epoch204  loss:1.144507050514221  accuracy:71.0110208992593\n",
      "Epoch205  loss:1.1408469378948214  accuracy:70.6621545797076\n",
      "Epoch206  loss:1.1324125945568084  accuracy:70.96990651361754\n",
      "Epoch207  loss:1.138386708498001  accuracy:71.19186393132041\n",
      "Epoch208  loss:1.127403512597084  accuracy:71.02350522292573\n",
      "Epoch209  loss:1.1156899005174634  accuracy:71.07929213806891\n",
      "Epoch210  loss:1.1249353140592573  accuracy:70.94900715114176\n",
      "Epoch211  loss:1.1221011310815812  accuracy:70.88718361819028\n",
      "Epoch212  loss:1.104655310511589  accuracy:72.04518465167803\n",
      "Epoch213  loss:1.108543121814728  accuracy:70.72795414138353\n",
      "Epoch214  loss:1.0991654753684996  accuracy:71.5348705861032\n",
      "Epoch215  loss:1.0900342732667923  accuracy:71.38108273854405\n",
      "Epoch216  loss:1.0977814197540283  accuracy:71.17214230168331\n",
      "Epoch217  loss:1.0868131488561632  accuracy:71.54069008807652\n",
      "Epoch218  loss:1.0973482429981232  accuracy:71.2431528124908\n",
      "Epoch219  loss:1.0770672500133514  accuracy:71.64513485168534\n",
      "Epoch220  loss:1.0798458814620973  accuracy:71.30829279487479\n",
      "Epoch221  loss:1.0801211982965468  accuracy:71.91549920659264\n",
      "Epoch222  loss:1.0727430462837217  accuracy:71.59820031098583\n",
      "Epoch223  loss:1.0835856318473815  accuracy:71.41147663124545\n",
      "Epoch224  loss:1.072153842449188  accuracy:71.53567835439783\n",
      "Epoch225  loss:1.0700812697410582  accuracy:72.17980658596355\n",
      "Epoch226  loss:1.0654010474681856  accuracy:71.86320673123232\n",
      "Epoch227  loss:1.0351610779762268  accuracy:72.85945400201693\n",
      "Epoch228  loss:1.067895457148552  accuracy:72.13875042197498\n",
      "Epoch229  loss:1.0424218088388444  accuracy:73.03085227472602\n",
      "Epoch230  loss:1.055731761455536  accuracy:72.3111820584444\n",
      "Epoch231  loss:1.0275933742523196  accuracy:73.0605659828761\n",
      "Epoch232  loss:1.0516788333654403  accuracy:71.7637445633236\n",
      "Epoch233  loss:1.0350110709667206  accuracy:71.35806158878096\n",
      "Epoch234  loss:1.0302964508533476  accuracy:72.67558823498743\n",
      "Epoch235  loss:1.0320912539958953  accuracy:72.89879060726602\n",
      "Epoch236  loss:1.0203005611896514  accuracy:73.69185877991751\n",
      "Epoch237  loss:1.016731309890747  accuracy:73.11234873630023\n",
      "Epoch238  loss:1.0242442071437836  accuracy:72.62111227897326\n",
      "Epoch239  loss:1.0225633054971697  accuracy:72.69545882958751\n",
      "Epoch240  loss:1.0171104490756988  accuracy:72.66987189320373\n",
      "Epoch241  loss:1.0109154462814331  accuracy:73.29982205032354\n",
      "Epoch242  loss:1.0095923542976382  accuracy:73.31503164994405\n",
      "Epoch243  loss:0.9910098850727083  accuracy:73.41198524102393\n",
      "Epoch244  loss:1.003134262561798  accuracy:73.16441121181508\n",
      "Epoch245  loss:0.991804164648056  accuracy:73.10061426949582\n",
      "Epoch246  loss:0.9871951758861541  accuracy:73.48325495718194\n",
      "Epoch247  loss:0.9931856721639636  accuracy:74.21874501297222\n",
      "Epoch248  loss:0.9856125235557556  accuracy:73.23638716682873\n",
      "Epoch249  loss:0.9914853572845459  accuracy:73.15861970318717\n",
      "Epoch250  loss:0.9819485157728195  accuracy:73.76085680058024\n",
      "Epoch251  loss:0.9759289532899857  accuracy:73.9209398898554\n",
      "Epoch252  loss:0.9766150951385499  accuracy:73.91596359446991\n",
      "Epoch253  loss:0.9830503523349761  accuracy:72.99119185962289\n",
      "Epoch254  loss:0.9692800313234331  accuracy:73.78226420302023\n",
      "Epoch255  loss:0.9846413135528564  accuracy:73.64805069394227\n",
      "Epoch256  loss:0.9692356854677201  accuracy:73.69720054637317\n",
      "Epoch257  loss:0.9706025689840316  accuracy:73.2026071620403\n",
      "Epoch258  loss:0.9577770978212358  accuracy:74.17377180008818\n",
      "Epoch259  loss:0.9677179247140884  accuracy:72.7880036935538\n",
      "Epoch260  loss:0.957270833849907  accuracy:73.66941257640984\n",
      "Epoch261  loss:0.9624804973602296  accuracy:73.39458783482753\n",
      "Epoch262  loss:0.9566514045000075  accuracy:74.19213651157307\n",
      "Epoch263  loss:0.9511433660984039  accuracy:73.58750211732074\n",
      "Epoch264  loss:0.9621692955493928  accuracy:72.97176757342433\n",
      "Epoch265  loss:0.9364222943782807  accuracy:73.87820343649959\n",
      "Epoch266  loss:0.9497250705957413  accuracy:74.13659849999543\n",
      "Epoch267  loss:0.9437281847000123  accuracy:74.63008909594927\n",
      "Epoch268  loss:0.9451036512851716  accuracy:74.24663904806098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch269  loss:0.937289386987686  accuracy:74.05430409113039\n",
      "Epoch270  loss:0.9349562019109725  accuracy:74.07491865981089\n",
      "Epoch271  loss:0.9286262214183807  accuracy:74.0988442196101\n",
      "Epoch272  loss:0.9240083515644073  accuracy:74.41952339776299\n",
      "Epoch273  loss:0.930867812037468  accuracy:74.76974423448681\n",
      "Epoch274  loss:0.9233167976140976  accuracy:74.57961207092569\n",
      "Epoch275  loss:0.9190049469470978  accuracy:74.79653982108178\n",
      "Epoch276  loss:0.9272795408964158  accuracy:74.31349132185868\n",
      "Epoch277  loss:0.9274469763040541  accuracy:74.09418658697275\n",
      "Epoch278  loss:0.9210182964801789  accuracy:75.06100681673992\n",
      "Epoch279  loss:0.9140280783176423  accuracy:74.91652442870874\n",
      "Epoch280  loss:0.9267109632492065  accuracy:74.42715497533453\n",
      "Epoch281  loss:0.9161523461341858  accuracy:74.35520348683016\n",
      "Epoch282  loss:0.9246771425008774  accuracy:75.0096971641778\n",
      "Epoch283  loss:0.9105062812566758  accuracy:74.51596444504435\n",
      "Epoch284  loss:0.9095922380685807  accuracy:75.02605021049109\n",
      "Epoch285  loss:0.9111940681934356  accuracy:74.07423470803528\n",
      "Epoch286  loss:0.9071974575519562  accuracy:74.77309453602372\n",
      "Epoch287  loss:0.9020712852478027  accuracy:75.12077285728593\n",
      "Epoch288  loss:0.8955424040555954  accuracy:74.710396410563\n",
      "Epoch289  loss:0.9005705416202547  accuracy:74.93665516547166\n",
      "Epoch290  loss:0.9102154836058616  accuracy:75.45603940701555\n",
      "Epoch291  loss:0.9128455191850662  accuracy:74.79696783415923\n",
      "Epoch292  loss:0.8939290821552278  accuracy:74.91811945342204\n",
      "Epoch293  loss:0.888403905928135  accuracy:74.99528752241793\n",
      "Epoch294  loss:0.8986959815025333  accuracy:75.0535891573478\n",
      "Epoch295  loss:0.8869371980428696  accuracy:75.17537724054931\n",
      "Epoch296  loss:0.8819435939192771  accuracy:75.12333084279501\n",
      "Epoch297  loss:0.8907915800809861  accuracy:74.77919507810455\n",
      "Epoch298  loss:0.8859923720359802  accuracy:75.1022321528603\n",
      "Epoch299  loss:0.8815634131431578  accuracy:75.13611582476916\n",
      "Epoch300  loss:0.896135500073433  accuracy:75.0873021556299\n"
     ]
    }
   ],
   "source": [
    "server = Server()\n",
    "workers = server.create_worker(federated_trainset,federated_valset,federated_testset)\n",
    "acc_train = []\n",
    "loss_train = []\n",
    "acc_valid = []\n",
    "loss_valid = []\n",
    "\n",
    "early_stopping = Early_Stopping(args.partience)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(args.global_epochs):\n",
    "  sample_worker = server.sample_worker(workers)\n",
    "  server.send_model(sample_worker)\n",
    "\n",
    "  acc_train_avg = 0.0\n",
    "  loss_train_avg = 0.0\n",
    "  acc_valid_avg = 0.0\n",
    "  loss_valid_avg = 0.0\n",
    "  for worker in sample_worker:\n",
    "    acc_train_tmp,loss_train_tmp,acc_valid_tmp,loss_valid_tmp = worker.local_train()\n",
    "    acc_train_avg += acc_train_tmp/len(sample_worker)\n",
    "    loss_train_avg += loss_train_tmp/len(sample_worker)\n",
    "    acc_valid_avg += acc_valid_tmp/len(sample_worker)\n",
    "    loss_valid_avg += loss_valid_tmp/len(sample_worker)\n",
    "  server.aggregate_model(sample_worker)\n",
    "  '''\n",
    "  server.model.to(args.device)\n",
    "  for worker in workers:\n",
    "    acc_valid_tmp,loss_valid_tmp = test(server.model,args.criterion,worker.valloader)\n",
    "    acc_valid_avg += acc_valid_tmp/len(workers)\n",
    "    loss_valid_avg += loss_valid_tmp/len(workers)\n",
    "  server.model.to('cpu')\n",
    "  '''\n",
    "  print('Epoch{}  loss:{}  accuracy:{}'.format(epoch+1,loss_valid_avg,acc_valid_avg))\n",
    "  acc_train.append(acc_train_avg)\n",
    "  loss_train.append(loss_train_avg)\n",
    "  acc_valid.append(acc_valid_avg)\n",
    "  loss_valid.append(loss_valid_avg)\n",
    "\n",
    "  if early_stopping.validate(loss_valid_avg):\n",
    "    print('Early Stop')\n",
    "    break\n",
    "    \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "mi_uceyoptLP",
    "outputId": "bc067e09-01bc-4e65-daf9-ac2f42373cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:70.58823529411765  loss:1.0342817306518555\n",
      "Worker2 accuracy:85.71428571428571  loss:0.4366610646247864\n",
      "Worker3 accuracy:72.5  loss:0.9161068797111511\n",
      "Worker4 accuracy:66.66666666666667  loss:1.6200659275054932\n",
      "Worker5 accuracy:82.3529411764706  loss:0.6161081790924072\n",
      "Worker6 accuracy:76.19047619047619  loss:0.6697072386741638\n",
      "Worker7 accuracy:73.6842105263158  loss:0.9483001232147217\n",
      "Worker8 accuracy:78.125  loss:0.6947300434112549\n",
      "Worker9 accuracy:31.57894736842105  loss:2.149538516998291\n",
      "Worker10 accuracy:78.04878048780488  loss:0.7790355086326599\n",
      "Worker11 accuracy:55.55555555555556  loss:1.6017330884933472\n",
      "Worker12 accuracy:73.6842105263158  loss:0.7236959338188171\n",
      "Worker13 accuracy:78.94736842105263  loss:0.7788953185081482\n",
      "Worker14 accuracy:63.333333333333336  loss:1.7813154458999634\n",
      "Worker15 accuracy:63.1578947368421  loss:0.7827916741371155\n",
      "Worker16 accuracy:70.58823529411765  loss:0.767959713935852\n",
      "Worker17 accuracy:69.6969696969697  loss:1.356797695159912\n",
      "Worker18 accuracy:64.51612903225806  loss:0.9062520265579224\n",
      "Worker19 accuracy:82.3529411764706  loss:0.94624263048172\n",
      "Worker20 accuracy:66.66666666666667  loss:1.288991093635559\n",
      "Test  loss:1.0399604916572571  accuracy:70.19744239320703\n"
     ]
    }
   ],
   "source": [
    "acc_test = []\n",
    "loss_test = []\n",
    "\n",
    "server.model.to(args.device)\n",
    "\n",
    "nums = 0\n",
    "for worker in workers:\n",
    "  nums += worker.test_data_num\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "  worker.aggregation_weight = 1.0*worker.test_data_num/nums\n",
    "  acc_tmp,loss_tmp = test(server.model,args.criterion,worker.testloader)\n",
    "  acc_test.append(acc_tmp)\n",
    "  loss_test.append(loss_tmp)\n",
    "  print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "acc_test_avg = sum(acc_test)/len(acc_test)\n",
    "loss_test_avg = sum(loss_test)/len(loss_test)\n",
    "print('Test  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 Valid accuracy:74.4186046511628  loss:0.7241300344467163\n",
      "Worker1 Test accuracy:82.3529411764706  loss:0.9369863867759705\n",
      "Worker2 Valid accuracy:85.1063829787234  loss:0.589558482170105\n",
      "Worker2 Test accuracy:85.71428571428571  loss:0.3438548743724823\n",
      "Worker3 Valid accuracy:69.52380952380952  loss:0.944478452205658\n",
      "Worker3 Test accuracy:82.5  loss:0.8113101124763489\n",
      "Worker4 Valid accuracy:76.08695652173913  loss:0.8718819618225098\n",
      "Worker4 Test accuracy:72.22222222222223  loss:1.3708428144454956\n",
      "Worker5 Valid accuracy:76.92307692307692  loss:0.692795991897583\n",
      "Worker5 Test accuracy:88.23529411764706  loss:0.47469061613082886\n",
      "Worker6 Valid accuracy:72.72727272727273  loss:0.9787224531173706\n",
      "Worker6 Test accuracy:71.42857142857143  loss:0.7181011438369751\n",
      "Worker7 Valid accuracy:81.0  loss:0.7959750890731812\n",
      "Worker7 Test accuracy:71.05263157894737  loss:0.9811251759529114\n",
      "Worker8 Valid accuracy:70.58823529411765  loss:0.9337114095687866\n",
      "Worker8 Test accuracy:75.0  loss:0.666111409664154\n",
      "Worker9 Valid accuracy:69.38775510204081  loss:1.0229748487472534\n",
      "Worker9 Test accuracy:57.89473684210526  loss:1.5124568939208984\n",
      "Worker10 Valid accuracy:82.56880733944953  loss:0.5908013582229614\n",
      "Worker10 Test accuracy:85.36585365853658  loss:0.547920286655426\n",
      "Worker11 Valid accuracy:58.69565217391305  loss:1.5616493225097656\n",
      "Worker11 Test accuracy:66.66666666666667  loss:1.3752468824386597\n",
      "Worker12 Valid accuracy:81.63265306122449  loss:0.5190411806106567\n",
      "Worker12 Test accuracy:78.94736842105263  loss:0.7610468864440918\n",
      "Worker13 Valid accuracy:75.51020408163265  loss:1.0515516996383667\n",
      "Worker13 Test accuracy:84.21052631578948  loss:0.7218244671821594\n",
      "Worker14 Valid accuracy:78.2051282051282  loss:0.977636456489563\n",
      "Worker14 Test accuracy:63.333333333333336  loss:1.9713270664215088\n",
      "Worker15 Valid accuracy:81.63265306122449  loss:0.7511224746704102\n",
      "Worker15 Test accuracy:78.94736842105263  loss:0.6826589703559875\n",
      "Worker16 Valid accuracy:80.0  loss:0.8580532670021057\n",
      "Worker16 Test accuracy:64.70588235294117  loss:0.7749234437942505\n",
      "Worker17 Valid accuracy:71.5909090909091  loss:0.8492691516876221\n",
      "Worker17 Test accuracy:72.72727272727273  loss:1.269315481185913\n",
      "Worker18 Valid accuracy:71.95121951219512  loss:1.1537705659866333\n",
      "Worker18 Test accuracy:70.96774193548387  loss:0.79142165184021\n",
      "Worker19 Valid accuracy:75.55555555555556  loss:0.8217066526412964\n",
      "Worker19 Test accuracy:76.47058823529412  loss:0.6222812533378601\n",
      "Worker20 Valid accuracy:66.66666666666667  loss:1.221513032913208\n",
      "Worker20 Test accuracy:66.66666666666667  loss:1.1513209342956543\n",
      "Validation(tune)  loss:0.8955171942710877  accuracy:74.9885771234921\n",
      "Test(tune)  loss:0.9242383375763893  accuracy:74.77049759071699\n"
     ]
    }
   ],
   "source": [
    "acc_tune_test = []\n",
    "loss_tune_test = []\n",
    "acc_tune_valid = []\n",
    "loss_tune_valid = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "    worker.model = copy.deepcopy(server.model)\n",
    "    worker.model = worker.model.to(args.device)\n",
    "    _,_,acc_tmp,loss_tmp = worker.local_train()\n",
    "    acc_tune_valid.append(acc_tmp)\n",
    "    loss_tune_valid.append(loss_tmp)\n",
    "    print('Worker{} Valid accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    \n",
    "    acc_tmp,loss_tmp = test(worker.model,args.criterion,worker.testloader)\n",
    "    acc_tune_test.append(acc_tmp)\n",
    "    loss_tune_test.append(loss_tmp)\n",
    "    print('Worker{} Test accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    worker.model = worker.model.to('cpu')\n",
    "    del worker.model\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "acc_valid_avg = sum(acc_tune_valid)/len(acc_tune_valid)\n",
    "loss_valid_avg = sum(loss_tune_valid)/len(loss_tune_valid)\n",
    "print('Validation(tune)  loss:{}  accuracy:{}'.format(loss_valid_avg,acc_valid_avg))\n",
    "acc_test_avg = sum(acc_tune_test)/len(acc_tune_test)\n",
    "loss_test_avg = sum(loss_tune_test)/len(loss_tune_test)\n",
    "print('Test(tune)  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FedAvg_femnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
