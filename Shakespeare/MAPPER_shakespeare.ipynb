{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "vkZxat4Y-IsQ",
    "outputId": "da86392c-66e8-4b60-b471-086e745cdcbc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from torch import nn, optim\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O0TfzOhU-QlG"
   },
   "outputs": [],
   "source": [
    "class Argments():\n",
    "  def __init__(self):\n",
    "    self.batch_size = 10\n",
    "    self.test_batch = 1000\n",
    "    self.global_epochs = 100\n",
    "    self.local_epochs = 2\n",
    "    self.lr = None\n",
    "    self.momentum = 0.9\n",
    "    self.weight_decay = 10**-4.0\n",
    "    self.clip = 20.0\n",
    "    self.partience = 100\n",
    "    self.worker_num = 20\n",
    "    self.sample_num = 20\n",
    "    self.device = device = torch.device('cuda:0'if torch.cuda.is_available() else'cpu')\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "args = Argments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(10**-3.0)\n",
    "lr_list.append(10**-2.5)\n",
    "lr_list.append(10**-2.0)\n",
    "lr_list.append(10**-1.5)\n",
    "lr_list.append(10**-1.0)\n",
    "lr_list.append(10**-0.5)\n",
    "lr_list.append(10**0.0)\n",
    "lr_list.append(10**0.5)\n",
    "\n",
    "args.lr = lr_list[lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r5PuCcqmJNUQ"
   },
   "outputs": [],
   "source": [
    "class LocalDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,dataset,worker_id):\n",
    "    self.data = []\n",
    "    self.target = []\n",
    "    self.id = worker_id\n",
    "    for i in range(len(dataset)):\n",
    "      self.data.append(dataset[i][0][0])\n",
    "      self.target.append(dataset[i][1][0])\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.data[index],self.target[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/federated_trainset_shakespeare.pickle', 'rb') as f:\n",
    "    all_federated_trainset = pickle.load(f)\n",
    "with open('../data/federated_testset_shakespeare.pickle', 'rb') as f:\n",
    "    all_federated_testset = pickle.load(f)\n",
    "all_worker_num = len(all_federated_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 6, 70, 62, 57, 35, 26, 139, 22, 108, 8, 7, 23, 55, 59, 129, 50, 107, 56, 114]\n"
     ]
    }
   ],
   "source": [
    "worker_id_list = random.sample(range(all_worker_num),args.worker_num)\n",
    "print(worker_id_list)\n",
    "federated_trainset = []\n",
    "federated_testset = []\n",
    "for i in worker_id_list:\n",
    "    federated_trainset.append(all_federated_trainset[i])\n",
    "    federated_testset.append(all_federated_testset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_valset = [None]*args.worker_num\n",
    "for i in range(args.worker_num):\n",
    "  n_samples = len(federated_trainset[i])\n",
    "  if n_samples==1:\n",
    "    federated_valset[i] = copy.deepcopy(federated_trainset[i])\n",
    "  else:\n",
    "    train_size = int(len(federated_trainset[i]) * 0.7) \n",
    "    val_size = n_samples - train_size \n",
    "    federated_trainset[i],federated_valset[i] = torch.utils.data.random_split(federated_trainset[i], [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZU3vAAb9-6SD"
   },
   "outputs": [],
   "source": [
    "class RNN1(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN1, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output\n",
    "\n",
    "class RNN2(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN2, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output\n",
    "\n",
    "class RNN3(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN3, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=3, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output\n",
    "    \n",
    "class RNN4(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN4, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=4, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Yu90X1TWJVKJ"
   },
   "outputs": [],
   "source": [
    "class Server():\n",
    "  def __init__(self):\n",
    "    self.global_model = RNN2()\n",
    " \n",
    "\n",
    "  def create_worker(self,federated_trainset,federated_valset,federated_testset):\n",
    "    workers = []\n",
    "    for i in range(args.worker_num):\n",
    "      workers.append(Worker(federated_trainset[i],federated_valset[i],federated_testset[i]))\n",
    "    return workers\n",
    "\n",
    "  def sample_worker(self,workers):\n",
    "    sample_worker = []\n",
    "    sample_num = random.sample(range(args.worker_num),args.sample_num)\n",
    "    for i in sample_num:\n",
    "      sample_worker.append(workers[i])\n",
    "    return sample_worker\n",
    "\n",
    "\n",
    "  def send_model(self,workers):\n",
    "    nums = 0\n",
    "    for worker in workers:\n",
    "      nums += worker.train_data_num\n",
    "\n",
    "    for worker in workers:\n",
    "      worker.aggregation_weight = 1.0*worker.train_data_num/nums\n",
    "      worker.global_model = copy.deepcopy(self.global_model)\n",
    "\n",
    "\n",
    "  def aggregate_model(self,workers):   \n",
    "    new_params = OrderedDict()\n",
    "    for i,worker in enumerate(workers):\n",
    "      worker_state = worker.global_model.state_dict()\n",
    "      for key in worker_state.keys():\n",
    "        if i==0:\n",
    "          new_params[key] = worker_state[key]*worker.aggregation_weight\n",
    "        else:\n",
    "          new_params[key] += worker_state[key]*worker.aggregation_weight\n",
    "      del worker.global_model \n",
    "    self.global_model.load_state_dict(new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LDWEBjgfJYFc"
   },
   "outputs": [],
   "source": [
    "class Worker():\n",
    "  def __init__(self,trainset,valset,testset):\n",
    "    self.train_data_num = len(trainset)\n",
    "    self.test_data_num = len(testset)\n",
    "    if len(trainset)<=2 :\n",
    "      trainset = [trainset,copy.deepcopy(trainset),copy.deepcopy(trainset)]\n",
    "    else:\n",
    "      split_len = [(len(trainset) + i) // 3 for i in range(3)]\n",
    "      trainset = torch.utils.data.random_split(trainset,split_len)\n",
    "    self.trainloader_local = torch.utils.data.DataLoader(trainset[0],batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.trainloader_lambda = torch.utils.data.DataLoader(trainset[1],batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.trainloader_global = torch.utils.data.DataLoader(trainset[2],batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.valloader = torch.utils.data.DataLoader(valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.testloader = torch.utils.data.DataLoader(testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.global_model = None\n",
    "    self.local_model = RNN2()\n",
    "    self.mix_model = None\n",
    "    self.lmd = None\n",
    "    self.aggregation_weight = None\n",
    "\n",
    "\n",
    "  def local_train(self):\n",
    "    loss = float('inf')\n",
    "    self.mix_model = RNN2()\n",
    "    model_tmp = RNN2()\n",
    "    for lmd in np.arange(0.0,1.1,0.1):\n",
    "      new_params = OrderedDict()\n",
    "      global_state = self.global_model.state_dict()\n",
    "      local_state = self.local_model.state_dict()\n",
    "      for key in global_state.keys():\n",
    "        new_params[key] = lmd*local_state[key] + (1.0-lmd)*global_state[key]     \n",
    "      model_tmp.load_state_dict(new_params)\n",
    "      model_tmp = model_tmp.to(args.device)\n",
    "      if lmd!=0.0:\n",
    "        _,_ = train(model_tmp,args.criterion,self.trainloader_local,args.local_epochs)\n",
    "\n",
    "      _,tmp = test(model_tmp,args.criterion,self.trainloader_lambda)\n",
    "      if tmp<loss:\n",
    "        loss = tmp\n",
    "        self.lmd = lmd\n",
    "        self.mix_model = copy.deepcopy(model_tmp)\n",
    "\n",
    "    if self.lmd!=0.0:\n",
    "      self.mix_model = self.mix_model.to('cpu')\n",
    "      new_params = OrderedDict()\n",
    "      mix_state = self.mix_model.state_dict()\n",
    "      global_state = self.global_model.state_dict()\n",
    "      for key in global_state.keys():\n",
    "        new_params[key] = (mix_state[key] - (1.0-self.lmd)*global_state[key])/self.lmd    \n",
    "      self.local_model.load_state_dict(new_params)\n",
    "      self.mix_model = self.mix_model.to(args.device)\n",
    "    \n",
    "    model_tmp = model_tmp.to('cpu')\n",
    "    del model_tmp\n",
    "\n",
    "\n",
    "  def global_train(self):\n",
    "    model_tmp = copy.deepcopy(self.mix_model)\n",
    "    model_tmp = model_tmp.to('cpu')\n",
    "    acc_train,loss_train = train(self.mix_model,args.criterion,self.trainloader_global,args.local_epochs)\n",
    "    acc_valid,loss_valid = test(self.mix_model,args.criterion,self.valloader)\n",
    "    self.mix_model = self.mix_model.to('cpu')\n",
    "    new_params = OrderedDict()\n",
    "    new_state = self.mix_model.state_dict()\n",
    "    old_state = model_tmp.state_dict()\n",
    "    global_state = self.global_model.state_dict()\n",
    "    for key in new_state.keys():\n",
    "        new_params[key] = global_state[key]+new_state[key]-old_state[key]  \n",
    "    self.global_model.load_state_dict(new_params)\n",
    "    del self.mix_model\n",
    "    del model_tmp\n",
    "    return acc_train,loss_train,acc_valid,loss_valid\n",
    "\n",
    "\n",
    "  def test_step(self):\n",
    "    self.local_train()\n",
    "    mix_model = RNN2()\n",
    "    new_params = OrderedDict()\n",
    "    global_state = self.global_model.state_dict()\n",
    "    local_state = self.local_model.state_dict()\n",
    "    for key in global_state.keys():\n",
    "      new_params[key] = self.lmd*local_state[key] + (1.0-self.lmd)*global_state[key]     \n",
    "    mix_model.load_state_dict(new_params)\n",
    "    mix_model = mix_model.to(args.device)\n",
    "    acc,loss = test(mix_model,args.criterion,self.testloader)\n",
    "    return acc,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7-GY66gROuEU"
   },
   "outputs": [],
   "source": [
    "def train(model,criterion,trainloader,epochs):\n",
    "  optimizer = optim.SGD(model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "  model.train()\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for (data,labels) in trainloader:\n",
    "      data,labels = Variable(data),Variable(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      count += len(labels)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "      optimizer.step()\n",
    "\n",
    "  return 100.0*correct/count,running_loss/len(trainloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "oA4URv9mQ3xV"
   },
   "outputs": [],
   "source": [
    "def test(model,criterion,testloader):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  count = 0\n",
    "  for (data,labels) in testloader:\n",
    "    data,labels = data.to(args.device),labels.to(args.device)\n",
    "    outputs = model(data)\n",
    "    running_loss += criterion(outputs,labels).item()\n",
    "    predicted = torch.argmax(outputs,dim=1)\n",
    "    correct += (predicted==labels).sum().item()\n",
    "    count += len(labels)\n",
    "\n",
    "  accuracy = 100.0*correct/count\n",
    "  loss = running_loss/len(testloader)\n",
    "\n",
    "\n",
    "  return accuracy,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WMO7_WSLHeGl"
   },
   "outputs": [],
   "source": [
    "class Early_Stopping():\n",
    "  def __init__(self,partience):\n",
    "    self.step = 0\n",
    "    self.loss = float('inf')\n",
    "    self.partience = partience\n",
    "\n",
    "  def validate(self,loss):\n",
    "    if self.loss<loss:\n",
    "      self.step += 1\n",
    "      if self.step>self.partience:\n",
    "        return True\n",
    "    else:\n",
    "      self.step = 0\n",
    "      self.loss = loss\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "-noG_98IR-nZ",
    "outputId": "78a6ebe2-854a-4f83-dc45-5c4ac35b69e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:582: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/aten/src/ATen/native/cudnn/RNN.cpp:775.)\n",
      "  self.dropout, self.training, self.bidirectional, self.batch_first)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1  loss:4.236473634839058  accuracy:8.069107456090777\n",
      "Epoch2  loss:4.174220880203776  accuracy:12.53862684942038\n",
      "Epoch3  loss:4.118661376171642  accuracy:13.001937767141902\n",
      "Epoch4  loss:4.100005786617597  accuracy:12.997982070939367\n",
      "Epoch5  loss:4.082577646772067  accuracy:10.234808034876503\n",
      "Epoch6  loss:4.064220839407708  accuracy:11.202437676864749\n",
      "Epoch7  loss:4.0475626581245  accuracy:11.73309805422324\n",
      "Epoch8  loss:4.031977803839578  accuracy:12.732748230263683\n",
      "Epoch9  loss:4.016399679912461  accuracy:13.025594142213368\n",
      "Epoch10  loss:4.002757818831339  accuracy:13.261339756248455\n",
      "Epoch11  loss:3.9879814263847138  accuracy:13.867955902400732\n",
      "Epoch12  loss:3.9763136920001765  accuracy:13.564641450471768\n",
      "Epoch13  loss:3.9631829420725495  accuracy:13.613631040183954\n",
      "Epoch14  loss:3.95337160759502  accuracy:13.660783520281932\n",
      "Epoch15  loss:3.9424619830316967  accuracy:13.44790857503284\n",
      "Epoch16  loss:3.9324807276328406  accuracy:13.365174853865257\n",
      "Epoch17  loss:3.9228401571512235  accuracy:13.314925861964714\n",
      "Epoch18  loss:3.914909324381088  accuracy:12.554709042793423\n",
      "Epoch19  loss:3.906040201915635  accuracy:12.58733152464553\n",
      "Epoch20  loss:3.8997628264957  accuracy:11.770295913239519\n",
      "Epoch21  loss:3.89304770330588  accuracy:11.46935977544161\n",
      "Epoch22  loss:3.882146707508298  accuracy:11.780171398552156\n",
      "Epoch23  loss:3.8779848767651455  accuracy:11.279426940624191\n",
      "Epoch24  loss:3.87260684006744  accuracy:11.224659974760954\n",
      "Epoch25  loss:3.866447898745537  accuracy:11.219998060799927\n",
      "Epoch26  loss:3.861396425631311  accuracy:10.934029751126806\n",
      "Epoch27  loss:3.855352865656217  accuracy:11.056939287194345\n",
      "Epoch28  loss:3.8520857221550404  accuracy:11.221778169197933\n",
      "Epoch29  loss:3.847460763321982  accuracy:11.086351939366178\n",
      "Epoch30  loss:3.84875891606013  accuracy:11.233700812393172\n",
      "Epoch31  loss:3.839377762211694  accuracy:11.294513221613883\n",
      "Epoch32  loss:3.837124542064137  accuracy:11.33100755236715\n",
      "Epoch33  loss:3.8341445939408416  accuracy:11.332487690919725\n",
      "Epoch34  loss:3.8271337363455027  accuracy:11.392691528623676\n",
      "Epoch35  loss:3.8238780356115765  accuracy:11.222365890933066\n",
      "Epoch36  loss:3.8219903369744617  accuracy:11.280884727405926\n",
      "Epoch37  loss:3.819377948178186  accuracy:11.240840772356568\n",
      "Epoch38  loss:3.815389570593834  accuracy:11.231949954567792\n",
      "Epoch39  loss:3.8101401428381605  accuracy:11.350178360033155\n",
      "Epoch40  loss:3.8107620858483844  accuracy:11.398558870907188\n",
      "Epoch41  loss:3.8103242059548696  accuracy:11.386700933553918\n",
      "Epoch42  loss:3.805967729290327  accuracy:11.39973050015926\n",
      "Epoch43  loss:3.8048455639017953  accuracy:11.44530719842548\n",
      "Epoch44  loss:3.796345145834817  accuracy:11.496443673229361\n",
      "Epoch45  loss:3.7944543259011376  accuracy:11.515949456685465\n",
      "Epoch46  loss:3.7940831936068  accuracy:11.53251790854828\n",
      "Epoch47  loss:3.7890872329473497  accuracy:11.438390923541178\n",
      "Epoch48  loss:3.782579670349757  accuracy:11.407770783823036\n",
      "Epoch49  loss:3.786914068460465  accuracy:11.979784971613094\n",
      "Epoch50  loss:3.782093637850549  accuracy:11.996566672244853\n",
      "Epoch51  loss:3.7766139358282085  accuracy:11.880124132854723\n",
      "Epoch52  loss:3.7747309800651347  accuracy:11.782725319714803\n",
      "Epoch53  loss:3.7709889382123944  accuracy:11.957003053114214\n",
      "Epoch54  loss:3.7737866656647787  accuracy:11.924076866775701\n",
      "Epoch55  loss:3.7673103335830906  accuracy:11.734696613187097\n",
      "Epoch56  loss:3.763591591848267  accuracy:12.140653419883796\n",
      "Epoch57  loss:3.7650117582745026  accuracy:11.791654860610755\n",
      "Epoch58  loss:3.7552706787983583  accuracy:11.802256295347739\n",
      "Epoch59  loss:3.7558441999885765  accuracy:12.283430979909603\n",
      "Epoch60  loss:3.7589496139023035  accuracy:12.16555347342302\n",
      "Epoch61  loss:3.748814751373397  accuracy:12.263790126845064\n",
      "Epoch62  loss:3.742915358808305  accuracy:12.36303046610181\n",
      "Epoch63  loss:3.741295522451401  accuracy:12.330567267645499\n",
      "Epoch64  loss:3.741711544328265  accuracy:12.417080284415386\n",
      "Epoch65  loss:3.733927345275878  accuracy:12.412489664640798\n",
      "Epoch66  loss:3.7347147368722493  accuracy:12.413168548974669\n",
      "Epoch67  loss:3.7305826654036833  accuracy:12.491751473890954\n",
      "Epoch68  loss:3.726625461710824  accuracy:12.53944968051776\n",
      "Epoch69  loss:3.72181052962939  accuracy:12.973070112201627\n",
      "Epoch70  loss:3.717515175872379  accuracy:12.955707404139796\n",
      "Epoch71  loss:3.7161147031519155  accuracy:13.15499773305159\n",
      "Epoch72  loss:3.713175578580962  accuracy:13.136730234997048\n",
      "Epoch73  loss:3.706318123141925  accuracy:14.085450687171564\n",
      "Epoch74  loss:3.706720024678442  accuracy:14.092196972820467\n",
      "Epoch75  loss:3.703888687491416  accuracy:13.206362884185985\n",
      "Epoch76  loss:3.703082292940881  accuracy:14.163305510975304\n",
      "Epoch77  loss:3.6962232046657144  accuracy:14.305183913055949\n",
      "Epoch78  loss:3.6933335175116864  accuracy:14.28806588217239\n",
      "Epoch79  loss:3.694100153777334  accuracy:14.412504165823881\n",
      "Epoch80  loss:3.690911599331432  accuracy:14.43303669229593\n",
      "Epoch81  loss:3.6872954908344475  accuracy:14.366007129996815\n",
      "Epoch82  loss:3.6841285063160796  accuracy:14.514105600032622\n",
      "Epoch83  loss:3.685927839742766  accuracy:14.285561170435134\n",
      "Epoch84  loss:3.6825617419348826  accuracy:14.510503876236502\n",
      "Epoch85  loss:3.6834733946455853  accuracy:14.434044333554738\n",
      "Epoch86  loss:3.6822737183835774  accuracy:14.51751639239094\n",
      "Epoch87  loss:3.678467050525877  accuracy:14.382931035400853\n",
      "Epoch88  loss:3.678325162000126  accuracy:14.509317618661266\n",
      "Epoch89  loss:3.676094651553366  accuracy:14.536640700090548\n",
      "Epoch90  loss:3.6781566636429894  accuracy:14.465993589939057\n",
      "Epoch91  loss:3.681716088785066  accuracy:14.2896965417406\n",
      "Epoch92  loss:3.670926738447613  accuracy:14.299770564002792\n",
      "Epoch93  loss:3.6710894217093784  accuracy:14.600093720873339\n",
      "Epoch94  loss:3.665067646900813  accuracy:14.459351770467224\n",
      "Epoch95  loss:3.6647642688618762  accuracy:14.24494933367569\n",
      "Epoch96  loss:3.666160501705275  accuracy:15.237274354036318\n",
      "Epoch97  loss:3.6629322760634953  accuracy:15.340408953227186\n",
      "Epoch98  loss:3.6670022110144296  accuracy:15.097280385334903\n",
      "Epoch99  loss:3.664052682783869  accuracy:15.301828709517595\n",
      "Epoch100  loss:3.6635296507014163  accuracy:15.34599293875009\n"
     ]
    }
   ],
   "source": [
    "server = Server()\n",
    "workers = server.create_worker(federated_trainset,federated_valset,federated_testset)\n",
    "acc_train = []\n",
    "loss_train = []\n",
    "acc_valid = []\n",
    "loss_valid = []\n",
    "\n",
    "early_stopping = Early_Stopping(args.partience)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(args.global_epochs):\n",
    "  sample_worker = server.sample_worker(workers)\n",
    "  server.send_model(sample_worker)\n",
    "\n",
    "  acc_train_avg = 0.0\n",
    "  loss_train_avg = 0.0\n",
    "  acc_valid_avg = 0.0\n",
    "  loss_valid_avg = 0.0\n",
    "  for worker in sample_worker:\n",
    "    worker.local_train()\n",
    "    acc_train_tmp,loss_train_tmp,acc_valid_tmp,loss_valid_tmp = worker.global_train()\n",
    "    acc_train_avg += acc_train_tmp/len(sample_worker)\n",
    "    loss_train_avg += loss_train_tmp/len(sample_worker)\n",
    "    acc_valid_avg += acc_valid_tmp/len(sample_worker)\n",
    "    loss_valid_avg += loss_valid_tmp/len(sample_worker)\n",
    "  server.aggregate_model(sample_worker)\n",
    "  '''\n",
    "  server.model.to(args.device)\n",
    "  for worker in workers:\n",
    "    acc_valid_tmp,loss_valid_tmp = test(server.model,args.criterion,worker.valloader)\n",
    "    acc_valid_avg += acc_valid_tmp/len(workers)\n",
    "    loss_valid_avg += loss_valid_tmp/len(workers)\n",
    "  server.model.to('cpu')\n",
    "  '''\n",
    "  print('Epoch{}  loss:{}  accuracy:{}'.format(epoch+1,loss_valid_avg,acc_valid_avg))\n",
    "  acc_train.append(acc_train_avg)\n",
    "  loss_train.append(loss_train_avg)\n",
    "  acc_valid.append(acc_valid_avg)\n",
    "  loss_valid.append(loss_valid_avg)\n",
    "\n",
    "  if early_stopping.validate(loss_valid_avg):\n",
    "    print('Early Stop')\n",
    "    break\n",
    "    \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "mi_uceyoptLP",
    "outputId": "bc067e09-01bc-4e65-daf9-ac2f42373cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:37.883908890521674  loss:2.259577138083322\n",
      "Worker2 accuracy:19.243986254295532  loss:3.3030569553375244\n",
      "Worker3 accuracy:11.363636363636363  loss:4.129376411437988\n",
      "Worker4 accuracy:19.696969696969695  loss:3.8436367511749268\n",
      "Worker5 accuracy:0.0  loss:4.1975603103637695\n",
      "Worker6 accuracy:4.761904761904762  loss:4.479913234710693\n",
      "Worker7 accuracy:20.0  loss:4.857960224151611\n",
      "Worker8 accuracy:20.66115702479339  loss:3.1175718307495117\n",
      "Worker9 accuracy:33.333333333333336  loss:4.348940372467041\n",
      "Worker10 accuracy:15.725806451612904  loss:3.228642225265503\n",
      "Worker11 accuracy:24.299065420560748  loss:3.164780855178833\n",
      "Worker12 accuracy:17.5  loss:4.214111804962158\n",
      "Worker13 accuracy:31.110254433307635  loss:2.554711182912191\n",
      "Worker14 accuracy:15.868263473053892  loss:3.123332977294922\n",
      "Worker15 accuracy:12.5  loss:4.019942283630371\n",
      "Worker16 accuracy:29.682090022033364  loss:2.445144534111023\n",
      "Worker17 accuracy:19.23076923076923  loss:3.732733726501465\n",
      "Worker18 accuracy:22.972972972972972  loss:3.9175314903259277\n",
      "Worker19 accuracy:28.29006266786034  loss:2.6251965363820395\n",
      "Worker20 accuracy:0.0  loss:4.207530498504639\n",
      "Test  loss:3.5885625671772727  accuracy:19.20620904988129\n"
     ]
    }
   ],
   "source": [
    "acc_test = []\n",
    "loss_test = []\n",
    "\n",
    "nums = 0\n",
    "for worker in workers:\n",
    "  nums += worker.test_data_num\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "  worker.aggregation_weight = 1.0*worker.test_data_num/nums\n",
    "  worker.global_model = copy.deepcopy(server.global_model)\n",
    "  worker.local_train()\n",
    "  acc_tmp,loss_tmp = test(worker.mix_model,args.criterion,worker.testloader)\n",
    "  acc_test.append(acc_tmp)\n",
    "  loss_test.append(loss_tmp)\n",
    "  print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "  worker.mix_model = worker.mix_model.to('cpu')\n",
    "  del worker.mix_model,worker.global_model\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "acc_test_avg = sum(acc_test)/len(acc_test)\n",
    "loss_test_avg = sum(loss_test)/len(loss_test)\n",
    "print('Test  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FedAvg_femnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
