{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "vkZxat4Y-IsQ",
    "outputId": "da86392c-66e8-4b60-b471-086e745cdcbc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from torch import nn, optim\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O0TfzOhU-QlG"
   },
   "outputs": [],
   "source": [
    "class Argments():\n",
    "  def __init__(self):\n",
    "    self.batch_size = 10\n",
    "    self.test_batch = 1000\n",
    "    self.global_epochs = 100\n",
    "    self.local_epochs = 2\n",
    "    self.lamda = 15\n",
    "    self.K = 5\n",
    "    self.lr = None\n",
    "    self.momentum = 0.9\n",
    "    self.weight_decay = 10**-4.0\n",
    "    self.clip = 20.0\n",
    "    self.partience = 100\n",
    "    self.worker_num = 20\n",
    "    self.sample_num = 20\n",
    "    self.device = device = torch.device('cuda:0'if torch.cuda.is_available() else'cpu')\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "args = Argments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(10**-3.0)\n",
    "lr_list.append(10**-2.5)\n",
    "lr_list.append(10**-2.0)\n",
    "lr_list.append(10**-1.5)\n",
    "lr_list.append(10**-1.0)\n",
    "lr_list.append(10**-0.5)\n",
    "lr_list.append(10**0.0)\n",
    "lr_list.append(10**0.5)\n",
    "\n",
    "args.lr = lr_list[lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,dataset,worker_id):\n",
    "    self.data = []\n",
    "    self.target = []\n",
    "    self.id = worker_id\n",
    "    for i in range(len(dataset)):\n",
    "      self.data.append(dataset[i][0][0])\n",
    "      self.target.append(dataset[i][1][0])\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.data[index],self.target[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/federated_trainset_shakespeare.pickle', 'rb') as f:\n",
    "    all_federated_trainset = pickle.load(f)\n",
    "with open('../data/federated_testset_shakespeare.pickle', 'rb') as f:\n",
    "    all_federated_testset = pickle.load(f)\n",
    "all_worker_num = len(all_federated_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 6, 70, 62, 57, 35, 26, 139, 22, 108, 8, 7, 23, 55, 59, 129, 50, 107, 56, 114]\n"
     ]
    }
   ],
   "source": [
    "worker_id_list = random.sample(range(all_worker_num),args.worker_num)\n",
    "print(worker_id_list)\n",
    "federated_trainset = []\n",
    "federated_testset = []\n",
    "for i in worker_id_list:\n",
    "    federated_trainset.append(all_federated_trainset[i])\n",
    "    federated_testset.append(all_federated_testset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_valset = [None]*args.worker_num\n",
    "for i in range(args.worker_num):\n",
    "  n_samples = len(federated_trainset[i])\n",
    "  if n_samples==1:\n",
    "    federated_valset[i] = copy.deepcopy(federated_trainset[i])\n",
    "  else:\n",
    "    train_size = int(len(federated_trainset[i]) * 0.7) \n",
    "    val_size = n_samples - train_size \n",
    "    federated_trainset[i],federated_valset[i] = torch.utils.data.random_split(federated_trainset[i], [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN1(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN1, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output\n",
    "\n",
    "class RNN2(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN2, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output\n",
    "\n",
    "class RNN3(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN3, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=3, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output\n",
    "    \n",
    "class RNN4(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN4, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=4, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pFedMeOptimizer(torch.optim.Optimizer):\n",
    "    def __init__(self, params, lr=0.01, lamda=0.1 , mu = 0.001):\n",
    "        #self.local_weight_updated = local_weight # w_i,K\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        defaults = dict(lr=lr, lamda=lamda, mu = mu)\n",
    "        super(pFedMeOptimizer, self).__init__(params, defaults)\n",
    "    \n",
    "    def step(self, local_weight_updated, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure\n",
    "        weight_update = local_weight_updated.copy()\n",
    "        for group in self.param_groups:\n",
    "            for p, localweight in zip( group['params'], weight_update):\n",
    "                localweight.data = localweight.data.to(args.device)\n",
    "                p.data = p.data - group['lr'] * (p.grad.data + group['lamda'] * (p.data - localweight.data) + group['mu']*p.data)\n",
    "                localweight.data = localweight.data.to('cpu')\n",
    "        return  group['params'], loss\n",
    "    \n",
    "    def update_param(self, local_weight_updated, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure\n",
    "        weight_update = local_weight_updated.copy()\n",
    "        for group in self.param_groups:\n",
    "            for p, localweight in zip( group['params'], weight_update):\n",
    "                p.data = localweight.data\n",
    "        #return  p.data\n",
    "        return  group['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Yu90X1TWJVKJ"
   },
   "outputs": [],
   "source": [
    "class Server():\n",
    "  def __init__(self):\n",
    "    self.model = RNN2()\n",
    "\n",
    "  def create_worker(self,federated_trainset,federated_valset,federated_testset):\n",
    "    workers = []\n",
    "    for i in range(args.worker_num):\n",
    "      workers.append(Worker(federated_trainset[i],federated_valset[i],federated_testset[i]))\n",
    "    return workers\n",
    "\n",
    "  def sample_worker(self,workers):\n",
    "    sample_worker = []\n",
    "    sample_worker_num = random.sample(range(args.worker_num),args.sample_num)\n",
    "    for i in sample_worker_num:\n",
    "      sample_worker.append(workers[i])\n",
    "    return sample_worker\n",
    "\n",
    "\n",
    "  def send_model(self,workers):\n",
    "    nums = 0\n",
    "    for worker in workers:\n",
    "      nums += worker.train_data_num\n",
    "\n",
    "    for worker in workers:\n",
    "      worker.aggregation_weight = 1.0*worker.train_data_num/nums\n",
    "      worker.model = copy.deepcopy(self.model)\n",
    "      worker.personalized_model = copy.deepcopy(self.model)\n",
    "      worker.local_model = copy.deepcopy(self.model)\n",
    "\n",
    "  def aggregate_model(self,workers):   \n",
    "    new_params = OrderedDict()\n",
    "    for i,worker in enumerate(workers):\n",
    "      worker_state = worker.model.state_dict()\n",
    "      for key in worker_state.keys():\n",
    "        if i==0:\n",
    "          new_params[key] = worker_state[key]*worker.aggregation_weight\n",
    "        else:\n",
    "          new_params[key] += worker_state[key]*worker.aggregation_weight\n",
    "    self.model.load_state_dict(new_params)\n",
    "    \n",
    "  def send_parameters(self,workers):\n",
    "    nums = 0\n",
    "    for worker in workers:\n",
    "      nums += worker.train_data_num\n",
    "    for worker in workers:\n",
    "        worker.aggregation_weight = 1.0*worker.train_data_num/nums\n",
    "        worker.set_parameters(self.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LDWEBjgfJYFc"
   },
   "outputs": [],
   "source": [
    "class Worker():\n",
    "  def __init__(self,trainset,valset,testset):\n",
    "    self.trainloader = torch.utils.data.DataLoader(trainset,batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.valloader = torch.utils.data.DataLoader(valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.testloader = torch.utils.data.DataLoader(testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    #self.iter_trainloader = iter(self.trainloader)\n",
    "    self.model = RNN2()\n",
    "    self.local_model = copy.deepcopy(list(self.model.parameters()))\n",
    "    self.persionalized_model = copy.deepcopy(list(self.model.parameters()))\n",
    "    self.persionalized_model_bar = copy.deepcopy(list(self.model.parameters()))\n",
    "    self.train_data_num = len(trainset)\n",
    "    self.test_data_num = len(testset)\n",
    "    \n",
    "    self.optimizer = pFedMeOptimizer(self.model.parameters(),lr=args.lr,lamda=args.lamda)\n",
    "    \n",
    "  def set_parameters(self, model):\n",
    "    for old_param, new_param, local_param in zip(self.model.parameters(), model.parameters(), self.local_model):\n",
    "        old_param.data = new_param.data.clone()\n",
    "        local_param.data = new_param.data.clone()\n",
    "    #self.local_weight_updated = copy.deepcopy(self.optimizer.param_groups[0]['params'])\n",
    "    \n",
    "  def get_next_train_batch(self):\n",
    "    try:\n",
    "        # Samples a new batch for persionalizing\n",
    "        (X, y) = next(self.iter_trainloader)\n",
    "    except StopIteration:\n",
    "        # restart the generator if the previous generator is exhausted.\n",
    "        self.iter_trainloader = iter(self.trainloader)\n",
    "        (X, y) = next(self.iter_trainloader)\n",
    "    return (X.to(args.device), y.to(args.device))    \n",
    "  '''\n",
    "  def local_train(self):\n",
    "    self.model.train()\n",
    "    optimizer = pFedMeOptimizer(self.model.parameters(),lr=args.lr,lamda=args.lamda)\n",
    "    for epoch in range(args.local_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        count = 0\n",
    "        data,labels = self.get_next_train_batch()\n",
    "        for i in range(args.K):\n",
    "            self.model = self.model.to(args.device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.model(data)\n",
    "            loss = args.criterion(outputs,labels)\n",
    "            running_loss += loss.item()\n",
    "            predicted = torch.argmax(outputs,dim=1)\n",
    "            correct += (predicted==labels).sum().item()\n",
    "            count += len(labels)\n",
    "            loss.backward()\n",
    "            #torch.nn.utils.clip_grad_norm_(self.model.parameters(), args.clip)\n",
    "            self.model = self.model.to('cpu')\n",
    "            personal_model,_ = optimizer.step(self.local_model)\n",
    "        \n",
    "        for new_param,localweight in zip(personal_model,self.local_model.parameters()):\n",
    "            localweight.data = localweight.data - args.lamda * args.lr * (localweight.data - new_param.data)    \n",
    "    \n",
    "    del self.model\n",
    "    \n",
    "    update_parameters(self.personalized_model,personal_model)\n",
    "    return 100.0*correct/count,running_loss/len(self.trainloader)\n",
    "  '''\n",
    "\n",
    "  def local_train(self):\n",
    "    self.model.train() \n",
    "    self.model = self.model.to(args.device)       \n",
    "    for epoch in range(args.local_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        count = 0\n",
    "        for (data,labels) in self.trainloader:\n",
    "            self.model.train()\n",
    "            data,labels = Variable(data),Variable(labels)\n",
    "            data,labels = data.to(args.device),labels.to(args.device)\n",
    "            for k in range(args.K):\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(data)\n",
    "                loss = args.criterion(outputs,labels)\n",
    "                if k==(args.K-1):\n",
    "                    running_loss += loss.item()\n",
    "                    predicted = torch.argmax(outputs,dim=1)\n",
    "                    correct += (predicted==labels).sum().item()\n",
    "                    count += len(labels)\n",
    "                loss.backward()\n",
    "                #torch.nn.utils.clip_grad_norm_(self.model.parameters(), args.clip)\n",
    "                self.persionalized_model_bar,_ = self.optimizer.step(self.local_model)\n",
    "        \n",
    "            for new_param, localweight in zip(self.persionalized_model_bar, self.local_model):\n",
    "                localweight.data = localweight.data.to(args.device)\n",
    "                localweight.data = localweight.data - args.lamda* args.lr * (localweight.data - new_param.data)\n",
    "                localweight.data = localweight.data.to('cpu')\n",
    "    \n",
    "    self.update_parameters(self.local_model)\n",
    "    \n",
    "    self.model = self.model.to('cpu')\n",
    "    for personal_weight, localweight in zip(self.persionalized_model_bar, self.local_model):\n",
    "        personal_weight.data = personal_weight.data.to('cpu')\n",
    "        localweight.data = localweight.data.to('cpu')\n",
    "        \n",
    "    return 100.0*correct/count,running_loss/len(self.trainloader)\n",
    "\n",
    "\n",
    "  def validate(self):\n",
    "    self.model.eval()\n",
    "    self.update_parameters(self.persionalized_model_bar)\n",
    "    self.model = self.model.to(args.device)\n",
    "    acc,loss = test(self.model,args.criterion,self.valloader)\n",
    "    self.model = self.model.to('cpu')\n",
    "    self.update_parameters(self.local_model)\n",
    "    return acc,loss\n",
    "\n",
    "\n",
    "  def test(self):\n",
    "    self.model.eval()\n",
    "    self.update_parameters(self.persionalized_model_bar)\n",
    "    self.model = self.model.to(args.device)\n",
    "    acc,loss = test(self.model,args.criterion,self.testloader)\n",
    "    self.model = self.model.to('cpu')\n",
    "    self.update_parameters(self.local_model)\n",
    "    return acc,loss\n",
    "\n",
    "\n",
    "  def update_parameters(self, new_params):\n",
    "    for param , new_param in zip(self.model.parameters(), new_params):\n",
    "      param.data = new_param.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "7-GY66gROuEU"
   },
   "outputs": [],
   "source": [
    "def train(model,criterion,trainloader,epochs):\n",
    "  optimizer = optim.SGD(model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "  model.train()\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for (data,labels) in trainloader:\n",
    "      data,labels = Variable(data),Variable(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      count += len(labels)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "      optimizer.step()\n",
    "\n",
    "  return 100.0*correct/count,running_loss/len(trainloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oA4URv9mQ3xV"
   },
   "outputs": [],
   "source": [
    "def test(model,criterion,testloader):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  count = 0\n",
    "  for (data,labels) in testloader:\n",
    "    data,labels = data.to(args.device),labels.to(args.device)\n",
    "    outputs = model(data)\n",
    "    running_loss += criterion(outputs,labels).item()\n",
    "    predicted = torch.argmax(outputs,dim=1)\n",
    "    correct += (predicted==labels).sum().item()\n",
    "    count += len(labels)\n",
    "\n",
    "  accuracy = 100.0*correct/count\n",
    "  loss = running_loss/len(testloader)\n",
    "\n",
    "\n",
    "  return accuracy,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WMO7_WSLHeGl"
   },
   "outputs": [],
   "source": [
    "class Early_Stopping():\n",
    "  def __init__(self,partience):\n",
    "    self.step = 0\n",
    "    self.loss = float('inf')\n",
    "    self.partience = partience\n",
    "\n",
    "  def validate(self,loss):\n",
    "    if self.loss<loss:\n",
    "      self.step += 1\n",
    "      if self.step>self.partience:\n",
    "        return True\n",
    "    else:\n",
    "      self.step = 0\n",
    "      self.loss = loss\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "-noG_98IR-nZ",
    "outputId": "78a6ebe2-854a-4f83-dc45-5c4ac35b69e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acc12212vx/jupyter_env/lib/python3.6/site-packages/torch/nn/modules/rnn.py:582: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:775.)\n",
      "  self.dropout, self.training, self.bidirectional, self.batch_first)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1  loss:4.474835537539588  accuracy:3.8146841051639013\n",
      "Epoch2  loss:4.320136395427915  accuracy:15.101252036950212\n",
      "Epoch3  loss:4.112746657596694  accuracy:15.101252036950212\n",
      "Epoch4  loss:3.8267593022849824  accuracy:15.10125203695021\n",
      "Epoch5  loss:3.5776475098398004  accuracy:15.10125203695021\n",
      "Epoch6  loss:3.438932335045602  accuracy:15.101252036950212\n",
      "Epoch7  loss:3.3777567287286123  accuracy:15.10125203695021\n",
      "Epoch8  loss:3.3496867037481732  accuracy:15.101252036950212\n",
      "Epoch9  loss:3.3343932708104456  accuracy:15.10125203695021\n",
      "Epoch10  loss:3.3254450533125137  accuracy:15.10125203695021\n",
      "Epoch11  loss:3.319454373584853  accuracy:15.101252036950212\n",
      "Epoch12  loss:3.3160468502177136  accuracy:15.101252036950214\n",
      "Epoch13  loss:3.313062215513653  accuracy:15.10125203695021\n",
      "Epoch14  loss:3.311489857236544  accuracy:15.10125203695021\n",
      "Epoch15  loss:3.3094887998369  accuracy:15.101252036950209\n",
      "Epoch16  loss:3.3073297040330045  accuracy:15.10125203695021\n",
      "Epoch17  loss:3.3067724049091347  accuracy:15.101252036950209\n",
      "Epoch18  loss:3.305559645427598  accuracy:15.10125203695021\n",
      "Epoch19  loss:3.3055887367990278  accuracy:15.101252036950212\n",
      "Epoch20  loss:3.3048212895790736  accuracy:15.10125203695021\n",
      "Epoch21  loss:3.3028952986001965  accuracy:15.10125203695021\n",
      "Epoch22  loss:3.304137671656078  accuracy:15.10125203695021\n",
      "Epoch23  loss:3.3014959467781915  accuracy:15.10125203695021\n",
      "Epoch24  loss:3.3012633522351584  accuracy:15.10125203695021\n",
      "Epoch25  loss:3.2998811764849556  accuracy:15.10125203695021\n",
      "Epoch26  loss:3.300492739346293  accuracy:15.101252036950212\n",
      "Epoch27  loss:3.300108964575662  accuracy:15.10125203695021\n",
      "Epoch28  loss:3.2988267256153954  accuracy:15.101252036950209\n",
      "Epoch29  loss:3.2990326566828623  accuracy:15.10125203695021\n",
      "Epoch30  loss:3.2984097497330773  accuracy:15.10125203695021\n",
      "Epoch31  loss:3.3003961582978563  accuracy:15.101252036950212\n",
      "Epoch32  loss:3.297823469837507  accuracy:15.10125203695021\n",
      "Epoch33  loss:3.298489348093669  accuracy:15.10125203695021\n",
      "Epoch34  loss:3.296630856394768  accuracy:15.101252036950212\n",
      "Epoch35  loss:3.295766764879227  accuracy:15.10125203695021\n",
      "Epoch36  loss:3.295660628212823  accuracy:15.10125203695021\n",
      "Epoch37  loss:3.297245997521612  accuracy:15.10125203695021\n",
      "Epoch38  loss:3.296585327055719  accuracy:15.10125203695021\n",
      "Epoch39  loss:3.2957796553770704  accuracy:15.101252036950212\n",
      "Epoch40  loss:3.2963281588421927  accuracy:15.101252036950209\n",
      "Epoch41  loss:3.2953333063258055  accuracy:15.10125203695021\n",
      "Epoch42  loss:3.2945212877459  accuracy:15.10125203695021\n",
      "Epoch43  loss:3.296072393986914  accuracy:15.10125203695021\n",
      "Epoch44  loss:3.2958841380145816  accuracy:15.10125203695021\n",
      "Epoch45  loss:3.293937770525614  accuracy:15.10125203695021\n",
      "Epoch46  loss:3.2959422273768326  accuracy:15.101252036950209\n",
      "Epoch47  loss:3.2947991371154783  accuracy:15.10125203695021\n",
      "Epoch48  loss:3.294865419467291  accuracy:15.10125203695021\n",
      "Epoch49  loss:3.2951491408877898  accuracy:15.101252036950209\n",
      "Epoch50  loss:3.2944892581966188  accuracy:15.10125203695021\n",
      "Epoch51  loss:3.2939429491758347  accuracy:15.101252036950209\n",
      "Epoch52  loss:3.2954312927193112  accuracy:15.10125203695021\n",
      "Epoch53  loss:3.2930092198981176  accuracy:15.101252036950212\n",
      "Epoch54  loss:3.2919727881749474  accuracy:15.10125203695021\n",
      "Epoch55  loss:3.2923093087143376  accuracy:15.10125203695021\n",
      "Epoch56  loss:3.292224335670471  accuracy:15.10125203695021\n",
      "Epoch57  loss:3.2933787922064464  accuracy:15.101252036950209\n",
      "Epoch58  loss:3.2917536507050196  accuracy:15.10125203695021\n",
      "Epoch59  loss:3.2946329010857487  accuracy:15.101252036950212\n",
      "Epoch60  loss:3.2935939427879117  accuracy:15.101252036950209\n",
      "Epoch61  loss:3.2926838080088294  accuracy:15.10125203695021\n",
      "Epoch62  loss:3.292665762702624  accuracy:15.101252036950214\n",
      "Epoch63  loss:3.2922858165370092  accuracy:15.101252036950212\n",
      "Epoch64  loss:3.2926947577132117  accuracy:15.10125203695021\n",
      "Epoch65  loss:3.2936193684736885  accuracy:15.101252036950212\n",
      "Epoch66  loss:3.292779896325536  accuracy:15.101252036950212\n",
      "Epoch67  loss:3.292131214009391  accuracy:15.10125203695021\n",
      "Epoch68  loss:3.2923971401320564  accuracy:15.101252036950209\n",
      "Epoch69  loss:3.2914377351601924  accuracy:15.10125203695021\n",
      "Epoch70  loss:3.291230360004637  accuracy:15.101252036950209\n",
      "Epoch71  loss:3.2911322044001685  accuracy:15.101252036950212\n",
      "Epoch72  loss:3.291979932453897  accuracy:15.10125203695021\n",
      "Epoch73  loss:3.2914662311474485  accuracy:15.10125203695021\n",
      "Epoch74  loss:3.2921894626484978  accuracy:15.101252036950212\n",
      "Epoch75  loss:3.2903744250535967  accuracy:15.10125203695021\n",
      "Epoch76  loss:3.2897268679406904  accuracy:15.101252036950209\n",
      "Epoch77  loss:3.290546071198252  accuracy:15.10125203695021\n",
      "Epoch78  loss:3.288011308511099  accuracy:15.10125203695021\n",
      "Epoch79  loss:3.2923329740762712  accuracy:15.101252036950212\n",
      "Epoch80  loss:3.2913117574320894  accuracy:15.10125203695021\n",
      "Epoch81  loss:3.2893982751501927  accuracy:15.10125203695021\n",
      "Epoch82  loss:3.2871148943901063  accuracy:15.10125203695021\n",
      "Epoch83  loss:3.2877643717659844  accuracy:15.10125203695021\n",
      "Epoch84  loss:3.2872621274656724  accuracy:15.101252036950209\n",
      "Epoch85  loss:3.286856180098322  accuracy:15.101252036950212\n",
      "Epoch86  loss:3.2883692794375947  accuracy:15.101252036950212\n",
      "Epoch87  loss:3.28790315952566  accuracy:15.10125203695021\n",
      "Epoch88  loss:3.2860035306877564  accuracy:15.10125203695021\n",
      "Epoch89  loss:3.2852007107602224  accuracy:15.10125203695021\n",
      "Epoch90  loss:3.2838231391376915  accuracy:15.10125203695021\n",
      "Epoch91  loss:3.284707183308072  accuracy:15.101252036950209\n",
      "Epoch92  loss:3.283297376831373  accuracy:15.10125203695021\n",
      "Epoch93  loss:3.285169966353311  accuracy:15.10125203695021\n",
      "Epoch94  loss:3.2832872211933135  accuracy:15.10125203695021\n",
      "Epoch95  loss:3.2815059264500936  accuracy:15.10125203695021\n",
      "Epoch96  loss:3.281594074434704  accuracy:15.10125203695021\n",
      "Epoch97  loss:3.279780881934696  accuracy:15.09329122862198\n",
      "Epoch98  loss:3.277299350500107  accuracy:15.094515968364785\n",
      "Epoch99  loss:3.276443691054981  accuracy:15.10138655976597\n",
      "Epoch100  loss:3.275226169824601  accuracy:15.107366224236062\n"
     ]
    }
   ],
   "source": [
    "server = Server()\n",
    "workers = server.create_worker(federated_trainset,federated_valset,federated_testset)\n",
    "acc_train = []\n",
    "loss_train = []\n",
    "acc_valid = []\n",
    "loss_valid = []\n",
    "\n",
    "early_stopping = Early_Stopping(args.partience)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(args.global_epochs):\n",
    "  sample_worker = server.sample_worker(workers)\n",
    "  server.send_parameters(sample_worker)\n",
    "\n",
    "  acc_train_avg = 0.0\n",
    "  loss_train_avg = 0.0\n",
    "  acc_valid_avg = 0.0\n",
    "  loss_valid_avg = 0.0\n",
    "  for worker in sample_worker:\n",
    "    acc_train_tmp,loss_train_tmp = worker.local_train()\n",
    "    acc_valid_tmp,loss_valid_tmp = worker.validate()\n",
    "    acc_train_avg += acc_train_tmp/len(sample_worker)\n",
    "    loss_train_avg += loss_train_tmp/len(sample_worker)\n",
    "    acc_valid_avg += acc_valid_tmp/len(sample_worker)\n",
    "    loss_valid_avg += loss_valid_tmp/len(sample_worker)\n",
    "  server.aggregate_model(sample_worker)\n",
    "  '''\n",
    "  server.model.to(args.device)\n",
    "  for worker in workers:\n",
    "    acc_valid_tmp,loss_valid_tmp = test(server.model,args.criterion,worker.valloader)\n",
    "    acc_valid_avg += acc_valid_tmp/len(workers)\n",
    "    loss_valid_avg += loss_valid_tmp/len(workers)\n",
    "  server.model.to('cpu')\n",
    "  '''\n",
    "  print('Epoch{}  loss:{}  accuracy:{}'.format(epoch+1,loss_valid_avg,acc_valid_avg))\n",
    "  acc_train.append(acc_train_avg)\n",
    "  loss_train.append(loss_train_avg)\n",
    "  acc_valid.append(acc_valid_avg)\n",
    "  loss_valid.append(loss_valid_avg)\n",
    "\n",
    "  if early_stopping.validate(loss_valid_avg):\n",
    "    print('Early Stop')\n",
    "    break\n",
    "    \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:18.559882439382807  loss:3.0714070796966553\n",
      "Worker2 accuracy:19.587628865979383  loss:3.2186944484710693\n",
      "Worker3 accuracy:11.363636363636363  loss:3.0423784255981445\n",
      "Worker4 accuracy:19.696969696969695  loss:3.0962367057800293\n",
      "Worker5 accuracy:25.0  loss:2.8974359035491943\n",
      "Worker6 accuracy:19.047619047619047  loss:3.162169933319092\n",
      "Worker7 accuracy:20.0  loss:2.7484309673309326\n",
      "Worker8 accuracy:20.66115702479339  loss:3.0136637687683105\n",
      "Worker9 accuracy:33.333333333333336  loss:3.6699912548065186\n",
      "Worker10 accuracy:16.129032258064516  loss:3.1718528270721436\n",
      "Worker11 accuracy:24.299065420560748  loss:2.8420252799987793\n",
      "Worker12 accuracy:17.5  loss:2.918381690979004\n",
      "Worker13 accuracy:18.889745566692365  loss:3.064676841100057\n",
      "Worker14 accuracy:15.868263473053892  loss:3.031698226928711\n",
      "Worker15 accuracy:12.5  loss:3.0544371604919434\n",
      "Worker16 accuracy:17.62669184765502  loss:3.092442512512207\n",
      "Worker17 accuracy:19.23076923076923  loss:3.2892088890075684\n",
      "Worker18 accuracy:22.972972972972972  loss:3.047985792160034\n",
      "Worker19 accuracy:19.203222918531782  loss:3.0621679623921714\n",
      "Worker20 accuracy:0.0  loss:3.6457767486572266\n",
      "Test(personalized)  loss:3.1070531209309897  accuracy:18.573499523000727\n"
     ]
    }
   ],
   "source": [
    "acc_test_personalized = []\n",
    "loss_test_personalized = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "  acc_tmp,loss_tmp = worker.test()\n",
    "  acc_test_personalized.append(acc_tmp)\n",
    "  loss_test_personalized.append(loss_tmp)\n",
    "  print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "acc_test_personalized_avg = sum(acc_test_personalized)/len(acc_test_personalized)\n",
    "loss_test_personalized_avg = sum(loss_test_personalized)/len(loss_test_personalized)\n",
    "print('Test(personalized)  loss:{}  accuracy:{}'.format(loss_test_personalized_avg,acc_test_personalized_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:18.603967670830272  loss:3.0738987241472517\n",
      "Worker2 accuracy:19.243986254295532  loss:3.2170419692993164\n",
      "Worker3 accuracy:11.363636363636363  loss:3.045091390609741\n",
      "Worker4 accuracy:19.696969696969695  loss:3.093329906463623\n",
      "Worker5 accuracy:25.0  loss:2.889305591583252\n",
      "Worker6 accuracy:19.047619047619047  loss:3.155130386352539\n",
      "Worker7 accuracy:20.0  loss:2.7341465950012207\n",
      "Worker8 accuracy:20.24793388429752  loss:3.0175766944885254\n",
      "Worker9 accuracy:33.333333333333336  loss:3.6672255992889404\n",
      "Worker10 accuracy:16.129032258064516  loss:3.1680707931518555\n",
      "Worker11 accuracy:24.299065420560748  loss:2.8331663608551025\n",
      "Worker12 accuracy:17.5  loss:2.9106369018554688\n",
      "Worker13 accuracy:18.889745566692365  loss:3.0665109952290854\n",
      "Worker14 accuracy:15.868263473053892  loss:3.03623628616333\n",
      "Worker15 accuracy:12.5  loss:3.0432639122009277\n",
      "Worker16 accuracy:17.469310670443814  loss:3.0892144441604614\n",
      "Worker17 accuracy:19.23076923076923  loss:3.286276340484619\n",
      "Worker18 accuracy:22.972972972972972  loss:3.041748046875\n",
      "Worker19 accuracy:19.29274843330349  loss:3.064527908960978\n",
      "Worker20 accuracy:0.0  loss:3.671940565109253\n",
      "Test(global)  loss:3.1052169706140247  accuracy:18.534467713842137\n"
     ]
    }
   ],
   "source": [
    "acc_test_global = []\n",
    "loss_test_global = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "  server.model = server.model.to(args.device)\n",
    "  acc_tmp,loss_tmp = test(server.model,args.criterion,worker.testloader)\n",
    "  acc_test_global.append(acc_tmp)\n",
    "  loss_test_global.append(loss_tmp)\n",
    "  print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "\n",
    "server.model = server.model.to('cpu')\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "acc_test_global_avg = sum(acc_test_global)/len(acc_test_global)\n",
    "loss_test_global_avg = sum(loss_test_global)/len(loss_test_global)\n",
    "print('Test(global)  loss:{}  accuracy:{}'.format(loss_test_global_avg,acc_test_global_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:20.955180014695078  loss:3.017582586833409\n",
      "Worker2 accuracy:18.213058419243985  loss:3.216718912124634\n",
      "Worker3 accuracy:11.363636363636363  loss:3.046257972717285\n",
      "Worker4 accuracy:19.696969696969695  loss:3.146597385406494\n",
      "Worker5 accuracy:25.0  loss:2.893698215484619\n",
      "Worker6 accuracy:19.047619047619047  loss:3.1696276664733887\n",
      "Worker7 accuracy:20.0  loss:2.7699174880981445\n",
      "Worker8 accuracy:20.24793388429752  loss:3.026095390319824\n",
      "Worker9 accuracy:33.333333333333336  loss:3.664252519607544\n",
      "Worker10 accuracy:15.725806451612904  loss:3.2126717567443848\n",
      "Worker11 accuracy:24.299065420560748  loss:2.9204323291778564\n",
      "Worker12 accuracy:17.5  loss:3.0243701934814453\n",
      "Worker13 accuracy:19.35235158057055  loss:3.0517078240712485\n",
      "Worker14 accuracy:15.868263473053892  loss:3.043837070465088\n",
      "Worker15 accuracy:25.0  loss:3.040376663208008\n",
      "Worker16 accuracy:17.469310670443814  loss:3.0914592146873474\n",
      "Worker17 accuracy:17.94871794871795  loss:3.3046464920043945\n",
      "Worker18 accuracy:22.972972972972972  loss:3.070438861846924\n",
      "Worker19 accuracy:19.382273948075202  loss:3.050982395807902\n",
      "Worker20 accuracy:0.0  loss:3.6923837661743164\n",
      "Test_fine-tune(global)  loss:3.122702735236713  accuracy:19.168824661290152\n"
     ]
    }
   ],
   "source": [
    "acc_tune_test_global = []\n",
    "loss_tune_test_global = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "  worker.model = copy.deepcopy(server.model)\n",
    "  worker.model = worker.model.to(args.device)\n",
    "  _,_ = train(worker.model,args.criterion,worker.trainloader,args.local_epochs)\n",
    "  acc_tmp,loss_tmp = test(worker.model,args.criterion,worker.testloader)\n",
    "  acc_tune_test_global.append(acc_tmp)\n",
    "  loss_tune_test_global.append(loss_tmp)\n",
    "  print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "  worker.model = worker.model.to('cpu')\n",
    "  del worker.model\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "acc_tune_test_global_avg = sum(acc_tune_test_global)/len(acc_tune_test_global)\n",
    "loss_tune_test_global_avg = sum(loss_tune_test_global)/len(loss_tune_test_global)\n",
    "print('Test_fine-tune(global)  loss:{}  accuracy:{}'.format(loss_tune_test_global_avg,acc_tune_test_global_avg))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FedAvg_femnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
