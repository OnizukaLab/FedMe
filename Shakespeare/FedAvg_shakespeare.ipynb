{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "vkZxat4Y-IsQ",
    "outputId": "da86392c-66e8-4b60-b471-086e745cdcbc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from torch import nn, optim\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O0TfzOhU-QlG"
   },
   "outputs": [],
   "source": [
    "class Argments():\n",
    "  def __init__(self):\n",
    "    self.batch_size = 10\n",
    "    self.test_batch = 1000\n",
    "    self.global_epochs = 100\n",
    "    self.local_epochs = 2\n",
    "    self.lr = None\n",
    "    self.momentum = 0.9\n",
    "    self.weight_decay = 10**-4.0\n",
    "    self.clip = 20.0\n",
    "    self.partience = 100\n",
    "    self.worker_num = 20\n",
    "    self.sample_num = 20\n",
    "    self.device = device = torch.device('cuda:0'if torch.cuda.is_available() else'cpu')\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "args = Argments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(10**-3.0)\n",
    "lr_list.append(10**-2.5)\n",
    "lr_list.append(10**-2.0)\n",
    "lr_list.append(10**-1.5)\n",
    "lr_list.append(10**-1.0)\n",
    "lr_list.append(10**-0.5)\n",
    "lr_list.append(10**0.0)\n",
    "lr_list.append(10**0.5)\n",
    "\n",
    "args.lr = lr_list[lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r5PuCcqmJNUQ"
   },
   "outputs": [],
   "source": [
    "class LocalDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,dataset,worker_id):\n",
    "    self.data = []\n",
    "    self.target = []\n",
    "    self.id = worker_id\n",
    "    for i in range(len(dataset)):\n",
    "      self.data.append(dataset[i][0][0])\n",
    "      self.target.append(dataset[i][1][0])\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.data[index],self.target[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/federated_trainset_shakespeare.pickle', 'rb') as f:\n",
    "    all_federated_trainset = pickle.load(f)\n",
    "with open('../data/federated_testset_shakespeare.pickle', 'rb') as f:\n",
    "    all_federated_testset = pickle.load(f)\n",
    "all_worker_num = len(all_federated_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 6, 70, 62, 57, 35, 26, 139, 22, 108, 8, 7, 23, 55, 59, 129, 50, 107, 56, 114]\n"
     ]
    }
   ],
   "source": [
    "worker_id_list = random.sample(range(all_worker_num),args.worker_num)\n",
    "print(worker_id_list)\n",
    "federated_trainset = []\n",
    "federated_testset = []\n",
    "for i in worker_id_list:\n",
    "    federated_trainset.append(all_federated_trainset[i])\n",
    "    federated_testset.append(all_federated_testset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_valset = [None]*args.worker_num\n",
    "for i in range(args.worker_num):\n",
    "  n_samples = len(federated_trainset[i])\n",
    "  if n_samples==1:\n",
    "    federated_valset[i] = copy.deepcopy(federated_trainset[i])\n",
    "  else:\n",
    "    train_size = int(len(federated_trainset[i]) * 0.7) \n",
    "    val_size = n_samples - train_size \n",
    "    federated_trainset[i],federated_valset[i] = torch.utils.data.random_split(federated_trainset[i], [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZU3vAAb9-6SD"
   },
   "outputs": [],
   "source": [
    "class RNN1(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN1, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output\n",
    "\n",
    "class RNN2(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN2, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output\n",
    "\n",
    "class RNN3(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN3, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=3, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output\n",
    "    \n",
    "class RNN4(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN4, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=4, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Yu90X1TWJVKJ"
   },
   "outputs": [],
   "source": [
    "class Server():\n",
    "  def __init__(self):\n",
    "    self.model = RNN2()\n",
    "\n",
    "  def create_worker(self,federated_trainset,federated_valset,federated_testset):\n",
    "    workers = []\n",
    "    for i in range(args.worker_num):\n",
    "      workers.append(Worker(federated_trainset[i],federated_valset[i],federated_testset[i]))\n",
    "    return workers\n",
    "\n",
    "  def sample_worker(self,workers):\n",
    "    sample_worker = []\n",
    "    sample_worker_num = random.sample(range(args.worker_num),args.sample_num)\n",
    "    for i in sample_worker_num:\n",
    "      sample_worker.append(workers[i])\n",
    "    return sample_worker\n",
    "\n",
    "\n",
    "  def send_model(self,workers):\n",
    "    nums = 0\n",
    "    for worker in workers:\n",
    "      nums += worker.train_data_num\n",
    "\n",
    "    for worker in workers:\n",
    "      worker.aggregation_weight = 1.0*worker.train_data_num/nums\n",
    "      worker.model = copy.deepcopy(self.model)\n",
    "      worker.model = worker.model.to(args.device)\n",
    "\n",
    "  def aggregate_model(self,workers):   \n",
    "    new_params = OrderedDict()\n",
    "    for i,worker in enumerate(workers):\n",
    "      worker_state = worker.model.state_dict()\n",
    "      for key in worker_state.keys():\n",
    "        if i==0:\n",
    "          new_params[key] = worker_state[key]*worker.aggregation_weight\n",
    "        else:\n",
    "          new_params[key] += worker_state[key]*worker.aggregation_weight\n",
    "      worker.model = worker.model.to('cpu')\n",
    "      del worker.model\n",
    "    self.model.load_state_dict(new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LDWEBjgfJYFc"
   },
   "outputs": [],
   "source": [
    "class Worker():\n",
    "  def __init__(self,trainset,valset,testset):\n",
    "    self.trainloader = torch.utils.data.DataLoader(trainset,batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.valloader = torch.utils.data.DataLoader(valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.testloader = torch.utils.data.DataLoader(testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.model = None\n",
    "    self.train_data_num = len(trainset)\n",
    "    self.test_data_num = len(testset)\n",
    "    self.aggregation_weight = None\n",
    "\n",
    "  def local_train(self):\n",
    "    acc_train,loss_train = train(self.model,args.criterion,self.trainloader,args.local_epochs)\n",
    "    acc_valid,loss_valid = test(self.model,args.criterion,self.valloader)\n",
    "    return acc_train,loss_train,acc_valid,loss_valid\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7-GY66gROuEU"
   },
   "outputs": [],
   "source": [
    "def train(model,criterion,trainloader,epochs):\n",
    "  optimizer = optim.SGD(model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "  model.train()\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for (data,labels) in trainloader:\n",
    "      data,labels = Variable(data),Variable(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      count += len(labels)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "      optimizer.step()\n",
    "\n",
    "  return 100.0*correct/count,running_loss/len(trainloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "oA4URv9mQ3xV"
   },
   "outputs": [],
   "source": [
    "def test(model,criterion,testloader):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  count = 0\n",
    "  for (data,labels) in testloader:\n",
    "    data,labels = data.to(args.device),labels.to(args.device)\n",
    "    outputs = model(data)\n",
    "    running_loss += criterion(outputs,labels).item()\n",
    "    predicted = torch.argmax(outputs,dim=1)\n",
    "    correct += (predicted==labels).sum().item()\n",
    "    count += len(labels)\n",
    "\n",
    "  accuracy = 100.0*correct/count\n",
    "  loss = running_loss/len(testloader)\n",
    "\n",
    "\n",
    "  return accuracy,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WMO7_WSLHeGl"
   },
   "outputs": [],
   "source": [
    "class Early_Stopping():\n",
    "  def __init__(self,partience):\n",
    "    self.step = 0\n",
    "    self.loss = float('inf')\n",
    "    self.partience = partience\n",
    "\n",
    "  def validate(self,loss):\n",
    "    if self.loss<loss:\n",
    "      self.step += 1\n",
    "      if self.step>self.partience:\n",
    "        return True\n",
    "    else:\n",
    "      self.step = 0\n",
    "      self.loss = loss\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "-noG_98IR-nZ",
    "outputId": "78a6ebe2-854a-4f83-dc45-5c4ac35b69e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1  loss:4.204553603132567  accuracy:11.184212977036275\n",
      "Epoch2  loss:3.3196941796276302  accuracy:15.101252036950212\n",
      "Epoch3  loss:3.308517340156767  accuracy:15.101252036950212\n",
      "Epoch4  loss:3.311732952131166  accuracy:15.10125203695021\n",
      "Epoch5  loss:3.308153922359148  accuracy:15.10125203695021\n",
      "Epoch6  loss:3.2992911414967647  accuracy:15.101252036950212\n",
      "Epoch7  loss:3.291659569078022  accuracy:15.095036831769045\n",
      "Epoch8  loss:3.2791014823648665  accuracy:15.399278328205316\n",
      "Epoch9  loss:3.254492508040535  accuracy:14.793856896139177\n",
      "Epoch10  loss:3.223819656835662  accuracy:15.805564353051349\n",
      "Epoch11  loss:3.187030514412456  accuracy:16.900371632349533\n",
      "Epoch12  loss:3.135467615061336  accuracy:17.795312922026962\n",
      "Epoch13  loss:3.088768356376224  accuracy:18.423005532498443\n",
      "Epoch14  loss:3.059980403052436  accuracy:18.580470615266993\n",
      "Epoch15  loss:3.0224409729242323  accuracy:20.305957350505675\n",
      "Epoch16  loss:2.992974316411548  accuracy:20.852386353546986\n",
      "Epoch17  loss:2.9677129778597093  accuracy:20.982508467947547\n",
      "Epoch18  loss:2.930122078789605  accuracy:21.648048658391254\n",
      "Epoch19  loss:2.9085919257667334  accuracy:22.40806823638618\n",
      "Epoch20  loss:2.883054439226786  accuracy:23.135204017719026\n",
      "Epoch21  loss:2.8464810076687073  accuracy:24.34452609485044\n",
      "Epoch22  loss:2.8142863717344078  accuracy:25.454215083075905\n",
      "Epoch23  loss:2.782354801562098  accuracy:25.688312473636138\n",
      "Epoch24  loss:2.7519562357001837  accuracy:26.559704480689607\n",
      "Epoch25  loss:2.72039291759332  accuracy:26.940980072203548\n",
      "Epoch26  loss:2.6999194453159965  accuracy:26.936599306304682\n",
      "Epoch27  loss:2.684847487012545  accuracy:27.84090017415033\n",
      "Epoch28  loss:2.660098991129133  accuracy:27.889413002366716\n",
      "Epoch29  loss:2.6445672396156525  accuracy:28.063687185724778\n",
      "Epoch30  loss:2.625703584816721  accuracy:29.17590337326112\n",
      "Epoch31  loss:2.609481238987711  accuracy:28.915875222873616\n",
      "Epoch32  loss:2.579079635275735  accuracy:29.243452738026292\n",
      "Epoch33  loss:2.569484638174375  accuracy:27.405405043895342\n",
      "Epoch34  loss:2.5437291827466755  accuracy:27.876997696974524\n",
      "Epoch35  loss:2.5282393564780548  accuracy:27.554804237573073\n",
      "Epoch36  loss:2.5148583819468815  accuracy:28.10264566989091\n",
      "Epoch37  loss:2.4882996039258116  accuracy:28.724423141362156\n",
      "Epoch38  loss:2.4754532131883833  accuracy:28.861351419655247\n",
      "Epoch39  loss:2.463082150949372  accuracy:28.700762469763347\n",
      "Epoch40  loss:2.4394773516390056  accuracy:29.528360571767767\n",
      "Epoch41  loss:2.4329117668999563  accuracy:30.207280528550633\n",
      "Epoch42  loss:2.407509908411238  accuracy:30.777555547802315\n",
      "Epoch43  loss:2.407292883263694  accuracy:29.912404663600654\n",
      "Epoch44  loss:2.3859009865257477  accuracy:30.330328263431667\n",
      "Epoch45  loss:2.3679356058438623  accuracy:30.303534262688654\n",
      "Epoch46  loss:2.372632563445303  accuracy:31.10974205433534\n",
      "Epoch47  loss:2.3522717747423383  accuracy:31.083381920801383\n",
      "Epoch48  loss:2.346994893418418  accuracy:31.335102552301286\n",
      "Epoch49  loss:2.3394550972514687  accuracy:31.61755034344364\n",
      "Epoch50  loss:2.323893732163641  accuracy:31.32884162667334\n",
      "Epoch51  loss:2.3141990901695353  accuracy:32.61793350870448\n",
      "Epoch52  loss:2.307886998024252  accuracy:31.881205076662198\n",
      "Epoch53  loss:2.298870562348101  accuracy:31.98192885634441\n",
      "Epoch54  loss:2.2809626470009485  accuracy:32.37168425651467\n",
      "Epoch55  loss:2.288030886650085  accuracy:34.87159282354651\n",
      "Epoch56  loss:2.267150276899338  accuracy:33.043153379459994\n",
      "Epoch57  loss:2.2636513777905045  accuracy:32.78675780542648\n",
      "Epoch58  loss:2.2510586094525125  accuracy:34.677868108224075\n",
      "Epoch59  loss:2.24963382234176  accuracy:33.092701810265424\n",
      "Epoch60  loss:2.2537964741388956  accuracy:33.44787604724052\n",
      "Epoch61  loss:2.235880648261971  accuracy:33.72311781156541\n",
      "Epoch62  loss:2.2395825867851578  accuracy:34.331137241343704\n",
      "Epoch63  loss:2.2317542995015778  accuracy:33.20489254434642\n",
      "Epoch64  loss:2.21340361552106  accuracy:33.522993577239504\n",
      "Epoch65  loss:2.2203409040967625  accuracy:34.327711751210565\n",
      "Epoch66  loss:2.2210128761000103  accuracy:34.5513670683678\n",
      "Epoch67  loss:2.219621818595462  accuracy:34.32674836411986\n",
      "Epoch68  loss:2.203043075568146  accuracy:33.94653441816965\n",
      "Epoch69  loss:2.2014649427599373  accuracy:34.36226651437384\n",
      "Epoch70  loss:2.1932799276378416  accuracy:33.93871703432953\n",
      "Epoch71  loss:2.1975650820467205  accuracy:35.124921848880376\n",
      "Epoch72  loss:2.1958646252751355  accuracy:34.60896211790917\n",
      "Epoch73  loss:2.1835734518037904  accuracy:35.60384390886104\n",
      "Epoch74  loss:2.179881261454688  accuracy:35.083186039884936\n",
      "Epoch75  loss:2.1803519687718818  accuracy:35.75685550183452\n",
      "Epoch76  loss:2.1767197635438706  accuracy:35.299194566478135\n",
      "Epoch77  loss:2.181454133325153  accuracy:35.77628019234113\n",
      "Epoch78  loss:2.173116628494528  accuracy:35.6753895756798\n",
      "Epoch79  loss:2.175786725017759  accuracy:36.78752135208993\n",
      "Epoch80  loss:2.1749936338928015  accuracy:35.08484363450834\n",
      "Epoch81  loss:2.1838032129738068  accuracy:35.822889772713296\n",
      "Epoch82  loss:2.173721935517258  accuracy:35.587863564906186\n",
      "Epoch83  loss:2.181784697208139  accuracy:37.08886010040302\n",
      "Epoch84  loss:2.1830065871278443  accuracy:36.06951384300468\n",
      "Epoch85  loss:2.1761258001128834  accuracy:35.591827472118844\n",
      "Epoch86  loss:2.1864221140742304  accuracy:36.612744696993765\n",
      "Epoch87  loss:2.1888079007466636  accuracy:35.44136399475477\n",
      "Epoch88  loss:2.1649686412678824  accuracy:38.06370490067896\n",
      "Epoch89  loss:2.1866176411509515  accuracy:35.72991752823351\n",
      "Epoch90  loss:2.1760726900564302  accuracy:36.336231245048154\n",
      "Epoch91  loss:2.171239082680808  accuracy:36.66283301822774\n",
      "Epoch92  loss:2.1902034211489885  accuracy:37.301379892899675\n",
      "Epoch93  loss:2.2280340878499874  accuracy:35.66656820800133\n",
      "Epoch94  loss:2.199345714019404  accuracy:38.236181741358486\n",
      "Epoch95  loss:2.229793273740345  accuracy:36.34814106690726\n",
      "Epoch96  loss:2.218317852748765  accuracy:37.36880505810661\n",
      "Epoch97  loss:2.2134890180495046  accuracy:36.63470318051525\n",
      "Epoch98  loss:2.2115722790360453  accuracy:37.00096500267704\n",
      "Epoch99  loss:2.207298526995712  accuracy:37.14026647510805\n",
      "Epoch100  loss:2.246599045726988  accuracy:36.61148692664877\n"
     ]
    }
   ],
   "source": [
    "server = Server()\n",
    "workers = server.create_worker(federated_trainset,federated_valset,federated_testset)\n",
    "acc_train = []\n",
    "loss_train = []\n",
    "acc_valid = []\n",
    "loss_valid = []\n",
    "\n",
    "early_stopping = Early_Stopping(args.partience)\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for epoch in range(args.global_epochs):\n",
    "  sample_worker = server.sample_worker(workers)\n",
    "  server.send_model(sample_worker)\n",
    "\n",
    "  acc_train_avg = 0.0\n",
    "  loss_train_avg = 0.0\n",
    "  acc_valid_avg = 0.0\n",
    "  loss_valid_avg = 0.0\n",
    "  for worker in sample_worker:\n",
    "    acc_train_tmp,loss_train_tmp,acc_valid_tmp,loss_valid_tmp = worker.local_train()\n",
    "    acc_train_avg += acc_train_tmp/len(sample_worker)\n",
    "    loss_train_avg += loss_train_tmp/len(sample_worker)\n",
    "    acc_valid_avg += acc_valid_tmp/len(sample_worker)\n",
    "    loss_valid_avg += loss_valid_tmp/len(sample_worker)\n",
    "  server.aggregate_model(sample_worker)\n",
    "  '''\n",
    "  server.model.to(args.device)\n",
    "  for worker in workers:\n",
    "    acc_valid_tmp,loss_valid_tmp = test(server.model,args.criterion,worker.valloader)\n",
    "    acc_valid_avg += acc_valid_tmp/len(workers)\n",
    "    loss_valid_avg += loss_valid_tmp/len(workers)\n",
    "  server.model.to('cpu')\n",
    "  '''\n",
    "  print('Epoch{}  loss:{}  accuracy:{}'.format(epoch+1,loss_valid_avg,acc_valid_avg))\n",
    "  acc_train.append(acc_train_avg)\n",
    "  loss_train.append(loss_train_avg)\n",
    "  acc_valid.append(acc_valid_avg)\n",
    "  loss_valid.append(loss_valid_avg)\n",
    "\n",
    "  if early_stopping.validate(loss_valid_avg):\n",
    "    print('Early Stop')\n",
    "    break\n",
    "    \n",
    "end = time.time()#終了時刻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習時間：47682.79522371292秒\n"
     ]
    }
   ],
   "source": [
    "print('学習時間：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "mi_uceyoptLP",
    "outputId": "bc067e09-01bc-4e65-daf9-ac2f42373cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:45.143277002204265  loss:1.9714974335261755\n",
      "Worker2 accuracy:41.23711340206186  loss:2.2287590503692627\n",
      "Worker3 accuracy:29.545454545454547  loss:2.723363161087036\n",
      "Worker4 accuracy:48.484848484848484  loss:1.9901113510131836\n",
      "Worker5 accuracy:50.0  loss:1.9885848760604858\n",
      "Worker6 accuracy:47.61904761904762  loss:3.3311269283294678\n",
      "Worker7 accuracy:60.0  loss:1.3989063501358032\n",
      "Worker8 accuracy:43.388429752066116  loss:2.128187894821167\n",
      "Worker9 accuracy:66.66666666666667  loss:1.1926192045211792\n",
      "Worker10 accuracy:43.54838709677419  loss:2.1859631538391113\n",
      "Worker11 accuracy:43.925233644859816  loss:2.1325252056121826\n",
      "Worker12 accuracy:42.5  loss:1.8316822052001953\n",
      "Worker13 accuracy:44.71858134155744  loss:2.0484863917032876\n",
      "Worker14 accuracy:37.125748502994014  loss:2.198683500289917\n",
      "Worker15 accuracy:50.0  loss:1.891714334487915\n",
      "Worker16 accuracy:43.814919735599624  loss:1.9841575920581818\n",
      "Worker17 accuracy:37.17948717948718  loss:2.951043128967285\n",
      "Worker18 accuracy:50.0  loss:1.7645763158798218\n",
      "Worker19 accuracy:43.82273948075201  loss:2.0767359733581543\n",
      "Worker20 accuracy:33.333333333333336  loss:1.5922836065292358\n",
      "Test  loss:2.0805503828894523  accuracy:45.10266338938536\n"
     ]
    }
   ],
   "source": [
    "acc_test = []\n",
    "loss_test = []\n",
    "\n",
    "server.model.to(args.device)\n",
    "\n",
    "nums = 0\n",
    "for worker in workers:\n",
    "  nums += worker.test_data_num\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "  worker.aggregation_weight = 1.0*worker.test_data_num/nums\n",
    "  acc_tmp,loss_tmp = test(server.model,args.criterion,worker.testloader)\n",
    "  acc_test.append(acc_tmp)\n",
    "  loss_test.append(loss_tmp)\n",
    "  print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "\n",
    "end = time.time()#終了時刻\n",
    "\n",
    "acc_test_avg = sum(acc_test)/len(acc_test)\n",
    "loss_test_avg = sum(loss_test)/len(loss_test)\n",
    "print('Test  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推論時間：9.248472452163696秒\n"
     ]
    }
   ],
   "source": [
    "print('推論時間：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 Valid accuracy:44.81322718922229  loss:2.056096831957499\n",
      "Worker1 Test accuracy:43.4974283614989  loss:2.0859892879213606\n",
      "Worker2 Valid accuracy:42.12034383954155  loss:2.066981792449951\n",
      "Worker2 Test accuracy:42.955326460481096  loss:2.1699910163879395\n",
      "Worker3 Valid accuracy:45.283018867924525  loss:2.42067813873291\n",
      "Worker3 Test accuracy:29.545454545454547  loss:2.66286301612854\n",
      "Worker4 Valid accuracy:43.037974683544306  loss:2.3434717655181885\n",
      "Worker4 Test accuracy:48.484848484848484  loss:1.9649291038513184\n",
      "Worker5 Valid accuracy:47.36842105263158  loss:2.615518093109131\n",
      "Worker5 Test accuracy:50.0  loss:1.8807145357131958\n",
      "Worker6 Valid accuracy:41.666666666666664  loss:1.9759297370910645\n",
      "Worker6 Test accuracy:38.095238095238095  loss:3.153210163116455\n",
      "Worker7 Valid accuracy:0.0  loss:3.1311652660369873\n",
      "Worker7 Test accuracy:60.0  loss:1.4143699407577515\n",
      "Worker8 Valid accuracy:46.04810996563574  loss:1.9552513360977173\n",
      "Worker8 Test accuracy:52.06611570247934  loss:1.8409031629562378\n",
      "Worker9 Valid accuracy:0.0  loss:3.1332740783691406\n",
      "Worker9 Test accuracy:66.66666666666667  loss:1.196926474571228\n",
      "Worker10 Valid accuracy:42.6890756302521  loss:2.0666158199310303\n",
      "Worker10 Test accuracy:39.516129032258064  loss:2.243527412414551\n",
      "Worker11 Valid accuracy:32.03125  loss:2.4953789710998535\n",
      "Worker11 Test accuracy:38.3177570093458  loss:2.2383642196655273\n",
      "Worker12 Valid accuracy:37.5  loss:2.088622570037842\n",
      "Worker12 Test accuracy:37.5  loss:1.9092079401016235\n",
      "Worker13 Valid accuracy:42.948923867651786  loss:2.012592226266861\n",
      "Worker13 Test accuracy:43.52351580570547  loss:2.0097649892171225\n",
      "Worker14 Valid accuracy:37.65586034912718  loss:2.3142926692962646\n",
      "Worker14 Test accuracy:38.622754491017965  loss:2.2443273067474365\n",
      "Worker15 Valid accuracy:50.0  loss:1.7695415019989014\n",
      "Worker15 Test accuracy:50.0  loss:1.9184871912002563\n",
      "Worker16 Valid accuracy:43.88772298006296  loss:2.052505761384964\n",
      "Worker16 Test accuracy:44.507396915328926  loss:1.9839234948158264\n",
      "Worker17 Valid accuracy:47.87234042553192  loss:2.0172641277313232\n",
      "Worker17 Test accuracy:30.76923076923077  loss:2.8666131496429443\n",
      "Worker18 Valid accuracy:44.31818181818182  loss:1.9752392768859863\n",
      "Worker18 Test accuracy:43.24324324324324  loss:1.63859224319458\n",
      "Worker19 Valid accuracy:43.11823946288698  loss:2.033100128173828\n",
      "Worker19 Test accuracy:42.07699194270367  loss:2.038362145423889\n",
      "Worker20 Valid accuracy:0.0  loss:2.8161780834198\n",
      "Worker20 Test accuracy:33.333333333333336  loss:1.6057418584823608\n",
      "Validation(tune)  loss:2.2669849087794622  accuracy:36.61796783994307\n",
      "Test(tune)  loss:2.0533404326155074  accuracy:43.63607154294172\n"
     ]
    }
   ],
   "source": [
    "acc_tune_test = []\n",
    "loss_tune_test = []\n",
    "acc_tune_valid = []\n",
    "loss_tune_valid = []\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "    worker.model = copy.deepcopy(server.model)\n",
    "    worker.model = worker.model.to(args.device)\n",
    "    _,_,acc_tmp,loss_tmp = worker.local_train()\n",
    "    acc_tune_valid.append(acc_tmp)\n",
    "    loss_tune_valid.append(loss_tmp)\n",
    "    print('Worker{} Valid accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    \n",
    "    acc_tmp,loss_tmp = test(worker.model,args.criterion,worker.testloader)\n",
    "    acc_tune_test.append(acc_tmp)\n",
    "    loss_tune_test.append(loss_tmp)\n",
    "    print('Worker{} Test accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    worker.model = worker.model.to('cpu')\n",
    "    del worker.model\n",
    "\n",
    "end = time.time()#終了時刻\n",
    "\n",
    "acc_valid_avg = sum(acc_tune_valid)/len(acc_tune_valid)\n",
    "loss_valid_avg = sum(loss_tune_valid)/len(loss_tune_valid)\n",
    "print('Validation(tune)  loss:{}  accuracy:{}'.format(loss_valid_avg,acc_valid_avg))\n",
    "acc_test_avg = sum(acc_tune_test)/len(acc_tune_test)\n",
    "loss_test_avg = sum(loss_tune_test)/len(loss_tune_test)\n",
    "print('Test(tune)  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習・推論時間（fine-tune）：248.0717670917511秒\n"
     ]
    }
   ],
   "source": [
    "print('学習・推論時間（fine-tune）：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FedAvg_femnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
