{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "vkZxat4Y-IsQ",
    "outputId": "da86392c-66e8-4b60-b471-086e745cdcbc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from torch import nn, optim\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O0TfzOhU-QlG"
   },
   "outputs": [],
   "source": [
    "class Argments():\n",
    "  def __init__(self):\n",
    "    self.batch_size = 10\n",
    "    self.test_batch = 1000\n",
    "    #self.global_epochs = 300\n",
    "    self.local_epochs = 100\n",
    "    self.lr = None\n",
    "    self.momentum = 0.9\n",
    "    self.weight_decay = 10**-4.0\n",
    "    self.clip = 20.0\n",
    "    self.partience = 100\n",
    "    self.worker_num = 20\n",
    "    #self.sample_num = 20\n",
    "    self.device = device = torch.device('cuda:0'if torch.cuda.is_available() else'cpu')\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "args = Argments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(10**-3.0)\n",
    "lr_list.append(10**-2.5)\n",
    "lr_list.append(10**-2.0)\n",
    "lr_list.append(10**-1.5)\n",
    "lr_list.append(10**-1.0)\n",
    "lr_list.append(10**-0.5)\n",
    "lr_list.append(10**0.0)\n",
    "lr_list.append(10**0.5)\n",
    "\n",
    "args.lr = lr_list[lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r5PuCcqmJNUQ"
   },
   "outputs": [],
   "source": [
    "class LocalDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,dataset,worker_id):\n",
    "    self.data = []\n",
    "    self.target = []\n",
    "    self.id = worker_id\n",
    "    for i in range(len(dataset)):\n",
    "      self.data.append(dataset[i][0][0])\n",
    "      self.target.append(dataset[i][1][0])\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.data[index],self.target[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/federated_trainset_shakespeare.pickle', 'rb') as f:\n",
    "    all_federated_trainset = pickle.load(f)\n",
    "with open('../data/federated_testset_shakespeare.pickle', 'rb') as f:\n",
    "    all_federated_testset = pickle.load(f)\n",
    "all_worker_num = len(all_federated_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 6, 70, 62, 57, 35, 26, 139, 22, 108, 8, 7, 23, 55, 59, 129, 50, 107, 56, 114]\n"
     ]
    }
   ],
   "source": [
    "worker_id_list = random.sample(range(all_worker_num),args.worker_num)\n",
    "print(worker_id_list)\n",
    "federated_trainset = []\n",
    "federated_testset = []\n",
    "for i in worker_id_list:\n",
    "    federated_trainset.append(all_federated_trainset[i])\n",
    "    federated_testset.append(all_federated_testset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_valset = [None]*args.worker_num\n",
    "for i in range(args.worker_num):\n",
    "  n_samples = len(federated_trainset[i])\n",
    "  if n_samples==1:\n",
    "    federated_valset[i] = copy.deepcopy(federated_trainset[i])\n",
    "  else:\n",
    "    train_size = int(len(federated_trainset[i]) * 0.7) \n",
    "    val_size = n_samples - train_size \n",
    "    federated_trainset[i],federated_valset[i] = torch.utils.data.random_split(federated_trainset[i], [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZU3vAAb9-6SD"
   },
   "outputs": [],
   "source": [
    "class RNN1(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN1, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output\n",
    "\n",
    "class RNN2(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN2, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output\n",
    "\n",
    "class RNN3(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN3, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=3, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output\n",
    "    \n",
    "class RNN4(nn.Module):\n",
    "    def __init__(self, embedding_dim=8, vocab_size=90, hidden_size=256):\n",
    "        super(RNN4, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=4, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embeds = self.embeddings(input_seq)\n",
    "        # Note that the order of mini-batch is random so there is no hidden relationship among batches.\n",
    "        # So we do not input the previous batch's hidden state,\n",
    "        # leaving the first hidden state zero `self.lstm(embeds, None)`.\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # use the final hidden state as the next character prediction\n",
    "        final_hidden_state = lstm_out[:, -1]\n",
    "        output = self.fc(final_hidden_state)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Yu90X1TWJVKJ"
   },
   "outputs": [],
   "source": [
    "class Server():\n",
    "  def __init__(self):\n",
    "    self.model = RNN2()\n",
    "\n",
    "  def create_worker(self,federated_trainset,federated_valset,federated_testset):\n",
    "    workers = []\n",
    "    for i in range(args.worker_num):\n",
    "      workers.append(Worker(federated_trainset[i],federated_valset[i],federated_testset[i]))\n",
    "    return workers\n",
    "\n",
    "  def sample_worker(self,workers):\n",
    "    sample_worker = []\n",
    "    sample_worker_num = random.sample(range(args.worker_num),args.sample_num)\n",
    "    for i in sample_worker_num:\n",
    "      sample_worker.append(workers[i])\n",
    "    return sample_worker\n",
    "\n",
    "\n",
    "  def send_model(self,workers):\n",
    "    nums = 0\n",
    "    for worker in workers:\n",
    "      nums += worker.train_data_num\n",
    "\n",
    "    for worker in workers:\n",
    "      worker.aggregation_weight = 1.0*worker.train_data_num/nums\n",
    "      worker.model = copy.deepcopy(self.model)\n",
    "      worker.model = worker.model.to(args.device)\n",
    "\n",
    "  def aggregate_model(self,workers):   \n",
    "    new_params = OrderedDict()\n",
    "    for i,worker in enumerate(workers):\n",
    "      worker_state = worker.model.state_dict()\n",
    "      for key in worker_state.keys():\n",
    "        if i==0:\n",
    "          new_params[key] = worker_state[key]*worker.aggregation_weight\n",
    "        else:\n",
    "          new_params[key] += worker_state[key]*worker.aggregation_weight\n",
    "      worker.model = worker.model.to('cpu')\n",
    "      del worker.model\n",
    "    self.model.load_state_dict(new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LDWEBjgfJYFc"
   },
   "outputs": [],
   "source": [
    "class Worker():\n",
    "  def __init__(self,trainset,valset,testset):\n",
    "    self.trainloader = torch.utils.data.DataLoader(trainset,batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.valloader = torch.utils.data.DataLoader(valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.testloader = torch.utils.data.DataLoader(testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.model = None\n",
    "    self.train_data_num = len(trainset)\n",
    "    self.test_data_num = len(testset)\n",
    "    self.aggregation_weight = None\n",
    "\n",
    "  def local_train(self):\n",
    "    acc_valid,loss_valid = train(self.model,args.criterion,self.trainloader,self.valloader,args.local_epochs,partience=args.partience,early_stop=True)\n",
    "    return acc_valid[-1],loss_valid[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7-GY66gROuEU"
   },
   "outputs": [],
   "source": [
    "def train(model,criterion,trainloader,valloader,epochs,partience=0,early_stop=False):\n",
    "  if early_stop:\n",
    "    early_stopping = Early_Stopping(partience)\n",
    "\n",
    "  acc_valid = []\n",
    "  loss_valid = []\n",
    "  optimizer = optim.SGD(model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    model.train()\n",
    "    for (data,labels) in trainloader:\n",
    "      data,labels = Variable(data),Variable(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "      optimizer.step()\n",
    "      \n",
    "    model.eval()\n",
    "    for (data,labels) in valloader:\n",
    "      count += len(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      \n",
    "    print('Epoch:{}  accuracy:{}  loss:{}'.format(epoch+1,100.0*correct/count,running_loss/len(valloader)))\n",
    "    acc_valid.append(100.0*correct/count)\n",
    "    loss_valid.append(running_loss/len(valloader))\n",
    "    if early_stop:\n",
    "      if early_stopping.validate(running_loss):\n",
    "        print('Early Stop')\n",
    "        return acc_valid,loss_valid\n",
    "\n",
    "  return acc_valid,loss_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "oA4URv9mQ3xV"
   },
   "outputs": [],
   "source": [
    "def test(model,criterion,testloader):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  count = 0\n",
    "  for (data,labels) in testloader:\n",
    "    data,labels = data.to(args.device),labels.to(args.device)\n",
    "    outputs = model(data)\n",
    "    running_loss += criterion(outputs,labels).item()\n",
    "    predicted = torch.argmax(outputs,dim=1)\n",
    "    correct += (predicted==labels).sum().item()\n",
    "    count += len(labels)\n",
    "\n",
    "  accuracy = 100.0*correct/count\n",
    "  loss = running_loss/len(testloader)\n",
    "\n",
    "\n",
    "  return accuracy,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WMO7_WSLHeGl"
   },
   "outputs": [],
   "source": [
    "class Early_Stopping():\n",
    "  def __init__(self,partience):\n",
    "    self.step = 0\n",
    "    self.loss = float('inf')\n",
    "    self.partience = partience\n",
    "\n",
    "  def validate(self,loss):\n",
    "    if self.loss<loss:\n",
    "      self.step += 1\n",
    "      if self.step>self.partience:\n",
    "        return True\n",
    "    else:\n",
    "      self.step = 0\n",
    "      self.loss = loss\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "-noG_98IR-nZ",
    "outputId": "78a6ebe2-854a-4f83-dc45-5c4ac35b69e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 start\n",
      "Epoch:1  accuracy:18.61604409063074  loss:3.1486911508772106\n",
      "Epoch:2  accuracy:18.61604409063074  loss:3.118537876341078\n",
      "Epoch:3  accuracy:18.61604409063074  loss:3.115110264884101\n",
      "Epoch:4  accuracy:18.61604409063074  loss:3.1076209810045032\n",
      "Epoch:5  accuracy:18.61604409063074  loss:3.105384190877279\n",
      "Epoch:6  accuracy:18.61604409063074  loss:3.1215279367234974\n",
      "Epoch:7  accuracy:18.61604409063074  loss:3.0868136088053384\n",
      "Epoch:8  accuracy:18.444580526638088  loss:3.064385096232096\n",
      "Epoch:9  accuracy:20.25719534598898  loss:3.0219382445017495\n",
      "Epoch:10  accuracy:20.943049601959583  loss:2.983137845993042\n",
      "Epoch:11  accuracy:21.249234537660747  loss:2.9525361326005726\n",
      "Epoch:13  accuracy:22.841396203306797  loss:2.8719292216830783\n",
      "Epoch:14  accuracy:23.306797305572566  loss:2.827807823816935\n",
      "Epoch:15  accuracy:24.262094304960197  loss:2.7795510821872287\n",
      "Epoch:16  accuracy:25.254133496631965  loss:2.7280083762274847\n",
      "Epoch:17  accuracy:25.229638701775873  loss:2.6937519444359674\n",
      "Epoch:18  accuracy:26.12369871402327  loss:2.648783657285902\n",
      "Epoch:19  accuracy:27.11573790569504  loss:2.618066390355428\n",
      "Epoch:20  accuracy:27.740355174525412  loss:2.5901886887020535\n",
      "Epoch:21  accuracy:27.679118187385182  loss:2.5754482216305203\n",
      "Epoch:22  accuracy:28.144519289650948  loss:2.5408929453955755\n",
      "Epoch:23  accuracy:29.23453766074709  loss:2.525105079015096\n",
      "Epoch:24  accuracy:29.62645437844458  loss:2.5042463143666587\n",
      "Epoch:25  accuracy:29.94488671157379  loss:2.479848994149102\n",
      "Epoch:26  accuracy:30.72872014696877  loss:2.457520220014784\n",
      "Epoch:27  accuracy:31.78199632578077  loss:2.4397074116600885\n",
      "Epoch:28  accuracy:31.414574402939376  loss:2.427086936102973\n",
      "Epoch:29  accuracy:32.34537660747091  loss:2.4106464121076794\n",
      "Epoch:30  accuracy:32.54133496631966  loss:2.3951088852352567\n",
      "Epoch:31  accuracy:32.23515003061849  loss:2.382252905103895\n",
      "Epoch:32  accuracy:33.55786895284752  loss:2.358252684275309\n",
      "Epoch:33  accuracy:32.5780771586038  loss:2.3645442856682672\n",
      "Epoch:34  accuracy:32.77403551745254  loss:2.337816211912367\n",
      "Epoch:35  accuracy:34.18248622167789  loss:2.312194585800171\n",
      "Epoch:36  accuracy:34.562155541947334  loss:2.2968822850121393\n",
      "Epoch:37  accuracy:34.08450704225352  loss:2.2980186409420438\n",
      "Epoch:38  accuracy:34.97856705450092  loss:2.287326865726047\n",
      "Epoch:39  accuracy:35.456215554194735  loss:2.2719660070207386\n",
      "Epoch:40  accuracy:35.33374157991427  loss:2.257901986440023\n",
      "Epoch:41  accuracy:36.09308022045315  loss:2.243391169442071\n",
      "Epoch:42  accuracy:35.81139007960808  loss:2.2386556466420493\n",
      "Epoch:43  accuracy:36.55848132271892  loss:2.223244825998942\n",
      "Epoch:44  accuracy:37.03612982241274  loss:2.2098426818847656\n",
      "Epoch:45  accuracy:36.55848132271892  loss:2.206863376829359\n",
      "Epoch:46  accuracy:37.53827311696264  loss:2.1875932216644287\n",
      "Epoch:47  accuracy:37.57501530924679  loss:2.1926192972395153\n",
      "Epoch:48  accuracy:38.40783833435395  loss:2.1757460965050592\n",
      "Epoch:49  accuracy:38.113900796080834  loss:2.1682072480519614\n",
      "Epoch:50  accuracy:38.101653398652786  loss:2.1713248623742\n",
      "Epoch:51  accuracy:39.15492957746479  loss:2.1371221012539334\n",
      "Epoch:52  accuracy:39.056950398040414  loss:2.1385780705346003\n",
      "Epoch:53  accuracy:39.240661359461114  loss:2.132222228580051\n",
      "Epoch:54  accuracy:39.68156766687079  loss:2.121285835901896\n",
      "Epoch:55  accuracy:39.546846295162275  loss:2.118563069237603\n",
      "Epoch:56  accuracy:39.57134109001837  loss:2.1397898462083607\n",
      "Epoch:57  accuracy:40.257195345988976  loss:2.09254871474372\n",
      "Epoch:58  accuracy:40.60012247397428  loss:2.086374150382148\n",
      "Epoch:59  accuracy:40.551132884262096  loss:2.0719342496660023\n",
      "Epoch:60  accuracy:41.09001837109614  loss:2.081712086995443\n",
      "Epoch:61  accuracy:41.886099203919166  loss:2.052522129482693\n",
      "Epoch:62  accuracy:41.71463563992651  loss:2.044727166493734\n",
      "Epoch:63  accuracy:41.51867728107777  loss:2.057195292578803\n",
      "Epoch:64  accuracy:42.15554194733619  loss:2.04437784353892\n",
      "Epoch:65  accuracy:41.690140845070424  loss:2.034982588556078\n",
      "Epoch:66  accuracy:42.75566442131047  loss:2.0368648370107016\n",
      "Epoch:67  accuracy:42.90263319044703  loss:2.036129845513238\n",
      "Epoch:68  accuracy:43.110838946723824  loss:2.0192734003067017\n",
      "Epoch:69  accuracy:42.92712798530312  loss:2.0203947093751697\n",
      "Epoch:70  accuracy:43.15982853643601  loss:2.0157702366511026\n",
      "Epoch:71  accuracy:43.22106552357624  loss:2.009959035449558\n",
      "Epoch:72  accuracy:42.79240661359461  loss:2.024986015425788\n",
      "Epoch:73  accuracy:43.95590936925903  loss:2.010690450668335\n",
      "Epoch:74  accuracy:43.233312921004284  loss:2.0060626003477307\n",
      "Epoch:75  accuracy:41.971830985915496  loss:2.0215153959062366\n",
      "Epoch:76  accuracy:43.56399265156154  loss:2.01139587826199\n",
      "Epoch:77  accuracy:43.99265156154317  loss:2.0015468862321644\n",
      "Epoch:78  accuracy:43.84568279240661  loss:2.0004607571495905\n",
      "Epoch:79  accuracy:43.808940600122476  loss:1.9911686446931627\n",
      "Epoch:80  accuracy:43.39252908756889  loss:2.004057354397244\n",
      "Epoch:81  accuracy:44.48254745866503  loss:2.005555576748318\n",
      "Epoch:82  accuracy:43.96815676668708  loss:1.9995369248920016\n",
      "Epoch:83  accuracy:44.48254745866503  loss:1.9888659848107233\n",
      "Epoch:84  accuracy:43.943661971830984  loss:2.0038221809599133\n",
      "Epoch:85  accuracy:43.63747703612982  loss:2.016568104426066\n",
      "Epoch:86  accuracy:43.24556031843233  loss:2.0054756270514593\n",
      "Epoch:87  accuracy:44.029393753827314  loss:2.020645168092516\n",
      "Epoch:88  accuracy:44.10287813839559  loss:2.032006780306498\n",
      "Epoch:89  accuracy:43.233312921004284  loss:2.033944990899828\n",
      "Epoch:90  accuracy:43.723208818126146  loss:2.029276967048645\n",
      "Epoch:91  accuracy:42.87813839559094  loss:2.0459799898995294\n",
      "Epoch:92  accuracy:43.96815676668708  loss:2.053933342297872\n",
      "Epoch:93  accuracy:43.06184935701164  loss:2.072917938232422\n",
      "Epoch:94  accuracy:42.90263319044703  loss:2.079160902235243\n",
      "Epoch:95  accuracy:42.46172688303736  loss:2.0874814722273083\n",
      "Epoch:96  accuracy:41.82486221677893  loss:2.096682892905341\n",
      "Epoch:97  accuracy:42.69442743417024  loss:2.115043189790514\n",
      "Epoch:98  accuracy:42.094304960195956  loss:2.1198586093054876\n",
      "Epoch:99  accuracy:42.6576852418861  loss:2.1235278712378607\n",
      "Epoch:100  accuracy:42.00857317819963  loss:2.1605471769968667\n",
      "Worker2 start\n",
      "Epoch:1  accuracy:18.33810888252149  loss:4.444697380065918\n",
      "Epoch:2  accuracy:18.33810888252149  loss:4.378734111785889\n",
      "Epoch:3  accuracy:18.33810888252149  loss:4.308140277862549\n",
      "Epoch:4  accuracy:18.33810888252149  loss:4.230894565582275\n",
      "Epoch:5  accuracy:18.33810888252149  loss:4.1416802406311035\n",
      "Epoch:6  accuracy:18.33810888252149  loss:4.0334038734436035\n",
      "Epoch:7  accuracy:18.33810888252149  loss:3.896484136581421\n",
      "Epoch:8  accuracy:18.33810888252149  loss:3.745354652404785\n",
      "Epoch:9  accuracy:18.33810888252149  loss:3.625642776489258\n",
      "Epoch:10  accuracy:18.33810888252149  loss:3.5407168865203857\n",
      "Epoch:11  accuracy:18.33810888252149  loss:3.471543550491333\n",
      "Epoch:12  accuracy:18.33810888252149  loss:3.4181671142578125\n",
      "Epoch:13  accuracy:18.33810888252149  loss:3.377558469772339\n",
      "Epoch:14  accuracy:18.33810888252149  loss:3.348757028579712\n",
      "Epoch:15  accuracy:18.33810888252149  loss:3.3259291648864746\n",
      "Epoch:16  accuracy:18.33810888252149  loss:3.308091402053833\n",
      "Epoch:17  accuracy:18.33810888252149  loss:3.2958147525787354\n",
      "Epoch:18  accuracy:18.33810888252149  loss:3.2843480110168457\n",
      "Epoch:19  accuracy:18.33810888252149  loss:3.276967763900757\n",
      "Epoch:20  accuracy:18.33810888252149  loss:3.2748866081237793\n",
      "Epoch:21  accuracy:18.33810888252149  loss:3.2653210163116455\n",
      "Epoch:22  accuracy:18.33810888252149  loss:3.2605974674224854\n",
      "Epoch:23  accuracy:18.33810888252149  loss:3.2535483837127686\n",
      "Epoch:24  accuracy:18.33810888252149  loss:3.251502513885498\n",
      "Epoch:25  accuracy:18.33810888252149  loss:3.2493460178375244\n",
      "Epoch:26  accuracy:18.33810888252149  loss:3.242358446121216\n",
      "Epoch:27  accuracy:18.33810888252149  loss:3.2391018867492676\n",
      "Epoch:28  accuracy:18.33810888252149  loss:3.2364342212677\n",
      "Epoch:29  accuracy:18.33810888252149  loss:3.235384702682495\n",
      "Epoch:30  accuracy:18.33810888252149  loss:3.2299630641937256\n",
      "Epoch:31  accuracy:18.33810888252149  loss:3.232908010482788\n",
      "Epoch:32  accuracy:18.33810888252149  loss:3.2318813800811768\n",
      "Epoch:33  accuracy:18.33810888252149  loss:3.2281017303466797\n",
      "Epoch:34  accuracy:18.33810888252149  loss:3.224619150161743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:35  accuracy:18.33810888252149  loss:3.2248222827911377\n",
      "Epoch:36  accuracy:18.33810888252149  loss:3.2231528759002686\n",
      "Epoch:37  accuracy:18.33810888252149  loss:3.221156120300293\n",
      "Epoch:38  accuracy:18.33810888252149  loss:3.2223708629608154\n",
      "Epoch:39  accuracy:18.33810888252149  loss:3.220662832260132\n",
      "Epoch:40  accuracy:18.33810888252149  loss:3.2260687351226807\n",
      "Epoch:41  accuracy:18.33810888252149  loss:3.220625877380371\n",
      "Epoch:42  accuracy:18.33810888252149  loss:3.2190043926239014\n",
      "Epoch:43  accuracy:18.33810888252149  loss:3.222245693206787\n",
      "Epoch:44  accuracy:18.33810888252149  loss:3.2232275009155273\n",
      "Epoch:45  accuracy:18.33810888252149  loss:3.216989278793335\n",
      "Epoch:46  accuracy:18.33810888252149  loss:3.222698211669922\n",
      "Epoch:47  accuracy:18.33810888252149  loss:3.2185208797454834\n",
      "Epoch:48  accuracy:18.33810888252149  loss:3.21962571144104\n",
      "Epoch:49  accuracy:18.33810888252149  loss:3.2197136878967285\n",
      "Epoch:50  accuracy:18.33810888252149  loss:3.2169864177703857\n",
      "Epoch:51  accuracy:18.33810888252149  loss:3.2116594314575195\n",
      "Epoch:52  accuracy:18.33810888252149  loss:3.2182183265686035\n",
      "Epoch:53  accuracy:18.33810888252149  loss:3.21968412399292\n",
      "Epoch:54  accuracy:18.33810888252149  loss:3.2209601402282715\n",
      "Epoch:55  accuracy:18.33810888252149  loss:3.2152819633483887\n",
      "Epoch:56  accuracy:18.33810888252149  loss:3.2136542797088623\n",
      "Epoch:57  accuracy:18.33810888252149  loss:3.2185604572296143\n",
      "Epoch:58  accuracy:18.33810888252149  loss:3.22257137298584\n",
      "Epoch:59  accuracy:18.33810888252149  loss:3.2218728065490723\n",
      "Epoch:60  accuracy:18.33810888252149  loss:3.214256763458252\n",
      "Epoch:61  accuracy:18.33810888252149  loss:3.219510078430176\n",
      "Epoch:62  accuracy:18.33810888252149  loss:3.226858377456665\n",
      "Epoch:63  accuracy:18.33810888252149  loss:3.2172484397888184\n",
      "Epoch:64  accuracy:18.33810888252149  loss:3.224792003631592\n",
      "Epoch:65  accuracy:18.33810888252149  loss:3.2152633666992188\n",
      "Epoch:66  accuracy:18.33810888252149  loss:3.216130256652832\n",
      "Epoch:67  accuracy:18.33810888252149  loss:3.222472667694092\n",
      "Epoch:68  accuracy:18.33810888252149  loss:3.225546360015869\n",
      "Epoch:69  accuracy:18.33810888252149  loss:3.2186384201049805\n",
      "Epoch:70  accuracy:18.33810888252149  loss:3.216057062149048\n",
      "Epoch:71  accuracy:18.33810888252149  loss:3.2160496711730957\n",
      "Epoch:72  accuracy:18.33810888252149  loss:3.222646713256836\n",
      "Epoch:73  accuracy:18.33810888252149  loss:3.2202131748199463\n",
      "Epoch:74  accuracy:18.33810888252149  loss:3.2201309204101562\n",
      "Epoch:75  accuracy:18.33810888252149  loss:3.2207374572753906\n",
      "Epoch:76  accuracy:18.33810888252149  loss:3.217393636703491\n",
      "Epoch:77  accuracy:18.33810888252149  loss:3.2236814498901367\n",
      "Epoch:78  accuracy:18.33810888252149  loss:3.2224128246307373\n",
      "Epoch:79  accuracy:18.33810888252149  loss:3.2213943004608154\n",
      "Epoch:80  accuracy:18.33810888252149  loss:3.223597526550293\n",
      "Epoch:81  accuracy:18.33810888252149  loss:3.217153310775757\n",
      "Epoch:82  accuracy:18.33810888252149  loss:3.2216601371765137\n",
      "Epoch:83  accuracy:17.191977077363898  loss:3.230170726776123\n",
      "Epoch:84  accuracy:18.33810888252149  loss:3.216766834259033\n",
      "Epoch:85  accuracy:18.33810888252149  loss:3.220324754714966\n",
      "Epoch:86  accuracy:18.33810888252149  loss:3.2156906127929688\n",
      "Epoch:87  accuracy:18.33810888252149  loss:3.211514711380005\n",
      "Epoch:88  accuracy:18.33810888252149  loss:3.2184407711029053\n",
      "Epoch:89  accuracy:18.33810888252149  loss:3.2120325565338135\n",
      "Epoch:90  accuracy:18.33810888252149  loss:3.2186038494110107\n",
      "Epoch:91  accuracy:18.33810888252149  loss:3.2146244049072266\n",
      "Epoch:92  accuracy:18.33810888252149  loss:3.221666097640991\n",
      "Epoch:93  accuracy:18.33810888252149  loss:3.2150063514709473\n",
      "Epoch:94  accuracy:18.33810888252149  loss:3.215510129928589\n",
      "Epoch:95  accuracy:18.33810888252149  loss:3.2164509296417236\n",
      "Epoch:96  accuracy:18.33810888252149  loss:3.2230308055877686\n",
      "Epoch:97  accuracy:18.33810888252149  loss:3.215040922164917\n",
      "Epoch:98  accuracy:18.33810888252149  loss:3.2114663124084473\n",
      "Epoch:99  accuracy:18.33810888252149  loss:3.2224082946777344\n",
      "Epoch:100  accuracy:18.33810888252149  loss:3.217738389968872\n",
      "Worker3 start\n",
      "Epoch:1  accuracy:0.0  loss:4.489154815673828\n",
      "Epoch:2  accuracy:18.867924528301888  loss:4.476607322692871\n",
      "Epoch:3  accuracy:18.867924528301888  loss:4.462236404418945\n",
      "Epoch:4  accuracy:18.867924528301888  loss:4.4484758377075195\n",
      "Epoch:5  accuracy:18.867924528301888  loss:4.433986663818359\n",
      "Epoch:6  accuracy:18.867924528301888  loss:4.419013977050781\n",
      "Epoch:7  accuracy:18.867924528301888  loss:4.404629230499268\n",
      "Epoch:8  accuracy:18.867924528301888  loss:4.389697551727295\n",
      "Epoch:9  accuracy:18.867924528301888  loss:4.375931262969971\n",
      "Epoch:10  accuracy:18.867924528301888  loss:4.362070560455322\n",
      "Epoch:11  accuracy:18.867924528301888  loss:4.348385334014893\n",
      "Epoch:12  accuracy:18.867924528301888  loss:4.332691669464111\n",
      "Epoch:13  accuracy:18.867924528301888  loss:4.3179497718811035\n",
      "Epoch:14  accuracy:18.867924528301888  loss:4.302795886993408\n",
      "Epoch:15  accuracy:18.867924528301888  loss:4.288172245025635\n",
      "Epoch:16  accuracy:18.867924528301888  loss:4.272472858428955\n",
      "Epoch:17  accuracy:18.867924528301888  loss:4.256208896636963\n",
      "Epoch:18  accuracy:18.867924528301888  loss:4.2386579513549805\n",
      "Epoch:19  accuracy:18.867924528301888  loss:4.22028112411499\n",
      "Epoch:20  accuracy:18.867924528301888  loss:4.20239782333374\n",
      "Epoch:21  accuracy:18.867924528301888  loss:4.183158874511719\n",
      "Epoch:22  accuracy:18.867924528301888  loss:4.162744998931885\n",
      "Epoch:23  accuracy:18.867924528301888  loss:4.1432366371154785\n",
      "Epoch:24  accuracy:18.867924528301888  loss:4.122889518737793\n",
      "Epoch:25  accuracy:18.867924528301888  loss:4.102159023284912\n",
      "Epoch:26  accuracy:18.867924528301888  loss:4.079604625701904\n",
      "Epoch:27  accuracy:18.867924528301888  loss:4.057368278503418\n",
      "Epoch:28  accuracy:18.867924528301888  loss:4.035080432891846\n",
      "Epoch:29  accuracy:18.867924528301888  loss:4.01241397857666\n",
      "Epoch:30  accuracy:18.867924528301888  loss:3.9883577823638916\n",
      "Epoch:31  accuracy:18.867924528301888  loss:3.962934732437134\n",
      "Epoch:32  accuracy:18.867924528301888  loss:3.935730457305908\n",
      "Epoch:33  accuracy:18.867924528301888  loss:3.909837245941162\n",
      "Epoch:34  accuracy:18.867924528301888  loss:3.8808646202087402\n",
      "Epoch:35  accuracy:18.867924528301888  loss:3.8493473529815674\n",
      "Epoch:36  accuracy:18.867924528301888  loss:3.8158724308013916\n",
      "Epoch:37  accuracy:18.867924528301888  loss:3.7870302200317383\n",
      "Epoch:38  accuracy:18.867924528301888  loss:3.7592227458953857\n",
      "Epoch:39  accuracy:18.867924528301888  loss:3.7314538955688477\n",
      "Epoch:40  accuracy:18.867924528301888  loss:3.7031431198120117\n",
      "Epoch:41  accuracy:18.867924528301888  loss:3.6748034954071045\n",
      "Epoch:42  accuracy:18.867924528301888  loss:3.6497843265533447\n",
      "Epoch:43  accuracy:18.867924528301888  loss:3.624605178833008\n",
      "Epoch:44  accuracy:18.867924528301888  loss:3.6019341945648193\n",
      "Epoch:45  accuracy:18.867924528301888  loss:3.577334403991699\n",
      "Epoch:46  accuracy:18.867924528301888  loss:3.553439140319824\n",
      "Epoch:47  accuracy:18.867924528301888  loss:3.52931547164917\n",
      "Epoch:48  accuracy:18.867924528301888  loss:3.504032850265503\n",
      "Epoch:49  accuracy:18.867924528301888  loss:3.479339838027954\n",
      "Epoch:50  accuracy:18.867924528301888  loss:3.4601950645446777\n",
      "Epoch:51  accuracy:18.867924528301888  loss:3.433913230895996\n",
      "Epoch:52  accuracy:18.867924528301888  loss:3.4117515087127686\n",
      "Epoch:53  accuracy:18.867924528301888  loss:3.3869967460632324\n",
      "Epoch:54  accuracy:18.867924528301888  loss:3.3610942363739014\n",
      "Epoch:55  accuracy:18.867924528301888  loss:3.3380792140960693\n",
      "Epoch:56  accuracy:18.867924528301888  loss:3.319666624069214\n",
      "Epoch:57  accuracy:18.867924528301888  loss:3.3011136054992676\n",
      "Epoch:58  accuracy:18.867924528301888  loss:3.29059100151062\n",
      "Epoch:59  accuracy:18.867924528301888  loss:3.2767350673675537\n",
      "Epoch:60  accuracy:18.867924528301888  loss:3.265516519546509\n",
      "Epoch:61  accuracy:18.867924528301888  loss:3.2492401599884033\n",
      "Epoch:62  accuracy:18.867924528301888  loss:3.227877616882324\n",
      "Epoch:63  accuracy:18.867924528301888  loss:3.213979482650757\n",
      "Epoch:64  accuracy:18.867924528301888  loss:3.2066843509674072\n",
      "Epoch:65  accuracy:18.867924528301888  loss:3.1976373195648193\n",
      "Epoch:66  accuracy:18.867924528301888  loss:3.1842079162597656\n",
      "Epoch:67  accuracy:18.867924528301888  loss:3.173729181289673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:68  accuracy:18.867924528301888  loss:3.173130512237549\n",
      "Epoch:69  accuracy:18.867924528301888  loss:3.1661694049835205\n",
      "Epoch:70  accuracy:18.867924528301888  loss:3.16613507270813\n",
      "Epoch:71  accuracy:18.867924528301888  loss:3.168424606323242\n",
      "Epoch:72  accuracy:18.867924528301888  loss:3.1577422618865967\n",
      "Epoch:73  accuracy:18.867924528301888  loss:3.1423580646514893\n",
      "Epoch:74  accuracy:18.867924528301888  loss:3.13348126411438\n",
      "Epoch:75  accuracy:18.867924528301888  loss:3.126765012741089\n",
      "Epoch:76  accuracy:18.867924528301888  loss:3.125476121902466\n",
      "Epoch:77  accuracy:18.867924528301888  loss:3.125183582305908\n",
      "Epoch:78  accuracy:18.867924528301888  loss:3.1207833290100098\n",
      "Epoch:79  accuracy:18.867924528301888  loss:3.1249356269836426\n",
      "Epoch:80  accuracy:18.867924528301888  loss:3.116079330444336\n",
      "Epoch:81  accuracy:18.867924528301888  loss:3.1086950302124023\n",
      "Epoch:82  accuracy:18.867924528301888  loss:3.1066622734069824\n",
      "Epoch:83  accuracy:18.867924528301888  loss:3.104383945465088\n",
      "Epoch:84  accuracy:18.867924528301888  loss:3.1112184524536133\n",
      "Epoch:85  accuracy:18.867924528301888  loss:3.115037441253662\n",
      "Epoch:86  accuracy:18.867924528301888  loss:3.1114187240600586\n",
      "Epoch:87  accuracy:18.867924528301888  loss:3.1124629974365234\n",
      "Epoch:88  accuracy:18.867924528301888  loss:3.1165270805358887\n",
      "Epoch:89  accuracy:18.867924528301888  loss:3.1120200157165527\n",
      "Epoch:90  accuracy:18.867924528301888  loss:3.1149916648864746\n",
      "Epoch:91  accuracy:18.867924528301888  loss:3.113524913787842\n",
      "Epoch:92  accuracy:18.867924528301888  loss:3.1040303707122803\n",
      "Epoch:93  accuracy:18.867924528301888  loss:3.0953562259674072\n",
      "Epoch:94  accuracy:18.867924528301888  loss:3.090449571609497\n",
      "Epoch:95  accuracy:18.867924528301888  loss:3.095726490020752\n",
      "Epoch:96  accuracy:18.867924528301888  loss:3.0912368297576904\n",
      "Epoch:97  accuracy:18.867924528301888  loss:3.0913267135620117\n",
      "Epoch:98  accuracy:18.867924528301888  loss:3.096830368041992\n",
      "Epoch:99  accuracy:18.867924528301888  loss:3.088650703430176\n",
      "Epoch:100  accuracy:18.867924528301888  loss:3.0796399116516113\n",
      "Worker4 start\n",
      "Epoch:1  accuracy:0.0  loss:4.4963812828063965\n",
      "Epoch:2  accuracy:0.0  loss:4.482759952545166\n",
      "Epoch:3  accuracy:0.0  loss:4.469067096710205\n",
      "Epoch:4  accuracy:16.455696202531644  loss:4.455219268798828\n",
      "Epoch:5  accuracy:16.455696202531644  loss:4.442286491394043\n",
      "Epoch:6  accuracy:16.455696202531644  loss:4.427849769592285\n",
      "Epoch:7  accuracy:16.455696202531644  loss:4.414355278015137\n",
      "Epoch:8  accuracy:16.455696202531644  loss:4.400099277496338\n",
      "Epoch:9  accuracy:16.455696202531644  loss:4.3866658210754395\n",
      "Epoch:10  accuracy:16.455696202531644  loss:4.372870445251465\n",
      "Epoch:11  accuracy:16.455696202531644  loss:4.359102249145508\n",
      "Epoch:12  accuracy:16.455696202531644  loss:4.3440446853637695\n",
      "Epoch:13  accuracy:16.455696202531644  loss:4.330264568328857\n",
      "Epoch:14  accuracy:16.455696202531644  loss:4.314667701721191\n",
      "Epoch:15  accuracy:16.455696202531644  loss:4.299280166625977\n",
      "Epoch:16  accuracy:16.455696202531644  loss:4.283356189727783\n",
      "Epoch:17  accuracy:16.455696202531644  loss:4.268455982208252\n",
      "Epoch:18  accuracy:16.455696202531644  loss:4.252261161804199\n",
      "Epoch:19  accuracy:16.455696202531644  loss:4.235812664031982\n",
      "Epoch:20  accuracy:16.455696202531644  loss:4.217809200286865\n",
      "Epoch:21  accuracy:16.455696202531644  loss:4.199962139129639\n",
      "Epoch:22  accuracy:16.455696202531644  loss:4.180575370788574\n",
      "Epoch:23  accuracy:16.455696202531644  loss:4.160893440246582\n",
      "Epoch:24  accuracy:16.455696202531644  loss:4.140549182891846\n",
      "Epoch:25  accuracy:16.455696202531644  loss:4.1194167137146\n",
      "Epoch:26  accuracy:16.455696202531644  loss:4.096902370452881\n",
      "Epoch:27  accuracy:16.455696202531644  loss:4.0725626945495605\n",
      "Epoch:28  accuracy:16.455696202531644  loss:4.049494743347168\n",
      "Epoch:29  accuracy:16.455696202531644  loss:4.022296905517578\n",
      "Epoch:30  accuracy:16.455696202531644  loss:3.9967808723449707\n",
      "Epoch:31  accuracy:16.455696202531644  loss:3.968085527420044\n",
      "Epoch:32  accuracy:16.455696202531644  loss:3.9415581226348877\n",
      "Epoch:33  accuracy:16.455696202531644  loss:3.9116110801696777\n",
      "Epoch:34  accuracy:16.455696202531644  loss:3.8799631595611572\n",
      "Epoch:35  accuracy:16.455696202531644  loss:3.8516814708709717\n",
      "Epoch:36  accuracy:16.455696202531644  loss:3.8244435787200928\n",
      "Epoch:37  accuracy:16.455696202531644  loss:3.800478458404541\n",
      "Epoch:38  accuracy:16.455696202531644  loss:3.77647066116333\n",
      "Epoch:39  accuracy:16.455696202531644  loss:3.75671124458313\n",
      "Epoch:40  accuracy:16.455696202531644  loss:3.7344577312469482\n",
      "Epoch:41  accuracy:16.455696202531644  loss:3.71508526802063\n",
      "Epoch:42  accuracy:16.455696202531644  loss:3.695646286010742\n",
      "Epoch:43  accuracy:16.455696202531644  loss:3.6748082637786865\n",
      "Epoch:44  accuracy:16.455696202531644  loss:3.6526222229003906\n",
      "Epoch:45  accuracy:16.455696202531644  loss:3.6339004039764404\n",
      "Epoch:46  accuracy:16.455696202531644  loss:3.6147537231445312\n",
      "Epoch:47  accuracy:16.455696202531644  loss:3.5941503047943115\n",
      "Epoch:48  accuracy:16.455696202531644  loss:3.573974609375\n",
      "Epoch:49  accuracy:16.455696202531644  loss:3.5622217655181885\n",
      "Epoch:50  accuracy:16.455696202531644  loss:3.5496981143951416\n",
      "Epoch:51  accuracy:16.455696202531644  loss:3.5349209308624268\n",
      "Epoch:52  accuracy:16.455696202531644  loss:3.52944278717041\n",
      "Epoch:53  accuracy:16.455696202531644  loss:3.514003038406372\n",
      "Epoch:54  accuracy:16.455696202531644  loss:3.5070714950561523\n",
      "Epoch:55  accuracy:16.455696202531644  loss:3.499323606491089\n",
      "Epoch:56  accuracy:16.455696202531644  loss:3.4921207427978516\n",
      "Epoch:57  accuracy:16.455696202531644  loss:3.481926918029785\n",
      "Epoch:58  accuracy:16.455696202531644  loss:3.47556734085083\n",
      "Epoch:59  accuracy:16.455696202531644  loss:3.4713363647460938\n",
      "Epoch:60  accuracy:16.455696202531644  loss:3.4690439701080322\n",
      "Epoch:61  accuracy:16.455696202531644  loss:3.468036413192749\n",
      "Epoch:62  accuracy:16.455696202531644  loss:3.46421480178833\n",
      "Epoch:63  accuracy:16.455696202531644  loss:3.4627275466918945\n",
      "Epoch:64  accuracy:16.455696202531644  loss:3.4651453495025635\n",
      "Epoch:65  accuracy:16.455696202531644  loss:3.4565892219543457\n",
      "Epoch:66  accuracy:16.455696202531644  loss:3.4620361328125\n",
      "Epoch:67  accuracy:16.455696202531644  loss:3.4613590240478516\n",
      "Epoch:68  accuracy:16.455696202531644  loss:3.462617874145508\n",
      "Epoch:69  accuracy:16.455696202531644  loss:3.4593937397003174\n",
      "Epoch:70  accuracy:16.455696202531644  loss:3.4555652141571045\n",
      "Epoch:71  accuracy:16.455696202531644  loss:3.4580812454223633\n",
      "Epoch:72  accuracy:16.455696202531644  loss:3.4569084644317627\n",
      "Epoch:73  accuracy:16.455696202531644  loss:3.4569880962371826\n",
      "Epoch:74  accuracy:16.455696202531644  loss:3.452610731124878\n",
      "Epoch:75  accuracy:16.455696202531644  loss:3.453298330307007\n",
      "Epoch:76  accuracy:16.455696202531644  loss:3.4500482082366943\n",
      "Epoch:77  accuracy:16.455696202531644  loss:3.4493532180786133\n",
      "Epoch:78  accuracy:16.455696202531644  loss:3.4557154178619385\n",
      "Epoch:79  accuracy:16.455696202531644  loss:3.452348232269287\n",
      "Epoch:80  accuracy:16.455696202531644  loss:3.4580419063568115\n",
      "Epoch:81  accuracy:16.455696202531644  loss:3.458207845687866\n",
      "Epoch:82  accuracy:16.455696202531644  loss:3.4516870975494385\n",
      "Epoch:83  accuracy:16.455696202531644  loss:3.440063953399658\n",
      "Epoch:84  accuracy:16.455696202531644  loss:3.446040630340576\n",
      "Epoch:85  accuracy:16.455696202531644  loss:3.448810338973999\n",
      "Epoch:86  accuracy:16.455696202531644  loss:3.4498560428619385\n",
      "Epoch:87  accuracy:16.455696202531644  loss:3.448765516281128\n",
      "Epoch:88  accuracy:16.455696202531644  loss:3.450115442276001\n",
      "Epoch:89  accuracy:16.455696202531644  loss:3.447432518005371\n",
      "Epoch:90  accuracy:16.455696202531644  loss:3.455033779144287\n",
      "Epoch:91  accuracy:16.455696202531644  loss:3.4352402687072754\n",
      "Epoch:92  accuracy:16.455696202531644  loss:3.446953058242798\n",
      "Epoch:93  accuracy:16.455696202531644  loss:3.4463577270507812\n",
      "Epoch:94  accuracy:16.455696202531644  loss:3.4468994140625\n",
      "Epoch:95  accuracy:16.455696202531644  loss:3.4382200241088867\n",
      "Epoch:96  accuracy:16.455696202531644  loss:3.4373326301574707\n",
      "Epoch:97  accuracy:16.455696202531644  loss:3.43381667137146\n",
      "Epoch:98  accuracy:16.455696202531644  loss:3.434526205062866\n",
      "Epoch:99  accuracy:16.455696202531644  loss:3.43227219581604\n",
      "Epoch:100  accuracy:16.455696202531644  loss:3.4346885681152344\n",
      "Worker5 start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1  accuracy:2.6315789473684212  loss:4.491479396820068\n",
      "Epoch:2  accuracy:2.6315789473684212  loss:4.486478328704834\n",
      "Epoch:3  accuracy:2.6315789473684212  loss:4.4809722900390625\n",
      "Epoch:4  accuracy:2.6315789473684212  loss:4.474759578704834\n",
      "Epoch:5  accuracy:2.6315789473684212  loss:4.468466281890869\n",
      "Epoch:6  accuracy:2.6315789473684212  loss:4.462224006652832\n",
      "Epoch:7  accuracy:10.526315789473685  loss:4.455883026123047\n",
      "Epoch:8  accuracy:10.526315789473685  loss:4.44955587387085\n",
      "Epoch:9  accuracy:10.526315789473685  loss:4.443349838256836\n",
      "Epoch:10  accuracy:10.526315789473685  loss:4.436854362487793\n",
      "Epoch:11  accuracy:10.526315789473685  loss:4.430279731750488\n",
      "Epoch:12  accuracy:10.526315789473685  loss:4.423807621002197\n",
      "Epoch:13  accuracy:10.526315789473685  loss:4.417612075805664\n",
      "Epoch:14  accuracy:10.526315789473685  loss:4.411118030548096\n",
      "Epoch:15  accuracy:10.526315789473685  loss:4.4045939445495605\n",
      "Epoch:16  accuracy:10.526315789473685  loss:4.398208141326904\n",
      "Epoch:17  accuracy:10.526315789473685  loss:4.391515731811523\n",
      "Epoch:18  accuracy:10.526315789473685  loss:4.384871006011963\n",
      "Epoch:19  accuracy:10.526315789473685  loss:4.37820291519165\n",
      "Epoch:20  accuracy:10.526315789473685  loss:4.371689796447754\n",
      "Epoch:21  accuracy:10.526315789473685  loss:4.364778518676758\n",
      "Epoch:22  accuracy:10.526315789473685  loss:4.358474254608154\n",
      "Epoch:23  accuracy:10.526315789473685  loss:4.351330280303955\n",
      "Epoch:24  accuracy:10.526315789473685  loss:4.344165802001953\n",
      "Epoch:25  accuracy:10.526315789473685  loss:4.337034702301025\n",
      "Epoch:26  accuracy:10.526315789473685  loss:4.3297505378723145\n",
      "Epoch:27  accuracy:10.526315789473685  loss:4.322719573974609\n",
      "Epoch:28  accuracy:10.526315789473685  loss:4.315466403961182\n",
      "Epoch:29  accuracy:10.526315789473685  loss:4.307806491851807\n",
      "Epoch:30  accuracy:10.526315789473685  loss:4.299989223480225\n",
      "Epoch:31  accuracy:10.526315789473685  loss:4.292397975921631\n",
      "Epoch:32  accuracy:10.526315789473685  loss:4.284578800201416\n",
      "Epoch:33  accuracy:10.526315789473685  loss:4.27648401260376\n",
      "Epoch:34  accuracy:10.526315789473685  loss:4.268404006958008\n",
      "Epoch:35  accuracy:10.526315789473685  loss:4.259722709655762\n",
      "Epoch:36  accuracy:10.526315789473685  loss:4.251369953155518\n",
      "Epoch:37  accuracy:10.526315789473685  loss:4.242804527282715\n",
      "Epoch:38  accuracy:10.526315789473685  loss:4.2336506843566895\n",
      "Epoch:39  accuracy:10.526315789473685  loss:4.224112033843994\n",
      "Epoch:40  accuracy:10.526315789473685  loss:4.214791774749756\n",
      "Epoch:41  accuracy:10.526315789473685  loss:4.205323219299316\n",
      "Epoch:42  accuracy:10.526315789473685  loss:4.195496559143066\n",
      "Epoch:43  accuracy:10.526315789473685  loss:4.185762405395508\n",
      "Epoch:44  accuracy:10.526315789473685  loss:4.1758317947387695\n",
      "Epoch:45  accuracy:10.526315789473685  loss:4.1655683517456055\n",
      "Epoch:46  accuracy:10.526315789473685  loss:4.15458345413208\n",
      "Epoch:47  accuracy:10.526315789473685  loss:4.143331050872803\n",
      "Epoch:48  accuracy:10.526315789473685  loss:4.132174968719482\n",
      "Epoch:49  accuracy:10.526315789473685  loss:4.120545864105225\n",
      "Epoch:50  accuracy:10.526315789473685  loss:4.108643531799316\n",
      "Epoch:51  accuracy:10.526315789473685  loss:4.096960544586182\n",
      "Epoch:52  accuracy:10.526315789473685  loss:4.084509372711182\n",
      "Epoch:53  accuracy:10.526315789473685  loss:4.071659564971924\n",
      "Epoch:54  accuracy:10.526315789473685  loss:4.059252738952637\n",
      "Epoch:55  accuracy:10.526315789473685  loss:4.045263767242432\n",
      "Epoch:56  accuracy:10.526315789473685  loss:4.031703472137451\n",
      "Epoch:57  accuracy:10.526315789473685  loss:4.018876552581787\n",
      "Epoch:58  accuracy:10.526315789473685  loss:4.00453519821167\n",
      "Epoch:59  accuracy:10.526315789473685  loss:3.9912755489349365\n",
      "Epoch:60  accuracy:10.526315789473685  loss:3.978184700012207\n",
      "Epoch:61  accuracy:10.526315789473685  loss:3.9643330574035645\n",
      "Epoch:62  accuracy:10.526315789473685  loss:3.9505696296691895\n",
      "Epoch:63  accuracy:10.526315789473685  loss:3.938429594039917\n",
      "Epoch:64  accuracy:10.526315789473685  loss:3.926429271697998\n",
      "Epoch:65  accuracy:10.526315789473685  loss:3.914499044418335\n",
      "Epoch:66  accuracy:10.526315789473685  loss:3.9032440185546875\n",
      "Epoch:67  accuracy:10.526315789473685  loss:3.8925368785858154\n",
      "Epoch:68  accuracy:10.526315789473685  loss:3.882615327835083\n",
      "Epoch:69  accuracy:10.526315789473685  loss:3.873342514038086\n",
      "Epoch:70  accuracy:10.526315789473685  loss:3.864739179611206\n",
      "Epoch:71  accuracy:10.526315789473685  loss:3.8566606044769287\n",
      "Epoch:72  accuracy:10.526315789473685  loss:3.8474931716918945\n",
      "Epoch:73  accuracy:10.526315789473685  loss:3.8376564979553223\n",
      "Epoch:74  accuracy:10.526315789473685  loss:3.827451705932617\n",
      "Epoch:75  accuracy:10.526315789473685  loss:3.8176984786987305\n",
      "Epoch:76  accuracy:10.526315789473685  loss:3.8104047775268555\n",
      "Epoch:77  accuracy:10.526315789473685  loss:3.8036274909973145\n",
      "Epoch:78  accuracy:10.526315789473685  loss:3.79471755027771\n",
      "Epoch:79  accuracy:10.526315789473685  loss:3.7882542610168457\n",
      "Epoch:80  accuracy:10.526315789473685  loss:3.7818732261657715\n",
      "Epoch:81  accuracy:10.526315789473685  loss:3.771754503250122\n",
      "Epoch:82  accuracy:10.526315789473685  loss:3.7624688148498535\n",
      "Epoch:83  accuracy:10.526315789473685  loss:3.7536656856536865\n",
      "Epoch:84  accuracy:10.526315789473685  loss:3.742868423461914\n",
      "Epoch:85  accuracy:10.526315789473685  loss:3.7363264560699463\n",
      "Epoch:86  accuracy:10.526315789473685  loss:3.7333598136901855\n",
      "Epoch:87  accuracy:10.526315789473685  loss:3.7251505851745605\n",
      "Epoch:88  accuracy:10.526315789473685  loss:3.715627908706665\n",
      "Epoch:89  accuracy:10.526315789473685  loss:3.7077085971832275\n",
      "Epoch:90  accuracy:10.526315789473685  loss:3.7003612518310547\n",
      "Epoch:91  accuracy:10.526315789473685  loss:3.6974937915802\n",
      "Epoch:92  accuracy:10.526315789473685  loss:3.693138837814331\n",
      "Epoch:93  accuracy:10.526315789473685  loss:3.691821336746216\n",
      "Epoch:94  accuracy:10.526315789473685  loss:3.6858677864074707\n",
      "Epoch:95  accuracy:10.526315789473685  loss:3.682750940322876\n",
      "Epoch:96  accuracy:10.526315789473685  loss:3.6760475635528564\n",
      "Epoch:97  accuracy:10.526315789473685  loss:3.6734554767608643\n",
      "Epoch:98  accuracy:10.526315789473685  loss:3.6725728511810303\n",
      "Epoch:99  accuracy:10.526315789473685  loss:3.670236349105835\n",
      "Epoch:100  accuracy:10.526315789473685  loss:3.664763927459717\n",
      "Worker6 start\n",
      "Epoch:1  accuracy:0.0  loss:4.4841227531433105\n",
      "Epoch:2  accuracy:0.0  loss:4.481724262237549\n",
      "Epoch:3  accuracy:0.0  loss:4.478305816650391\n",
      "Epoch:4  accuracy:0.0  loss:4.474754810333252\n",
      "Epoch:5  accuracy:0.0  loss:4.471250534057617\n",
      "Epoch:6  accuracy:8.333333333333334  loss:4.46744966506958\n",
      "Epoch:7  accuracy:16.666666666666668  loss:4.463660717010498\n",
      "Epoch:8  accuracy:16.666666666666668  loss:4.459888458251953\n",
      "Epoch:9  accuracy:16.666666666666668  loss:4.456167697906494\n",
      "Epoch:10  accuracy:16.666666666666668  loss:4.452286243438721\n",
      "Epoch:11  accuracy:16.666666666666668  loss:4.448442459106445\n",
      "Epoch:12  accuracy:16.666666666666668  loss:4.444441795349121\n",
      "Epoch:13  accuracy:16.666666666666668  loss:4.440662860870361\n",
      "Epoch:14  accuracy:16.666666666666668  loss:4.436954975128174\n",
      "Epoch:15  accuracy:16.666666666666668  loss:4.433120250701904\n",
      "Epoch:16  accuracy:16.666666666666668  loss:4.4294304847717285\n",
      "Epoch:17  accuracy:16.666666666666668  loss:4.425561428070068\n",
      "Epoch:18  accuracy:16.666666666666668  loss:4.421828269958496\n",
      "Epoch:19  accuracy:16.666666666666668  loss:4.417945384979248\n",
      "Epoch:20  accuracy:16.666666666666668  loss:4.414026737213135\n",
      "Epoch:21  accuracy:16.666666666666668  loss:4.410402774810791\n",
      "Epoch:22  accuracy:16.666666666666668  loss:4.406386852264404\n",
      "Epoch:23  accuracy:16.666666666666668  loss:4.402542591094971\n",
      "Epoch:24  accuracy:16.666666666666668  loss:4.398805141448975\n",
      "Epoch:25  accuracy:16.666666666666668  loss:4.394909858703613\n",
      "Epoch:26  accuracy:16.666666666666668  loss:4.390995025634766\n",
      "Epoch:27  accuracy:16.666666666666668  loss:4.386966228485107\n",
      "Epoch:28  accuracy:16.666666666666668  loss:4.38297700881958\n",
      "Epoch:29  accuracy:16.666666666666668  loss:4.378813743591309\n",
      "Epoch:30  accuracy:16.666666666666668  loss:4.374462127685547\n",
      "Epoch:31  accuracy:16.666666666666668  loss:4.3705244064331055\n",
      "Epoch:32  accuracy:16.666666666666668  loss:4.366385459899902\n",
      "Epoch:33  accuracy:16.666666666666668  loss:4.36221170425415\n",
      "Epoch:34  accuracy:16.666666666666668  loss:4.358072757720947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:35  accuracy:16.666666666666668  loss:4.354092121124268\n",
      "Epoch:36  accuracy:16.666666666666668  loss:4.349672794342041\n",
      "Epoch:37  accuracy:16.666666666666668  loss:4.345517158508301\n",
      "Epoch:38  accuracy:16.666666666666668  loss:4.341277122497559\n",
      "Epoch:39  accuracy:16.666666666666668  loss:4.336878776550293\n",
      "Epoch:40  accuracy:16.666666666666668  loss:4.332719802856445\n",
      "Epoch:41  accuracy:16.666666666666668  loss:4.328542709350586\n",
      "Epoch:42  accuracy:16.666666666666668  loss:4.324111461639404\n",
      "Epoch:43  accuracy:16.666666666666668  loss:4.319706439971924\n",
      "Epoch:44  accuracy:16.666666666666668  loss:4.315385341644287\n",
      "Epoch:45  accuracy:16.666666666666668  loss:4.3110737800598145\n",
      "Epoch:46  accuracy:16.666666666666668  loss:4.306848049163818\n",
      "Epoch:47  accuracy:16.666666666666668  loss:4.302502632141113\n",
      "Epoch:48  accuracy:16.666666666666668  loss:4.297891616821289\n",
      "Epoch:49  accuracy:16.666666666666668  loss:4.2928595542907715\n",
      "Epoch:50  accuracy:16.666666666666668  loss:4.288119792938232\n",
      "Epoch:51  accuracy:16.666666666666668  loss:4.283660411834717\n",
      "Epoch:52  accuracy:16.666666666666668  loss:4.278702259063721\n",
      "Epoch:53  accuracy:16.666666666666668  loss:4.273789405822754\n",
      "Epoch:54  accuracy:16.666666666666668  loss:4.268899440765381\n",
      "Epoch:55  accuracy:16.666666666666668  loss:4.264001369476318\n",
      "Epoch:56  accuracy:16.666666666666668  loss:4.258967876434326\n",
      "Epoch:57  accuracy:16.666666666666668  loss:4.253938674926758\n",
      "Epoch:58  accuracy:16.666666666666668  loss:4.2487053871154785\n",
      "Epoch:59  accuracy:16.666666666666668  loss:4.243287563323975\n",
      "Epoch:60  accuracy:16.666666666666668  loss:4.23807954788208\n",
      "Epoch:61  accuracy:16.666666666666668  loss:4.2325758934021\n",
      "Epoch:62  accuracy:16.666666666666668  loss:4.227271556854248\n",
      "Epoch:63  accuracy:16.666666666666668  loss:4.221945285797119\n",
      "Epoch:64  accuracy:16.666666666666668  loss:4.216179370880127\n",
      "Epoch:65  accuracy:16.666666666666668  loss:4.2107086181640625\n",
      "Epoch:66  accuracy:16.666666666666668  loss:4.204935550689697\n",
      "Epoch:67  accuracy:16.666666666666668  loss:4.199342250823975\n",
      "Epoch:68  accuracy:16.666666666666668  loss:4.193359375\n",
      "Epoch:69  accuracy:16.666666666666668  loss:4.187586307525635\n",
      "Epoch:70  accuracy:16.666666666666668  loss:4.1817851066589355\n",
      "Epoch:71  accuracy:16.666666666666668  loss:4.175416469573975\n",
      "Epoch:72  accuracy:16.666666666666668  loss:4.169214725494385\n",
      "Epoch:73  accuracy:16.666666666666668  loss:4.163044452667236\n",
      "Epoch:74  accuracy:16.666666666666668  loss:4.156655311584473\n",
      "Epoch:75  accuracy:16.666666666666668  loss:4.149776935577393\n",
      "Epoch:76  accuracy:16.666666666666668  loss:4.14315938949585\n",
      "Epoch:77  accuracy:16.666666666666668  loss:4.136669635772705\n",
      "Epoch:78  accuracy:16.666666666666668  loss:4.129714012145996\n",
      "Epoch:79  accuracy:16.666666666666668  loss:4.122982978820801\n",
      "Epoch:80  accuracy:16.666666666666668  loss:4.115496635437012\n",
      "Epoch:81  accuracy:16.666666666666668  loss:4.107931137084961\n",
      "Epoch:82  accuracy:16.666666666666668  loss:4.100251197814941\n",
      "Epoch:83  accuracy:16.666666666666668  loss:4.092904090881348\n",
      "Epoch:84  accuracy:16.666666666666668  loss:4.085132122039795\n",
      "Epoch:85  accuracy:16.666666666666668  loss:4.077055931091309\n",
      "Epoch:86  accuracy:16.666666666666668  loss:4.0689215660095215\n",
      "Epoch:87  accuracy:16.666666666666668  loss:4.060919284820557\n",
      "Epoch:88  accuracy:16.666666666666668  loss:4.052785396575928\n",
      "Epoch:89  accuracy:16.666666666666668  loss:4.044517993927002\n",
      "Epoch:90  accuracy:16.666666666666668  loss:4.03571891784668\n",
      "Epoch:91  accuracy:16.666666666666668  loss:4.02635383605957\n",
      "Epoch:92  accuracy:16.666666666666668  loss:4.017082691192627\n",
      "Epoch:93  accuracy:16.666666666666668  loss:4.008108615875244\n",
      "Epoch:94  accuracy:16.666666666666668  loss:3.9989917278289795\n",
      "Epoch:95  accuracy:16.666666666666668  loss:3.98974347114563\n",
      "Epoch:96  accuracy:16.666666666666668  loss:3.9796931743621826\n",
      "Epoch:97  accuracy:16.666666666666668  loss:3.9704103469848633\n",
      "Epoch:98  accuracy:16.666666666666668  loss:3.960538148880005\n",
      "Epoch:99  accuracy:16.666666666666668  loss:3.950303792953491\n",
      "Epoch:100  accuracy:16.666666666666668  loss:3.940070390701294\n",
      "Worker7 start\n",
      "Epoch:1  accuracy:0.0  loss:4.499684810638428\n",
      "Epoch:2  accuracy:0.0  loss:4.49847936630249\n",
      "Epoch:3  accuracy:0.0  loss:4.497350215911865\n",
      "Epoch:4  accuracy:0.0  loss:4.495807647705078\n",
      "Epoch:5  accuracy:0.0  loss:4.493872165679932\n",
      "Epoch:6  accuracy:0.0  loss:4.492140293121338\n",
      "Epoch:7  accuracy:0.0  loss:4.490574836730957\n",
      "Epoch:8  accuracy:0.0  loss:4.4891438484191895\n",
      "Epoch:9  accuracy:0.0  loss:4.487822532653809\n",
      "Epoch:10  accuracy:0.0  loss:4.48659610748291\n",
      "Epoch:11  accuracy:0.0  loss:4.485445022583008\n",
      "Epoch:12  accuracy:0.0  loss:4.484353065490723\n",
      "Epoch:13  accuracy:0.0  loss:4.48306941986084\n",
      "Epoch:14  accuracy:0.0  loss:4.481604099273682\n",
      "Epoch:15  accuracy:0.0  loss:4.480258464813232\n",
      "Epoch:16  accuracy:0.0  loss:4.479010105133057\n",
      "Epoch:17  accuracy:0.0  loss:4.477368354797363\n",
      "Epoch:18  accuracy:0.0  loss:4.475114822387695\n",
      "Epoch:19  accuracy:0.0  loss:4.472871780395508\n",
      "Epoch:20  accuracy:0.0  loss:4.4709062576293945\n",
      "Epoch:21  accuracy:0.0  loss:4.469162464141846\n",
      "Epoch:22  accuracy:0.0  loss:4.4676008224487305\n",
      "Epoch:23  accuracy:0.0  loss:4.465937614440918\n",
      "Epoch:24  accuracy:0.0  loss:4.464167594909668\n",
      "Epoch:25  accuracy:0.0  loss:4.462337970733643\n",
      "Epoch:26  accuracy:0.0  loss:4.460426330566406\n",
      "Epoch:27  accuracy:0.0  loss:4.4584760665893555\n",
      "Epoch:28  accuracy:0.0  loss:4.4562296867370605\n",
      "Epoch:29  accuracy:0.0  loss:4.45350980758667\n",
      "Epoch:30  accuracy:0.0  loss:4.450625419616699\n",
      "Epoch:31  accuracy:0.0  loss:4.448142051696777\n",
      "Epoch:32  accuracy:0.0  loss:4.445989608764648\n",
      "Epoch:33  accuracy:0.0  loss:4.444094657897949\n",
      "Epoch:34  accuracy:0.0  loss:4.442408561706543\n",
      "Epoch:35  accuracy:0.0  loss:4.440901756286621\n",
      "Epoch:36  accuracy:0.0  loss:4.439540386199951\n",
      "Epoch:37  accuracy:0.0  loss:4.43781042098999\n",
      "Epoch:38  accuracy:0.0  loss:4.435717582702637\n",
      "Epoch:39  accuracy:0.0  loss:4.433859348297119\n",
      "Epoch:40  accuracy:0.0  loss:4.432191371917725\n",
      "Epoch:41  accuracy:0.0  loss:4.430434226989746\n",
      "Epoch:42  accuracy:0.0  loss:4.428576469421387\n",
      "Epoch:43  accuracy:0.0  loss:4.426663398742676\n",
      "Epoch:44  accuracy:0.0  loss:4.424677848815918\n",
      "Epoch:45  accuracy:0.0  loss:4.422664642333984\n",
      "Epoch:46  accuracy:0.0  loss:4.420608043670654\n",
      "Epoch:47  accuracy:0.0  loss:4.41879415512085\n",
      "Epoch:48  accuracy:0.0  loss:4.417176246643066\n",
      "Epoch:49  accuracy:0.0  loss:4.415720462799072\n",
      "Epoch:50  accuracy:0.0  loss:4.414397239685059\n",
      "Epoch:51  accuracy:0.0  loss:4.41317081451416\n",
      "Epoch:52  accuracy:0.0  loss:4.41176700592041\n",
      "Epoch:53  accuracy:0.0  loss:4.410192012786865\n",
      "Epoch:54  accuracy:0.0  loss:4.408502101898193\n",
      "Epoch:55  accuracy:0.0  loss:4.406693458557129\n",
      "Epoch:56  accuracy:0.0  loss:4.405067443847656\n",
      "Epoch:57  accuracy:0.0  loss:4.403589248657227\n",
      "Epoch:58  accuracy:0.0  loss:4.402228355407715\n",
      "Epoch:59  accuracy:0.0  loss:4.400959014892578\n",
      "Epoch:60  accuracy:0.0  loss:4.399771690368652\n",
      "Epoch:61  accuracy:0.0  loss:4.398654937744141\n",
      "Epoch:62  accuracy:0.0  loss:4.397333145141602\n",
      "Epoch:63  accuracy:0.0  loss:4.39581298828125\n",
      "Epoch:64  accuracy:0.0  loss:4.394161701202393\n",
      "Epoch:65  accuracy:0.0  loss:4.392382621765137\n",
      "Epoch:66  accuracy:0.0  loss:4.390283584594727\n",
      "Epoch:67  accuracy:0.0  loss:4.387358665466309\n",
      "Epoch:68  accuracy:0.0  loss:4.384261131286621\n",
      "Epoch:69  accuracy:0.0  loss:4.381582260131836\n",
      "Epoch:70  accuracy:0.0  loss:4.3792500495910645\n",
      "Epoch:71  accuracy:0.0  loss:4.377200603485107\n",
      "Epoch:72  accuracy:0.0  loss:4.375383377075195\n",
      "Epoch:73  accuracy:0.0  loss:4.373752593994141\n",
      "Epoch:74  accuracy:0.0  loss:4.372264862060547\n",
      "Epoch:75  accuracy:0.0  loss:4.370885848999023\n",
      "Epoch:76  accuracy:0.0  loss:4.369603633880615\n",
      "Epoch:77  accuracy:0.0  loss:4.368396282196045\n",
      "Epoch:78  accuracy:0.0  loss:4.367239475250244\n",
      "Epoch:79  accuracy:0.0  loss:4.366123199462891\n",
      "Epoch:80  accuracy:0.0  loss:4.364780426025391\n",
      "Epoch:81  accuracy:0.0  loss:4.363223075866699\n",
      "Epoch:82  accuracy:0.0  loss:4.361780166625977\n",
      "Epoch:83  accuracy:0.0  loss:4.360430717468262\n",
      "Epoch:84  accuracy:0.0  loss:4.359154224395752\n",
      "Epoch:85  accuracy:0.0  loss:4.357944011688232\n",
      "Epoch:86  accuracy:0.0  loss:4.356787204742432\n",
      "Epoch:87  accuracy:0.0  loss:4.355399131774902\n",
      "Epoch:88  accuracy:0.0  loss:4.353794574737549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:89  accuracy:0.0  loss:4.3523077964782715\n",
      "Epoch:90  accuracy:0.0  loss:4.350916862487793\n",
      "Epoch:91  accuracy:0.0  loss:4.349609375\n",
      "Epoch:92  accuracy:0.0  loss:4.348377227783203\n",
      "Epoch:93  accuracy:0.0  loss:4.346926212310791\n",
      "Epoch:94  accuracy:0.0  loss:4.3452653884887695\n",
      "Epoch:95  accuracy:0.0  loss:4.34374475479126\n",
      "Epoch:96  accuracy:0.0  loss:4.3423357009887695\n",
      "Epoch:97  accuracy:0.0  loss:4.341011047363281\n",
      "Epoch:98  accuracy:0.0  loss:4.33974552154541\n",
      "Epoch:99  accuracy:0.0  loss:4.337984561920166\n",
      "Epoch:100  accuracy:0.0  loss:4.335484504699707\n",
      "Worker8 start\n",
      "Epoch:1  accuracy:19.587628865979383  loss:4.462831020355225\n",
      "Epoch:2  accuracy:19.587628865979383  loss:4.403066635131836\n",
      "Epoch:3  accuracy:19.587628865979383  loss:4.342139720916748\n",
      "Epoch:4  accuracy:19.587628865979383  loss:4.276172161102295\n",
      "Epoch:5  accuracy:19.587628865979383  loss:4.205042362213135\n",
      "Epoch:6  accuracy:19.587628865979383  loss:4.122610569000244\n",
      "Epoch:7  accuracy:19.587628865979383  loss:4.025086879730225\n",
      "Epoch:8  accuracy:19.587628865979383  loss:3.912445068359375\n",
      "Epoch:9  accuracy:19.587628865979383  loss:3.7853870391845703\n",
      "Epoch:10  accuracy:19.587628865979383  loss:3.670560359954834\n",
      "Epoch:11  accuracy:19.587628865979383  loss:3.572772741317749\n",
      "Epoch:12  accuracy:19.587628865979383  loss:3.479969024658203\n",
      "Epoch:13  accuracy:19.587628865979383  loss:3.3994333744049072\n",
      "Epoch:14  accuracy:19.587628865979383  loss:3.3333683013916016\n",
      "Epoch:15  accuracy:19.587628865979383  loss:3.285877227783203\n",
      "Epoch:16  accuracy:19.587628865979383  loss:3.242009162902832\n",
      "Epoch:17  accuracy:19.587628865979383  loss:3.213330030441284\n",
      "Epoch:18  accuracy:19.587628865979383  loss:3.1929969787597656\n",
      "Epoch:19  accuracy:19.587628865979383  loss:3.1726253032684326\n",
      "Epoch:20  accuracy:19.587628865979383  loss:3.1679298877716064\n",
      "Epoch:21  accuracy:19.587628865979383  loss:3.1520543098449707\n",
      "Epoch:22  accuracy:19.587628865979383  loss:3.147495746612549\n",
      "Epoch:23  accuracy:19.587628865979383  loss:3.1388943195343018\n",
      "Epoch:24  accuracy:19.587628865979383  loss:3.134808301925659\n",
      "Epoch:25  accuracy:19.587628865979383  loss:3.134493827819824\n",
      "Epoch:26  accuracy:19.587628865979383  loss:3.127028465270996\n",
      "Epoch:27  accuracy:19.587628865979383  loss:3.1232008934020996\n",
      "Epoch:28  accuracy:19.587628865979383  loss:3.1215288639068604\n",
      "Epoch:29  accuracy:19.587628865979383  loss:3.1195013523101807\n",
      "Epoch:30  accuracy:19.587628865979383  loss:3.1134891510009766\n",
      "Epoch:31  accuracy:19.587628865979383  loss:3.1186318397521973\n",
      "Epoch:32  accuracy:19.587628865979383  loss:3.118023157119751\n",
      "Epoch:33  accuracy:19.587628865979383  loss:3.1212756633758545\n",
      "Epoch:34  accuracy:19.587628865979383  loss:3.117943525314331\n",
      "Epoch:35  accuracy:19.587628865979383  loss:3.1162798404693604\n",
      "Epoch:36  accuracy:19.587628865979383  loss:3.1062333583831787\n",
      "Epoch:37  accuracy:19.587628865979383  loss:3.124002695083618\n",
      "Epoch:38  accuracy:19.587628865979383  loss:3.116865873336792\n",
      "Epoch:39  accuracy:19.587628865979383  loss:3.112244129180908\n",
      "Epoch:40  accuracy:19.587628865979383  loss:3.1157803535461426\n",
      "Epoch:41  accuracy:19.587628865979383  loss:3.111614942550659\n",
      "Epoch:42  accuracy:19.587628865979383  loss:3.110837936401367\n",
      "Epoch:43  accuracy:19.587628865979383  loss:3.1121864318847656\n",
      "Epoch:44  accuracy:19.587628865979383  loss:3.1120526790618896\n",
      "Epoch:45  accuracy:19.587628865979383  loss:3.1094932556152344\n",
      "Epoch:46  accuracy:19.587628865979383  loss:3.1094183921813965\n",
      "Epoch:47  accuracy:19.587628865979383  loss:3.1157572269439697\n",
      "Epoch:48  accuracy:19.587628865979383  loss:3.1144258975982666\n",
      "Epoch:49  accuracy:19.587628865979383  loss:3.114933729171753\n",
      "Epoch:50  accuracy:19.587628865979383  loss:3.112169027328491\n",
      "Epoch:51  accuracy:19.587628865979383  loss:3.1073405742645264\n",
      "Epoch:52  accuracy:19.587628865979383  loss:3.1120777130126953\n",
      "Epoch:53  accuracy:19.587628865979383  loss:3.110646963119507\n",
      "Epoch:54  accuracy:19.587628865979383  loss:3.109412431716919\n",
      "Epoch:55  accuracy:19.587628865979383  loss:3.103986978530884\n",
      "Epoch:56  accuracy:19.587628865979383  loss:3.1036217212677\n",
      "Epoch:57  accuracy:19.587628865979383  loss:3.1100430488586426\n",
      "Epoch:58  accuracy:19.587628865979383  loss:3.1065168380737305\n",
      "Epoch:59  accuracy:19.587628865979383  loss:3.111527681350708\n",
      "Epoch:60  accuracy:19.587628865979383  loss:3.114551067352295\n",
      "Epoch:61  accuracy:19.587628865979383  loss:3.114957809448242\n",
      "Epoch:62  accuracy:19.587628865979383  loss:3.1193628311157227\n",
      "Epoch:63  accuracy:19.587628865979383  loss:3.117126226425171\n",
      "Epoch:64  accuracy:19.587628865979383  loss:3.111034393310547\n",
      "Epoch:65  accuracy:19.587628865979383  loss:3.115557909011841\n",
      "Epoch:66  accuracy:19.587628865979383  loss:3.116215705871582\n",
      "Epoch:67  accuracy:19.587628865979383  loss:3.1113333702087402\n",
      "Epoch:68  accuracy:19.587628865979383  loss:3.11732816696167\n",
      "Epoch:69  accuracy:19.587628865979383  loss:3.10599946975708\n",
      "Epoch:70  accuracy:19.587628865979383  loss:3.1031150817871094\n",
      "Epoch:71  accuracy:19.587628865979383  loss:3.104982614517212\n",
      "Epoch:72  accuracy:19.587628865979383  loss:3.1089658737182617\n",
      "Epoch:73  accuracy:19.587628865979383  loss:3.11618971824646\n",
      "Epoch:74  accuracy:19.587628865979383  loss:3.120123863220215\n",
      "Epoch:75  accuracy:19.587628865979383  loss:3.1057817935943604\n",
      "Epoch:76  accuracy:19.587628865979383  loss:3.1116490364074707\n",
      "Epoch:77  accuracy:19.587628865979383  loss:3.11088490486145\n",
      "Epoch:78  accuracy:19.587628865979383  loss:3.110278844833374\n",
      "Epoch:79  accuracy:19.587628865979383  loss:3.106832981109619\n",
      "Epoch:80  accuracy:19.587628865979383  loss:3.117050886154175\n",
      "Epoch:81  accuracy:19.587628865979383  loss:3.1206188201904297\n",
      "Epoch:82  accuracy:19.587628865979383  loss:3.107893466949463\n",
      "Epoch:83  accuracy:19.587628865979383  loss:3.11287522315979\n",
      "Epoch:84  accuracy:19.587628865979383  loss:3.109851837158203\n",
      "Epoch:85  accuracy:19.587628865979383  loss:3.112457275390625\n",
      "Epoch:86  accuracy:19.587628865979383  loss:3.1055777072906494\n",
      "Epoch:87  accuracy:19.587628865979383  loss:3.1154701709747314\n",
      "Epoch:88  accuracy:19.587628865979383  loss:3.108100652694702\n",
      "Epoch:89  accuracy:19.587628865979383  loss:3.1145541667938232\n",
      "Epoch:90  accuracy:19.587628865979383  loss:3.1133475303649902\n",
      "Epoch:91  accuracy:19.587628865979383  loss:3.102822780609131\n",
      "Epoch:92  accuracy:19.587628865979383  loss:3.10894513130188\n",
      "Epoch:93  accuracy:19.587628865979383  loss:3.1100013256073\n",
      "Epoch:94  accuracy:19.587628865979383  loss:3.110182523727417\n",
      "Epoch:95  accuracy:19.587628865979383  loss:3.114851474761963\n",
      "Epoch:96  accuracy:19.587628865979383  loss:3.1091654300689697\n",
      "Epoch:97  accuracy:19.587628865979383  loss:3.1127636432647705\n",
      "Epoch:98  accuracy:19.587628865979383  loss:3.1058506965637207\n",
      "Epoch:99  accuracy:19.587628865979383  loss:3.114030599594116\n",
      "Epoch:100  accuracy:19.587628865979383  loss:3.1062607765197754\n",
      "Worker9 start\n",
      "Epoch:1  accuracy:0.0  loss:4.491615295410156\n",
      "Epoch:2  accuracy:0.0  loss:4.491626739501953\n",
      "Epoch:3  accuracy:0.0  loss:4.491642475128174\n",
      "Epoch:4  accuracy:0.0  loss:4.491663455963135\n",
      "Epoch:5  accuracy:0.0  loss:4.491687774658203\n",
      "Epoch:6  accuracy:0.0  loss:4.491715908050537\n",
      "Epoch:7  accuracy:0.0  loss:4.49174690246582\n",
      "Epoch:8  accuracy:0.0  loss:4.491781711578369\n",
      "Epoch:9  accuracy:0.0  loss:4.491818904876709\n",
      "Epoch:10  accuracy:0.0  loss:4.491858005523682\n",
      "Epoch:11  accuracy:0.0  loss:4.491899490356445\n",
      "Epoch:12  accuracy:0.0  loss:4.491943359375\n",
      "Epoch:13  accuracy:0.0  loss:4.4919891357421875\n",
      "Epoch:14  accuracy:0.0  loss:4.492036819458008\n",
      "Epoch:15  accuracy:0.0  loss:4.492085933685303\n",
      "Epoch:16  accuracy:0.0  loss:4.492136478424072\n",
      "Epoch:17  accuracy:0.0  loss:4.492188930511475\n",
      "Epoch:18  accuracy:0.0  loss:4.492242336273193\n",
      "Epoch:19  accuracy:0.0  loss:4.4922966957092285\n",
      "Epoch:20  accuracy:0.0  loss:4.492352485656738\n",
      "Epoch:21  accuracy:0.0  loss:4.4924092292785645\n",
      "Epoch:22  accuracy:0.0  loss:4.492466926574707\n",
      "Epoch:23  accuracy:0.0  loss:4.492525577545166\n",
      "Epoch:24  accuracy:0.0  loss:4.492585182189941\n",
      "Epoch:25  accuracy:0.0  loss:4.492645263671875\n",
      "Epoch:26  accuracy:0.0  loss:4.492706775665283\n",
      "Epoch:27  accuracy:0.0  loss:4.492767810821533\n",
      "Epoch:28  accuracy:0.0  loss:4.492830753326416\n",
      "Epoch:29  accuracy:0.0  loss:4.492894649505615\n",
      "Epoch:30  accuracy:0.0  loss:4.492957592010498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:31  accuracy:0.0  loss:4.493022441864014\n",
      "Epoch:32  accuracy:0.0  loss:4.493087291717529\n",
      "Epoch:33  accuracy:0.0  loss:4.493153095245361\n",
      "Epoch:34  accuracy:0.0  loss:4.493218898773193\n",
      "Epoch:35  accuracy:0.0  loss:4.4932861328125\n",
      "Epoch:36  accuracy:0.0  loss:4.493353366851807\n",
      "Epoch:37  accuracy:0.0  loss:4.4934210777282715\n",
      "Epoch:38  accuracy:0.0  loss:4.493489742279053\n",
      "Epoch:39  accuracy:0.0  loss:4.493558406829834\n",
      "Epoch:40  accuracy:0.0  loss:4.493627071380615\n",
      "Epoch:41  accuracy:0.0  loss:4.493696689605713\n",
      "Epoch:42  accuracy:0.0  loss:4.493766784667969\n",
      "Epoch:43  accuracy:0.0  loss:4.493837833404541\n",
      "Epoch:44  accuracy:0.0  loss:4.493908405303955\n",
      "Epoch:45  accuracy:0.0  loss:4.4939799308776855\n",
      "Epoch:46  accuracy:0.0  loss:4.494052410125732\n",
      "Epoch:47  accuracy:0.0  loss:4.494124412536621\n",
      "Epoch:48  accuracy:0.0  loss:4.494197368621826\n",
      "Epoch:49  accuracy:0.0  loss:4.494270324707031\n",
      "Epoch:50  accuracy:0.0  loss:4.494344711303711\n",
      "Epoch:51  accuracy:0.0  loss:4.494418621063232\n",
      "Epoch:52  accuracy:0.0  loss:4.494493007659912\n",
      "Epoch:53  accuracy:0.0  loss:4.49456787109375\n",
      "Epoch:54  accuracy:0.0  loss:4.494643688201904\n",
      "Epoch:55  accuracy:0.0  loss:4.4947190284729\n",
      "Epoch:56  accuracy:0.0  loss:4.494795322418213\n",
      "Epoch:57  accuracy:0.0  loss:4.494872570037842\n",
      "Epoch:58  accuracy:0.0  loss:4.4949493408203125\n",
      "Epoch:59  accuracy:0.0  loss:4.4950270652771\n",
      "Epoch:60  accuracy:0.0  loss:4.495104789733887\n",
      "Epoch:61  accuracy:0.0  loss:4.49518346786499\n",
      "Epoch:62  accuracy:0.0  loss:4.495262145996094\n",
      "Epoch:63  accuracy:0.0  loss:4.4953413009643555\n",
      "Epoch:64  accuracy:0.0  loss:4.495420932769775\n",
      "Epoch:65  accuracy:0.0  loss:4.4955010414123535\n",
      "Epoch:66  accuracy:0.0  loss:4.495582103729248\n",
      "Epoch:67  accuracy:0.0  loss:4.495663166046143\n",
      "Epoch:68  accuracy:0.0  loss:4.495744228363037\n",
      "Epoch:69  accuracy:0.0  loss:4.495826721191406\n",
      "Epoch:70  accuracy:0.0  loss:4.495908737182617\n",
      "Epoch:71  accuracy:0.0  loss:4.4959917068481445\n",
      "Epoch:72  accuracy:0.0  loss:4.49607515335083\n",
      "Epoch:73  accuracy:0.0  loss:4.496159076690674\n",
      "Epoch:74  accuracy:0.0  loss:4.496243000030518\n",
      "Epoch:75  accuracy:0.0  loss:4.496327877044678\n",
      "Epoch:76  accuracy:0.0  loss:4.496413707733154\n",
      "Epoch:77  accuracy:0.0  loss:4.496499061584473\n",
      "Epoch:78  accuracy:0.0  loss:4.496584892272949\n",
      "Epoch:79  accuracy:0.0  loss:4.496671676635742\n",
      "Epoch:80  accuracy:0.0  loss:4.496758937835693\n",
      "Epoch:81  accuracy:0.0  loss:4.496846675872803\n",
      "Epoch:82  accuracy:0.0  loss:4.496934413909912\n",
      "Epoch:83  accuracy:0.0  loss:4.497023105621338\n",
      "Epoch:84  accuracy:0.0  loss:4.497112274169922\n",
      "Epoch:85  accuracy:0.0  loss:4.497201919555664\n",
      "Epoch:86  accuracy:0.0  loss:4.4972920417785645\n",
      "Epoch:87  accuracy:0.0  loss:4.497382640838623\n",
      "Epoch:88  accuracy:0.0  loss:4.49747371673584\n",
      "Epoch:89  accuracy:0.0  loss:4.497565746307373\n",
      "Epoch:90  accuracy:0.0  loss:4.497657775878906\n",
      "Epoch:91  accuracy:0.0  loss:4.497750759124756\n",
      "Epoch:92  accuracy:0.0  loss:4.497843265533447\n",
      "Epoch:93  accuracy:0.0  loss:4.497937202453613\n",
      "Epoch:94  accuracy:0.0  loss:4.4980316162109375\n",
      "Epoch:95  accuracy:0.0  loss:4.49812650680542\n",
      "Epoch:96  accuracy:0.0  loss:4.4982218742370605\n",
      "Epoch:97  accuracy:0.0  loss:4.498317718505859\n",
      "Epoch:98  accuracy:0.0  loss:4.498414516448975\n",
      "Epoch:99  accuracy:0.0  loss:4.498510837554932\n",
      "Epoch:100  accuracy:0.0  loss:4.4986090660095215\n",
      "Worker10 start\n",
      "Epoch:1  accuracy:17.647058823529413  loss:4.3965983390808105\n",
      "Epoch:2  accuracy:17.647058823529413  loss:4.2718095779418945\n",
      "Epoch:3  accuracy:17.647058823529413  loss:4.119787216186523\n",
      "Epoch:4  accuracy:17.647058823529413  loss:3.916123151779175\n",
      "Epoch:5  accuracy:17.647058823529413  loss:3.6824116706848145\n",
      "Epoch:6  accuracy:17.647058823529413  loss:3.495539903640747\n",
      "Epoch:7  accuracy:17.647058823529413  loss:3.367492198944092\n",
      "Epoch:8  accuracy:17.647058823529413  loss:3.3053574562072754\n",
      "Epoch:9  accuracy:17.647058823529413  loss:3.269726037979126\n",
      "Epoch:10  accuracy:17.647058823529413  loss:3.2498655319213867\n",
      "Epoch:11  accuracy:17.647058823529413  loss:3.22934889793396\n",
      "Epoch:12  accuracy:17.647058823529413  loss:3.21325421333313\n",
      "Epoch:13  accuracy:17.647058823529413  loss:3.207462787628174\n",
      "Epoch:14  accuracy:17.647058823529413  loss:3.200810194015503\n",
      "Epoch:15  accuracy:17.647058823529413  loss:3.1950902938842773\n",
      "Epoch:16  accuracy:17.647058823529413  loss:3.1917107105255127\n",
      "Epoch:17  accuracy:17.647058823529413  loss:3.1894171237945557\n",
      "Epoch:18  accuracy:17.647058823529413  loss:3.1869301795959473\n",
      "Epoch:19  accuracy:17.647058823529413  loss:3.181426525115967\n",
      "Epoch:20  accuracy:17.647058823529413  loss:3.180757999420166\n",
      "Epoch:21  accuracy:17.647058823529413  loss:3.179150342941284\n",
      "Epoch:22  accuracy:17.647058823529413  loss:3.178959846496582\n",
      "Epoch:23  accuracy:17.647058823529413  loss:3.176011323928833\n",
      "Epoch:24  accuracy:17.647058823529413  loss:3.1752288341522217\n",
      "Epoch:25  accuracy:17.647058823529413  loss:3.186272382736206\n",
      "Epoch:26  accuracy:17.647058823529413  loss:3.1757938861846924\n",
      "Epoch:27  accuracy:17.647058823529413  loss:3.1769397258758545\n",
      "Epoch:28  accuracy:17.647058823529413  loss:3.173783779144287\n",
      "Epoch:29  accuracy:17.647058823529413  loss:3.174746513366699\n",
      "Epoch:30  accuracy:17.647058823529413  loss:3.1768805980682373\n",
      "Epoch:31  accuracy:17.647058823529413  loss:3.1744332313537598\n",
      "Epoch:32  accuracy:17.647058823529413  loss:3.173717498779297\n",
      "Epoch:33  accuracy:17.647058823529413  loss:3.1732144355773926\n",
      "Epoch:34  accuracy:17.647058823529413  loss:3.178100347518921\n",
      "Epoch:35  accuracy:17.647058823529413  loss:3.1774184703826904\n",
      "Epoch:36  accuracy:17.647058823529413  loss:3.1807265281677246\n",
      "Epoch:37  accuracy:17.647058823529413  loss:3.180427312850952\n",
      "Epoch:38  accuracy:17.647058823529413  loss:3.171597719192505\n",
      "Epoch:39  accuracy:17.647058823529413  loss:3.1771974563598633\n",
      "Epoch:40  accuracy:17.647058823529413  loss:3.1826705932617188\n",
      "Epoch:41  accuracy:17.647058823529413  loss:3.1867785453796387\n",
      "Epoch:42  accuracy:17.647058823529413  loss:3.1748406887054443\n",
      "Epoch:43  accuracy:17.647058823529413  loss:3.1828205585479736\n",
      "Epoch:44  accuracy:17.647058823529413  loss:3.174722671508789\n",
      "Epoch:45  accuracy:17.647058823529413  loss:3.178485155105591\n",
      "Epoch:46  accuracy:17.647058823529413  loss:3.1797447204589844\n",
      "Epoch:47  accuracy:17.647058823529413  loss:3.1798133850097656\n",
      "Epoch:48  accuracy:17.647058823529413  loss:3.1828765869140625\n",
      "Epoch:49  accuracy:17.647058823529413  loss:3.1769399642944336\n",
      "Epoch:50  accuracy:17.647058823529413  loss:3.1740798950195312\n",
      "Epoch:51  accuracy:17.647058823529413  loss:3.1799583435058594\n",
      "Epoch:52  accuracy:17.647058823529413  loss:3.18135142326355\n",
      "Epoch:53  accuracy:17.647058823529413  loss:3.1760990619659424\n",
      "Epoch:54  accuracy:17.647058823529413  loss:3.179549217224121\n",
      "Epoch:55  accuracy:17.647058823529413  loss:3.1723597049713135\n",
      "Epoch:56  accuracy:17.647058823529413  loss:3.1729090213775635\n",
      "Epoch:57  accuracy:17.647058823529413  loss:3.188323736190796\n",
      "Epoch:58  accuracy:17.647058823529413  loss:3.178333044052124\n",
      "Epoch:59  accuracy:17.647058823529413  loss:3.17195725440979\n",
      "Epoch:60  accuracy:17.647058823529413  loss:3.1676743030548096\n",
      "Epoch:61  accuracy:17.647058823529413  loss:3.169420003890991\n",
      "Epoch:62  accuracy:17.647058823529413  loss:3.169238805770874\n",
      "Epoch:63  accuracy:17.647058823529413  loss:3.1808128356933594\n",
      "Epoch:64  accuracy:17.647058823529413  loss:3.1823389530181885\n",
      "Epoch:65  accuracy:17.647058823529413  loss:3.188028573989868\n",
      "Epoch:66  accuracy:17.647058823529413  loss:3.1859374046325684\n",
      "Epoch:67  accuracy:17.647058823529413  loss:3.1726059913635254\n",
      "Epoch:68  accuracy:17.647058823529413  loss:3.178114891052246\n",
      "Epoch:69  accuracy:17.647058823529413  loss:3.177532434463501\n",
      "Epoch:70  accuracy:17.647058823529413  loss:3.172581195831299\n",
      "Epoch:71  accuracy:17.647058823529413  loss:3.171417713165283\n",
      "Epoch:72  accuracy:17.647058823529413  loss:3.174025058746338\n",
      "Epoch:73  accuracy:17.647058823529413  loss:3.1821208000183105\n",
      "Epoch:74  accuracy:17.647058823529413  loss:3.172696352005005\n",
      "Epoch:75  accuracy:17.647058823529413  loss:3.17814040184021\n",
      "Epoch:76  accuracy:17.647058823529413  loss:3.1733577251434326\n",
      "Epoch:77  accuracy:17.647058823529413  loss:3.1747841835021973\n",
      "Epoch:78  accuracy:17.647058823529413  loss:3.1738858222961426\n",
      "Epoch:79  accuracy:17.647058823529413  loss:3.174086332321167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:80  accuracy:17.647058823529413  loss:3.1832756996154785\n",
      "Epoch:81  accuracy:17.647058823529413  loss:3.1767208576202393\n",
      "Epoch:82  accuracy:17.647058823529413  loss:3.1795382499694824\n",
      "Epoch:83  accuracy:17.647058823529413  loss:3.1748242378234863\n",
      "Epoch:84  accuracy:17.647058823529413  loss:3.1729941368103027\n",
      "Epoch:85  accuracy:17.647058823529413  loss:3.1749699115753174\n",
      "Epoch:86  accuracy:17.647058823529413  loss:3.1708269119262695\n",
      "Epoch:87  accuracy:17.647058823529413  loss:3.1747310161590576\n",
      "Epoch:88  accuracy:17.647058823529413  loss:3.1724977493286133\n",
      "Epoch:89  accuracy:17.647058823529413  loss:3.171229839324951\n",
      "Epoch:90  accuracy:17.647058823529413  loss:3.1748545169830322\n",
      "Epoch:91  accuracy:17.647058823529413  loss:3.178070306777954\n",
      "Epoch:92  accuracy:17.647058823529413  loss:3.1753792762756348\n",
      "Epoch:93  accuracy:17.647058823529413  loss:3.1769723892211914\n",
      "Epoch:94  accuracy:17.647058823529413  loss:3.1798295974731445\n",
      "Epoch:95  accuracy:17.647058823529413  loss:3.173435926437378\n",
      "Epoch:96  accuracy:17.647058823529413  loss:3.1968302726745605\n",
      "Epoch:97  accuracy:17.647058823529413  loss:3.1764047145843506\n",
      "Epoch:98  accuracy:17.647058823529413  loss:3.1771397590637207\n",
      "Epoch:99  accuracy:17.647058823529413  loss:3.174696445465088\n",
      "Epoch:100  accuracy:17.647058823529413  loss:3.1694328784942627\n",
      "Worker11 start\n",
      "Epoch:1  accuracy:0.0  loss:4.494834899902344\n",
      "Epoch:2  accuracy:15.625  loss:4.474560737609863\n",
      "Epoch:3  accuracy:15.625  loss:4.453263282775879\n",
      "Epoch:4  accuracy:15.625  loss:4.43204402923584\n",
      "Epoch:5  accuracy:15.625  loss:4.411436080932617\n",
      "Epoch:6  accuracy:15.625  loss:4.390425682067871\n",
      "Epoch:7  accuracy:15.625  loss:4.369566917419434\n",
      "Epoch:8  accuracy:15.625  loss:4.347472667694092\n",
      "Epoch:9  accuracy:15.625  loss:4.325035095214844\n",
      "Epoch:10  accuracy:15.625  loss:4.302483558654785\n",
      "Epoch:11  accuracy:15.625  loss:4.278663635253906\n",
      "Epoch:12  accuracy:15.625  loss:4.2534871101379395\n",
      "Epoch:13  accuracy:15.625  loss:4.226800441741943\n",
      "Epoch:14  accuracy:15.625  loss:4.199562072753906\n",
      "Epoch:15  accuracy:15.625  loss:4.16940975189209\n",
      "Epoch:16  accuracy:15.625  loss:4.137013912200928\n",
      "Epoch:17  accuracy:15.625  loss:4.103459358215332\n",
      "Epoch:18  accuracy:15.625  loss:4.066294193267822\n",
      "Epoch:19  accuracy:15.625  loss:4.025755882263184\n",
      "Epoch:20  accuracy:15.625  loss:3.9825098514556885\n",
      "Epoch:21  accuracy:15.625  loss:3.9361701011657715\n",
      "Epoch:22  accuracy:15.625  loss:3.887253999710083\n",
      "Epoch:23  accuracy:15.625  loss:3.8378090858459473\n",
      "Epoch:24  accuracy:15.625  loss:3.7904155254364014\n",
      "Epoch:25  accuracy:15.625  loss:3.747734308242798\n",
      "Epoch:26  accuracy:15.625  loss:3.7078239917755127\n",
      "Epoch:27  accuracy:15.625  loss:3.6700096130371094\n",
      "Epoch:28  accuracy:15.625  loss:3.638305187225342\n",
      "Epoch:29  accuracy:15.625  loss:3.605632781982422\n",
      "Epoch:30  accuracy:15.625  loss:3.5777924060821533\n",
      "Epoch:31  accuracy:15.625  loss:3.5503382682800293\n",
      "Epoch:32  accuracy:15.625  loss:3.529308319091797\n",
      "Epoch:33  accuracy:15.625  loss:3.506559133529663\n",
      "Epoch:34  accuracy:15.625  loss:3.4896230697631836\n",
      "Epoch:35  accuracy:15.625  loss:3.4706978797912598\n",
      "Epoch:36  accuracy:15.625  loss:3.457836389541626\n",
      "Epoch:37  accuracy:15.625  loss:3.444047689437866\n",
      "Epoch:38  accuracy:15.625  loss:3.4307236671447754\n",
      "Epoch:39  accuracy:15.625  loss:3.4211440086364746\n",
      "Epoch:40  accuracy:15.625  loss:3.413055896759033\n",
      "Epoch:41  accuracy:15.625  loss:3.4053115844726562\n",
      "Epoch:42  accuracy:15.625  loss:3.400560140609741\n",
      "Epoch:43  accuracy:15.625  loss:3.3974814414978027\n",
      "Epoch:44  accuracy:15.625  loss:3.388756275177002\n",
      "Epoch:45  accuracy:15.625  loss:3.3881149291992188\n",
      "Epoch:46  accuracy:15.625  loss:3.3837552070617676\n",
      "Epoch:47  accuracy:15.625  loss:3.383882999420166\n",
      "Epoch:48  accuracy:15.625  loss:3.3756539821624756\n",
      "Epoch:49  accuracy:15.625  loss:3.375257968902588\n",
      "Epoch:50  accuracy:15.625  loss:3.376286506652832\n",
      "Epoch:51  accuracy:15.625  loss:3.3728761672973633\n",
      "Epoch:52  accuracy:15.625  loss:3.370739221572876\n",
      "Epoch:53  accuracy:15.625  loss:3.368929386138916\n",
      "Epoch:54  accuracy:15.625  loss:3.3702187538146973\n",
      "Epoch:55  accuracy:15.625  loss:3.3666131496429443\n",
      "Epoch:56  accuracy:15.625  loss:3.364381790161133\n",
      "Epoch:57  accuracy:15.625  loss:3.365314483642578\n",
      "Epoch:58  accuracy:15.625  loss:3.3651623725891113\n",
      "Epoch:59  accuracy:15.625  loss:3.3608574867248535\n",
      "Epoch:60  accuracy:15.625  loss:3.3625502586364746\n",
      "Epoch:61  accuracy:15.625  loss:3.362786293029785\n",
      "Epoch:62  accuracy:15.625  loss:3.3573665618896484\n",
      "Epoch:63  accuracy:15.625  loss:3.3561887741088867\n",
      "Epoch:64  accuracy:15.625  loss:3.364832639694214\n",
      "Epoch:65  accuracy:15.625  loss:3.3609981536865234\n",
      "Epoch:66  accuracy:15.625  loss:3.353353977203369\n",
      "Epoch:67  accuracy:15.625  loss:3.356182813644409\n",
      "Epoch:68  accuracy:15.625  loss:3.3553781509399414\n",
      "Epoch:69  accuracy:15.625  loss:3.3547534942626953\n",
      "Epoch:70  accuracy:15.625  loss:3.3554580211639404\n",
      "Epoch:71  accuracy:15.625  loss:3.357055425643921\n",
      "Epoch:72  accuracy:15.625  loss:3.349400520324707\n",
      "Epoch:73  accuracy:15.625  loss:3.352922201156616\n",
      "Epoch:74  accuracy:15.625  loss:3.350698471069336\n",
      "Epoch:75  accuracy:15.625  loss:3.3526995182037354\n",
      "Epoch:76  accuracy:15.625  loss:3.3563601970672607\n",
      "Epoch:77  accuracy:15.625  loss:3.3525454998016357\n",
      "Epoch:78  accuracy:15.625  loss:3.3531665802001953\n",
      "Epoch:79  accuracy:15.625  loss:3.349785089492798\n",
      "Epoch:80  accuracy:15.625  loss:3.35537052154541\n",
      "Epoch:81  accuracy:15.625  loss:3.3441686630249023\n",
      "Epoch:82  accuracy:15.625  loss:3.351231098175049\n",
      "Epoch:83  accuracy:15.625  loss:3.34140682220459\n",
      "Epoch:84  accuracy:15.625  loss:3.34629225730896\n",
      "Epoch:85  accuracy:15.625  loss:3.3514232635498047\n",
      "Epoch:86  accuracy:15.625  loss:3.3540139198303223\n",
      "Epoch:87  accuracy:15.625  loss:3.3500759601593018\n",
      "Epoch:88  accuracy:15.625  loss:3.3479487895965576\n",
      "Epoch:89  accuracy:15.625  loss:3.347015380859375\n",
      "Epoch:90  accuracy:15.625  loss:3.349696397781372\n",
      "Epoch:91  accuracy:15.625  loss:3.348597764968872\n",
      "Epoch:92  accuracy:15.625  loss:3.344198226928711\n",
      "Epoch:93  accuracy:15.625  loss:3.343407154083252\n",
      "Epoch:94  accuracy:15.625  loss:3.3490421772003174\n",
      "Epoch:95  accuracy:15.625  loss:3.349374532699585\n",
      "Epoch:96  accuracy:15.625  loss:3.350142240524292\n",
      "Epoch:97  accuracy:15.625  loss:3.3431851863861084\n",
      "Epoch:98  accuracy:15.625  loss:3.3437445163726807\n",
      "Epoch:99  accuracy:15.625  loss:3.3444671630859375\n",
      "Epoch:100  accuracy:15.625  loss:3.3449811935424805\n",
      "Worker12 start\n",
      "Epoch:1  accuracy:0.0  loss:4.483851909637451\n",
      "Epoch:2  accuracy:0.0  loss:4.477917194366455\n",
      "Epoch:3  accuracy:6.25  loss:4.471496105194092\n",
      "Epoch:4  accuracy:6.25  loss:4.46459436416626\n",
      "Epoch:5  accuracy:6.25  loss:4.457240581512451\n",
      "Epoch:6  accuracy:6.25  loss:4.449831485748291\n",
      "Epoch:7  accuracy:6.25  loss:4.442883491516113\n",
      "Epoch:8  accuracy:6.25  loss:4.436197757720947\n",
      "Epoch:9  accuracy:6.25  loss:4.429287433624268\n",
      "Epoch:10  accuracy:6.25  loss:4.422524929046631\n",
      "Epoch:11  accuracy:6.25  loss:4.415603160858154\n",
      "Epoch:12  accuracy:6.25  loss:4.408415794372559\n",
      "Epoch:13  accuracy:6.25  loss:4.4011664390563965\n",
      "Epoch:14  accuracy:6.25  loss:4.393043041229248\n",
      "Epoch:15  accuracy:6.25  loss:4.384703636169434\n",
      "Epoch:16  accuracy:6.25  loss:4.377327919006348\n",
      "Epoch:17  accuracy:6.25  loss:4.3700995445251465\n",
      "Epoch:18  accuracy:6.25  loss:4.361652374267578\n",
      "Epoch:19  accuracy:6.25  loss:4.353964328765869\n",
      "Epoch:20  accuracy:6.25  loss:4.344966411590576\n",
      "Epoch:21  accuracy:6.25  loss:4.336089611053467\n",
      "Epoch:22  accuracy:6.25  loss:4.327647686004639\n",
      "Epoch:23  accuracy:6.25  loss:4.318612098693848\n",
      "Epoch:24  accuracy:6.25  loss:4.309070110321045\n",
      "Epoch:25  accuracy:6.25  loss:4.299168586730957\n",
      "Epoch:26  accuracy:6.25  loss:4.289613723754883\n",
      "Epoch:27  accuracy:6.25  loss:4.2802910804748535\n",
      "Epoch:28  accuracy:6.25  loss:4.2704176902771\n",
      "Epoch:29  accuracy:6.25  loss:4.260802745819092\n",
      "Epoch:30  accuracy:6.25  loss:4.250511646270752\n",
      "Epoch:31  accuracy:6.25  loss:4.239596843719482\n",
      "Epoch:32  accuracy:6.25  loss:4.228837490081787\n",
      "Epoch:33  accuracy:6.25  loss:4.217492580413818\n",
      "Epoch:34  accuracy:6.25  loss:4.2050862312316895\n",
      "Epoch:35  accuracy:6.25  loss:4.192415237426758\n",
      "Epoch:36  accuracy:6.25  loss:4.18137264251709\n",
      "Epoch:37  accuracy:6.25  loss:4.1718926429748535\n",
      "Epoch:38  accuracy:6.25  loss:4.162835597991943\n",
      "Epoch:39  accuracy:6.25  loss:4.15529203414917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:40  accuracy:6.25  loss:4.148861408233643\n",
      "Epoch:41  accuracy:6.25  loss:4.141816139221191\n",
      "Epoch:42  accuracy:6.25  loss:4.1407294273376465\n",
      "Epoch:43  accuracy:6.25  loss:4.139702320098877\n",
      "Epoch:44  accuracy:6.25  loss:4.132625579833984\n",
      "Epoch:45  accuracy:6.25  loss:4.1286420822143555\n",
      "Epoch:46  accuracy:6.25  loss:4.124375820159912\n",
      "Epoch:47  accuracy:6.25  loss:4.117904186248779\n",
      "Epoch:48  accuracy:6.25  loss:4.104287624359131\n",
      "Epoch:49  accuracy:6.25  loss:4.0926594734191895\n",
      "Epoch:50  accuracy:6.25  loss:4.077754020690918\n",
      "Epoch:51  accuracy:6.25  loss:4.063443660736084\n",
      "Epoch:52  accuracy:6.25  loss:4.053758144378662\n",
      "Epoch:53  accuracy:6.25  loss:4.0265398025512695\n",
      "Epoch:54  accuracy:6.25  loss:4.010758399963379\n",
      "Epoch:55  accuracy:6.25  loss:4.012521266937256\n",
      "Epoch:56  accuracy:6.25  loss:3.992772340774536\n",
      "Epoch:57  accuracy:6.25  loss:3.9688985347747803\n",
      "Epoch:58  accuracy:6.25  loss:3.9502179622650146\n",
      "Epoch:59  accuracy:6.25  loss:3.9336862564086914\n",
      "Epoch:60  accuracy:6.25  loss:3.9235479831695557\n",
      "Epoch:61  accuracy:6.25  loss:3.9089345932006836\n",
      "Epoch:62  accuracy:6.25  loss:3.90470814704895\n",
      "Epoch:63  accuracy:6.25  loss:3.897965431213379\n",
      "Epoch:64  accuracy:6.25  loss:3.8982696533203125\n",
      "Epoch:65  accuracy:6.25  loss:3.8846120834350586\n",
      "Epoch:66  accuracy:6.25  loss:3.883312463760376\n",
      "Epoch:67  accuracy:6.25  loss:3.8552863597869873\n",
      "Epoch:68  accuracy:6.25  loss:3.8250949382781982\n",
      "Epoch:69  accuracy:6.25  loss:3.812314748764038\n",
      "Epoch:70  accuracy:6.25  loss:3.826003313064575\n",
      "Epoch:71  accuracy:6.25  loss:3.8169937133789062\n",
      "Epoch:72  accuracy:6.25  loss:3.793339490890503\n",
      "Epoch:73  accuracy:6.25  loss:3.7745139598846436\n",
      "Epoch:74  accuracy:6.25  loss:3.787304162979126\n",
      "Epoch:75  accuracy:6.25  loss:3.7843873500823975\n",
      "Epoch:76  accuracy:6.25  loss:3.770705223083496\n",
      "Epoch:77  accuracy:6.25  loss:3.7826592922210693\n",
      "Epoch:78  accuracy:6.25  loss:3.7868471145629883\n",
      "Epoch:79  accuracy:6.25  loss:3.768152952194214\n",
      "Epoch:80  accuracy:6.25  loss:3.7756195068359375\n",
      "Epoch:81  accuracy:6.25  loss:3.7505061626434326\n",
      "Epoch:82  accuracy:6.25  loss:3.754924774169922\n",
      "Epoch:83  accuracy:6.25  loss:3.765265703201294\n",
      "Epoch:84  accuracy:6.25  loss:3.747941017150879\n",
      "Epoch:85  accuracy:6.25  loss:3.716120481491089\n",
      "Epoch:86  accuracy:6.25  loss:3.701809883117676\n",
      "Epoch:87  accuracy:6.25  loss:3.699457883834839\n",
      "Epoch:88  accuracy:6.25  loss:3.711880683898926\n",
      "Epoch:89  accuracy:6.25  loss:3.707749366760254\n",
      "Epoch:90  accuracy:6.25  loss:3.70868182182312\n",
      "Epoch:91  accuracy:6.25  loss:3.6844403743743896\n",
      "Epoch:92  accuracy:6.25  loss:3.709941864013672\n",
      "Epoch:93  accuracy:6.25  loss:3.699427366256714\n",
      "Epoch:94  accuracy:6.25  loss:3.6882002353668213\n",
      "Epoch:95  accuracy:6.25  loss:3.683516502380371\n",
      "Epoch:96  accuracy:6.25  loss:3.681297540664673\n",
      "Epoch:97  accuracy:6.25  loss:3.712573766708374\n",
      "Epoch:98  accuracy:6.25  loss:3.6990764141082764\n",
      "Epoch:99  accuracy:6.25  loss:3.6783149242401123\n",
      "Epoch:100  accuracy:6.25  loss:3.6784067153930664\n",
      "Worker13 start\n",
      "Epoch:1  accuracy:19.884355926758754  loss:3.6391438841819763\n",
      "Epoch:2  accuracy:19.884355926758754  loss:3.1880295276641846\n",
      "Epoch:3  accuracy:19.884355926758754  loss:3.142543375492096\n",
      "Epoch:4  accuracy:19.884355926758754  loss:3.1295395493507385\n",
      "Epoch:5  accuracy:19.884355926758754  loss:3.124384343624115\n",
      "Epoch:6  accuracy:19.884355926758754  loss:3.1215139031410217\n",
      "Epoch:7  accuracy:19.884355926758754  loss:3.113300383090973\n",
      "Epoch:8  accuracy:19.884355926758754  loss:3.1227466464042664\n",
      "Epoch:9  accuracy:19.884355926758754  loss:3.1140553951263428\n",
      "Epoch:10  accuracy:19.884355926758754  loss:3.1054510474205017\n",
      "Epoch:11  accuracy:19.884355926758754  loss:3.095150053501129\n",
      "Epoch:12  accuracy:19.884355926758754  loss:3.0856356024742126\n",
      "Epoch:13  accuracy:19.884355926758754  loss:3.0811803340911865\n",
      "Epoch:14  accuracy:20.334082878252488  loss:3.0665361285209656\n",
      "Epoch:15  accuracy:21.94025056215869  loss:3.04742294549942\n",
      "Epoch:16  accuracy:22.19723739158368  loss:3.027063488960266\n",
      "Epoch:17  accuracy:21.39415354963058  loss:3.009508430957794\n",
      "Epoch:18  accuracy:22.936074526180533  loss:2.9918978214263916\n",
      "Epoch:19  accuracy:23.064567940893028  loss:2.9774418473243713\n",
      "Epoch:20  accuracy:23.578541599743012  loss:2.9567245841026306\n",
      "Epoch:21  accuracy:25.50594282043045  loss:2.9389679431915283\n",
      "Epoch:22  accuracy:24.413748795374236  loss:2.9242130517959595\n",
      "Epoch:23  accuracy:25.377449405717957  loss:2.9086745381355286\n",
      "Epoch:24  accuracy:25.056215868936718  loss:2.8936022520065308\n",
      "Epoch:25  accuracy:26.084163186636683  loss:2.8851636052131653\n",
      "Epoch:26  accuracy:25.473819466752328  loss:2.868048131465912\n",
      "Epoch:27  accuracy:25.281079344683587  loss:2.8616946935653687\n",
      "Epoch:28  accuracy:24.959845807902344  loss:2.849824905395508\n",
      "Epoch:29  accuracy:25.666559588821073  loss:2.8423990607261658\n",
      "Epoch:30  accuracy:25.89142306456794  loss:2.82854425907135\n",
      "Epoch:31  accuracy:26.11628654031481  loss:2.8164762258529663\n",
      "Epoch:32  accuracy:26.405396723417926  loss:2.7973973155021667\n",
      "Epoch:33  accuracy:25.859299710889818  loss:2.801623821258545\n",
      "Epoch:34  accuracy:24.991969161580467  loss:2.7877679467201233\n",
      "Epoch:35  accuracy:26.309026662383552  loss:2.768883228302002\n",
      "Epoch:36  accuracy:26.373273369739803  loss:2.76054310798645\n",
      "Epoch:37  accuracy:25.602312881464826  loss:2.740681290626526\n",
      "Epoch:38  accuracy:26.91937038226791  loss:2.73748779296875\n",
      "Epoch:39  accuracy:26.53389013813042  loss:2.710816979408264\n",
      "Epoch:40  accuracy:28.23642788307099  loss:2.6975695490837097\n",
      "Epoch:41  accuracy:27.56183745583039  loss:2.6906991004943848\n",
      "Epoch:42  accuracy:28.429168005139736  loss:2.6761337518692017\n",
      "Epoch:43  accuracy:28.750401541920976  loss:2.6588926315307617\n",
      "Epoch:44  accuracy:29.296498554449084  loss:2.652692675590515\n",
      "Epoch:45  accuracy:28.975265017667844  loss:2.6364532709121704\n",
      "Epoch:46  accuracy:30.131705750080307  loss:2.6251543164253235\n",
      "Epoch:47  accuracy:29.778348859620944  loss:2.6225855350494385\n",
      "Epoch:48  accuracy:29.553485383874076  loss:2.601563572883606\n",
      "Epoch:49  accuracy:29.74622550594282  loss:2.5907599925994873\n",
      "Epoch:50  accuracy:30.999036299389655  loss:2.5834035873413086\n",
      "Epoch:51  accuracy:31.159653067780276  loss:2.575883448123932\n",
      "Epoch:52  accuracy:31.288146482492774  loss:2.575890004634857\n",
      "Epoch:53  accuracy:31.256023128814647  loss:2.55887371301651\n",
      "Epoch:54  accuracy:31.127529714102153  loss:2.5617253184318542\n",
      "Epoch:55  accuracy:30.64567940893029  loss:2.577535569667816\n",
      "Epoch:56  accuracy:32.02698361708963  loss:2.5341790914535522\n",
      "Epoch:57  accuracy:31.76999678766463  loss:2.539356827735901\n",
      "Epoch:58  accuracy:32.25184709283649  loss:2.526768982410431\n",
      "Epoch:59  accuracy:32.15547703180212  loss:2.5201008915901184\n",
      "Epoch:60  accuracy:31.962736909733376  loss:2.514418065547943\n",
      "Epoch:61  accuracy:31.866366848699005  loss:2.5168208479881287\n",
      "Epoch:62  accuracy:32.50883392226148  loss:2.507081091403961\n",
      "Epoch:63  accuracy:32.05910697076775  loss:2.504103362560272\n",
      "Epoch:64  accuracy:32.60520398329586  loss:2.4920095205307007\n",
      "Epoch:65  accuracy:32.47671056858336  loss:2.5083836913108826\n",
      "Epoch:66  accuracy:31.866366848699005  loss:2.490655303001404\n",
      "Epoch:67  accuracy:32.99068422743334  loss:2.4761509895324707\n",
      "Epoch:68  accuracy:32.73369739800835  loss:2.4684837460517883\n",
      "Epoch:69  accuracy:33.53678123996145  loss:2.4610116481781006\n",
      "Epoch:70  accuracy:33.18342434950209  loss:2.470495820045471\n",
      "Epoch:71  accuracy:33.08705428846772  loss:2.455681324005127\n",
      "Epoch:72  accuracy:33.151300995823966  loss:2.4403483271598816\n",
      "Epoch:73  accuracy:33.408287825248955  loss:2.4520082473754883\n",
      "Epoch:74  accuracy:33.37616447157083  loss:2.4500696063041687\n",
      "Epoch:75  accuracy:33.76164471570832  loss:2.428312599658966\n",
      "Epoch:76  accuracy:32.86219081272085  loss:2.429525077342987\n",
      "Epoch:77  accuracy:34.33986508191455  loss:2.427820920944214\n",
      "Epoch:78  accuracy:34.24349502088018  loss:2.4075098037719727\n",
      "Epoch:79  accuracy:34.436235142948924  loss:2.414974093437195\n",
      "Epoch:80  accuracy:34.85383874076454  loss:2.405935227870941\n",
      "Epoch:81  accuracy:35.2071956312239  loss:2.3977092504501343\n",
      "Epoch:82  accuracy:34.72534532605204  loss:2.3965631127357483\n",
      "Epoch:83  accuracy:34.66109861869579  loss:2.388312876224518\n",
      "Epoch:84  accuracy:34.436235142948924  loss:2.3888425827026367\n",
      "Epoch:85  accuracy:34.50048185030517  loss:2.390302002429962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:86  accuracy:34.56472855766142  loss:2.373402774333954\n",
      "Epoch:87  accuracy:35.0787022165114  loss:2.3701154589653015\n",
      "Epoch:88  accuracy:35.0787022165114  loss:2.3643566966056824\n",
      "Epoch:89  accuracy:34.532605203983294  loss:2.368120014667511\n",
      "Epoch:90  accuracy:34.918085448120785  loss:2.3765076398849487\n",
      "Epoch:91  accuracy:34.59685191133954  loss:2.3535879254341125\n",
      "Epoch:92  accuracy:35.43205910697077  loss:2.3551486134529114\n",
      "Epoch:93  accuracy:35.52842916800514  loss:2.355376362800598\n",
      "Epoch:94  accuracy:35.27144233858015  loss:2.3547325134277344\n",
      "Epoch:95  accuracy:35.94603276582075  loss:2.347601532936096\n",
      "Epoch:96  accuracy:36.042402826855124  loss:2.345323324203491\n",
      "Epoch:97  accuracy:36.010279473177  loss:2.3424474596977234\n",
      "Epoch:98  accuracy:35.43205910697077  loss:2.3463568091392517\n",
      "Epoch:99  accuracy:36.042402826855124  loss:2.3311917185783386\n",
      "Epoch:100  accuracy:36.65274654673948  loss:2.3147172927856445\n",
      "Worker14 start\n",
      "Epoch:1  accuracy:16.209476309226932  loss:4.426682472229004\n",
      "Epoch:2  accuracy:16.209476309226932  loss:4.350205421447754\n",
      "Epoch:3  accuracy:16.209476309226932  loss:4.2679877281188965\n",
      "Epoch:4  accuracy:16.209476309226932  loss:4.174806594848633\n",
      "Epoch:5  accuracy:16.209476309226932  loss:4.06125545501709\n",
      "Epoch:6  accuracy:16.209476309226932  loss:3.9158847332000732\n",
      "Epoch:7  accuracy:16.209476309226932  loss:3.744873046875\n",
      "Epoch:8  accuracy:16.209476309226932  loss:3.5886282920837402\n",
      "Epoch:9  accuracy:16.209476309226932  loss:3.4571282863616943\n",
      "Epoch:10  accuracy:16.209476309226932  loss:3.3558499813079834\n",
      "Epoch:11  accuracy:16.209476309226932  loss:3.297544002532959\n",
      "Epoch:12  accuracy:16.209476309226932  loss:3.2598273754119873\n",
      "Epoch:13  accuracy:16.209476309226932  loss:3.234304904937744\n",
      "Epoch:14  accuracy:16.209476309226932  loss:3.2176589965820312\n",
      "Epoch:15  accuracy:16.209476309226932  loss:3.199108362197876\n",
      "Epoch:16  accuracy:16.209476309226932  loss:3.1928021907806396\n",
      "Epoch:17  accuracy:16.209476309226932  loss:3.1798856258392334\n",
      "Epoch:18  accuracy:16.209476309226932  loss:3.1709094047546387\n",
      "Epoch:19  accuracy:16.209476309226932  loss:3.1658811569213867\n",
      "Epoch:20  accuracy:16.209476309226932  loss:3.1603543758392334\n",
      "Epoch:21  accuracy:16.209476309226932  loss:3.154172897338867\n",
      "Epoch:22  accuracy:16.209476309226932  loss:3.1545495986938477\n",
      "Epoch:23  accuracy:16.209476309226932  loss:3.148998260498047\n",
      "Epoch:24  accuracy:16.209476309226932  loss:3.1481845378875732\n",
      "Epoch:25  accuracy:16.209476309226932  loss:3.1432623863220215\n",
      "Epoch:26  accuracy:16.209476309226932  loss:3.1440680027008057\n",
      "Epoch:27  accuracy:16.209476309226932  loss:3.1410460472106934\n",
      "Epoch:28  accuracy:16.209476309226932  loss:3.1366679668426514\n",
      "Epoch:29  accuracy:16.209476309226932  loss:3.1376140117645264\n",
      "Epoch:30  accuracy:16.209476309226932  loss:3.1380836963653564\n",
      "Epoch:31  accuracy:16.209476309226932  loss:3.144660234451294\n",
      "Epoch:32  accuracy:16.209476309226932  loss:3.138970136642456\n",
      "Epoch:33  accuracy:16.209476309226932  loss:3.136193037033081\n",
      "Epoch:34  accuracy:16.209476309226932  loss:3.137220621109009\n",
      "Epoch:35  accuracy:16.209476309226932  loss:3.138951063156128\n",
      "Epoch:36  accuracy:16.209476309226932  loss:3.1304876804351807\n",
      "Epoch:37  accuracy:16.209476309226932  loss:3.137002468109131\n",
      "Epoch:38  accuracy:16.209476309226932  loss:3.135697364807129\n",
      "Epoch:39  accuracy:16.209476309226932  loss:3.1313722133636475\n",
      "Epoch:40  accuracy:16.209476309226932  loss:3.133906841278076\n",
      "Epoch:41  accuracy:16.209476309226932  loss:3.1313695907592773\n",
      "Epoch:42  accuracy:16.209476309226932  loss:3.1358909606933594\n",
      "Epoch:43  accuracy:16.209476309226932  loss:3.1267457008361816\n",
      "Epoch:44  accuracy:16.209476309226932  loss:3.146831750869751\n",
      "Epoch:45  accuracy:16.209476309226932  loss:3.1344447135925293\n",
      "Epoch:46  accuracy:16.209476309226932  loss:3.1322975158691406\n",
      "Epoch:47  accuracy:16.209476309226932  loss:3.1428792476654053\n",
      "Epoch:48  accuracy:16.209476309226932  loss:3.1338751316070557\n",
      "Epoch:49  accuracy:16.209476309226932  loss:3.1331489086151123\n",
      "Epoch:50  accuracy:16.209476309226932  loss:3.1329643726348877\n",
      "Epoch:51  accuracy:16.209476309226932  loss:3.136730432510376\n",
      "Epoch:52  accuracy:16.209476309226932  loss:3.1334011554718018\n",
      "Epoch:53  accuracy:16.209476309226932  loss:3.135944128036499\n",
      "Epoch:54  accuracy:16.209476309226932  loss:3.1308586597442627\n",
      "Epoch:55  accuracy:16.209476309226932  loss:3.1356496810913086\n",
      "Epoch:56  accuracy:16.209476309226932  loss:3.1319215297698975\n",
      "Epoch:57  accuracy:16.209476309226932  loss:3.1318469047546387\n",
      "Epoch:58  accuracy:16.209476309226932  loss:3.1298067569732666\n",
      "Epoch:59  accuracy:16.209476309226932  loss:3.1399550437927246\n",
      "Epoch:60  accuracy:16.209476309226932  loss:3.1340858936309814\n",
      "Epoch:61  accuracy:16.209476309226932  loss:3.140180826187134\n",
      "Epoch:62  accuracy:16.209476309226932  loss:3.134974718093872\n",
      "Epoch:63  accuracy:16.209476309226932  loss:3.129908323287964\n",
      "Epoch:64  accuracy:16.209476309226932  loss:3.1332693099975586\n",
      "Epoch:65  accuracy:16.209476309226932  loss:3.1371376514434814\n",
      "Epoch:66  accuracy:16.209476309226932  loss:3.136735439300537\n",
      "Epoch:67  accuracy:16.209476309226932  loss:3.13814640045166\n",
      "Epoch:68  accuracy:16.209476309226932  loss:3.135899543762207\n",
      "Epoch:69  accuracy:16.209476309226932  loss:3.1351373195648193\n",
      "Epoch:70  accuracy:16.209476309226932  loss:3.1305086612701416\n",
      "Epoch:71  accuracy:16.209476309226932  loss:3.135000705718994\n",
      "Epoch:72  accuracy:16.209476309226932  loss:3.1333301067352295\n",
      "Epoch:73  accuracy:16.209476309226932  loss:3.13474702835083\n",
      "Epoch:74  accuracy:16.209476309226932  loss:3.1369881629943848\n",
      "Epoch:75  accuracy:16.209476309226932  loss:3.1315863132476807\n",
      "Epoch:76  accuracy:16.209476309226932  loss:3.139739513397217\n",
      "Epoch:77  accuracy:16.209476309226932  loss:3.12744402885437\n",
      "Epoch:78  accuracy:16.209476309226932  loss:3.1399896144866943\n",
      "Epoch:79  accuracy:16.209476309226932  loss:3.1378567218780518\n",
      "Epoch:80  accuracy:16.209476309226932  loss:3.1359663009643555\n",
      "Epoch:81  accuracy:16.209476309226932  loss:3.1279916763305664\n",
      "Epoch:82  accuracy:16.209476309226932  loss:3.12965726852417\n",
      "Epoch:83  accuracy:16.209476309226932  loss:3.1346797943115234\n",
      "Epoch:84  accuracy:16.209476309226932  loss:3.136997938156128\n",
      "Epoch:85  accuracy:16.209476309226932  loss:3.125437021255493\n",
      "Epoch:86  accuracy:16.209476309226932  loss:3.1295955181121826\n",
      "Epoch:87  accuracy:16.209476309226932  loss:3.130988359451294\n",
      "Epoch:88  accuracy:16.209476309226932  loss:3.134636640548706\n",
      "Epoch:89  accuracy:16.209476309226932  loss:3.1324946880340576\n",
      "Epoch:90  accuracy:16.209476309226932  loss:3.1282856464385986\n",
      "Epoch:91  accuracy:16.209476309226932  loss:3.136028289794922\n",
      "Epoch:92  accuracy:16.209476309226932  loss:3.135249376296997\n",
      "Epoch:93  accuracy:16.209476309226932  loss:3.132082223892212\n",
      "Epoch:94  accuracy:16.209476309226932  loss:3.132061243057251\n",
      "Epoch:95  accuracy:16.209476309226932  loss:3.1210665702819824\n",
      "Epoch:96  accuracy:16.209476309226932  loss:3.1248486042022705\n",
      "Epoch:97  accuracy:16.209476309226932  loss:3.1382672786712646\n",
      "Epoch:98  accuracy:16.209476309226932  loss:3.124112129211426\n",
      "Epoch:99  accuracy:16.209476309226932  loss:3.124659299850464\n",
      "Epoch:100  accuracy:16.209476309226932  loss:3.1277599334716797\n",
      "Worker15 start\n",
      "Epoch:1  accuracy:0.0  loss:4.506617069244385\n",
      "Epoch:2  accuracy:0.0  loss:4.506246089935303\n",
      "Epoch:3  accuracy:0.0  loss:4.50575590133667\n",
      "Epoch:4  accuracy:0.0  loss:4.505201816558838\n",
      "Epoch:5  accuracy:0.0  loss:4.50460147857666\n",
      "Epoch:6  accuracy:0.0  loss:4.503785133361816\n",
      "Epoch:7  accuracy:0.0  loss:4.502620220184326\n",
      "Epoch:8  accuracy:0.0  loss:4.501293182373047\n",
      "Epoch:9  accuracy:0.0  loss:4.500155448913574\n",
      "Epoch:10  accuracy:0.0  loss:4.499054431915283\n",
      "Epoch:11  accuracy:0.0  loss:4.497950553894043\n",
      "Epoch:12  accuracy:0.0  loss:4.496654987335205\n",
      "Epoch:13  accuracy:0.0  loss:4.495410919189453\n",
      "Epoch:14  accuracy:0.0  loss:4.494039535522461\n",
      "Epoch:15  accuracy:10.0  loss:4.492791652679443\n",
      "Epoch:16  accuracy:10.0  loss:4.491701126098633\n",
      "Epoch:17  accuracy:20.0  loss:4.490673065185547\n",
      "Epoch:18  accuracy:20.0  loss:4.489764213562012\n",
      "Epoch:19  accuracy:20.0  loss:4.48887300491333\n",
      "Epoch:20  accuracy:20.0  loss:4.488038063049316\n",
      "Epoch:21  accuracy:20.0  loss:4.487117767333984\n",
      "Epoch:22  accuracy:20.0  loss:4.485860347747803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:23  accuracy:10.0  loss:4.484407901763916\n",
      "Epoch:24  accuracy:10.0  loss:4.482901573181152\n",
      "Epoch:25  accuracy:10.0  loss:4.481595039367676\n",
      "Epoch:26  accuracy:10.0  loss:4.480316638946533\n",
      "Epoch:27  accuracy:10.0  loss:4.478793144226074\n",
      "Epoch:28  accuracy:10.0  loss:4.4772257804870605\n",
      "Epoch:29  accuracy:10.0  loss:4.47575569152832\n",
      "Epoch:30  accuracy:10.0  loss:4.474245071411133\n",
      "Epoch:31  accuracy:10.0  loss:4.47292947769165\n",
      "Epoch:32  accuracy:10.0  loss:4.471663475036621\n",
      "Epoch:33  accuracy:10.0  loss:4.470297813415527\n",
      "Epoch:34  accuracy:10.0  loss:4.469080924987793\n",
      "Epoch:35  accuracy:10.0  loss:4.4680094718933105\n",
      "Epoch:36  accuracy:10.0  loss:4.466901779174805\n",
      "Epoch:37  accuracy:10.0  loss:4.4655070304870605\n",
      "Epoch:38  accuracy:10.0  loss:4.464034080505371\n",
      "Epoch:39  accuracy:10.0  loss:4.462754249572754\n",
      "Epoch:40  accuracy:0.0  loss:4.461661338806152\n",
      "Epoch:41  accuracy:0.0  loss:4.460541725158691\n",
      "Epoch:42  accuracy:0.0  loss:4.459142208099365\n",
      "Epoch:43  accuracy:0.0  loss:4.457548141479492\n",
      "Epoch:44  accuracy:0.0  loss:4.455788612365723\n",
      "Epoch:45  accuracy:10.0  loss:4.453943729400635\n",
      "Epoch:46  accuracy:10.0  loss:4.45212459564209\n",
      "Epoch:47  accuracy:10.0  loss:4.450601100921631\n",
      "Epoch:48  accuracy:10.0  loss:4.449182510375977\n",
      "Epoch:49  accuracy:10.0  loss:4.447688102722168\n",
      "Epoch:50  accuracy:10.0  loss:4.446383476257324\n",
      "Epoch:51  accuracy:10.0  loss:4.445134162902832\n",
      "Epoch:52  accuracy:10.0  loss:4.4437255859375\n",
      "Epoch:53  accuracy:10.0  loss:4.4424004554748535\n",
      "Epoch:54  accuracy:10.0  loss:4.440962791442871\n",
      "Epoch:55  accuracy:10.0  loss:4.4397077560424805\n",
      "Epoch:56  accuracy:10.0  loss:4.438467979431152\n",
      "Epoch:57  accuracy:10.0  loss:4.437119483947754\n",
      "Epoch:58  accuracy:10.0  loss:4.435925483703613\n",
      "Epoch:59  accuracy:10.0  loss:4.434852600097656\n",
      "Epoch:60  accuracy:10.0  loss:4.433713436126709\n",
      "Epoch:61  accuracy:10.0  loss:4.432269096374512\n",
      "Epoch:62  accuracy:10.0  loss:4.43074893951416\n",
      "Epoch:63  accuracy:10.0  loss:4.429457664489746\n",
      "Epoch:64  accuracy:10.0  loss:4.428317070007324\n",
      "Epoch:65  accuracy:10.0  loss:4.4271345138549805\n",
      "Epoch:66  accuracy:10.0  loss:4.425790786743164\n",
      "Epoch:67  accuracy:10.0  loss:4.424600124359131\n",
      "Epoch:68  accuracy:10.0  loss:4.423399448394775\n",
      "Epoch:69  accuracy:10.0  loss:4.422049522399902\n",
      "Epoch:70  accuracy:10.0  loss:4.420741081237793\n",
      "Epoch:71  accuracy:10.0  loss:4.419260025024414\n",
      "Epoch:72  accuracy:10.0  loss:4.417856693267822\n",
      "Epoch:73  accuracy:10.0  loss:4.416376113891602\n",
      "Epoch:74  accuracy:10.0  loss:4.415045261383057\n",
      "Epoch:75  accuracy:10.0  loss:4.413741111755371\n",
      "Epoch:76  accuracy:10.0  loss:4.4123077392578125\n",
      "Epoch:77  accuracy:10.0  loss:4.411089897155762\n",
      "Epoch:78  accuracy:10.0  loss:4.409969329833984\n",
      "Epoch:79  accuracy:10.0  loss:4.408924102783203\n",
      "Epoch:80  accuracy:10.0  loss:4.407853126525879\n",
      "Epoch:81  accuracy:10.0  loss:4.406420707702637\n",
      "Epoch:82  accuracy:10.0  loss:4.404717445373535\n",
      "Epoch:83  accuracy:10.0  loss:4.402931213378906\n",
      "Epoch:84  accuracy:10.0  loss:4.401429653167725\n",
      "Epoch:85  accuracy:10.0  loss:4.399970054626465\n",
      "Epoch:86  accuracy:10.0  loss:4.398274898529053\n",
      "Epoch:87  accuracy:10.0  loss:4.396536350250244\n",
      "Epoch:88  accuracy:10.0  loss:4.395010471343994\n",
      "Epoch:89  accuracy:10.0  loss:4.393572807312012\n",
      "Epoch:90  accuracy:10.0  loss:4.391984939575195\n",
      "Epoch:91  accuracy:10.0  loss:4.390629768371582\n",
      "Epoch:92  accuracy:10.0  loss:4.3894267082214355\n",
      "Epoch:93  accuracy:10.0  loss:4.388306617736816\n",
      "Epoch:94  accuracy:10.0  loss:4.387270927429199\n",
      "Epoch:95  accuracy:10.0  loss:4.386279582977295\n",
      "Epoch:96  accuracy:10.0  loss:4.385205268859863\n",
      "Epoch:97  accuracy:10.0  loss:4.3838791847229\n",
      "Epoch:98  accuracy:10.0  loss:4.3825554847717285\n",
      "Epoch:99  accuracy:10.0  loss:4.380885124206543\n",
      "Epoch:100  accuracy:10.0  loss:4.379128456115723\n",
      "Worker16 start\n",
      "Epoch:1  accuracy:19.25498426023085  loss:3.3927173018455505\n",
      "Epoch:2  accuracy:19.25498426023085  loss:3.167153537273407\n",
      "Epoch:3  accuracy:19.25498426023085  loss:3.143514096736908\n",
      "Epoch:4  accuracy:19.25498426023085  loss:3.1342344880104065\n",
      "Epoch:5  accuracy:19.25498426023085  loss:3.1371944546699524\n",
      "Epoch:6  accuracy:19.25498426023085  loss:3.1356506943702698\n",
      "Epoch:7  accuracy:19.25498426023085  loss:3.1336382031440735\n",
      "Epoch:8  accuracy:19.25498426023085  loss:3.1344523429870605\n",
      "Epoch:9  accuracy:19.25498426023085  loss:3.1242329478263855\n",
      "Epoch:10  accuracy:19.25498426023085  loss:3.1201984882354736\n",
      "Epoch:11  accuracy:19.25498426023085  loss:3.1105130314826965\n",
      "Epoch:12  accuracy:19.25498426023085  loss:3.0962889194488525\n",
      "Epoch:13  accuracy:19.517313746065057  loss:3.079807221889496\n",
      "Epoch:14  accuracy:19.727177334732424  loss:3.0650810599327087\n",
      "Epoch:15  accuracy:20.67156348373557  loss:3.0437241196632385\n",
      "Epoch:16  accuracy:20.724029380902415  loss:3.0246253609657288\n",
      "Epoch:17  accuracy:21.248688352570827  loss:3.0147441029548645\n",
      "Epoch:18  accuracy:20.173137460650576  loss:2.997555136680603\n",
      "Epoch:19  accuracy:21.32738719832109  loss:2.99274343252182\n",
      "Epoch:20  accuracy:21.694648478488983  loss:2.9679627418518066\n",
      "Epoch:21  accuracy:21.35362014690451  loss:2.9522106647491455\n",
      "Epoch:22  accuracy:21.53725078698846  loss:2.93719482421875\n",
      "Epoch:23  accuracy:22.429171038824762  loss:2.925252377986908\n",
      "Epoch:24  accuracy:22.27177334732424  loss:2.9133958220481873\n",
      "Epoch:25  accuracy:22.9800629590766  loss:2.9014108180999756\n",
      "Epoch:26  accuracy:22.114375655823714  loss:2.879955768585205\n",
      "Epoch:27  accuracy:22.219307450157398  loss:2.879457712173462\n",
      "Epoch:28  accuracy:22.717733473242394  loss:2.8604227900505066\n",
      "Epoch:29  accuracy:23.478488982161593  loss:2.8458282351493835\n",
      "Epoch:30  accuracy:23.767051416579225  loss:2.8480225801467896\n",
      "Epoch:31  accuracy:21.065057712486883  loss:2.8598764538764954\n",
      "Epoch:32  accuracy:24.422875131164744  loss:2.8177980184555054\n",
      "Epoch:33  accuracy:24.711437565582372  loss:2.8067120909690857\n",
      "Epoch:34  accuracy:24.763903462749212  loss:2.8046159744262695\n",
      "Epoch:35  accuracy:24.134312696747113  loss:2.793366551399231\n",
      "Epoch:36  accuracy:23.845750262329485  loss:2.790112316608429\n",
      "Epoch:37  accuracy:24.31794333683106  loss:2.7754989862442017\n",
      "Epoch:38  accuracy:24.554039874081848  loss:2.7658281922340393\n",
      "Epoch:39  accuracy:24.921301154249736  loss:2.767572283744812\n",
      "Epoch:40  accuracy:25.183630640083944  loss:2.7507323622703552\n",
      "Epoch:41  accuracy:24.790136411332632  loss:2.7410192489624023\n",
      "Epoch:42  accuracy:25.104931794333684  loss:2.741583287715912\n",
      "Epoch:43  accuracy:24.921301154249736  loss:2.728895902633667\n",
      "Epoch:44  accuracy:24.422875131164744  loss:2.721319615840912\n",
      "Epoch:45  accuracy:25.498426023084996  loss:2.7128925919532776\n",
      "Epoch:46  accuracy:25.05246589716684  loss:2.697463035583496\n",
      "Epoch:47  accuracy:24.895068205666316  loss:2.6969290375709534\n",
      "Epoch:48  accuracy:25.209863588667368  loss:2.6827723383903503\n",
      "Epoch:49  accuracy:25.865687303252887  loss:2.6704717874526978\n",
      "Epoch:50  accuracy:25.918153200419727  loss:2.6564671397209167\n",
      "Epoch:51  accuracy:24.685204616998952  loss:2.6562724113464355\n",
      "Epoch:52  accuracy:27.203567681007346  loss:2.6409448385238647\n",
      "Epoch:53  accuracy:26.67890870933893  loss:2.6317418217658997\n",
      "Epoch:54  accuracy:27.046169989506822  loss:2.618238687515259\n",
      "Epoch:55  accuracy:27.938090241343126  loss:2.5993093252182007\n",
      "Epoch:56  accuracy:27.780692549842602  loss:2.615423798561096\n",
      "Epoch:57  accuracy:28.72507869884575  loss:2.5816755890846252\n",
      "Epoch:58  accuracy:28.226652675760757  loss:2.572866976261139\n",
      "Epoch:59  accuracy:28.515215110178385  loss:2.556741774082184\n",
      "Epoch:60  accuracy:28.64637985309549  loss:2.5490967631340027\n",
      "Epoch:61  accuracy:29.564533053515216  loss:2.5355623960494995\n",
      "Epoch:62  accuracy:29.512067156348373  loss:2.520142436027527\n",
      "Epoch:63  accuracy:30.84994753410283  loss:2.5046364068984985\n",
      "Epoch:64  accuracy:29.77439664218258  loss:2.5114192366600037\n",
      "Epoch:65  accuracy:30.4302203567681  loss:2.481809079647064\n",
      "Epoch:66  accuracy:30.40398740818468  loss:2.470964252948761\n",
      "Epoch:67  accuracy:30.220356768100736  loss:2.4640390276908875\n",
      "Epoch:68  accuracy:30.954879328436515  loss:2.4513245224952698\n",
      "Epoch:69  accuracy:31.610703043022035  loss:2.443151831626892\n",
      "Epoch:70  accuracy:31.794333683105982  loss:2.4396960139274597\n",
      "Epoch:71  accuracy:32.05666316894019  loss:2.411076068878174\n",
      "Epoch:72  accuracy:32.922350472193074  loss:2.4044259190559387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:73  accuracy:32.896117523609654  loss:2.4004116654396057\n",
      "Epoch:74  accuracy:32.712486883525706  loss:2.3838558197021484\n",
      "Epoch:75  accuracy:33.7093389296957  loss:2.3868849873542786\n",
      "Epoch:76  accuracy:33.7093389296957  loss:2.3659104108810425\n",
      "Epoch:77  accuracy:33.31584470094439  loss:2.3654114603996277\n",
      "Epoch:78  accuracy:32.922350472193074  loss:2.366914749145508\n",
      "Epoch:79  accuracy:34.81112277019937  loss:2.343853235244751\n",
      "Epoch:80  accuracy:34.73242392444911  loss:2.336832821369171\n",
      "Epoch:81  accuracy:34.70619097586569  loss:2.3336893916130066\n",
      "Epoch:82  accuracy:34.28646379853095  loss:2.3425930738449097\n",
      "Epoch:83  accuracy:33.971668415529905  loss:2.3310571908950806\n",
      "Epoch:84  accuracy:34.81112277019937  loss:2.323542892932892\n",
      "Epoch:85  accuracy:35.204616998950684  loss:2.305777847766876\n",
      "Epoch:86  accuracy:35.75550891920252  loss:2.3005893230438232\n",
      "Epoch:87  accuracy:35.44071353620147  loss:2.3013240098953247\n",
      "Epoch:88  accuracy:35.99160545645331  loss:2.2854475378990173\n",
      "Epoch:89  accuracy:35.70304302203568  loss:2.274062156677246\n",
      "Epoch:90  accuracy:35.7292759706191  loss:2.2829811573028564\n",
      "Epoch:91  accuracy:36.56873032528856  loss:2.2748242616653442\n",
      "Epoch:92  accuracy:36.14900314795383  loss:2.2604411244392395\n",
      "Epoch:93  accuracy:36.358866736621195  loss:2.257616877555847\n",
      "Epoch:94  accuracy:36.01783840503673  loss:2.2618388533592224\n",
      "Epoch:95  accuracy:36.96222455403987  loss:2.245093584060669\n",
      "Epoch:96  accuracy:36.72612801678909  loss:2.2474692463874817\n",
      "Epoch:97  accuracy:36.80482686253935  loss:2.241802752017975\n",
      "Epoch:98  accuracy:36.75236096537251  loss:2.2381016612052917\n",
      "Epoch:99  accuracy:37.460650577124866  loss:2.228874921798706\n",
      "Epoch:100  accuracy:37.618048268625394  loss:2.231680154800415\n",
      "Worker17 start\n",
      "Epoch:1  accuracy:0.0  loss:4.5015997886657715\n",
      "Epoch:2  accuracy:0.0  loss:4.485898017883301\n",
      "Epoch:3  accuracy:14.893617021276595  loss:4.470381259918213\n",
      "Epoch:4  accuracy:14.893617021276595  loss:4.455313682556152\n",
      "Epoch:5  accuracy:14.893617021276595  loss:4.4401679039001465\n",
      "Epoch:6  accuracy:14.893617021276595  loss:4.425295352935791\n",
      "Epoch:7  accuracy:14.893617021276595  loss:4.408714771270752\n",
      "Epoch:8  accuracy:14.893617021276595  loss:4.3936238288879395\n",
      "Epoch:9  accuracy:14.893617021276595  loss:4.377161502838135\n",
      "Epoch:10  accuracy:14.893617021276595  loss:4.360880374908447\n",
      "Epoch:11  accuracy:14.893617021276595  loss:4.344419479370117\n",
      "Epoch:12  accuracy:14.893617021276595  loss:4.327928066253662\n",
      "Epoch:13  accuracy:14.893617021276595  loss:4.311265468597412\n",
      "Epoch:14  accuracy:14.893617021276595  loss:4.293539047241211\n",
      "Epoch:15  accuracy:14.893617021276595  loss:4.275473117828369\n",
      "Epoch:16  accuracy:14.893617021276595  loss:4.256354808807373\n",
      "Epoch:17  accuracy:14.893617021276595  loss:4.2374267578125\n",
      "Epoch:18  accuracy:14.893617021276595  loss:4.217613220214844\n",
      "Epoch:19  accuracy:14.893617021276595  loss:4.196157455444336\n",
      "Epoch:20  accuracy:14.893617021276595  loss:4.174944877624512\n",
      "Epoch:21  accuracy:14.893617021276595  loss:4.152109146118164\n",
      "Epoch:22  accuracy:14.893617021276595  loss:4.127866268157959\n",
      "Epoch:23  accuracy:14.893617021276595  loss:4.102188587188721\n",
      "Epoch:24  accuracy:14.893617021276595  loss:4.0758185386657715\n",
      "Epoch:25  accuracy:14.893617021276595  loss:4.047556400299072\n",
      "Epoch:26  accuracy:14.893617021276595  loss:4.018383979797363\n",
      "Epoch:27  accuracy:14.893617021276595  loss:3.9888410568237305\n",
      "Epoch:28  accuracy:14.893617021276595  loss:3.9593799114227295\n",
      "Epoch:29  accuracy:14.893617021276595  loss:3.9285342693328857\n",
      "Epoch:30  accuracy:14.893617021276595  loss:3.899186849594116\n",
      "Epoch:31  accuracy:14.893617021276595  loss:3.8709633350372314\n",
      "Epoch:32  accuracy:14.893617021276595  loss:3.8448102474212646\n",
      "Epoch:33  accuracy:14.893617021276595  loss:3.821274995803833\n",
      "Epoch:34  accuracy:14.893617021276595  loss:3.797508716583252\n",
      "Epoch:35  accuracy:14.893617021276595  loss:3.7761430740356445\n",
      "Epoch:36  accuracy:14.893617021276595  loss:3.754138708114624\n",
      "Epoch:37  accuracy:14.893617021276595  loss:3.7318248748779297\n",
      "Epoch:38  accuracy:14.893617021276595  loss:3.7098541259765625\n",
      "Epoch:39  accuracy:14.893617021276595  loss:3.6840226650238037\n",
      "Epoch:40  accuracy:14.893617021276595  loss:3.664247512817383\n",
      "Epoch:41  accuracy:14.893617021276595  loss:3.645082950592041\n",
      "Epoch:42  accuracy:14.893617021276595  loss:3.6256325244903564\n",
      "Epoch:43  accuracy:14.893617021276595  loss:3.6079816818237305\n",
      "Epoch:44  accuracy:14.893617021276595  loss:3.5937182903289795\n",
      "Epoch:45  accuracy:14.893617021276595  loss:3.576854944229126\n",
      "Epoch:46  accuracy:14.893617021276595  loss:3.5669167041778564\n",
      "Epoch:47  accuracy:14.893617021276595  loss:3.5554232597351074\n",
      "Epoch:48  accuracy:14.893617021276595  loss:3.5468015670776367\n",
      "Epoch:49  accuracy:14.893617021276595  loss:3.537281036376953\n",
      "Epoch:50  accuracy:14.893617021276595  loss:3.5310568809509277\n",
      "Epoch:51  accuracy:14.893617021276595  loss:3.5238800048828125\n",
      "Epoch:52  accuracy:14.893617021276595  loss:3.517725944519043\n",
      "Epoch:53  accuracy:14.893617021276595  loss:3.507505416870117\n",
      "Epoch:54  accuracy:14.893617021276595  loss:3.5063276290893555\n",
      "Epoch:55  accuracy:14.893617021276595  loss:3.5019514560699463\n",
      "Epoch:56  accuracy:14.893617021276595  loss:3.49534010887146\n",
      "Epoch:57  accuracy:14.893617021276595  loss:3.4902524948120117\n",
      "Epoch:58  accuracy:14.893617021276595  loss:3.486133098602295\n",
      "Epoch:59  accuracy:14.893617021276595  loss:3.487504720687866\n",
      "Epoch:60  accuracy:14.893617021276595  loss:3.486427068710327\n",
      "Epoch:61  accuracy:14.893617021276595  loss:3.478724718093872\n",
      "Epoch:62  accuracy:14.893617021276595  loss:3.47448992729187\n",
      "Epoch:63  accuracy:14.893617021276595  loss:3.4689104557037354\n",
      "Epoch:64  accuracy:14.893617021276595  loss:3.4664366245269775\n",
      "Epoch:65  accuracy:14.893617021276595  loss:3.465420961380005\n",
      "Epoch:66  accuracy:14.893617021276595  loss:3.4640285968780518\n",
      "Epoch:67  accuracy:14.893617021276595  loss:3.461977005004883\n",
      "Epoch:68  accuracy:14.893617021276595  loss:3.455028772354126\n",
      "Epoch:69  accuracy:14.893617021276595  loss:3.457824468612671\n",
      "Epoch:70  accuracy:14.893617021276595  loss:3.455475091934204\n",
      "Epoch:71  accuracy:14.893617021276595  loss:3.4523773193359375\n",
      "Epoch:72  accuracy:14.893617021276595  loss:3.448671340942383\n",
      "Epoch:73  accuracy:14.893617021276595  loss:3.445925712585449\n",
      "Epoch:74  accuracy:14.893617021276595  loss:3.4459471702575684\n",
      "Epoch:75  accuracy:14.893617021276595  loss:3.4443297386169434\n",
      "Epoch:76  accuracy:14.893617021276595  loss:3.4428675174713135\n",
      "Epoch:77  accuracy:14.893617021276595  loss:3.4439635276794434\n",
      "Epoch:78  accuracy:14.893617021276595  loss:3.4466793537139893\n",
      "Epoch:79  accuracy:14.893617021276595  loss:3.441758871078491\n",
      "Epoch:80  accuracy:14.893617021276595  loss:3.442474365234375\n",
      "Epoch:81  accuracy:14.893617021276595  loss:3.442039966583252\n",
      "Epoch:82  accuracy:14.893617021276595  loss:3.442664861679077\n",
      "Epoch:83  accuracy:14.893617021276595  loss:3.4378833770751953\n",
      "Epoch:84  accuracy:14.893617021276595  loss:3.438406467437744\n",
      "Epoch:85  accuracy:14.893617021276595  loss:3.4368746280670166\n",
      "Epoch:86  accuracy:14.893617021276595  loss:3.437321186065674\n",
      "Epoch:87  accuracy:14.893617021276595  loss:3.4361679553985596\n",
      "Epoch:88  accuracy:14.893617021276595  loss:3.43937087059021\n",
      "Epoch:89  accuracy:14.893617021276595  loss:3.4375531673431396\n",
      "Epoch:90  accuracy:14.893617021276595  loss:3.437253952026367\n",
      "Epoch:91  accuracy:14.893617021276595  loss:3.4408228397369385\n",
      "Epoch:92  accuracy:14.893617021276595  loss:3.4365789890289307\n",
      "Epoch:93  accuracy:14.893617021276595  loss:3.4389262199401855\n",
      "Epoch:94  accuracy:14.893617021276595  loss:3.4402711391448975\n",
      "Epoch:95  accuracy:14.893617021276595  loss:3.4364688396453857\n",
      "Epoch:96  accuracy:14.893617021276595  loss:3.4355223178863525\n",
      "Epoch:97  accuracy:14.893617021276595  loss:3.4374990463256836\n",
      "Epoch:98  accuracy:14.893617021276595  loss:3.4395997524261475\n",
      "Epoch:99  accuracy:14.893617021276595  loss:3.443101644515991\n",
      "Epoch:100  accuracy:14.893617021276595  loss:3.433945894241333\n",
      "Worker18 start\n",
      "Epoch:1  accuracy:0.0  loss:4.493997097015381\n",
      "Epoch:2  accuracy:0.0  loss:4.4755754470825195\n",
      "Epoch:3  accuracy:25.0  loss:4.456991195678711\n",
      "Epoch:4  accuracy:25.0  loss:4.437121868133545\n",
      "Epoch:5  accuracy:25.0  loss:4.416872978210449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6  accuracy:25.0  loss:4.396905899047852\n",
      "Epoch:7  accuracy:25.0  loss:4.376923561096191\n",
      "Epoch:8  accuracy:25.0  loss:4.357165336608887\n",
      "Epoch:9  accuracy:25.0  loss:4.337282657623291\n",
      "Epoch:10  accuracy:25.0  loss:4.315758228302002\n",
      "Epoch:11  accuracy:25.0  loss:4.293973922729492\n",
      "Epoch:12  accuracy:25.0  loss:4.2723846435546875\n",
      "Epoch:13  accuracy:25.0  loss:4.250145435333252\n",
      "Epoch:14  accuracy:25.0  loss:4.228387832641602\n",
      "Epoch:15  accuracy:25.0  loss:4.20399284362793\n",
      "Epoch:16  accuracy:25.0  loss:4.178944110870361\n",
      "Epoch:17  accuracy:25.0  loss:4.15255069732666\n",
      "Epoch:18  accuracy:25.0  loss:4.1270880699157715\n",
      "Epoch:19  accuracy:25.0  loss:4.098607063293457\n",
      "Epoch:20  accuracy:25.0  loss:4.067458152770996\n",
      "Epoch:21  accuracy:25.0  loss:4.035757064819336\n",
      "Epoch:22  accuracy:25.0  loss:4.001965522766113\n",
      "Epoch:23  accuracy:25.0  loss:3.966278076171875\n",
      "Epoch:24  accuracy:25.0  loss:3.9295668601989746\n",
      "Epoch:25  accuracy:25.0  loss:3.8898353576660156\n",
      "Epoch:26  accuracy:25.0  loss:3.8459486961364746\n",
      "Epoch:27  accuracy:25.0  loss:3.8020544052124023\n",
      "Epoch:28  accuracy:25.0  loss:3.7543065547943115\n",
      "Epoch:29  accuracy:25.0  loss:3.7076988220214844\n",
      "Epoch:30  accuracy:25.0  loss:3.659714460372925\n",
      "Epoch:31  accuracy:25.0  loss:3.6130287647247314\n",
      "Epoch:32  accuracy:25.0  loss:3.565609931945801\n",
      "Epoch:33  accuracy:25.0  loss:3.528233528137207\n",
      "Epoch:34  accuracy:25.0  loss:3.490506887435913\n",
      "Epoch:35  accuracy:25.0  loss:3.4561409950256348\n",
      "Epoch:36  accuracy:25.0  loss:3.426809072494507\n",
      "Epoch:37  accuracy:25.0  loss:3.4023513793945312\n",
      "Epoch:38  accuracy:25.0  loss:3.375054121017456\n",
      "Epoch:39  accuracy:25.0  loss:3.354400396347046\n",
      "Epoch:40  accuracy:25.0  loss:3.334822177886963\n",
      "Epoch:41  accuracy:25.0  loss:3.3128600120544434\n",
      "Epoch:42  accuracy:25.0  loss:3.2950263023376465\n",
      "Epoch:43  accuracy:25.0  loss:3.280379295349121\n",
      "Epoch:44  accuracy:25.0  loss:3.26499342918396\n",
      "Epoch:45  accuracy:25.0  loss:3.251861810684204\n",
      "Epoch:46  accuracy:25.0  loss:3.236788272857666\n",
      "Epoch:47  accuracy:25.0  loss:3.2199461460113525\n",
      "Epoch:48  accuracy:25.0  loss:3.212033271789551\n",
      "Epoch:49  accuracy:25.0  loss:3.2054998874664307\n",
      "Epoch:50  accuracy:25.0  loss:3.1981096267700195\n",
      "Epoch:51  accuracy:25.0  loss:3.196697235107422\n",
      "Epoch:52  accuracy:25.0  loss:3.18424916267395\n",
      "Epoch:53  accuracy:25.0  loss:3.17158579826355\n",
      "Epoch:54  accuracy:25.0  loss:3.1659276485443115\n",
      "Epoch:55  accuracy:25.0  loss:3.1556737422943115\n",
      "Epoch:56  accuracy:25.0  loss:3.151561737060547\n",
      "Epoch:57  accuracy:25.0  loss:3.1537909507751465\n",
      "Epoch:58  accuracy:25.0  loss:3.1443891525268555\n",
      "Epoch:59  accuracy:25.0  loss:3.1406960487365723\n",
      "Epoch:60  accuracy:25.0  loss:3.1362533569335938\n",
      "Epoch:61  accuracy:25.0  loss:3.1331870555877686\n",
      "Epoch:62  accuracy:25.0  loss:3.13053035736084\n",
      "Epoch:63  accuracy:25.0  loss:3.1215898990631104\n",
      "Epoch:64  accuracy:25.0  loss:3.1253855228424072\n",
      "Epoch:65  accuracy:25.0  loss:3.1125404834747314\n",
      "Epoch:66  accuracy:25.0  loss:3.114424705505371\n",
      "Epoch:67  accuracy:25.0  loss:3.1171884536743164\n",
      "Epoch:68  accuracy:25.0  loss:3.1096391677856445\n",
      "Epoch:69  accuracy:25.0  loss:3.115001678466797\n",
      "Epoch:70  accuracy:25.0  loss:3.1029741764068604\n",
      "Epoch:71  accuracy:25.0  loss:3.103131055831909\n",
      "Epoch:72  accuracy:25.0  loss:3.106579542160034\n",
      "Epoch:73  accuracy:25.0  loss:3.099405527114868\n",
      "Epoch:74  accuracy:25.0  loss:3.105294942855835\n",
      "Epoch:75  accuracy:25.0  loss:3.096395254135132\n",
      "Epoch:76  accuracy:25.0  loss:3.0984771251678467\n",
      "Epoch:77  accuracy:25.0  loss:3.099416971206665\n",
      "Epoch:78  accuracy:25.0  loss:3.0991671085357666\n",
      "Epoch:79  accuracy:25.0  loss:3.089322805404663\n",
      "Epoch:80  accuracy:25.0  loss:3.0935964584350586\n",
      "Epoch:81  accuracy:25.0  loss:3.0996057987213135\n",
      "Epoch:82  accuracy:25.0  loss:3.095777988433838\n",
      "Epoch:83  accuracy:25.0  loss:3.0974280834198\n",
      "Epoch:84  accuracy:25.0  loss:3.0934410095214844\n",
      "Epoch:85  accuracy:25.0  loss:3.096982717514038\n",
      "Epoch:86  accuracy:25.0  loss:3.0956976413726807\n",
      "Epoch:87  accuracy:25.0  loss:3.0977585315704346\n",
      "Epoch:88  accuracy:25.0  loss:3.1000006198883057\n",
      "Epoch:89  accuracy:25.0  loss:3.1053245067596436\n",
      "Epoch:90  accuracy:25.0  loss:3.085036277770996\n",
      "Epoch:91  accuracy:25.0  loss:3.0908384323120117\n",
      "Epoch:92  accuracy:25.0  loss:3.081423044204712\n",
      "Epoch:93  accuracy:25.0  loss:3.087024688720703\n",
      "Epoch:94  accuracy:25.0  loss:3.090023994445801\n",
      "Epoch:95  accuracy:25.0  loss:3.083780527114868\n",
      "Epoch:96  accuracy:25.0  loss:3.0881223678588867\n",
      "Epoch:97  accuracy:25.0  loss:3.0883328914642334\n",
      "Epoch:98  accuracy:25.0  loss:3.0744659900665283\n",
      "Epoch:99  accuracy:25.0  loss:3.07968807220459\n",
      "Epoch:100  accuracy:25.0  loss:3.0908753871917725\n",
      "Worker19 start\n",
      "Epoch:1  accuracy:18.202163371876164  loss:3.853030522664388\n",
      "Epoch:2  accuracy:18.202163371876164  loss:3.220052639643351\n",
      "Epoch:3  accuracy:18.202163371876164  loss:3.151912291844686\n",
      "Epoch:4  accuracy:18.202163371876164  loss:3.1439077059427896\n",
      "Epoch:5  accuracy:18.202163371876164  loss:3.1359954675038657\n",
      "Epoch:6  accuracy:18.202163371876164  loss:3.1334142684936523\n",
      "Epoch:7  accuracy:18.202163371876164  loss:3.1313772996266684\n",
      "Epoch:8  accuracy:18.202163371876164  loss:3.1291929880777993\n",
      "Epoch:9  accuracy:18.202163371876164  loss:3.1237786610921225\n",
      "Epoch:10  accuracy:18.202163371876164  loss:3.1262969175974527\n",
      "Epoch:11  accuracy:18.202163371876164  loss:3.122809966405233\n",
      "Epoch:12  accuracy:18.202163371876164  loss:3.127291440963745\n",
      "Epoch:13  accuracy:18.202163371876164  loss:3.1195009549458823\n",
      "Epoch:14  accuracy:18.202163371876164  loss:3.121697266896566\n",
      "Epoch:15  accuracy:18.202163371876164  loss:3.120021422704061\n",
      "Epoch:16  accuracy:18.202163371876164  loss:3.1167546113332114\n",
      "Epoch:17  accuracy:18.202163371876164  loss:3.120002349217733\n",
      "Epoch:18  accuracy:18.202163371876164  loss:3.108912785847982\n",
      "Epoch:19  accuracy:18.202163371876164  loss:3.1040244102478027\n",
      "Epoch:20  accuracy:18.202163371876164  loss:3.0953250726064048\n",
      "Epoch:21  accuracy:18.164863856769863  loss:3.093851407368978\n",
      "Epoch:22  accuracy:18.202163371876164  loss:3.0806427796681723\n",
      "Epoch:23  accuracy:18.202163371876164  loss:3.0737326939900718\n",
      "Epoch:24  accuracy:18.127564341663557  loss:3.073373556137085\n",
      "Epoch:25  accuracy:19.50764640059679  loss:3.047520160675049\n",
      "Epoch:26  accuracy:20.626631853785902  loss:3.0316950480143228\n",
      "Epoch:27  accuracy:20.70123088399851  loss:3.0206758975982666\n",
      "Epoch:28  accuracy:21.372622155911973  loss:3.010352293650309\n",
      "Epoch:29  accuracy:21.78291682208131  loss:2.9959892431894937\n",
      "Epoch:30  accuracy:21.409921671018278  loss:2.985011259714762\n",
      "Epoch:31  accuracy:22.305110033569562  loss:2.969156265258789\n",
      "Epoch:32  accuracy:21.55911973144349  loss:2.960975408554077\n",
      "Epoch:33  accuracy:21.93211488250653  loss:2.9421354134877524\n",
      "Epoch:34  accuracy:22.342409548675867  loss:2.9306770165761313\n",
      "Epoch:35  accuracy:23.38679597165237  loss:2.9176319440205893\n",
      "Epoch:36  accuracy:22.79000372995151  loss:2.9065065383911133\n",
      "Epoch:37  accuracy:22.566206639313688  loss:2.8995779355367026\n",
      "Epoch:38  accuracy:22.901902275270423  loss:2.8830083211263022\n",
      "Epoch:39  accuracy:23.535994032077582  loss:2.8830915292104087\n",
      "Epoch:40  accuracy:22.305110033569562  loss:2.863819678624471\n",
      "Epoch:41  accuracy:23.871689668034314  loss:2.847952206929525\n",
      "Epoch:42  accuracy:23.312196941439762  loss:2.8478824297587075\n",
      "Epoch:43  accuracy:23.274897426333457  loss:2.8299317359924316\n",
      "Epoch:44  accuracy:23.20029839612085  loss:2.8362279733022056\n",
      "Epoch:45  accuracy:23.535994032077582  loss:2.818796237309774\n",
      "Epoch:46  accuracy:24.319283849309958  loss:2.805620272954305\n",
      "Epoch:47  accuracy:23.573293547183887  loss:2.7979324658711753\n",
      "Epoch:48  accuracy:24.02088772845953  loss:2.8179723421732583\n",
      "Epoch:49  accuracy:25.25177172696755  loss:2.7846762339274087\n",
      "Epoch:50  accuracy:26.221559119731445  loss:2.7709412574768066\n",
      "Epoch:51  accuracy:23.461395001864975  loss:2.7724994818369546\n",
      "Epoch:52  accuracy:24.319283849309958  loss:2.7533439000447593\n",
      "Epoch:53  accuracy:25.027974636329727  loss:2.7386574745178223\n",
      "Epoch:54  accuracy:26.18425960462514  loss:2.726385752360026\n",
      "Epoch:55  accuracy:25.960462513987316  loss:2.7265570163726807\n",
      "Epoch:56  accuracy:26.18425960462514  loss:2.7058728535970054\n",
      "Epoch:57  accuracy:26.557254755688177  loss:2.6891981760660806\n",
      "Epoch:58  accuracy:27.41514360313316  loss:2.678508996963501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:59  accuracy:27.52704214845207  loss:2.656424045562744\n",
      "Epoch:60  accuracy:27.63894069377098  loss:2.648080587387085\n",
      "Epoch:61  accuracy:27.265945542707946  loss:2.639937400817871\n",
      "Epoch:62  accuracy:28.384930995897054  loss:2.626230239868164\n",
      "Epoch:63  accuracy:28.944423722491607  loss:2.6144770781199136\n",
      "Epoch:64  accuracy:28.422230511003356  loss:2.6056386629740396\n",
      "Epoch:65  accuracy:28.907124207385305  loss:2.5930046240488687\n",
      "Epoch:66  accuracy:28.8325251771727  loss:2.583352486292521\n",
      "Epoch:67  accuracy:29.019022752704213  loss:2.5825725396474204\n",
      "Epoch:68  accuracy:29.39201790376725  loss:2.568549315134684\n",
      "Epoch:69  accuracy:30.21260723610593  loss:2.5641608238220215\n",
      "Epoch:70  accuracy:30.32450578142484  loss:2.5510810216267905\n",
      "Epoch:71  accuracy:30.43640432674375  loss:2.5387128988901773\n",
      "Epoch:72  accuracy:30.21260723610593  loss:2.5403590202331543\n",
      "Epoch:73  accuracy:30.361805296531145  loss:2.52181339263916\n",
      "Epoch:74  accuracy:30.958597538232002  loss:2.521624485651652\n",
      "Epoch:75  accuracy:30.39910481163745  loss:2.515534241994222\n",
      "Epoch:76  accuracy:30.9212980231257  loss:2.5063579082489014\n",
      "Epoch:77  accuracy:30.697500932487877  loss:2.49648380279541\n",
      "Epoch:78  accuracy:30.660201417381575  loss:2.4936840534210205\n",
      "Epoch:79  accuracy:31.62998881014547  loss:2.476675271987915\n",
      "Epoch:80  accuracy:31.741887355464378  loss:2.4734203020731607\n",
      "Epoch:81  accuracy:31.182394628869826  loss:2.466897885004679\n",
      "Epoch:82  accuracy:31.62998881014547  loss:2.4599886735280356\n",
      "Epoch:83  accuracy:32.37597911227154  loss:2.458437999089559\n",
      "Epoch:84  accuracy:31.592689295039165  loss:2.4585957527160645\n",
      "Epoch:85  accuracy:32.86087280865349  loss:2.431830962498983\n",
      "Epoch:86  accuracy:32.67437523312197  loss:2.431638161341349\n",
      "Epoch:87  accuracy:32.226781051846324  loss:2.433748245239258\n",
      "Epoch:88  accuracy:33.15926892950392  loss:2.418281316757202\n",
      "Epoch:89  accuracy:33.04737038418501  loss:2.4197238286336265\n",
      "Epoch:90  accuracy:33.23386795971653  loss:2.4130449295043945\n",
      "Epoch:91  accuracy:32.748974263334574  loss:2.4061973889668784\n",
      "Epoch:92  accuracy:33.68146214099217  loss:2.3963990211486816\n",
      "Epoch:93  accuracy:34.0171577769489  loss:2.3956309159596763\n",
      "Epoch:94  accuracy:33.64416262588586  loss:2.3848124345143638\n",
      "Epoch:95  accuracy:34.390152928011936  loss:2.384609858194987\n",
      "Epoch:96  accuracy:33.867959716523686  loss:2.3799663384755454\n",
      "Epoch:97  accuracy:34.24095486758672  loss:2.3690877755482993\n",
      "Epoch:98  accuracy:34.42745244311824  loss:2.3620170752207437\n",
      "Epoch:99  accuracy:34.53935098843715  loss:2.3578304449717202\n",
      "Epoch:100  accuracy:34.53935098843715  loss:2.3635626633961997\n",
      "Worker20 start\n",
      "Epoch:1  accuracy:0.0  loss:4.518032073974609\n",
      "Epoch:2  accuracy:0.0  loss:4.518091201782227\n",
      "Epoch:3  accuracy:0.0  loss:4.518176555633545\n",
      "Epoch:4  accuracy:0.0  loss:4.518284320831299\n",
      "Epoch:5  accuracy:0.0  loss:4.51841402053833\n",
      "Epoch:6  accuracy:0.0  loss:4.518561363220215\n",
      "Epoch:7  accuracy:0.0  loss:4.518726348876953\n",
      "Epoch:8  accuracy:0.0  loss:4.518906116485596\n",
      "Epoch:9  accuracy:0.0  loss:4.519099712371826\n",
      "Epoch:10  accuracy:0.0  loss:4.519306182861328\n",
      "Epoch:11  accuracy:0.0  loss:4.519523620605469\n",
      "Epoch:12  accuracy:0.0  loss:4.519752025604248\n",
      "Epoch:13  accuracy:0.0  loss:4.519989013671875\n",
      "Epoch:14  accuracy:0.0  loss:4.520235061645508\n",
      "Epoch:15  accuracy:0.0  loss:4.52048921585083\n",
      "Epoch:16  accuracy:0.0  loss:4.520749568939209\n",
      "Epoch:17  accuracy:0.0  loss:4.521016597747803\n",
      "Epoch:18  accuracy:0.0  loss:4.521289825439453\n",
      "Epoch:19  accuracy:0.0  loss:4.521568298339844\n",
      "Epoch:20  accuracy:0.0  loss:4.521852016448975\n",
      "Epoch:21  accuracy:0.0  loss:4.522140026092529\n",
      "Epoch:22  accuracy:0.0  loss:4.522432327270508\n",
      "Epoch:23  accuracy:0.0  loss:4.522728443145752\n",
      "Epoch:24  accuracy:0.0  loss:4.5230278968811035\n",
      "Epoch:25  accuracy:0.0  loss:4.523331165313721\n",
      "Epoch:26  accuracy:0.0  loss:4.523637294769287\n",
      "Epoch:27  accuracy:0.0  loss:4.523946285247803\n",
      "Epoch:28  accuracy:0.0  loss:4.524257659912109\n",
      "Epoch:29  accuracy:0.0  loss:4.524572372436523\n",
      "Epoch:30  accuracy:0.0  loss:4.524888515472412\n",
      "Epoch:31  accuracy:0.0  loss:4.525207042694092\n",
      "Epoch:32  accuracy:0.0  loss:4.525528430938721\n",
      "Epoch:33  accuracy:0.0  loss:4.525851249694824\n",
      "Epoch:34  accuracy:0.0  loss:4.526176452636719\n",
      "Epoch:35  accuracy:0.0  loss:4.526503086090088\n",
      "Epoch:36  accuracy:0.0  loss:4.526831150054932\n",
      "Epoch:37  accuracy:0.0  loss:4.527162075042725\n",
      "Epoch:38  accuracy:0.0  loss:4.527493476867676\n",
      "Epoch:39  accuracy:0.0  loss:4.52782678604126\n",
      "Epoch:40  accuracy:0.0  loss:4.528162002563477\n",
      "Epoch:41  accuracy:0.0  loss:4.528499126434326\n",
      "Epoch:42  accuracy:0.0  loss:4.528836727142334\n",
      "Epoch:43  accuracy:0.0  loss:4.529176712036133\n",
      "Epoch:44  accuracy:0.0  loss:4.529517650604248\n",
      "Epoch:45  accuracy:0.0  loss:4.529860019683838\n",
      "Epoch:46  accuracy:0.0  loss:4.5302042961120605\n",
      "Epoch:47  accuracy:0.0  loss:4.5305495262146\n",
      "Epoch:48  accuracy:0.0  loss:4.530895709991455\n",
      "Epoch:49  accuracy:0.0  loss:4.53124475479126\n",
      "Epoch:50  accuracy:0.0  loss:4.5315937995910645\n",
      "Epoch:51  accuracy:0.0  loss:4.531944751739502\n",
      "Epoch:52  accuracy:0.0  loss:4.532297611236572\n",
      "Epoch:53  accuracy:0.0  loss:4.532651424407959\n",
      "Epoch:54  accuracy:0.0  loss:4.533006191253662\n",
      "Epoch:55  accuracy:0.0  loss:4.533362865447998\n",
      "Epoch:56  accuracy:0.0  loss:4.533721446990967\n",
      "Epoch:57  accuracy:0.0  loss:4.534080505371094\n",
      "Epoch:58  accuracy:0.0  loss:4.534440994262695\n",
      "Epoch:59  accuracy:0.0  loss:4.53480339050293\n",
      "Epoch:60  accuracy:0.0  loss:4.535167694091797\n",
      "Epoch:61  accuracy:0.0  loss:4.535532474517822\n",
      "Epoch:62  accuracy:0.0  loss:4.535899639129639\n",
      "Epoch:63  accuracy:0.0  loss:4.5362677574157715\n",
      "Epoch:64  accuracy:0.0  loss:4.536637783050537\n",
      "Epoch:65  accuracy:0.0  loss:4.5370097160339355\n",
      "Epoch:66  accuracy:0.0  loss:4.537382125854492\n",
      "Epoch:67  accuracy:0.0  loss:4.53775691986084\n",
      "Epoch:68  accuracy:0.0  loss:4.538133144378662\n",
      "Epoch:69  accuracy:0.0  loss:4.538510799407959\n",
      "Epoch:70  accuracy:0.0  loss:4.538890361785889\n",
      "Epoch:71  accuracy:0.0  loss:4.539270877838135\n",
      "Epoch:72  accuracy:0.0  loss:4.539653778076172\n",
      "Epoch:73  accuracy:0.0  loss:4.540038585662842\n",
      "Epoch:74  accuracy:0.0  loss:4.540424346923828\n",
      "Epoch:75  accuracy:0.0  loss:4.540812015533447\n",
      "Epoch:76  accuracy:0.0  loss:4.541202068328857\n",
      "Epoch:77  accuracy:0.0  loss:4.541593074798584\n",
      "Epoch:78  accuracy:0.0  loss:4.541986465454102\n",
      "Epoch:79  accuracy:0.0  loss:4.542381763458252\n",
      "Epoch:80  accuracy:0.0  loss:4.542778968811035\n",
      "Epoch:81  accuracy:0.0  loss:4.543177604675293\n",
      "Epoch:82  accuracy:0.0  loss:4.543578624725342\n",
      "Epoch:83  accuracy:0.0  loss:4.543981075286865\n",
      "Epoch:84  accuracy:0.0  loss:4.5443854331970215\n",
      "Epoch:85  accuracy:0.0  loss:4.544792652130127\n",
      "Epoch:86  accuracy:0.0  loss:4.545201301574707\n",
      "Epoch:87  accuracy:0.0  loss:4.54561185836792\n",
      "Epoch:88  accuracy:0.0  loss:4.546024799346924\n",
      "Epoch:89  accuracy:0.0  loss:4.5464396476745605\n",
      "Epoch:90  accuracy:0.0  loss:4.54685640335083\n",
      "Epoch:91  accuracy:0.0  loss:4.547276020050049\n",
      "Epoch:92  accuracy:0.0  loss:4.5476975440979\n",
      "Epoch:93  accuracy:0.0  loss:4.548120975494385\n",
      "Epoch:94  accuracy:0.0  loss:4.548546314239502\n",
      "Epoch:95  accuracy:0.0  loss:4.548974990844727\n",
      "Epoch:96  accuracy:0.0  loss:4.549405574798584\n",
      "Epoch:97  accuracy:0.0  loss:4.549838542938232\n",
      "Epoch:98  accuracy:0.0  loss:4.550273418426514\n",
      "Epoch:99  accuracy:0.0  loss:4.550711154937744\n",
      "Epoch:100  accuracy:0.0  loss:4.551151275634766\n"
     ]
    }
   ],
   "source": [
    "server = Server()\n",
    "workers = server.create_worker(federated_trainset,federated_valset,federated_testset)\n",
    "acc_valid = []\n",
    "loss_valid = []\n",
    "\n",
    "early_stopping = Early_Stopping(args.partience)\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "    print('Worker{} start'.format(i+1))\n",
    "    worker.model = RNN2()\n",
    "    worker.model = worker.model.to(args.device)\n",
    "    acc_tmp,loss_tmp = worker.local_train()\n",
    "    acc_valid.append(acc_tmp)\n",
    "    loss_valid.append(loss_tmp)\n",
    "    worker.model = worker.model.to('cpu')\n",
    "    \n",
    "end = time.time()#終了時刻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習時間：24766.437942028046秒\n"
     ]
    }
   ],
   "source": [
    "print('学習時間：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker1 accuracy:42.43938280675974  loss:2.178865058081491\n",
      "Worker2 accuracy:19.243986254295532  loss:3.2454605102539062\n",
      "Worker3 accuracy:11.363636363636363  loss:3.1809258460998535\n",
      "Worker4 accuracy:19.696969696969695  loss:3.285339593887329\n",
      "Worker5 accuracy:25.0  loss:3.129007339477539\n",
      "Worker6 accuracy:19.047619047619047  loss:3.8749141693115234\n",
      "Worker7 accuracy:0.0  loss:4.449426174163818\n",
      "Worker8 accuracy:20.66115702479339  loss:3.0661745071411133\n",
      "Worker9 accuracy:0.0  loss:4.375886917114258\n",
      "Worker10 accuracy:15.92741935483871  loss:3.2231366634368896\n",
      "Worker11 accuracy:24.299065420560748  loss:3.017181158065796\n",
      "Worker12 accuracy:17.5  loss:3.2829365730285645\n",
      "Worker13 accuracy:36.31457208943716  loss:2.287992318471273\n",
      "Worker14 accuracy:15.868263473053892  loss:3.053452253341675\n",
      "Worker15 accuracy:12.5  loss:4.213351249694824\n",
      "Worker16 accuracy:37.04752911551778  loss:2.212414264678955\n",
      "Worker17 accuracy:19.23076923076923  loss:3.3681042194366455\n",
      "Worker18 accuracy:22.972972972972972  loss:3.1939125061035156\n",
      "Worker19 accuracy:35.049239033124444  loss:2.3477912743886313\n",
      "Worker20 accuracy:0.0  loss:4.539947986602783\n"
     ]
    }
   ],
   "source": [
    "acc_test = []\n",
    "loss_test = []\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "    worker.model = worker.model.to(args.device)\n",
    "    acc_tmp,loss_tmp = test(worker.model,args.criterion,worker.testloader)\n",
    "    acc_test.append(acc_tmp)\n",
    "    loss_test.append(loss_tmp)\n",
    "    print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    worker.model = worker.model.to('cpu')\n",
    "    \n",
    "end = time.time()#終了時刻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推論時間：10.104694128036499秒\n"
     ]
    }
   ],
   "source": [
    "print('推論時間：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation  loss:3.356172227859497  accuracy:17.844310603575472\n",
      "Test  loss:3.276311029139019  accuracy:19.708129094217433\n"
     ]
    }
   ],
   "source": [
    "acc_valid_avg = sum(acc_valid)/len(acc_valid)\n",
    "loss_valid_avg = sum(loss_valid)/len(loss_valid)\n",
    "print('Validation  loss:{}  accuracy:{}'.format(loss_valid_avg,acc_valid_avg))\n",
    "\n",
    "acc_test_avg = sum(acc_test)/len(acc_test)\n",
    "loss_test_avg = sum(loss_test)/len(loss_test)\n",
    "print('Test  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FedAvg_femnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
